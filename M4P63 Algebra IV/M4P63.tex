\def\module{M4P63 Algebra IV}
\def\lecturer{Dr John Britnell}
\def\term{Spring 2020}
\def\cover{
$$
\begin{tikzcd}[ampersand replacement=\&, column sep=small]
\& 0 \arrow{d} \& \vdots \& 0 \arrow{d} \& \vdots \& 0 \arrow{d} \& \vdots \& \& \\
0 \arrow{r} \& \Ker d_n^A \arrow{rr} \arrow{dr} \& \& \Ker d_n^B \arrow{rr} \arrow{dr} \& \& \Ker d_n^C \arrow{dr} \& \& \& \\
\& 0 \arrow{r} \& A_{n + 1} \arrow[from=uu, crossing over]{} \arrow[near start]{rr}{f_{n + 1}} \& \& B_{n + 1} \arrow[from=uu, crossing over]{} \arrow[near start]{rr}{g_{n + 1}} \& \& C_{n + 1} \arrow[from=uu, crossing over]{} \arrow{r} \& 0 \& \\
\& 0 \arrow{d} \& \& 0 \arrow{d} \& \& 0 \arrow{d} \& \& \& \\
0 \arrow{r} \& \Ker d_{n - 1}^A \arrow{rr} \arrow{dr} \& \& \Ker d_{n - 1}^B \arrow{rr} \arrow{dr} \& \& \Ker d_{n - 1}^C \arrow{dr} \& \& \& \\
\& 0 \arrow{r} \& A_n \arrow[from=uuu, crossing over, near start, swap]{}{d_n^A} \arrow[near end, swap]{rr}{f_n} \arrow{dr} \arrow[near end]{ddd}{d_{n - 1}^A} \& \& B_n \arrow[from=uuu, crossing over, near start, swap]{}{d_n^B} \arrow[near start]{rr}{g_n} \arrow{dr} \arrow[near end]{ddd}{d_{n - 1}^B} \& \& C_n \arrow[from=uuu, crossing over, near start, swap]{}{d_n^C} \arrow{r} \arrow{dr} \arrow[near end]{ddd}{d_{n - 1}^C} \& 0 \& \\
\& \& \& \Coker d_n^A \arrow[from=uuuuurr, crossing over, in=195, out=15]{} \arrow[crossing over]{rr} \arrow{d} \& \& \Coker d_n^B \arrow[crossing over]{rr} \arrow{d} \& \& \Coker d_n^C \arrow{r} \arrow{d} \& 0 \\
\& \& \& 0 \& \& 0 \& \& 0 \& \\
\& 0 \arrow{r} \& A_{n - 1} \arrow[near end, swap]{rr}{f_{n - 1}} \arrow{dr} \arrow{dd} \& \& B_{n - 1} \arrow[near end, swap]{rr}{g_{n - 1}} \arrow{dr} \arrow{dd} \& \& C_{n - 1} \arrow{r} \arrow{dr} \arrow{dd} \& 0 \& \\
\& \& \& \Coker d_{n - 1}^A \arrow[from=uuuuurr, crossing over, in=195, out=15]{} \arrow[crossing over]{rr} \arrow{d} \& \& \Coker d_{n - 1}^B \arrow[crossing over]{rr} \arrow{d} \& \& \Coker d_{n - 1}^C \arrow{r} \arrow{d} \& 0 \\
\& \& \vdots \& 0 \& \vdots \& 0 \& \vdots \& 0 \& \\
\end{tikzcd}
$$
}
\def\syllabus{Exact sequences. Hom and tensor product. Projective and free modules. Injective and divisible modules. Torsion-free and flat modules. Projective and injective resolutions. Chain and cochain complexes. Homology and cohomology. Derived functors. Tor and torsion. Ext and extensions. Global dimension.}
\def\thm{section}

\input{../style/header}

\begin{document}

\input{../style/cover}

\setcounter{section}{0}

\section{Modules over a ring}

\lecture{1}{Friday}{10/01/20}

Let $ R $ be an \textbf{associative ring with unity}, that is an abelian group written additively with a multiplication which is associative but not necessarily commutative, with an identity $ 1 $ and distributive laws $ a\br{b + c} = ab + ac $ and $ \br{a + b}c = ac + bc $. Then
$$ R^* = \cbr{r \in R \st \exists s \in R, \ rs = 1 = sr} $$
is the unit group of $ R $. If $ R^* = R \setminus \cbr{0} $ then $ R $ is a \textbf{division ring}, or a \textbf{skew field}. In the case that $ R $ is commutative, $ R $ is a \textbf{field}.

\begin{example*}
\hfill
\begin{itemize}
\item Fields $ \CC $, $ \RR $, $ \QQ $, and $ \FF_q $, the field with $ q = p^a $ elements with $ p $ a prime and $ a \ge 1 $.
\item Skew fields $ \HH = \cbr{a + bi + cj + dk \st a, b, c, d \in \RR} $ where $ i^2 = j^2 = k^2 = ijk = -1 $.
\item Other rings are polynomial rings $ k\sbr{x} $ for $ k $ a field, more generally $ k\sbr{x_1, \dots, x_p} $, and $ \Mat_n k $, the $ n \times n $ matrices with entries from $ k $, a field.
\end{itemize}
\end{example*}

\subsection{Modules over rings}

\begin{definition}
Let $ R $ be a ring. A \textbf{left $ R $-module} is an abelian group $ M $, written additively, together with a function $ * : R \times M \to M $ satisfying
$$ r * \br{m_1 + m_2} = r * m_1 + r * m_2, \qquad \br{r_1 + r_2} * m = r_1 * m + r_2 * m, \qquad \br{r_1r_2} * m = r_1 * \br{r_2 * m}, \qquad 1 * m = m. $$
\end{definition}

We write $ rm $ for $ r * m $.

\begin{example*}
\hfill
\begin{itemize}
\item $ R $ is itself a left $ R $-module, with $ * $ as ring multiplication. More generally, let $ I $ be a left ideal of $ R $, so $ I $ is an additive subgroup, and $ rI \le I $ for all $ r \in R $. Then $ I $ is an $ R $-module with $ * $ as ring multiplication.
\item Let $ k $ be a field. Then any vector space over $ k $ is a $ k $-module, and vice versa.
\item Any abelian group is a $ \ZZ $-module, with $ * $ defined by $ na = a + \dots + a $ for $ n \in \ZZ^+ $ and $ a \in A $, and $ \br{-n}a = -\br{na} $.
\item Let $ k $ be a field. Let $ k^n $ be column vectors. Then $ k^n $ is a left $ \Mat_n k $-module, with $ * $ as the usual matrix-vector multiplication.
\item Let $ M \in \Mat_n k $. Then we can define a left $ k\sbr{x} $-module structure on $ k^* $ by letting $ x $ act as $ M $ on $ k^* $. So $ \br{x^2 + 3x - 2} * v = M^2v + 3Mv - 2v $.
\item Let $ G $ be a group. Any representation of $ G $ over the field $ k $ is a left module for $ k\sbr{G} $, the \textbf{group algebra}, a vector space over $ k $ with elements of $ G $ as a basis, with multiplication derived from that of $ G $.
\end{itemize}
\end{example*}

\begin{definition}
A \textbf{right $ R $-module} is defined similarly, with the $ R $-multiplication on the right, so $ M $ an abelian group under $ + $, and a map $ M \times R \to M $ satisfying
$$ \br{m_1 + m_2} * r = m_1 * r + m_2 * r, \qquad m * \br{r_1 + r_2} = m * r_1 + m * r_2, \qquad m * \br{r_1r_2} = \br{m * r_1} * r_2, \qquad m * 1 = m. $$
\end{definition}

Left and right modules are not quite the same. If we amend this definition by putting the ring multiplication on the left, the third axiom becomes $ \br{r_1r_2}m = r_2\br{r_1m} $. But in a left module, we have $ \br{r_1r_2}m = r_1\br{r_2m} $.

\begin{definition}
Let $ R $ be a ring. The \textbf{opposite ring} $ R^{\op} $ is $ R $ with a redefined multiplication $ r *_{R^{\op}} s = s *_R r $.
\end{definition}

It is easy to see that a left $ R $-module is the same as a right $ R^{\op} $-module and vice versa. If $ R $ is commutative then $ R = R^{\op} $.

\begin{exercise*}
Show that $ \Mat_n k \cong \Mat_n k^{\op} $.
\end{exercise*}

Except where otherwise stated, $ R $-modules are assumed to be left $ R $-modules.

\pagebreak

\subsection{Homomorphisms and submodules}

\begin{definition}
Let $ M_1 $ and $ M_2 $ be $ R $-modules. A map $ f : M_1 \to M_2 $ is an \textbf{$ R $-module homomorphism} if
\begin{itemize}
\item $ f $ is a group homomorphism, with respect to the $ + $ operation, and
\item $ f\br{rm} = rf\br{m} $, for $ r \in R $ and $ m \in M $.
\end{itemize}
If $ f $ is bijective, then it is an \textbf{$ R $-module isomorphism}.
\end{definition}

\begin{definition}
An additive subgroup $ L \le M $ is a \textbf{submodule} if $ rL \le L $ for $ r \in R $. In this case we automatically get an $ R $-module structure on the quotient $ M / L $ with multiplication given by $ r\br{m + L} = rm + L $.
\end{definition}

\begin{theorem}[First isomorphism theorem]
Let $ f : M_1 \to M_2 $ be an $ R $-module homomorphism. Then
$$ \Im f \le M_2, \qquad \Ker f \le M_1, \qquad \Im f \cong M / \Ker f. $$
\end{theorem}

The other isomorphism theorems have $ R $-module versions too.

\subsection{Direct products and direct sums}

\lecture{2}{Monday}{13/01/20}

Let $ S $ be a set. We have a collection of $ R $-modules $ \br{M_s}_S $ indexed by $ S $.

\begin{definition}
The \textbf{direct product} is
$$ \prod_{s \in S} M_s = \cbr{\br{m_s}_S \st m_s \in M_s}, $$
with coordinate-wise addition and $ R $-multiplication, so
$$ \br{m_s}_S + \br{n_s}_S = \br{m_s + n_s}_S, \qquad r\br{m_s}_S = \br{rm_s}_S. $$
If $ M_s = M $ for all $ s \in S $, then we write $ M^S $ for $ \prod_{s \in S} M_s $.
\end{definition}

\begin{definition}
The \textbf{direct sum} is
$$ \bigoplus_{s \in S} M_s = \cbr{\br{m_s}_S \st \text{all but finitely many coordinates} \ m_s \ \text{are zero}} \le \prod_{s \in S} M_s. $$
\end{definition}

If $ S $ is finite then the direct product and the direct sum are equal.

\begin{example*}
Let $ M = \ZZ_2 $, as a $ \ZZ $-module, and let $ S = \NN $. Then $ \bigoplus_{s \in \NN} \ZZ_2 $ is a countable $ \ZZ $-module but $ \prod_{s \in \NN} \ZZ_2 = \ZZ_2^\NN $ is uncountable.
\end{example*}

When $ \abs{S} = 2 $, generally we write $ M_1 \oplus M_2 $ for the direct sum or product. There are natural injective maps
$$ \function[\iota_A]{A}{A \oplus B}{a}{\br{a, 0}}, \qquad \function[\iota_B]{B}{A \oplus B}{b}{\br{0, b}}, $$
and surjective maps
$$ \function[\pi_A]{A \oplus B}{A}{\br{a, b}}{a}, \qquad \function[\pi_B]{A \oplus B}{B}{\br{a, b}}{b}. $$

\subsection{Exact sequences}

\begin{definition}
Suppose we have a sequence of $ R $-modules
$$ \dots \xrightarrow{f_{n - 1}} M_n \xrightarrow{f_n} M_{n + 1} \xrightarrow{f_{n + 1}} \dots, $$
with maps $ f_n : M_n \to M_{n + 1} $. Say the sequence is \textbf{exact at $ M_n $} if
$$ \Im f_{n - 1} = \Ker f_n. $$
The sequence is \textbf{exact} if it is exact everywhere. A \textbf{short exact sequence} is an exact sequence
$$ 0 \to A \xrightarrow{\alpha} B \xrightarrow{\beta} C \to 0. $$
\end{definition}

\begin{note*}
$ \alpha $ is injective and $ \beta $ is surjective.
\end{note*}

\pagebreak

The first isomorphism theorem implies that $ B / \Im \alpha \cong C $, where $ \Im \alpha \cong A $. An easy case is
$$ B \cong A \oplus C, $$
with $ \Im \alpha = \Im \iota_A = A \oplus 0 $ and $ \Im \beta = \Im \pi_\beta = C $. We say that the short exact sequence \textbf{splits} in this case.

\begin{example*}
A non-split short exact sequence of $ \ZZ $-modules, or abelian groups, is
$$ 0 \to \ZZ / 2\ZZ \to \ZZ / 4\ZZ \to \ZZ / 2\ZZ \to 0. $$
\end{example*}

\begin{proposition}
A short exact sequence
$$ 0 \to A \xrightarrow{\alpha} B \xrightarrow{\beta} C \to 0 $$
is split if and only if there exists an $ R $-module homomorphism $ \sigma : C \to B $ such that $ \beta \circ \sigma = \id_C $.
\end{proposition}

Such a $ \sigma $ is called a \textbf{section} of $ \beta $.

\begin{proof}
\hfill
\begin{itemize}
\item[$ \implies $] Suppose that the short exact sequence is split. So assume $ B = A \oplus C $, with $ \alpha = \iota_A $ and $ \beta = \pi_C $. Now $ \iota_C $ is a section for $ \beta $.
\item[$ \impliedby $] For the converse, suppose that $ \sigma $ is a section for $ \beta $. We want $ f : A \oplus C \xrightarrow{\sim} B $ such that $ f \circ \iota_A = \alpha $ and $ \beta \circ f = \pi_C $, so
$$
\begin{tikzcd}[row sep=tiny]
& & A \oplus C \arrow{dr}{\pi_C} \arrow{dd}{f} & & \\
0 \arrow{r} & A \arrow{ur}{\iota_A} \arrow[swap]{dr}{\alpha} & & C \arrow{r} & 0 \\
& & B \arrow[swap]{ur}{\beta} & &
\end{tikzcd}.
$$
Define
$$ \function[f]{A \times C}{B}{\br{a, c}}{\alpha\br{a} + \sigma\br{c}}. $$
Need to check the following.
\begin{itemize}
\item $ f $ is an $ R $-module homomorphism. \footnote{Exercise}
\item $ f $ is injective. Suppose $ f\br{a, c} = 0 $. Then $ \alpha\br{a} + \sigma\br{c} = 0 $. Now $ \alpha\br{a} \in \Im \alpha = \Ker \beta $, so $ \beta\br{\alpha\br{a} + \sigma\br{c}} = \beta\br{\sigma\br{c}} = c $. Since $ \alpha\br{a} + \sigma\br{c} = 0 $, we have $ c = 0 $. Hence $ \alpha\br{a} = 0 $, and so $ a = 0 $ since $ \alpha $ is injective. We have shown that $ f $ is injective.
\item $ f $ is surjective. Let $ b \in B $. Let $ c = \beta\br{b} $. We have $ \br{\beta \circ \sigma}\br{c} = c = \beta\br{b} $, so $ b - \sigma\br{c} \in \Ker \beta = \Im \alpha $. So there exists $ a \in A $ with $ \alpha\br{a} = b - \sigma\br{c} $. Then $ b = \alpha\br{a} + \sigma\br{c} = f\br{a, c} $.
\item $ f \circ \iota_A = \alpha $ and $ \beta \circ f = \pi_C $. Immediate from the construction of $ f $.
\end{itemize}
\end{itemize}
\end{proof}

\begin{proposition}
The short exact sequence
$$ 0 \to A \xrightarrow{\alpha} B \xrightarrow{\beta} C \to 0 $$
is split if and only if there exists $ \rho : B \to A $ such that $ \rho \circ \alpha = \id_A $.
\end{proposition}

Such a $ \rho $ is a \textbf{retraction} of $ \alpha $.

\begin{proof}
\hfill
\begin{itemize}
\item[$ \implies $] Once again, if the short exact sequence is split then the existence of $ \rho $ is clear.
\item[$ \impliedby $] Suppose that $ \rho $ is a retraction for $ \alpha $. We define $ f : B \xrightarrow{\sim} A \oplus C $ such that $ f \circ \alpha = \iota_A $ and $ \pi_C \circ f = \beta $. Do this by
$$ \function[g]{B}{A \oplus C}{b}{\br{\rho\br{a}, \beta\br{c}}}. $$
\end{itemize}
\end{proof}

\pagebreak

\section{Projective and injective modules}

\subsection{Projective modules}

\lecture{3}{Tuesday}{14/01/20}

\begin{definition}
An $ R $-module $ M $ is \textbf{projective} if any surjective map $ \beta : B \to M $ has a section. In other words, any short exact sequence
$$ 0 \to A \to B \to M \to 0 $$
splits.
\end{definition}

\begin{example*}
The $ R $-module $ R $ is projective. Let
$$ 0 \to A \to B \xrightarrow{\beta} R \to 0 $$
be a short exact sequence. Since $ \beta $ is surjective, there exists $ b \in B $ such that $ \beta\br{b} = 1 $. Now for all $ r \in R $, $ \beta\br{rb} = r $. Now define
$$ \function[\sigma]{R}{B}{r}{rb}. $$
Then $ \sigma $ is a section for $ \beta $.
\end{example*}

\begin{proposition}
An $ R $-module $ M $ is projective if and only if whenever $ \beta : B \to C $ is surjective, and $ f : M \to C $, there exists $ g : M \to B $ such that $ f = \beta \circ g $, so
$$
\begin{tikzcd}[row sep=small]
& & & M \arrow[dashed, swap]{dl}{g} \arrow{d}{f} & \\
0 \arrow{r} & A \arrow{r} & B \arrow[swap]{r}{\beta} & C \arrow{r} & 0
\end{tikzcd}.
$$
\end{proposition}

Such a $ g $ is called a \textbf{lift} of $ f $.

\begin{proof}
\hfill
\begin{itemize}
\item[$ \impliedby $] Suppose that whenever $ \beta : B \to C $ is surjective and $ f : M \to C $ then there exists $ g : M \to B $ with $ f = \beta \circ g $. Suppose $ \beta : B \to M $ is a surjective map. Define $ f : M \to M $ to be $ \id_M $. Then there exists $ g : M \to B $ such that $ f = \beta \circ g $, so $ \id_M = \beta \circ g $. So $ g $ is a section for $ \beta $, and so $ M $ is projective.
\item[$ \implies $] For the converse, suppose $ \beta : B \to C $ is surjective, and $ f : M \to C $. We construct a module $ X $ to complete a commuting square
$$
\begin{tikzcd}
X \arrow{r}{\epsilon} \arrow[swap]{d}{\delta} & M \arrow{d}{f} \\
B \arrow[swap]{r}{\beta} & C
\end{tikzcd}.
$$
Let $ X $ be the submodule of $ B \oplus M $ defined by
$$ X = \cbr{\br{b, m} \st \beta\br{b} = f\br{m}}. $$
The maps $ \delta $ and $ \epsilon $ are just $ \pi_B $ and $ \pi_M $ respectively, in their restrictions to $ X $. It is clear that $ X \le B \oplus M $, and that the square above commutes. Now suppose that $ M $ is projective. Since $ \beta $ is surjective, we see that for all $ m \in M $ there exists $ b \in B $ with $ \beta\br{b} = f\br{m} $. It follows that $ \epsilon : X \to M $ is surjective. So $ \epsilon $ has a section $ \sigma : M \to X $. Define $ g = \delta \circ \sigma : M \to B $, so
$$
\begin{tikzcd}
X \arrow[bend left=15]{r}{\epsilon} \arrow[swap]{d}{\delta} & M \arrow[bend left=15, dashed]{l}{\sigma} \arrow[dashed]{dl}{g} \arrow{d}{f} \\
B \arrow[swap]{r}{\beta} & C
\end{tikzcd}.
$$
Since $ \beta \circ \delta = f \circ \epsilon $, we have
$$ \br{\beta \circ g}\br{m} = \br{\beta \circ \delta \circ \sigma}\br{m} = \br{f \circ \epsilon \circ \sigma}\br{m} = \br{f \circ \id_M}\br{m} = f\br{m}, \qquad m \in M. $$
So $ \beta \circ g = f $ as required.
\end{itemize}
\end{proof}

\pagebreak

Such an $ X $ is the \textbf{pullback} of $ \beta $ and $ f $, and there is a short exact sequence
$$ 0 \to A \to X \to M \to 0. $$

\subsection{Free modules}

\begin{definition}
An $ R $-module $ M $ is \textbf{free} if $ M $ is a direct sum of copies of $ R $, so
$$ M = \bigoplus_{s \in S} R. $$
A \textbf{basis} for a module $ M $ is a set $ T $ of elements such that every element $ m \in M $ has a unique expression as
$$ m = \sum_{i = 1}^m r_it_i, \qquad r_i \in R, \qquad t_i \in T. $$
\end{definition}

If $ M = \bigoplus_{s \in S} R $, then $ M $ has a basis consisting of elements with exactly one coordinate one, and the rest zero. On the other hand, if $ M $ has a basis $ T $ then it is straightforward to show that $ M \cong \bigoplus_{t \in T} R $.

\begin{proposition}
Let $ F $ be a free $ R $-module with basis $ T $. Let $ M $ be some $ R $-module, and let $ \psi : T \to M $ be a set map. Then $ \psi $ extends uniquely to an $ R $-module homomorphism $ \psi : F \to M $.
\end{proposition}

\begin{proof}
Each element of $ F $ has a unique expression as $ \sum_i r_it_i $ for $ r_i \in R $ and $ t_i \in T $. Now define
$$ \function[\psi]{F}{M}{\sum_i r_it_i}{\sum_i r_i\psi\br{t_i}}. $$
It is easy to check that this respects $ + $ and $ R $-multiplication.
\end{proof}

\begin{proposition}
A module $ M $ is projective if and only if there exists $ N $ such that $ M \oplus N $ is free, so projective modules are direct summands of free modules.
\end{proposition}

\begin{proof}
\hfill
\begin{itemize}
\item[$ \implies $] Suppose $ M $ is projective. Let $ F $ be the free module with basis $ \cbr{b_m \st m \in M} $. Now the map $ b_m \mapsto m $ extends to an $ R $-module homomorphism $ F \to M $, which is clearly surjective. Then if $ K = \Ker \psi $, we have a short exact sequence
$$ 0 \to K \to F \xrightarrow{\psi} M \to 0. $$
Since $ M $ is projective, there is a section $ \sigma $ for $ \psi $, and so the short exact sequence splits, and $ F \cong K \oplus M $.

\lecture{4}{Friday}{17/01/20}

\item[$ \impliedby $] Suppose that $ M \oplus N = F $, a free module with basis $ T $. Suppose $ \beta : B \to C $ is surjective, and that $ f : M \to C $. Note that $ f \circ \pi_M : F \to C $. For each $ t \in T $, let $ b_t \in B $ be such that $ \beta\br{b_t} = \br{f \circ \pi_M}\br{t} $. The set map
$$ \function{T}{B}{t}{b_t} $$
extends to a homomorphism $ \widehat{g} : F \to B $. Now define $ g : M \to B $ by $ g = \widehat{g} \circ \iota_M $. We need to show $ f = \beta \circ g $. Take $ m \in M $. Then $ \iota_M\br{m} = \br{m, 0} \in F $ can be written as $ \sum_i r_it_i $, where $ t_i \in T $ and $ r_i \in R $. Applying $ \pi_M $, $ m = \sum_i r_im_{t_i} $. Then
$$ g\br{m} = \br{\widehat{g} \circ \iota_M}\br{m} = \widehat{g}\br{\sum_i r_it_i} = \sum_i r_ib_{t_i}. $$
So
$$ \br{\beta \circ g}\br{m} = \beta\br{\sum_i r_ib_{t_i}} = \sum_i r_i\beta\br{b_{t_i}} = \sum_i r_if\br{m_{t_i}} = f\br{\sum_i r_im_{t_i}} = f\br{m}. $$
Hence $ \beta \circ g = f $. So $ M $ is projective.
\end{itemize}
\end{proof}

\pagebreak

\subsection{Injective modules}

\begin{definition}
Let $ M $ be an $ R $-module. Then $ M $ is \textbf{injective} if whenever $ \alpha : M \to B $ is an injective map, it has a retraction $ \rho : B \to M $, so $ \rho \circ \alpha = \id_M $. Equivalently, every short exact sequence
$$ 0 \to M \to B \to C \to 0 $$
splits.
\end{definition}

\begin{example*}
Let $ k $ be a field. Then $ k $-modules are vector spaces. Every $ k $-module is injective. Suppose $ M $ and $ N $ are $ k $-vector spaces and $ \alpha : M \to N $ is a injective map. Then $ \Im \alpha $ is a submodule, or subspace, of $ N $. Take a basis for $ \Im \alpha $, and extend to a basis for $ N $. The basis vectors not in $ \Im \alpha $ form a basis for a complementary subspace $ U $, so $ N = \Im \alpha \oplus U $. Now $ \pi_{\Im \alpha} $ is surjective, and $ \alpha : M \to \Im \alpha $ is an isomorphism. This gives a retraction $ N \to M $.
\end{example*}

If $ R $ is a general ring, the module $ R $ need not be injective.

\begin{example*}
Let $ R = \ZZ $. Then $ R $-modules are abelian groups. There exists an injective $ \alpha : \ZZ \to \QQ $. But $ \ZZ $ is not a quotient of $ \QQ $, \footnote{Exercise} so no retraction exists for $ \alpha $.
\end{example*}

\begin{proposition}
An $ R $-module $ M $ is injective if and only if whenever $ \alpha : A \to B $ is injective, and $ f : A \to M $, there exists $ g : B \to M $ such that $ f = g \circ \alpha $.
\end{proposition}

\begin{proof}
\hfill
\begin{itemize}
\item[$ \impliedby $] Suppose that whenever $ \alpha : A \to B $ is injective, and $ f : A \to M $, there exists $ g : B \to M $ such that $ f = g \circ \alpha $. Suppose that $ \alpha : M \to B $ is injective. We have a map $ M \to M $, namely $ \id_M $. There exists $ g : B \to M $ such that $ \id_M = g \circ \alpha $. So $ g $ is a retraction for $ \alpha $, and so $ M $ is injective.
\item[$ \implies $] For the converse, suppose $ \alpha : A \to B $ is injective, and $ M $ is an injective module, with $ f : A \to M $. We define a module $ Y $ completing a square
$$
\begin{tikzcd}
A \arrow{r}{\alpha} \arrow[swap]{d}{f} & B \arrow{d}{\delta} \\
M \arrow[swap]{r}{\epsilon} & Y
\end{tikzcd},
$$
with $ \epsilon \circ f = \delta \circ \alpha $. Let $ Y $ be a quotient of $ B \oplus M $, by the kernel
$$ K = \cbr{\br{\alpha\br{a}, -f\br{a}} \st a \in A}. $$
Let $ \gamma : B \oplus M \to \br{B \oplus M} / K $ be the canonical quotient map. Then we define $ \delta = \gamma \circ \iota_B $ and $ \epsilon = \gamma \circ \iota_M $. By construction, we have
\begin{align*}
\br{\epsilon \circ f}\br{a}
& = \br{\gamma \circ \iota_M \circ f}\br{a}
= \gamma\br{0, f\br{a}}
= \br{0, f\br{a}} + K \\
& = \br{\alpha\br{a}, 0} + K
= \gamma\br{\alpha\br{a}, 0}
= \br{\gamma \circ \iota_B \circ \alpha}\br{a}
= \br{\delta \circ \alpha}\br{a}.
\end{align*}
Hence $ \epsilon \circ f = \delta \circ \alpha $. Claim that $ \epsilon $ is injective. Suppose $ \epsilon\br{m} = 0 $. Then $ \iota_M\br{m} \in K $, so $ \br{0, m} = \br{\alpha\br{a}, -f\br{a}} $ for some $ a \in A $. But $ \alpha\br{a} = 0 $ implies that $ a = 0 $, and so $ m = -f\br{0} = 0 $. Since $ M $ is injective, $ \epsilon $ has a retraction $ \rho : Y \to M $. Define $ g : B \to M $ by $ g = \rho \circ \delta $, so
$$
\begin{tikzcd}
A \arrow{r}{\alpha} \arrow[swap]{d}{f} & B \arrow[dashed, swap]{dl}{g} \arrow{d}{\delta} \\
M \arrow[bend right=15, swap]{r}{\epsilon} & Y \arrow[bend right=15, dashed, swap]{l}{\rho}
\end{tikzcd},
$$
We know that $ \br{\epsilon \circ f}\br{a} = \br{\delta \circ \alpha}\br{a} $ for all $ a \in A $. So
$$ f\br{a} = \br{\id_M \circ f}\br{a} = \br{\rho \circ \epsilon \circ f}\br{a} = \br{\rho \circ \delta \circ \alpha}\br{a} = \br{g \circ \alpha}\br{a}, $$
so $ f = g \circ \alpha $ as required.
\end{itemize}
\end{proof}

\pagebreak

We know that projectives are direct summands of free modules. We might hope for a dual version of this for injective modules. But there is no straightforward way of doing this.

\lecture{5}{Monday}{20/01/20}

\begin{proposition}[Baer's criterion for injectivity]
Let $ M $ be an $ R $-module. Then $ M $ is injective if and only if every $ R $-module map $ f : I \to M $, where $ I $ is a left ideal of $ R $, has the form $ f\br{x} = xm $ for some $ m \in M $. Equivalently, every map $ I \to M $ extends to a map $ R \to M $.
\end{proposition}

Why are these two conditions equivalent? If $ f\br{x} = xm $ for $ x \in I $, then we can extend $ f $ to $ R $ by $ f\br{r} = rm $. Conversely, suppose that $ f : I \to M $ extends to $ f^+ : R \to M $. Let $ m = f^+\br{1} $. Then for all $ r \in R $, $ f^+\br{r} = rm $, and so $ f\br{x} = xm $ for $ x \in I $. The proof requires Zorn's lemma.

\begin{lemma}[Zorn's lemma]
Let $ X $ be a non-empty set, partially ordered by $ \le $. If every chain, or totally ordered subset, in $ X $ has an upper bound in $ X $, then $ X $ has a maximal element.
\end{lemma}

\begin{proof}
\hfill
\begin{itemize}
\item[$ \impliedby $] Suppose $ \alpha : A \to B $, where $ \alpha $ is injective. Suppose $ f : A \to M $. We want to show there exists $ g : B \to M $ such that $ f = g \circ \alpha $. We have $ \Im \alpha \le B $. Define
$$ X = \cbr{\br{L, h} \st \Im \alpha \le L \le B, \ h : L \to M, \ f = h \circ \alpha}. $$
Note that $ X \ne \emptyset $ since $ \br{\Im \alpha, f \circ \alpha^{-1}} $ is in it. Define $ \le $ on $ X $ by $ \br{L_1, h_1} \le \br{L_2, h_2} $ if $ L_1 \le L_2 $ and $ h_2 $ extends $ h_1 $, so $ \eval{h_2}_{L_1} = h_1 $. Suppose $ \cbr{\br{L_s, h_s} \st s \in S} $ is a chain in $ X $. Set $ L = \bigcup_{s \in S} L_s $. Then $ \Im \alpha \le L \le B $. Define
$$ \function[h]{L}{M}{l}{h_s\br{l}}, \qquad l \in L_s. $$
This does not depend on the choice of $ s $. Then $ \br{L, h} $ is an upper bound for the chain $ \cbr{\br{L_s, h_s} \st s \in S} $. Hence $ X $ has a maximal element, $ \br{L_0, h_0} $. We want to show that $ L_0 = B $. Then we may set $ g = h_0 $. Suppose that $ L_0 \ne B $. Let $ b \in B \setminus L_0 $. Note that $ Rb \le B $. Consider
$$ L_0 + Rb = \cbr{l + rb \st l \in L_0, \ r \in R} \le B. $$
We would like to extend $ h_0 $ to $ h_0^+ $ by specifying an image for $ h_0^+\br{b} $. The problem is that $ Rb \cap L_0 $ may not be $ \cbr{0} $, and if $ rb \in L_0 $ then we require $ rh_0^+\br{b} = h_0\br{rb} $, otherwise $ h_0^+ $ will not be well-defined. Note that $ I = \cbr{r \in R \st rb \in L_0} $ is a left ideal for $ R $. Suppose that $ M $ has the condition from Baer's criterion, so every map $ I \to M $ has the form $ x \mapsto xm $ for some $ m \in M $. Note that $ \cbr{xb \st x \in I} $ is a submodule of $ L_0 $. Define
$$ \function[\delta]{I}{M}{x}{h_0\br{xb}}. $$
This is an $ R $-module homomorphism. So $ \delta\br{x} = xm $ for some $ m \in M $. Hence $ h_0\br{xb} = xm $ for all $ x \in I $. So we can safely define $ h_0^+\br{b} = m $. Now $ \br{L_0 + Rb, h_0^+} \in X $, and $ \br{L_0, h_0} < \br{L_0 + Rb, h_0^+} $, which contradicts the maximality of $ \br{L_0, h_0} $. Hence $ L_0 = B $, and we are done.
\item[$ \implies $] The converse is left as an exercise. \footnote{Exercise}
\end{itemize}
\end{proof}

\begin{example*}
\hfill
\begin{itemize}
\item Suppose $ R $ is a field. Then the only ideals of $ R $ are zero and $ R $. Any map $ 0 \to M $, for $ M $ an $ R $-module, can be extended to the zero map $ R \to M $. Hence any $ R $-module is injective.
\item Let $ \ZZ $ be a module for itself. The ideals of $ \ZZ $ are $ k\ZZ $ for $ k \in \ZZ $. Define
$$ \function[f]{k\ZZ}{\ZZ}{km}{m}. $$
If $ k \ne 0, \pm 1 $, then $ f\br{k} = 1 $, and so $ f\br{x} \ne xm $ for $ m \in \ZZ $, since one is not divisible by $ k $ in $ \ZZ $. So Baer's criterion fails, and $ \ZZ $ is not injective. We already knew that $ \ZZ \to \QQ $ has no retraction.
\item $ \QQ $ is injective as a $ \ZZ $-module. Suppose we have a map $ f : k\ZZ \to \QQ $. Let $ q = f\br{k} $. Then $ f\br{kt} = qt = \br{q / k}kt $. So $ f\br{x} = x\br{q / k} $ for all $ x $, so $ \QQ $ satisfies Baer's criterion.
\end{itemize}
\end{example*}

\pagebreak

\section{Hom and tensor products}

\subsection{Hom}

\lecture{6}{Tuesday}{21/01/20}

Let $ A $ and $ B $ be two $ R $-modules.

\begin{definition}
Define
$$ \Hom_R\br{A, B} = \cbr{\text{$ R $-module homomorphisms} \ A \to B}. $$
\end{definition}

We can define a natural addition on $ \Hom_R\br{A, B} $ by defining $ f_1 + f_2 $ by
$$ \br{f_1 + f_2}\br{a} = f_1\br{a} + f_2\br{b}, \qquad f_1, f_2 \in \Hom_R\br{A, B}. $$
This gives $ \Hom_R\br{A, B} $ the structure of an abelian group. Why does $ \Hom_R\br{A, B} $ not carry an $ R $-module structure in general? The only obvious candidate for $ rf $ is
$$ \br{rf}\br{a} = rf\br{a} = f\br{ra}, \qquad r \in R, \qquad f \in \Hom_R\br{A, B}. $$
Now suppose $ s \in R $. We have $ \br{rf}\br{sa} = rf\br{sa} = rsf\br{a} $. But for $ rf $ to be a homomorphism, we would need $ \br{rf}\br{sa} = s\br{rf}\br{a} = srf\br{a} $. If $ R $ is non-commutative, then $ rs $ may not be $ sr $, and so $ rf $ is not an $ R $-module homomorphism in general. Clearly, however, if $ R $ is commutative then $ rf $ is an $ R $-module homomorphism, and $ \Hom_R\br{A, B} $ has an $ R $-module structure. The following are observations.

\begin{proposition}
Suppose $ A, A_1, A_2, B, B_1, B_2, M $ are $ R $-modules, and $ \alpha : A \to B $.
\begin{itemize}
\item $ \Hom_R\br{A_1 \oplus A_2, B} \cong \Hom_R\br{A_1, B} \oplus \Hom_R\br{A_2, B} $.
\item $ \Hom_R\br{A, B_1 \oplus B_2} \cong \Hom_R\br{A, B_1} \oplus \Hom_R\br{A, B_2} $.
\item Then we can define
$$ \function[\alpha_*]{\Hom_R\br{M, A}}{\Hom_R\br{M, B}}{f}{\alpha \circ f}, \qquad f : M \to A. $$
\item We can also define
$$ \function[\alpha^*]{\Hom_R\br{B, M}}{\Hom_R\br{A, M}}{g}{g \circ \alpha}, \qquad g : B \to M. $$
\end{itemize}
\end{proposition}

Thus Hom is a bifunctor between the category of $ R $-modules and the category of abelian groups, additive in both arguments, covariant in the second argument and contravariant in the first argument.
\begin{itemize}
\item Bi means Hom takes two arguments.
\item Functor means that homomorphisms between $ R $-modules turn into abelian group homomorphisms.
\item Covariant means the homomorphism goes in the same direction.
\item Contravariant means the direction gets reversed.
\item Additive in both arguments means Hom respects direct sums.
\end{itemize}

\begin{proposition}
Suppose $ \alpha : A \to B $ is surjective. Then $ \alpha^* : \Hom_R\br{B, M} \to \Hom_R\br{A, M} $ is injective.
\end{proposition}

\begin{proof}
Suppose $ f_1, f_2 : B \to M $ are such that $ \alpha^*\br{f_1} = \alpha^*\br{f_2} $. Then $ f_1 \circ \alpha = f_2 \circ \alpha $, so $ \br{f_1 \circ \alpha}\br{a} = \br{f_2 \circ \alpha}\br{a} $ for all $ a \in A $. Let $ b \in B $. Then $ b = \alpha\br{a} $ for some $ a $, since $ \alpha $ is surjective, so $ f_1\br{b} = \br{f_1 \circ \alpha}\br{a} = \br{f_2 \circ \alpha}\br{a} = f_2\br{b} $, so $ f_1 = f_2 $.
\end{proof}

\begin{proposition}
Suppose $ \alpha : A \to B $ is injective. Then $ \alpha_* : \Hom_R\br{M, A} \to \Hom_R\br{M, B} $ is injective.
\end{proposition}

\begin{proof}
Suppose $ f_1, f_2 : M \to A $, and $ \alpha_*\br{f_1} = \alpha_*\br{f_2} $. Then $ \alpha \circ f_1 = \alpha \circ f_2 $, so $ \br{\alpha \circ f_1}\br{m} = \br{\alpha \circ f_2}\br{m} $ for all $ m \in M $. But $ \alpha $ is injective, so this implies $ f_1\br{m} = f_2\br{m} $ for all $ m \in M $.
\end{proof}

\pagebreak

\begin{proposition}
Suppose
$$ 0 \to A \xrightarrow{\alpha} B \xrightarrow{\beta} C \to 0 $$
is a short exact sequence of $ R $-modules. Then we have an exact sequence
$$ 0 \to \Hom_R\br{C, M} \xrightarrow{\beta^*} \Hom_R\br{B, M} \xrightarrow{\alpha^*} \Hom_R\br{A, M}. $$
\end{proposition}

\begin{proof}
This is exact at $ \Hom_R\br{C, M} $, since $ \beta^* $ is injective. Claim that the sequence is also exact at $ \Hom_R\br{B, M} $, so it is an exact sequence. It is not necessarily a short exact sequence since $ \alpha^* $ is not generally surjective. Let $ g : B \to M $. We have
$$ g \in \Ker \alpha^* \iff \alpha^*\br{g} = 0 \iff g \circ \alpha = 0 \iff g\br{\alpha\br{A}} = 0 \iff \Im \alpha \le \Ker g \iff \Ker \beta \le \Ker g, $$
Then $ g \in \Ker \alpha^* $ if and only if for all $ b_1, b_2 \in B $, $ \beta\br{b_1} = \beta\br{b_2} $ implies that $ g\br{b_1} = g\br{b_2} $, which is if and only if the map defined by
$$ \function[f]{C}{M}{c}{g\br{b}}, \qquad \beta\br{b} = c $$
is well-defined, since $ \beta $ is surjective, and $ f $ is an $ R $-module homomorphism. Thus
$$ g \in \Ker \alpha^* \qquad \iff \qquad \exists f \in \Hom_R\br{C, M}, \ \beta^*\br{f} = g \qquad \iff \qquad g \in \Im \beta^*. $$
Hence $ \Ker \alpha^* = \Im \beta^* $. So the sequence is exact at $ \Hom_R\br{B, M} $.
\end{proof}

\lecture{7}{Friday}{24/01/20}

\begin{example*}
These examples show that $ \alpha : A \to B $ is injective does not imply $ \alpha^* : \Hom_R\br{B, M} \to \Hom_R\br{A, M} $ is surjective.
\begin{itemize}
\item The inclusion $ \alpha : \ZZ \to \QQ $ is a $ \ZZ $-module homomorphism. Let $ M = \ZZ $. Then we get $ \alpha^* : \Hom_\ZZ\br{\QQ, \ZZ} \to \Hom_\ZZ\br{\ZZ, \ZZ} $. Then $ \alpha $ is injective, but $ \alpha^* $ is not surjective. Why is this? In fact $ \Hom_\ZZ\br{\QQ, \ZZ} = 0 $. Suppose
$$ \function[f]{\QQ}{\ZZ}{1}{k \ne 0}. $$
Suppose $ p \nmid k $. Then there is no possible image for $ 1 / p \in \QQ $, since we would require $ pf\br{1 / p} = f\br{1} = k $. But $ \Hom_\ZZ\br{\ZZ, \ZZ} \cong \ZZ $, so $ \alpha^* $ is not surjective.
\item Let $ \alpha : k\ZZ \to \ZZ $ be the inclusion, so $ \alpha $ is injective and not surjective. Let $ M = \ZZ $. So we get $ \alpha^* : \Hom_\ZZ\br{\ZZ, \ZZ} \to \Hom_\ZZ\br{k\ZZ, \ZZ} $. Suppose that $ g \in \Im \alpha^* $. Then $ g = f \circ \alpha $, where $ f : \ZZ \to \ZZ $. Then $ g\br{k} = f\br{k} = kf\br{1} $, so $ \Im g \le k\ZZ $. But there exists $ g \in \Hom_\ZZ\br{k\ZZ, \ZZ} $ such that $ g\br{k} = 1 $. So this $ g \notin \Im \alpha^* $, so $ \alpha^* $ is not surjective.
\end{itemize}
\end{example*}

\begin{proposition}
Let
$$ 0 \to A \xrightarrow{\alpha} B \xrightarrow{\beta} C \to 0 $$
be exact. Then
$$ 0 \to \Hom_R\br{M, A} \xrightarrow{\alpha_*} \Hom_R\br{M, B} \xrightarrow{\beta_*} \Hom_R\br{M, C} $$
is exact.
\end{proposition}

\begin{proof}
We already know that $ \alpha $ injective implies that $ \alpha_* $ is injective, so the sequence is exact at $ \Hom_R\br{M, A} $. We show that $ \Ker \beta_* = \Im \alpha_* $. Suppose $ g \in \Hom_R\br{M, B} $. Then
$$ g \in \Ker \beta_* \qquad \iff \qquad \br{\beta \circ g}\br{M} = 0 \qquad \iff \qquad \Im g \le \Ker \beta \qquad \iff \qquad \Im g \le \Im \alpha. $$
Note there exists $ \alpha^{-1} : \Im \alpha \to A $. If $ \Im g \le \Im \alpha $, then $ \alpha^{-1} \circ g : M \to A $. If $ f = \alpha^{-1} \circ g $, then $ \alpha \circ f = g $, so $ g \in \Im \alpha_* $. Conversely, if $ g \in \Im \alpha_* $, then $ g = \alpha \circ f $ for some $ f \in \Hom_R\br{M, A} $ and so $ \Im g \le \Im \alpha $. So
$$ g \in \Ker \beta_* \qquad \iff \qquad \Im g \le \Im \alpha \qquad \iff \qquad g \in \Im \alpha_*. $$
Hence $ \Ker \beta_* = \Im \alpha_* $. So the sequence is exact at $ \Hom_R\br{M, B} $.
\end{proof}

\pagebreak

\begin{example*}
These examples show that $ \beta : B \to C $ is surjective does not imply $ \beta_* : \Hom_R\br{M, B} \to \Hom_R\br{M, C} $ is surjective.
\begin{itemize}
\item Let
$$ \function[\beta]{\sum_{q \in \QQ} \ZZ}{\QQ}{e_q}{q}. $$
In general $ \beta : \sum_{m \in M} R \to M $ defined by mapping the basis vector $ e_m $ to $ m $, is a surjective homomorphism, so $ \beta $ is surjective. Let $ M = \QQ $. So we get $ \beta_* : \Hom_\ZZ\br{\QQ, \sum_{q \in \QQ} \ZZ} \to \Hom_\ZZ\br{\QQ, \QQ} $. Claim that $ \Hom_\ZZ\br{\QQ, \sum_{q \in \QQ} \ZZ} $ is trivial. Suppose $ f : \QQ \to \sum_{q \in \QQ} \ZZ $ is not zero. Suppose $ f\br{q_0} \ne 0 $. Then there exist $ q_1, \dots, q_t \in \QQ $ and $ a_1, \dots, a_t \in \ZZ $ such that $ f\br{q_0} = \sum_{i = 1}^t a_ie_{q_i} $. Now the projection of $ \sum_{q \in \QQ} \ZZ $ onto $ \ZZ e_{q_1} $ is a non-trivial $ \ZZ $-module homomorphism. But $ \ZZ e_{q_1} \cong \ZZ $, and so no non-trivial map $ \QQ \to \ZZ e_{q_1} $ exists. But $ \Hom_\ZZ\br{\QQ, \QQ} $ is not trivial, so $ \beta_* $ is not surjective.
\item Let
$$ 0 \to \ZZ_2 \to \ZZ_4 \to \ZZ_2 \to 0 $$
be a short exact sequence of $ \ZZ $-modules. Then we have
$$
\begin{tikzcd}[row sep=tiny]
0 \arrow{r} & \Hom_\ZZ\br{\ZZ_2, \ZZ_2} \arrow{r}{\alpha_*} \arrow[cong]{d} & \Hom_\ZZ\br{\ZZ_2, \ZZ_4} \arrow{r}{\beta_*} \arrow[cong]{d} & \Hom_\ZZ\br{\ZZ_2, \ZZ_2} \arrow[cong]{d} \\
& \ZZ_2 & \ZZ_2 & \ZZ_2
\end{tikzcd}.
$$
But there is no short exact sequence of abelian groups
$$ 0 \to \ZZ_2 \to \ZZ_2 \to \ZZ_2 \to 0, $$
and so $ \beta_* $ cannot be surjective.
\end{itemize}
\end{example*}

\begin{proposition}
Let $ M $ be an $ R $-module. Then $ M $ is injective if and only if for every injective map $ \alpha : A \to B $, we get $ \alpha^* : \Hom_R\br{B, M} \to \Hom_R\br{A, M} $ is surjective.
\end{proposition}

\begin{proof}
$ M $ is injective if and only if for all injective $ \alpha : A \to B $, for all $ f \in \Hom_R\br{A, M} $, there exists $ g \in \Hom_R\br{B, M} $ such that $ f = g \circ \alpha $, so $ f = \alpha^*\br{g} $. This is if and only if for all injective $ \alpha : A \to B $, $ f \in \Im \alpha^* $ for all $ f \in \Hom_R\br{A, M} $, which is if and only if $ \alpha^* $ is surjective.
\end{proof}

\begin{proposition}
Let $ M $ be an $ R $-module. Then $ M $ is projective if and only if whenever $ \beta : B \to C $ is surjective, the map $ \beta_* : \Hom_R\br{M, B} \to \Hom_R\br{M, C} $ is surjective.
\end{proposition}

\begin{proof}
$ M $ is projective if and only if whenever $ \beta : B \to C $ is surjective, and $ f \in \Hom_R\br{M, C} $, there exists $ g \in \Hom_R\br{M, B} $ such that $ f = \beta \circ g $. This is if and only if whenever $ \beta : B \to C $ is surjective, and $ f \in \Hom_R\br{M, C} $, then $ f \in \Im \beta_* $, which is if and only if $ \beta_* $ is surjective.
\end{proof}

\subsection{The snake lemma}

\lecture{8}{Monday}{27/01/20}

Let $ \alpha : A \to B $ be an $ R $-module homomorphism. The \textbf{cokernel} of $ \alpha $ is $ B / \Im \alpha $, written $ \Coker \alpha $. The sequence
$$ 0 \to \Ker \alpha \to A \xrightarrow{\alpha} B \to \Coker \alpha \to 0 $$
is exact.

\begin{lemma}[The snake lemma]
Suppose we have a commutative diagram
$$
\begin{tikzcd}
& A \arrow{r}{\alpha} \arrow{d}{f} & B \arrow{r}{\beta} \arrow{d}{g} & C \arrow{r} \arrow{d}{h} & 0 \\
0 \arrow{r} & X \arrow[swap]{r}{\phi} & Y \arrow[swap]{r}{\psi} & Z &
\end{tikzcd},
$$
where the rows are exact. Then we obtain an exact sequence
$$ \Ker f \xrightarrow{\alpha} \Ker g \xrightarrow{\beta} \Ker h \xrightarrow{\delta} \Coker f \xrightarrow{\overline{\phi}} \Coker g \xrightarrow{\overline{\psi}} \Coker h. $$
\end{lemma}

\pagebreak

\begin{proof}
\hfill
\begin{itemize}
\item The maps $ \alpha : \Ker f \to \Ker g $ and $ \beta : \Ker g \to \Ker h $ are obtained simply by restricting $ \alpha $ and $ \beta $ respectively. Observe that if $ a \in \Ker f $ then $ f\br{a} = 0 $, so $ \br{\phi \circ f}\br{a} = 0 $. But $ \phi \circ f = g \circ \alpha $, and so $ \br{g \circ \alpha}\br{a} = 0 $, so $ \alpha\br{a} \in \Ker g $, which is what we wanted.
\item The maps $ \overline{\phi} : \Coker f \to \Coker g $ and $ \overline{\psi} : \Coker g \to \Coker h $ are induced from $ \phi $ and $ \psi $ by
$$ \overline{\phi}\br{x + \Im f} = \phi\br{x} + \Im g, \qquad \overline{\psi}\br{y + \Im g} = \psi\br{g} + \Im h. $$
Check that these maps make sense. Suppose $ x_1 + \Im f = x_2 + \Im f $. Then $ x_1 - x_2 \in \Im f $, so there exists $ a \in A $ such that $ f\br{a} = x_1 - x_2 $. Now
$$ \phi\br{x_1} - \phi\br{x_2} = \phi\br{x_1 - x_2} = \br{\phi \circ f}\br{a} = \br{g \circ \alpha}\br{a} \in \Im g. $$
So $ \phi\br{x_1} + \Im g = \phi\br{x_2} + \Im g $. So $ \overline{\phi} $ is well-defined, and $ \overline{\psi} $ is shown to be well-defined by a similar argument.
\item How is the \textbf{connecting homomorphism} $ \delta $ defined? Since $ \beta $ is surjective, for all $ c \in C $, there exists $ b \in B $ with $ \beta\br{b} = c $. Suppose $ c \in \Ker h $. Then $ \br{h \circ \beta}\br{b} = 0 $, so $ \br{\psi \circ g}\br{b} = 0 $. Hence $ g\br{b} \in \Ker \psi = \Im \phi $. Define
$$ \delta\br{c} = x + \Im f, \qquad \phi\br{x} = g\br{b}, \qquad \beta\br{b} = c. $$
Check this is well-defined. Suppose $ b_1, b_2, x_1, x_2 $ are such that $ \phi\br{x_1} = g\br{b_1} $ and $ \phi\br{x_2} = g\br{b_2} $, and $ \beta\br{b_1} = \beta\br{b_2} = c $. We have $ b_1 - b_2 \in \Ker \beta = \Im \alpha $. So $ b_1 - b_2 = \alpha\br{a} $ for some $ a \in A $. Then
$$ \br{\phi \circ f}\br{a} = \br{g \circ \alpha}\br{a} = g\br{b_1 - b_2} = g\br{b_1} - g\br{b_2} = \phi\br{x_1} - \phi\br{x_2} = \phi\br{x_1 - x_2}. $$
But $ \phi $ is injective, and so $ f\br{a} = x_1 - x_2 $, and so $ x_1 + \Im f = x_2 + \Im f $. So $ \delta $ is well-defined.
\end{itemize}
Exactness of the sequence is an exercise, on problem sheet.
\end{proof}

\subsection{Tensor products}

\begin{definition}
Let $ M $ be a left $ R $-module, and let $ L $ be a right $ R $-module. The \textbf{tensor product} $ L \otimes_R M $ is an abelian group generated as an abelian group by a set of \textbf{pure tensors}
$$ \cbr{l \otimes m \st l \in L, \ m \in M}, $$
subject to the relations
$$ l_1 \otimes m + l_2 \otimes m = \br{l_1 + l_2} \otimes m, \qquad l_1, l_2 \in L, \qquad m \in M, $$
$$ l \otimes m_1 + l \otimes m_2 = l \otimes \br{m_1 + m_2}, \qquad l \in L, \qquad m_1, m_2 \in M, $$
$$ \br{lr} \otimes m = l \otimes \br{rm}, \qquad l \in L, \qquad m \in M, \qquad r \in R. $$
\end{definition}

The following are observations.
\begin{itemize}
\item In general, not every element of $ L \otimes_R M $ is a pure tensor. A general element of $ L \otimes_R M $ is a $ \ZZ $-linear combination of pure tensors.
\item If $ R $ is commutative, $ L $ can be a left module, since left and right modules are the same. Also, in this case, $ L \otimes_R M $ has an $ R $-module structure, by $ r\br{l \otimes m} = rl \otimes m $.
\item Suppose that $ S $ is a set of generators for $ L $, as an abelian group, and $ T $ is a set of generators for $ M $, as an abelian group. Then a smaller generating set for $ L \otimes_R M $ is $ \cbr{s \otimes t \st s \in S, \ t \in T} $. This is because if
$$ l = \sum_{i = 1}^p a_is_i, \qquad m = \sum_{i = 1}^q b_jt_j, \qquad s_i \in S, \qquad t_i \in T, \qquad a_i, b_i \in \ZZ, $$
then, from the relations,
$$ l \otimes m = \sum_{i = 1}^p \sum_{j = 1}^q a_ib_j\br{s_i \otimes t_j}. $$
\end{itemize}

\begin{example*}
Tensor products can be counter intuitive, such as $ \ZZ_2 \otimes_\ZZ \ZZ_3 = 0 $. Why? Observe that for $ x \in \ZZ_2 $, $ x3 = 3x = x $. So for all $ x \in \ZZ_2 $ and $ y \in \ZZ_3 $,
$$ x \otimes y = x3 \otimes y = x \otimes 3y = x \otimes 0 = x \otimes y - x \otimes y = 0. $$
\end{example*}

\lecture{9}{Tuesday}{28/01/20}

\begin{theorem}[Universal property of tensor products]
Let $ A $ be a right $ R $-module and $ B $ a left $ R $-module. Let $ C $ be an abelian group. Let $ f : A \times B \to C $ be a map, not necessarily a homomorphism, which is $ \ZZ $-linear in both arguments, so
$$ f\br{a_1 + a_2, b} = f\br{a_1, b} + f\br{a_2, b}, \qquad a_1, a_2 \in A, \qquad b \in B, $$
$$ f\br{a, b_1 + b_2} = f\br{a, b_1} + f\br{a, b_2}, \qquad a \in A, \qquad b_1, b_2 \in B, $$
and such that
$$ f\br{ar, b} = f\br{a, rb}, \qquad a \in A, \qquad b \in B, \qquad r \in R. $$
Then there is a unique homomorphism
$$ \function[g]{A \otimes_R B}{C}{a \otimes b}{f\br{a, b}}. $$
\end{theorem}

\begin{proof}
In formal group theoretic terms, the tensor product $ A \otimes_R B $ is a quotient $ F / K $, where $ F $ is the free abelian group on the set of pure tensors $ a \otimes b $, and $ K $ is the subgroup of $ F $ generated by elements of the form
$$ \br{a_1 + a_2} \otimes b - a_1 \otimes b - a_2 \otimes b, \qquad a \otimes \br{b_1 + b_2} - a \otimes b_1 - a \otimes b_2, \qquad ar \otimes b - a \otimes rb. $$
The universal property of free abelian groups states that if $ F $ is free abelian on a set $ S $, then any set map $ S \to C $, for $ C $ an abelian group, extends uniquely to a homomorphism $ F \to C $. In the situation under discussion, we have a map
$$ g' : \cbr{a \otimes b \st a \in A, \ b \in B} \to C. $$
So $ g' $ extends uniquely to a homomorphism $ F \to C $. The conditions stipulated on $ f $ guarantee that $ g'\br{K} = 0 $. So $ g' $ induces a map $ g : F / K \to C $, which is what we want, since $ F / K = A \otimes_R B $. This establishes the existence of $ g $. Since the images of the pure tensors under $ g $ are specified, it is clear that $ g $ is unique.
\end{proof}

\begin{corollary}
\hfill
\begin{enumerate}
\item Let $ M $ be a left $ R $-module. Then $ R \otimes_R M \cong M $, via the map
$$ \function[f]{M}{R \otimes_R M}{m}{1 \otimes m}. $$
\item Let $ M $ be a right $ R $-module. Then $ M \otimes_R R \cong M $.
\end{enumerate}
\end{corollary}

\begin{proof}
\hfill
\begin{enumerate}
\item It is clear that $ f $ is a homomorphism of abelian groups. Now $ r \otimes m = 1 \otimes rm $, so $ R \otimes_R M $ is generated by $ \cbr{1 \otimes m \st m \in M} $, so $ f $ is surjective. For injectivity of $ f $, we need the universal property. Define a bilinear map
$$ \function{R \times M}{M}{\br{r, m}}{rm}. $$
This induces a homomorphism
$$ \function[g]{R \otimes_R M}{M}{r \otimes m}{rm}. $$
It is easy to check that $ g $ is an inverse for $ f $, so $ f $ is bijective.
\item By the same argument as $ 1 $.
\end{enumerate}
\end{proof}

\pagebreak

\begin{corollary}
Let $ A $ and $ B $ be right $ R $-modules, and let $ C $ be a left $ R $-module.
\begin{enumerate}
\item $ \br{A \oplus B} \otimes_R C \cong \br{A \otimes_R C} \oplus \br{B \otimes_R C} $, via the map
$$ \function[f]{\br{A \oplus B} \otimes_R C}{\br{A \otimes_R C} \oplus \br{B \otimes_R C}}{\br{a, b} \otimes c}{\br{a \otimes c, b \otimes c}}. $$
\item $ A \otimes_R \br{B \oplus C} \cong \br{A \otimes_R B} \oplus \br{A \otimes_R C} $.
\end{enumerate}
\end{corollary}

\begin{proof}
\hfill
\begin{enumerate}
\item Take a bilinear map, that is $ \ZZ $-bilinear in both arguments, and respecting $ R $-multiplication,
$$ \function{A \oplus B \times C}{\br{A \otimes_R C} \oplus \br{B \otimes_R C}}{\br{\br{a, b}, c}}{\br{a \otimes c, b \otimes c}}. $$
This induces a homomorphism $ f : \br{A \oplus B} \otimes_R C \to \br{A \otimes_R C} \oplus \br{B \otimes_R C} $ with the description as given above. Now take the bilinear map given by
$$ \function{A \times C}{\br{A \oplus B} \otimes_R C}{\br{a, c}}{\br{a, 0} \otimes c}. $$
This induces a homomorphism $ g_1 : A \otimes_R C \to \br{A \oplus B} \otimes_R C $. Similarly, we get a homomorphism $ g_2 : B \otimes_R C \to \br{A \oplus B} \otimes_R C $. Now define
$$ \function[g = g_1 \oplus g_2]{\br{A \otimes_R C} \oplus \br{B \otimes_R C}}{\br{A \oplus B} \otimes_R C}{\br{x, y}}{g_1\br{x} + g_2\br{y}}. $$
It is easy to check that $ f $ and $ g $ are mutually inverse, so both isomorphisms.
\item Similarly.
\end{enumerate}
\end{proof}

\begin{corollary}
Let $ A $ be an abelian group. Then
\begin{enumerate}
\item $ \ZZ_n \otimes_\ZZ A \cong A / nA $, and
\item $ A \otimes_\ZZ \ZZ_n \cong A / nA $.
\end{enumerate}
\end{corollary}

\begin{proof}
\hfill
\begin{enumerate}
\item Define a map by
$$ \function[f]{A}{\ZZ_n \otimes_\ZZ A}{a}{1 \otimes a}. $$
Suppose $ a_0 \in A $ such that $ a_0 = na $ for some $ a $. Then $ f\br{a_0} = 1 \otimes a_0 = 1 \otimes na = n \otimes a = 0 $ so $ nA \le \Ker f $. So $ f $ induces a map
$$ \overline{f} : A / nA \to \ZZ_n \otimes_\ZZ A. $$
Notice that the pure tensor $ k \otimes a $ is equal to $ 1 \otimes ka $, so $ \ZZ_n \otimes_\ZZ A $ is generated by $ \cbr{1 \otimes a \st a \in A} $. So $ \overline{f} $ is surjective. For injectivity, use the universal property. We have a bilinear map
$$ \function[g]{\ZZ_n \times A}{A / nA}{\br{k, a}}{ka + nA}. $$
This is well-defined and bilinear. So extends to a homomorphism
$$ \overline{g} : \ZZ_n \otimes_\ZZ A \to A / nA. $$
It is easy to check that $ \overline{g} \circ \overline{f} = \id_{A / nA} $, so $ \overline{f} $ is injective.
\item Similarly.
\end{enumerate}
\end{proof}

\pagebreak

\lecture{10}{Friday}{31/01/20}

\begin{proposition}
Let $ \alpha : A \to B $ be a homomorphism of right $ R $-modules. Let $ M $ be a left $ R $-module. There is a unique abelian group homomorphism
$$ \function[\alpha']{A \otimes_R M}{B \otimes_R M}{a \otimes m}{\alpha\br{a} \otimes m}, \qquad a \in A, \qquad m \in M. $$
\end{proposition}

\begin{proof}
The set map defined by
$$ \function[f]{A \times M}{B \otimes_R M}{\br{a, m}}{\alpha\br{a} \otimes m} $$
is linear in both arguments, and we have
$$ f\br{ar, m} = \alpha\br{ar} \otimes m = \alpha\br{a}r \otimes m = \alpha\br{a} \otimes rm = f\br{a, rm}. $$
Now by the universal property of tensor products, $ f $ gives rise to a unique homomorphism $ \alpha' : A \otimes_R M \to B \otimes_R M $ with the properties claimed.
\end{proof}

\begin{proposition}
Suppose $ \alpha : A \to B $ is surjective. Then $ \alpha' : A \otimes_R M \to B \otimes_R M $ is surjective.
\end{proposition}

\begin{proof}
Since $ \alpha $ is surjective, every pure tensor $ b \otimes m \in B \otimes_R M $ is equal to $ \alpha\br{a} \otimes m $ for some $ a \in A $. So $ b \otimes m = \alpha'\br{a \otimes m} \in \Im \alpha' $. Since $ B \otimes_R M $ is generated by its pure tensors, $ \alpha' $ is surjective.
\end{proof}

An observation is that it is not true that $ A \to B $ is injective implies $ A \otimes_R M \to B \otimes_R M $ is injective.

\begin{example*}
Let
$$ \function[\alpha]{\ZZ_2}{\ZZ_4}{1}{2}, $$
which is injective. Consider
$$ \function[\alpha']{\ZZ_2 \otimes_\ZZ \ZZ_2 \cong \ZZ_2}{\ZZ_4 \otimes_\ZZ \ZZ_2}{1 \otimes 1}{2 \otimes 1 = 1 \otimes 2 = 0}. $$
So $ \alpha' $ is the zero map, which is not injective.
\end{example*}

\begin{proposition}
Let
$$ 0 \to A \xrightarrow{\alpha} B \xrightarrow{\beta} C \to 0 $$
be a short exact sequence of right $ R $-modules. Then the sequence
$$ A \otimes_R M \xrightarrow{\alpha'} B \otimes_R M \xrightarrow{\beta'} C \otimes_R M \to 0 $$
is exact.
\end{proposition}

\begin{proof}
Since $ \beta' $ is surjective, the sequence is exact at $ C \otimes_R M $. We show it is exact at $ B \otimes_R M $. Since $ \beta $ is surjective, for every $ c \in C $, there exists $ f\br{c} \in B $ such that $ \beta\br{f\br{c}} = c $. Here $ f $ is a set map $ C \to B $, which is not uniquely defined in general. Suppose that $ \beta\br{b} = c $. Then $ b - f\br{c} \in \Ker \beta = \Im \alpha $, so $ f\br{c} + \Im \alpha = b + \Im \alpha $. Define a set map by
$$ \function[g]{C \times M}{\br{B \otimes_R M} / \Im \alpha'}{\br{c, m}}{f\br{c} \otimes m + \Im \alpha'}. $$
Note that if $ \beta\br{b} = c $, then $ b \otimes m - f\br{c} \otimes m = \alpha\br{a} \otimes m \in \Im \alpha' $ for some $ a \in A $. We can check that $ g $ is linear in both arguments. For example, for the first argument, we have $ g\br{c_1 + c_2, m} = f\br{c_1 + c_2} \otimes m + \Im \alpha' $. Now $ \beta\br{f\br{c_1 + c_2}} = c_1 + c_2 = \beta\br{f\br{c_1}} + \beta\br{f\br{c_2}} = \beta\br{f\br{c_1} + f\br{c_2}} $ so
$$ g\br{c_1 + c_2, m} = \br{f\br{c_1} + f\br{c_2}} \otimes m + \Im \alpha' = f\br{c_1} \otimes m + f\br{c_2} \otimes m + \Im \alpha' = g\br{c_1, m} + g\br{c_2, m}. $$
Also, we have $ g\br{cr, m} = f\br{cr} \otimes m + \Im \alpha' $. But $ \beta\br{f\br{cr}} = cr = \beta\br{f\br{c}r} $, so $ f\br{cr} \otimes m + \Im \alpha' = f\br{c}r \otimes m + \Im \alpha' $. So
$$ g\br{cr, m} = f\br{c}r \otimes m + \Im \alpha' = f\br{c} \otimes rm + \Im \alpha' = g\br{c, rm}. $$

\pagebreak

By the universal property, there is a unique homomorphism
$$ \function[\psi]{C \otimes_R M}{\br{B \otimes_R M} / \Im \alpha'}{c \otimes m}{f\br{c} \otimes m + \Im \alpha'}. $$
Next observe that $ \br{\beta' \circ \alpha'}\br{a \otimes m} = \br{\beta \circ \alpha}\br{a} \otimes m = 0 $, since $ \Im \alpha = \Ker \beta $. Since $ A \otimes_R M $ is generated by pure tensors, we have $ \beta' \circ \alpha' = 0 $. So $ \Im \alpha' \le \Ker \beta' $. Hence $ \beta' $ induces a map
$$ \phi : \br{B \otimes_R M} / \Im \alpha' \to C \otimes_R M. $$
It is easy to check that $ \phi $ and $ \psi $ are mutually inverse, and so both are isomorphisms. In particular $ \phi $ is injective, and so $ \Im \alpha' = \Ker \beta' $ as required.
\end{proof}

\subsection{Flat modules}

\begin{definition}
A left $ R $-module $ M $ is \textbf{flat} if $ A \to B $ is injective implies that $ A \otimes_R M \to B \otimes_R M $ is injective.
\end{definition}

If $ M $ is flat then any short exact sequence of right $ R $-modules
$$ 0 \to A \to B \to C \to 0 $$
corresponds to a short exact sequence of abelian groups
$$ 0 \to A \otimes_R M \to B \otimes_R M \to C \otimes_R M \to 0. $$

\begin{proposition}
\label{prop:projectiveflat}
Every projective module is flat.
\end{proposition}

This follows from two lemmas.

\begin{lemma}
\label{lem:projectiveflat1}
$ P \oplus Q $ is flat if and only if $ P $ and $ Q $ are both flat.
\end{lemma}

\begin{proof}
Recall there is a canonical isomorphism
$$ A \otimes_R \br{P \oplus Q} \cong \br{A \otimes_R P} \oplus \br{A \otimes_R Q}. $$
Suppose $ \alpha : A \to B $ is injective. Then $ \alpha' : A \otimes_R \br{P \oplus Q} \to B \otimes_R \br{P \oplus Q} $ corresponds to
$$ \functions[\overline{\alpha'}]{\br{A \otimes_R P} \oplus \br{A \otimes_R Q}}{\br{B \otimes_R P} \oplus \br{B \otimes_R Q}}{\br{a \otimes p, 0}}{\br{\alpha\br{a} \otimes p, 0}}{\br{0, a \otimes q}}{\br{0, \alpha\br{a} \otimes q}}. $$
It is clear from this that $ \overline{\alpha'} $ is injective if and only if $ A \otimes_R P \to B \otimes_R P $ and $ A \otimes_R Q \to B \otimes_R Q $ are injective, and Lemma \ref{lem:projectiveflat1} follows immediately.
\end{proof}

\begin{lemma}
\label{lem:projectiveflat2}
Every free $ R $-module is flat.
\end{lemma}

\lecture{11}{Monday}{03/02/20}

Lecture 11 is a problems class.

\lecture{12}{Tuesday}{04/02/20}

\begin{proof}
We know $ \br{A \oplus B} \otimes_R C \cong \br{A \otimes_R C} \oplus \br{B \otimes_R C} $. Similarly,
$$ \br{\bigoplus_{s \in S} A_s} \otimes_R C \cong \bigoplus_{s \in S} \br{A_s \otimes_R C}. $$
So Lemma \ref{lem:projectiveflat1} generalises, so $ \bigoplus_{s \in S} A_s $ is flat if and only if all of the $ A_s $ is flat for $ s \in S $. Let $ F $ be free. Then $ F = \bigoplus_{s \in S} R $, and so $ F $ is flat if and only if $ R $ is flat. But for any $ R $-module in $ A $, we have $ A \otimes_R R \cong A $, so
$$
\begin{tikzcd}[row sep=tiny]
A \arrow{r}{\alpha} \arrow[cong]{d} & B \arrow[cong]{d} \\
A \otimes_R R \arrow[dashed, swap]{r}{\alpha'} & B \otimes_R R
\end{tikzcd},
$$
and it is easy to check that $ R $ is flat.
\end{proof}

\begin{proof}[Proof of Proposition \ref{prop:projectiveflat}]
Lemma \ref{lem:projectiveflat1} and Lemma \ref{lem:projectiveflat2} imply Proposition \ref{prop:projectiveflat}, since a projective module is a direct summand of a free module.
\end{proof}

\pagebreak

\section{Modules over a PID}

There exist flat modules which are not projective. We will show that $ \QQ $ as a module for $ \ZZ $ is flat, and it is easy to see it is not projective. To do this we will study the case of modules over a PID. Recall that $ R $ is an \textbf{integral domain} if $ R $ is commutative and $ rs = 0 $ implies that $ r = 0 $ or $ s = 0 $ for $ r, s \in R $. An integral domain is a \textbf{PID} if every ideal is $ \abr{a} = \cbr{ra \st r \in R} $ for some $ a \in R $.

\begin{example*}
The ring $ \ZZ $ is an example of a PID.
\end{example*}

\subsection{Free and projective modules}

\begin{proposition}
Let $ R $ be a PID. Then every projective $ R $-module is free. Equivalently, every summand of a free module is free.
\end{proposition}

In fact we will show that any submodule of a free module is free. Moreover, if $ F_1 \le F_2 $, where $ F_1 $ and $ F_2 $ are free, and if $ B_1 $ and $ B_2 $ are bases for $ F_1 $ and $ F_2 $ respectively, then $ \abs{B_1} \le \abs{B_2} $. In particular, if $ M \le R^n $, then $ M \cong R^m $ for some $ m \le n $. For this, we will need the well-ordering theorem.

\begin{theorem}[Well-ordering theorem]
Let $ X $ be a set. There exists a well-order $ \le $ on $ X $, that is a total order such that every non-empty subset of $ X $ has a least element.
\end{theorem}

\begin{corollary}[Transfinite induction]
Let $ X $ be a non-empty set well-ordered by $ \le $. Let $ x_0 $ be the least element of $ X $. Let $ S \subseteq X $. If $ x_0 \in S $, and $ s < t $ implies $ s \in S $ implies that $ t \in S $, then $ S = X $.
\end{corollary}

\begin{proof}
Let $ F = \bigoplus_{s \in S} R $. Let $ \le $ be a well-order on $ S $. For $ s \in S $, let $ \pi_s $ be the projection map $ F \to R $ onto the $ s $-coordinate. Let $ e_s $ be the element of $ F $ with one in coordinate $ s $, and zero elsewhere. Suppose $ U \le F $ is an $ R $-submodule of $ F $. Define $ R_t $ to be the submodule of $ F $ generated by $ \cbr{e_s \st s \le t} $, so
$$ R_t = \sp \cbr{e_s \st s \le t}. $$
So if $ t_1 \le t_2 $ then $ R_{t_1} \le R_{t_2} $. Let
$$ U_t = U \cap R_t. $$
So $ t_1 < t_2 $ implies that $ U_{t_1} \le U_{t_2} $. Consider $ \pi_s\br{U_s} $. This is an ideal of $ R $. Hence there exists $ a_s \in R $ such that $ \pi_s\br{U_s} = \abr{a_s} $, since $ R $ is a PID. For each $ s $, let $ u_s \in U_s $ be such that $ \pi_s\br{u_s} = a_s $. In cases where $ a_s = 0 $, assume $ u_s = 0 $. Let
$$ B = \cbr{u_s \st s \in S, \ u_s \ne 0}. $$
\begin{itemize}
\item Claim that $ B $ generates $ U $. We will actually prove that $ B_t = \cbr{u_s \st s \le t} $ generates $ U_t $, using transfinite induction. If $ s_0 $ is the least element of $ S $, it is easy to see that $ B_{s_0} = \cbr{u_{s_0}} $ generates $ U_{s_0} $. Suppose $ B_t $ generates $ U_t $ for all $ t < t_0 $. Let $ u \in U_{t_0} $. Then $ \pi_{t_0}\br{u} = ra_{t_0} $. Hence $ \pi_{t_0}\br{u - ru_{t_0}} = 0 $. So $ u - ru_{t_0} $ has zero in the $ t_0 $-coordinate, so $ u - ru_{t_0} \in \sp \cbr{e_s \st s < t_0} $. Clearly $ u - ru_{t_0} \in U $. We have $ u - ru_{t_0} = \sum_{i = 1}^q r_ie_{s_i} $, where $ s_i < t_0 $, and $ s_1 < \dots < s_q $. Then
$$ u - ru_{t_0} \in U \cap R_{s_q} = U_{s_q} = \sp B_{s_q}, $$
by the inductive hypothesis. Hence $ u \in \sp \br{B_{s_q} \cup \cbr{u_{t_0}}} \subseteq \sp B_{t_0} $. Hence $ B_{t_0} $ generates $ U_{t_0} $, as required.
\item Next we show the linear independence of $ B $. Suppose we have a linear combination of elements of $ B $ equal to zero. Say $ \sum_{i = 1}^k r_iu_{s_i} = 0 $. Assume $ s_1 < \dots < s_k $. We have
$$ \pi_{s_k}\br{\sum_{i = 1}^k r_iu_{s_i}} = \sum_{i = 1}^k r_i\pi_{s_k}\br{u_{s_i}}. $$
Now $ u_{s_i} \in U_{s_i} \subseteq R_{s_i} $, and so $ \pi_{s_k}\br{u_{s_i}} = 0 $ if $ s_i < s_k $. Hence $ r_k\pi_{s_k}\br{u_{s_k}} = 0 $, so $ r_ka_{s_k} = 0 $. But $ a_{s_k} \ne 0 $, and $ R $ is an integral domain. So $ r_k = 0 $. It follows easily that $ r_i = 0 $ for all $ i $, so $ B $ is linearly independent.
\end{itemize}
We have shown that $ B $ is a basis for $ U $. Hence $ U $ is free. Since the elements of $ B $ are indexed by a subset of $ S $, we have $ \abs{B} \le \abs{S} $.
\end{proof}

\lecture{13}{Friday}{07/02/20}

Lecture 13 is a problems class.

\pagebreak

\subsection{Injective and divisible modules}

\lecture{14}{Monday}{10/02/20}

\begin{definition}
Let $ R $ be an integral domain, and $ M $ an $ R $-module. Let $ m \in M $. Say that $ m $ is \textbf{infinitely divisible} if for all $ r \in R \setminus \cbr{0} $ there exists $ l \in M $ such that $ rl = m $.
\end{definition}

\begin{proposition}
The divisible elements of $ M $ form a submodule $ \D\br{M} $.
\end{proposition}

\begin{proof}
Easy.
\end{proof}

\begin{definition}
If $ \D\br{M} = M $, then $ M $ is \textbf{divisible}.
\end{definition}

\begin{proposition}
Let $ R $ be an integral domain. Then if an $ R $-module $ M $ is injective then it is divisible.
\end{proposition}

\begin{proof}
Recall that for an integral domain $ R $, and $ a \in R \setminus \cbr{0} $, the map
$$ \function[f]{R}{\abr{a}}{r}{ra} $$
is an isomorphism. Suppose $ M $ is an injective $ R $-module. Let
$$ \function[g]{R}{M}{1}{m}. $$
Then $ g \circ f^{-1} $ is a homomorphism $ \abr{a} \to M $, and $ \br{g \circ f^{-1}}\br{a} = g\br{1} = m $. Now by Baer's criterion, there is a map $ h : R \to M $ extending $ g \circ f^{-1} $. Now $ ah\br{1} = h\br{a} = \br{g \circ f^{-1}}\br{a} = m $. Hence there exists $ l \in M $ such that $ al = m $. So $ m $ is a divisible element, and so $ M $ is divisible.
\end{proof}

\begin{proposition}
Let $ R $ be a PID. If $ M $ is a divisible $ R $-module then $ M $ is injective.
\end{proposition}

So divisible equals injective when $ R $ is a PID.

\begin{proof}
We use Baer's criterion. Let $ I $ be an ideal of $ R $, and $ f : I \to M $ an $ R $-module homomorphism. Since $ R $ is a PID, $ I = \abr{a} $ for some $ a \in R $. Suppose $ f\br{a} = m $. If $ a = 0 $ there is nothing to prove, since the zero map $ R \to M $ extends $ f $. So assume $ a \ne 0 $. Since $ m $ is divisible, there exists $ l \in M $ with $ al = m $. Now the map given by
$$ \function{R}{M}{1}{l} $$
extends $ f $. So Baer's criterion is satisfied, and so $ M $ is injective.
\end{proof}

\subsection{Flat and torsion-free modules}

\begin{definition}
Let $ R $ be an integral domain. Let $ M $ be an $ R $-module. Say that $ m \in M $ is a \textbf{torsion element} if there exists $ r \in R \setminus \cbr{0} $ such that $ rm = 0 $.
\end{definition}

\begin{proposition}
The torsion elements of $ M $ form a submodule $ \T\br{M} $.
\end{proposition}

\begin{proof}
Easy, using the fact that integral domains are commutative.
\end{proof}

\begin{definition}
If $ \T\br{M} = 0 $, then $ M $ is \textbf{torsion-free}. If $ \T\br{M} = M $, then $ M $ is a \textbf{torsion module}.
\end{definition}

\begin{proposition}
Let $ R $ be an integral domain. Let $ M $ be a flat $ R $-module. Then $ M $ is torsion-free.
\end{proposition}

\begin{proof}
Let $ a \in R \setminus \cbr{0} $. Then
$$ \function[f]{R}{R}{1}{a} $$
is an injective $ R $-module homomorphism. Suppose that $ M $ is flat. Then the map
$$ \function[g]{R \otimes_R M}{R \otimes_R M}{r \otimes m}{ra \otimes m = r \otimes am} $$
is injective. But $ R \otimes_R M $ is canonically isomorphic to $ M $, under which the map $ g $ corresponds to $ m \mapsto am $. Since $ g $ is injective, we have $ am \ne 0 $ for $ m \ne 0 $. Hence $ m $ is not a torsion element, if $ m \ne 0 $, and so $ M $ is torsion-free.
\end{proof}

\pagebreak

We now build up to the following.

\begin{proposition}
\label{prop:torsionflat}
Let $ R $ be a PID. If $ M $ is a torsion-free $ R $-module then $ M $ is flat.
\end{proposition}

The following is the strategy. We want to prove that whenever $ \alpha : A \to B $ is injective, so is $ \alpha' : A \otimes_R M \to B \otimes_R M $, where $ M $ is torsion-free.
\begin{enumerate}
\item Prove this in the case that $ B $ is free, and $ A $ is a submodule of $ B $, and $ \alpha $ is the inclusion map, by
\begin{itemize}
\item first reducing the problem to the case that $ A $ and $ B $ are finitely generated, so $ B \cong \RR^n $, and
\item then using induction on the rank $ n $ of $ B $.
\end{itemize}
\item Show the general case follows from $ 1 $.
\end{enumerate}

\begin{lemma}
\label{lem:torsionflat1}
Let $ R $ be a PID, let $ I = \abr{a} $ be an ideal of $ R $, and let $ M $ be a torsion-free $ R $-module. Then $ g : I \otimes_R M \to R \otimes_R M $ is injective.
\end{lemma}

\begin{proof}
The homomorphism given by
$$ \function{R}{I}{r}{ra} $$
gives a map $ f : R \otimes_R M \to I \otimes_R M $. Now $ g \circ f $ is a map
$$ \function{R \otimes_R M}{R \otimes_R M}{r}{ra}. $$
Now $ f $ is surjective, and $ g \circ f $ is injective, since $ R $ is an integral domain. But this implies that $ g $ is injective, as required.
\end{proof}

\begin{lemma}
\label{lem:torsionflat2}
Let $ A $ be a right $ R $-module. Let $ M $ be a left $ R $-module. Suppose $ \sum_{i = 1}^t \br{a_i \otimes m_i} = 0 $ in $ A \otimes_R M $. There exists a finitely generated submodule $ A_0 \le A $ such that $ a_i \in A_0 $ for all $ i $, and $ \sum_{i = 1}^t \br{a_i \otimes m_i} = 0 $ in $ A_0 \otimes_R M $.
\end{lemma}

\begin{proof}
Recall that
$$ A \otimes_R M = \F_{\ab}\br{A \times M} / K, $$
where $ K $ is generated by certain relators. If $ \sum_{i = 1}^t \br{a_i \otimes m_i} = 0 $ in $ A \otimes_R M $, then in $ \F_{\ab}\br{A \times M} $, we have $ \sum_{i = 1}^t \br{a_i \otimes m_i} \in K $. So there exist relators $ s_1, \dots, s_q $, or their negations, such that
$$ \sum_{i = 1}^t \br{a_i \otimes m_i} = \sum_{i = 1}^q s_i. $$
Only finitely many elements of $ A $ are involved in the relators $ s_1, \dots, s_q $. Let $ A_0 $ be generated by these together with $ a_1, \dots, a_t $. Then certainly $ a_i \in A_0 $ for all $ i $. And $ \sum_{i = 1}^t \br{a_i \otimes m_i} = \sum_{i = 1}^q s_i $ in $ \F_{\ab}\br{A_0 \times M} $ so $ \sum_{i = 1}^t \br{a_i \otimes m_i} = 0 $ in $ A_0 \otimes_R M $. Clearly $ A_0 $ is finitely generated.
\end{proof}

\lecture{15}{Tuesday}{11/02/20}

\begin{lemma}
\label{lem:torsionflat3}
Let $ F = \F\br{S} = \bigoplus_{s \in S} R $. Let $ U $ be a finitely generated submodule of $ F $. Then there exists a finite $ T \subseteq S $ such that $ U \le \F\br{T} $, and for any $ M $, the map $ \F\br{T} \otimes_R M \to \F\br{S} \otimes_R M $ is injective.
\end{lemma}

\begin{proof}
Let $ u_1, \dots, u_q $ be generators for $ U $. Every $ u_i $ is an $ R $-linear combination of elements of $ S $. Since each of these linear combinations mentions only finitely many elements of $ S $, there is a finite subset $ T \subseteq S $ such that every $ u_i $ is an $ R $-linear combination of elements of $ T $. So $ U \le \F\br{T} $. We have
$$ \F\br{S} = \F\br{T} \oplus \F\br{S \setminus T}, $$
and so
$$ \F\br{S} \otimes_R M \cong \br{\F\br{T} \otimes_R M} \oplus \br{\F\br{S \setminus T} \otimes_R M}. $$
It follows that the natural map $ \F\br{T} \otimes_R M \to \F\br{S} \otimes_R M $ is injective.
\end{proof}

\pagebreak

Lemma \ref{lem:torsionflat2} and Lemma \ref{lem:torsionflat3} tell us that if $ F $ is free and $ U \le F $, and if $ M $ is an $ R $-module, if $ U \otimes_R M \to F \otimes_R M $ is not injective, then there exists a finitely generated $ U_0 < U $ and a finite rank free submodule $ F_0 < F $ such that $ U_0 \otimes_R M \to F_0 \otimes_R M $ is not injective.

\begin{lemma}
\label{lem:torsionflat4}
Let $ R $ be a PID. Let $ F $ be free, and $ U \le F $. Let $ M $ be torsion-free. Then $ U \otimes_R M \to F \otimes_R M $ is injective.
\end{lemma}

\begin{proof}
We assume that $ F = R^n $. We do this by induction on $ n $.
\begin{itemize}[leftmargin=1.5in]
\item[Base case.] Let $ n = 1 $. So $ F $ is $ R $, and $ U $ is an ideal of $ R $. By Lemma \ref{lem:torsionflat1}, $ U \otimes_R M \to F \otimes_R M $ is injective in this case.
\item[Inductive hypothesis.] $ U \le F = R^{n - 1} $ implies that $ U \otimes_R M \to F \otimes_R M $ is injective.
\item[Inductive step.] Assume $ U \le F = R^n $. Write $ R^n = R \oplus R^{n - 1} $. So we have a short exact sequence
$$ 0 \to R \to R^n \to R^{n - 1} \to 0. $$
We also have a short exact sequence
$$ 0 \to U_1 \to U \to \pi_{R^{n - 1}}\br{U} \to 0, $$
where $ U_1 = U \cap \br{R \oplus 0^{n - 1}} $. Identifying $ R $ with $ R \oplus 0^{n - 1} $, we get a commuting diagram
$$
\begin{tikzcd}
0 \arrow{r} & U_1 \arrow{r} \arrow{d} & U \arrow{r} \arrow{d} & \pi_{R^{n - 1}}\br{U} \arrow{r} \arrow{d} & 0 \\
0 \arrow{r} & R \arrow{r} & R^n \arrow{r} & R^{n - 1} \arrow{r} & 0
\end{tikzcd},
$$
where the vertical maps are inclusions, and the rows are exact. Tensoring everything with $ M $, we get a new commuting diagram
$$
\begin{tikzcd}
& U_1 \otimes_R M \arrow{r} \arrow{d}{f} & U \otimes_R M \arrow{r} \arrow{d}{g} & \pi_{R^{n - 1}}\br{U} \otimes_R M \arrow{r} \arrow{d}{h} & 0 \\
0 \arrow{r} & R \otimes_R M \arrow{r} & R^n \otimes_R M \arrow{r} & R^{n - 1} \otimes_R M \arrow{r} & 0
\end{tikzcd}.
$$
The initial zero in the bottom row comes from the fact that
$$ 0 \to R \to R^n \to R^{n - 1} \to 0 $$
is split, since $ R^n = R \oplus R^{n - 1} $, and so
$$ R^n \otimes_R M \cong \br{R \otimes_R M} \oplus \br{R^{n - 1} \otimes_R M}. $$
Now $ f $ is injective by Lemma \ref{lem:torsionflat1}, and $ h $ is injective by the inductive hypothesis. The snake lemma tells us that the sequence
$$ \Ker f \to \Ker g \to \Ker h $$
is exact at $ \Ker g $. So
$$ 0 \to \Ker g \to 0 $$
is exact, and so $ \Ker g = 0 $. So $ g $ is injective, and this completes the induction.
\end{itemize}
\end{proof}

\pagebreak

\begin{proof}[Proof of Proposition \ref{prop:torsionflat}]
Prove that if $ \alpha : A \to B $ is injective, and $ M $ is torsion-free, over a PID $ R $, then $ \alpha' : A \otimes_R M \to B \otimes_R M $ is injective. There exists a free module $ F $ such that $ B $ is quotient of $ F $. So there is a short exact sequence
$$ 0 \to K \to F \xrightarrow{\delta} B \to 0. $$
Now $ A \cong \alpha A = \Im \alpha $. Let $ F_A $ be the $ \delta $-preimage of $ \alpha A $. Then $ K < F_A $, and we have another short exact sequence
$$ 0 \to K \to F_A \to \alpha A \to 0. $$
We have a commuting diagram
$$
\begin{tikzcd}[row sep=tiny]
& & F_A \arrow{r} \arrow[hookrightarrow]{dd} & \alpha A \arrow{r} \arrow[hookrightarrow]{dd} & 0 \\
0 \arrow{r} & K \arrow{ur} \arrow{dr} & & & \\
& & F \arrow{r} & B \arrow{r} & 0
\end{tikzcd}.
$$
Tensoring with $ M $,
$$
\begin{tikzcd}[row sep=tiny]
& F_A \otimes_R M \arrow{r}{\gamma} \arrow{dd}{f} & \alpha A \otimes_R M \arrow{r} \arrow{dd}{g} & 0 \\
K \otimes_R M \arrow{ur}{\beta} \arrow[swap]{dr}{\delta} & & & \\
& F \otimes_R M \arrow[swap]{r}{\epsilon} & B \otimes_R M \arrow{r} & 0
\end{tikzcd}
$$
is commuting, and exact along rows. Let $ u \in \Ker g \le \alpha A \otimes_R M \cong A \otimes_R M $. Since $ \gamma $ is surjective, there is $ w \in F_A \otimes_R M $ with $ \gamma\br{w} = u $. So $ \br{g \circ \gamma}\br{w} = 0 $. So $ \br{\epsilon \circ f}\br{w} = 0 $. So $ f\br{w} \in \Ker \epsilon = \Im \delta $, so $ f\br{w} = \delta\br{k} $ for $ k \in K \otimes_R M $. Since $ f $ is injective, by Lemma \ref{lem:torsionflat4}, we get $ w = \beta\br{k} \in \Im \beta $. So $ w \in \Ker \gamma $, so $ u = 0 $. Hence $ g $ is injective, as required.
\end{proof}

We have shown that if $ R $ is a PID, and if $ M $ is torsion-free, then $ M $ is flat.

\subsection{Modules over PIDs}

\lecture{16}{Friday}{14/02/20}

For an $ R $-module $ M $
$$ \text{free} \implies \text{projective} \implies \text{flat} \implies \text{torsion-free}, \qquad \text{injective} \implies \text{divisible}. $$
Over a PID
$$ \text{free} \iff \text{projective} \implies \text{flat} \iff \text{torsion-free}, \qquad \text{injective} \iff \text{divisible}. $$
Do we have projective if and only if flat, over a general ring, or over a PID? The answer is no.

\begin{example*}
The $ \ZZ $-module $ \QQ $ is torsion-free, so flat. Is $ \QQ $ projective? Is $ \QQ $ free, since $ \ZZ $ is a PID? Consider a free $ \ZZ $-module $ F = \bigoplus_{s \in S} \ZZ $. Let $ s_0 \in S $. Then let
$$ x = \br{x_s}_{s \in S} =
\begin{cases}
1 & s = s_0 \\
0 & \text{otherwise}
\end{cases}
\in F. $$
It is clear there are no $ y \in F $ such that $ 2y = x $. So $ x $ is not a divisible element of $ F $. Indeed, $ \D\br{F} = \cbr{0} $. But $ \D\br{\QQ} = \QQ $. Hence $ \QQ \not\cong F $. So $ \QQ $ is an example of a flat module which is not projective.
\end{example*}

\pagebreak

\section{Projective and injective resolutions}

\begin{definition}
Let $ M $ be an $ R $-module. A \textbf{resolution}, or \textbf{left resolution}, for $ M $ is a sequence of $ R $-modules $ A_0, A_1, A_2, \dots $, with homomorphisms $ d : A_{i + 1} \to A_i $, and also a homomorphism $ A_0 \to M $, such that
$$ \dots \xrightarrow{d} A_2 \xrightarrow{d} A_1 \xrightarrow{d} A_0 \to M \to 0 $$
is an exact sequence, where $ d $ is the \textbf{differential}. If all of the modules $ A_i $ have a property $ \PPP $, we call this a \textbf{$ \PPP $-resolution}.
\end{definition}

So we can talk about free resolutions, projective resolutions, flat resolutions. We do not use the term injective resolution in this context.

\begin{definition}
A \textbf{right resolution}, or \textbf{coresolution}, for $ M $ is a sequence of $ R $-modules $ A^0, A^1, A^2, \dots $, with homomorphisms $ d : A^i \to A^{i + 1} $, and $ M \to A^0 $, such that
$$ 0 \to M \to A^0 \xrightarrow{d} A^1 \xrightarrow{d} A^2 \xrightarrow{d} \dots $$
is exact. If the modules $ A^i $ have a property $ \PPP $, we can refer to a \textbf{right $ \PPP $-resolution}.
\end{definition}

An injective resolution always means a right injective resolution.

\subsection{Existence of projective resolutions}

\begin{proposition}
Let $ M $ be an $ R $-module. Then $ M $ has free, projective, and flat resolutions.
\end{proposition}

\begin{proof}
Since free implies projective implies flat, it is enough to show that free resolutions exist. Use the fact that for any module $ L $, there exist a free module $ F $ and $ K \le F $ such that $ L \cong F / K $. So we get a short exact sequence
$$ 0 \to K \to F \to L \to 0. $$
It follows that we can find $ F_0, F_1, F_2, \dots $, and $ K_0 \le F_0, K_1 \le F_1, K_2 \le F_2, \dots $ such that
$$ 0 \to K_0 \to F_0 \to M \to 0, \qquad 0 \to K_1 \to F_1 \to K_0 \to 0, \qquad 0 \to K_2 \to F_2 \to K_1 \to 0, \qquad \dots $$
are all exact. Since $ K_i \le F_i $, we may consider the maps $ F_{i + 1} \to K_i $ as maps $ F_{i + 1} \to F_i $ with image $ K_i $. But $ K_i $ is the kernel of the map $ F_i \to K_{i - 1} $, so the sequence
$$ \dots \to F_2 \to F_1 \to F_0 \to M \to 0 $$
is exact, and a free resolution for $ M $.
\end{proof}

\subsection{Existence of injective resolutions}

Injective coresolutions exist too, but the proof is more intricate. It involves making use of properties of the abelian group $ \QQ / \ZZ $.

\begin{proposition}
Let $ A $ be an abelian group, and let $ a \in A \setminus \cbr{0} $. There is a homomorphism $ f : A \to \QQ / \ZZ $ such that $ f\br{a} \ne 0 $.
\end{proposition}

\begin{proof}
Start by defining $ f_0 : \abr{a} \to \QQ / \ZZ $. If $ a $ has finite order $ t $, then $ f_0 : a \mapsto 1 / t + \ZZ $. If $ a $ has infinite order, then $ f_0 : a \mapsto \tfrac{1}{2} + \ZZ $. We will use Zorn's lemma. Let $ X $ be the set
$$ \cbr{\br{B, f} \st B \le A, \ a \in B, \ f : B \to \QQ / \ZZ, \ f \ \text{extends} \ f_0}. $$
Then $ X $ is non-empty, since $ \br{\abr{a}, f_0} \in X $. Define a partial order $ \le $ on $ X $ by $ \br{B_1, f_1} \le \br{B_2, f_2} $ if $ B_1 \le B_2 $ and $ f_2 $ extends $ f $. Let $ \cbr{\br{B_s, f_s} \st s \in S} $ be a chain in $ X $, where $ S $ is a suitable indexing set. Then $ \cbr{B_s \st s \in S} $ is a chain of subgroups of $ A $. So the union $ B = \bigcup_{s \in S} B_s $ is a subgroup of $ A $, containing $ a $. Define
$$ \function[f]{B}{\QQ / \ZZ}{b}{f_s\br{b}}, \qquad b \in B_s. $$

\pagebreak

This is well-defined since if $ b \in B_t $ then $ f_s\br{b} = f_t\br{b} $. Now $ \br{B, f} $ is an upper bound for $ \cbr{B_s \st s \in S} $ in $ X $. So by Zorn's lemma, $ X $ has a maximal element, which we will call $ \br{B, f} $. We show that $ B = A $. Since $ f\br{a} = f_0\br{a} $, this will complete the proof. Suppose $ x \in A \setminus B $. Then let $ I < \ZZ $ be defined by
$$ I = \cbr{k \st kx \in B}. $$
Since $ \ZZ $ is a PID, we have $ I = n\ZZ $ for some $ n $. We have $ \abr{B, x} \le A $, and $ \abr{B, x} \cong \br{B \oplus \abr{x}} / \abr{nx - b_0} $, where $ b_0 = nx $ in $ A $. Define
$$ \function[\phi]{B \oplus \abr{x}}{\QQ / \ZZ}{\br{b, kx}}{f\br{b} + \dfrac{kf\br{b_0}}{n}}, $$
so sending $ x $ to $ f\br{b_0} / n $. We see that $ \phi\br{nx - b_0} = 0 $, so $ \phi $ induces a map $ \br{B \oplus \abr{x}} / \abr{nx - b_0} \to \QQ / \ZZ $, and hence a map $ f' : \abr{B, x} \to \QQ / \ZZ $. But $ f'\br{a} = f_0\br{a} $, so $ \br{\abr{B, x}, f} $ is an element of $ X $ greater than $ \br{B, f} $, contradicting maximality of $ \br{B, f} $. Hence $ B = A $ as required.
\end{proof}

\lecture{17}{Monday}{17/02/20}

\begin{proposition}
For every abelian group $ A $, there is an injective abelian group $ I $ such that $ A $ is isomorphic to a subgroup of $ I $.
\end{proposition}

\begin{proof}
We know that $ \QQ / \ZZ $ is injective, as a $ \ZZ $-module, since it is divisible, and $ \ZZ $ is a PID. So $ \prod_{s \in S} \QQ / \ZZ $ is also injective. Take $ S = A \setminus \cbr{0} $. Then define, for each $ s \in S $, $ f_s : A \to \QQ / \ZZ $ such that $ f_s\br{s} \ne 0 $. Define
$$ \function[f]{A}{\prod_{s \in S} \QQ / \ZZ}{a}{\br{f_s\br{a}}_{s \in S}}. $$
Now if $ s \in A \setminus \cbr{0} $, then $ f_s\br{s} \ne 0 $, so $ f\br{s} \ne 0 $. So $ f $ is injective. It is easy to check that $ f $ is a homomorphism.
\end{proof}

\begin{proposition}
Let $ M $ be a right $ R $-module, and let $ A $ be an abelian group. Then $ \Hom_\ZZ\br{M, A} $ is a left $ R $-module, with the $ R $-action defined by $ \br{rf}\br{m} = f\br{mr} $.
\end{proposition}

\begin{proof}
This is clearer if we write the map $ f $ on the right instead of the left. Then the proposition becomes $ \br{m}\br{rf} = \br{mr}f $, and it is easy to see this works.
\end{proof}

\begin{proposition}
Let $ M $ be a left $ R $-module, and $ A $ an abelian group. Then $ \Hom_\ZZ\br{R, A} $ is a left $ R $-module, and there is a natural isomorphism
$$ \Hom_R\br{M, \Hom_\ZZ\br{R, A}} \cong \Hom_\ZZ\br{M, A}. $$
\end{proposition}

\begin{proof}
Write $ H = \Hom_\ZZ\br{R, A} $. Define
$$ \function[\Phi]{\Hom_R\br{M, H}}{\Hom_\ZZ\br{M, A}}{f}{\br{m \mapsto f\br{m}\br{1}}}, \qquad m \in M, \qquad 1 \in R. $$
Check the following.
\begin{itemize}
\item $ \Phi\br{f} $ is a homomorphism, since
\begin{align*}
\Phi\br{f}\br{m_1 + m_2}
& = f\br{m_1 + m_2}\br{1} \\
& = \br{f\br{m_1} + f\br{m_2}}\br{1} \\
& = f\br{m_1}\br{1} + f\br{m_2}\br{1} & \text{definition of} \ + \ \text{in} \ \Hom_\ZZ\br{R, A} \\
& = \Phi\br{f}\br{m_1} + \Phi\br{f}\br{m_2}.
\end{align*}
\item $ \Phi $ is a homomorphism, since
\begin{align*}
\Phi\br{f_1 + f_2}\br{m}
& = \br{f_1 + f_2}\br{m}\br{1} \\
& = \br{f_1\br{m} + f_2\br{m}}\br{1} & \text{definition of} \ + \ \text{in} \ \Hom_\ZZ\br{M, A} \\
& = f_1\br{m}\br{1} + f_2\br{m}\br{1} \\
& = \Phi\br{f_1}\br{m} + \Phi\br{f_2}\br{m} \\
& = \br{\Phi\br{f_1} + \Phi\br{f_2}}\br{m} & \text{definition of} \ + \ \text{in} \ \Hom_\ZZ\br{M, A},
\end{align*}
so since $ m $ was arbitrary, $ \Phi\br{f_1 + f_2} = \Phi\br{f_1} + \Phi\br{f_2} $.
\end{itemize}

\pagebreak

Now define
$$ \function[\Psi]{\Hom_\ZZ\br{M, A}}{\Hom_R\br{M, H}}{p}{\br{m \mapsto \br{r \mapsto p\br{rm}}}}, \qquad m \in M, \qquad r \in R. $$
Check the following.
\begin{itemize}
\item $ \Psi\br{p}\br{m} $ is a homomorphism, since
\begin{align*}
\Psi\br{p}\br{m}\br{r_1 + r_2}
& = p\br{\br{r_1 + r_2}m}
= p\br{r_1m + r_2m} \\
& = p\br{r_1m} + p\br{r_2m}
= \Psi\br{p}\br{m}\br{r_1} + \Psi\br{p}\br{m}\br{r_1}.
\end{align*}
\item $ \Psi\br{p} $ is an $ R $-module homomorphism, since
\begin{align*}
\Psi\br{p}\br{m_1 + m_2}\br{r}
& = p\br{r\br{m_1 + m_2}}
= p\br{rm_1 + rm_2}
= p\br{rm_1} + p\br{rm_2} \\
& = \Psi\br{p}\br{m_1}\br{r} + \Psi\br{p}\br{m_2}\br{r}
= \br{\Psi\br{p}\br{m_1} + \Psi\br{p}\br{m_2}}\br{r},
\end{align*}
so $ \Psi\br{p}\br{m_1 + m_2} = \Psi\br{p}\br{m_1} + \Psi\br{p}\br{m_2} $, and for $ h \in H $, we have $ \br{sh}\br{r} = h\br{rs} $, by definition of the $ R $-module structure on $ H $, so
$$ s\Psi\br{p}\br{m}\br{r} = \Psi\br{p}\br{m}\br{rs} = p\br{rsm} = \Psi\br{p}\br{sm}\br{r}, $$
so $ s\Psi\br{p}\br{m} = \Psi\br{p}\br{sm} $.
\item $ \Psi $ is a homomorphism, since
\begin{align*}
\Psi\br{p_1 + p_2}\br{m}\br{r}
& = \br{p_1 + p_2}\br{rm}
= p_1\br{rm} + p_2\br{rm} \\
& = \Psi\br{p_1}\br{m}\br{r} + \Psi\br{p_2}\br{m}\br{r}
= \br{\Psi\br{p_1} + \Psi\br{p_2}}\br{m}\br{r},
\end{align*}
so $ \Psi\br{p_1 + p_2} = \Psi\br{p_1} + \Psi\br{p_2} $.
\end{itemize}
Then $ \Psi \circ \Phi = \id_{\Hom_R\br{M, H}} $ and $ \Phi \circ \Psi = \id_{\Hom_\ZZ\br{M, A}} $. \footnote{Exercise} Hence $ \Phi $ and $ \Psi $ are isomorphisms.
\end{proof}

We are interested in the case $ A = \QQ / \ZZ $. Write $ S = \Hom_\ZZ\br{M, \QQ / \ZZ} $.

\lecture{18}{Tuesday}{18/02/20}

\begin{proposition}
$ S $ is injective as a left $ R $-module.
\end{proposition}

\begin{proof}
Let $ M $ and $ N $ be $ R $-modules, and $ \alpha : M \to N $ an injective homomorphism. By identifying $ M $ with $ \Im \alpha $, we may assume that $ M \le N $, and $ \alpha $ is the inclusion map. Since $ \QQ / \ZZ $ is injective as an abelian group, any $ \ZZ $-module homomorphism $ M \to S $ extends to a homomorphism $ N \to S $. Define
$$ \function[\Theta]{\Hom_\ZZ\br{N, \QQ / \ZZ}}{\Hom_\ZZ\br{M, \QQ / \ZZ}}{f}{\eval{f}_M}, $$
the restriction to $ M $. We see that $ \Theta $ is surjective. Similarly, we can define
$$ \function[\Theta']{\Hom_R\br{N, S}}{\Hom_R\br{M, S}}{f}{\eval{f}_M}. $$
Then $ \Theta' $ is an abelian group homomorphism. But we know there is a naturally defined isomorphism between $ \Hom_R\br{M, S} $ and $ \Hom_\ZZ\br{M, \QQ / \ZZ} $. So we get
$$
\begin{tikzcd}
\Hom_\ZZ\br{N, \QQ / \ZZ} \arrow{r}{\Theta} \arrow{d}{\sim}[swap]{\Psi} & \Hom_\ZZ\br{M, \QQ / \ZZ} \arrow{d}{\Psi}[swap]{\sim} \\
\Hom_R\br{N, S} \arrow[swap]{r}{\Theta'} & \Hom_R\br{M, S}
\end{tikzcd}.
$$
It is easy to see that this diagram commutes. It follows that $ \Theta' $ is surjective. So any $ R $-module homomorphism $ M \to S $ extends to a homomorphism $ N \to S $. Hence $ S $ is injective.
\end{proof}

\pagebreak

\begin{proposition}
Let $ M $ be a left $ R $-module, and $ m \in M \setminus \cbr{0} $. Then there exists $ f : M \to S $ such that $ f\br{m} \ne 0 $.
\end{proposition}

\begin{proof}
We know there is an abelian group homomorphism $ g : M \to \QQ / \ZZ $ such that $ g\br{m} \ne 0 $. Now $ \Psi\br{g} \in \Hom_R\br{M, S} $, and $ \Psi\br{g}\br{m}\br{1} = g\br{m} \ne 0 $ for $ 1 \in R $, so $ \Psi\br{g}\br{m} $ is not the zero map.
\end{proof}

\begin{proposition}
Let $ M $ be a left $ R $-module. There exists an injective $ R $-module $ I $ such that $ M $ is isomorphic to a submodule of $ I $. Equivalently, there exists an injection $ M \to I $.
\end{proposition}

\begin{proof}
Same as abelian groups. Let $ T = M \setminus \cbr{0} $. Then $ I = \prod_{t \in T} S $ is injective. Let $ f_t $ be a homomorphism $ M \to S $ such that $ f_t\br{t} \ne 0 $. Then
$$ \function[f]{M}{I}{m}{\br{f_t\br{m}}_{t \in T}} $$
is injective, and a homomorphism.
\end{proof}

\begin{proposition}
Every $ R $-module admits an injective resolution.
\end{proposition}

Thus there exist injective $ I_0, I_1, I_2, \dots $ such that
$$ 0 \to M \to I_0 \to I_1 \to I_2 \to \dots $$
is exact.

\begin{proof}
Let $ M $ be an $ R $-module. Then $ M $ injects into some injective module $ I_0 $. Let $ C_0 = I_0 / \Im \br{M \to I_0} $. Then $ C_0 $ injects into some injective $ I_1 $. This induces a map $ I_0 \to I_1 $ whose kernel is $ \Im \br{M \to I_0} $. Further terms in the sequence are constructed in an identical manner.
\end{proof}

\subsection{Uniqueness of projective resolutions}

\begin{proposition}
\label{prop:projectiveresolution}
Let $ M $ and $ N $ be $ R $-modules, and $ \phi : M \to N $. Let $ \br{P_i} $ be a projective resolution for $ M $, and $ \br{Q_i} $ a projective resolution for $ N $.
\begin{enumerate}
\item There exist $ R $-module homomorphisms $ f_i : P_i \to Q_i $ such that the diagram
$$
\begin{tikzcd}
\dots \arrow{r}{d_2} & P_2 \arrow{r}{d_1} \arrow[dashed]{d}{f_2} & P_1 \arrow{r}{d_0} \arrow[dashed]{d}{f_1} & P_0 \arrow{r}{p} \arrow[dashed]{d}{f_0} & M \arrow{r} \arrow{d}{\phi} & 0 \\
\dots \arrow[swap]{r}{d_2'} & Q_2 \arrow[swap]{r}{d_1'} & Q_1 \arrow[swap]{r}{d_0'} & Q_0 \arrow[swap]{r}{q} & N \arrow{r} & 0
\end{tikzcd}
$$
commutes.
\item Let $ g_i : P_i \to Q_i $ be such that the diagram
$$
\begin{tikzcd}
\dots \arrow{r}{d_2} & P_2 \arrow{r}{d_1} \arrow[bend right=30, swap]{d}{g_2} \arrow[bend left=30]{d}{f_2} & P_1 \arrow{r}{d_0} \arrow[bend right=30, swap]{d}{g_1} \arrow[bend left=30]{d}{f_1} & P_0 \arrow{r}{p} \arrow[bend right=30, swap]{d}{g_0} \arrow[bend left=30]{d}{f_0} & M \arrow{r} \arrow{d}{\phi} & 0 \\
\dots \arrow[swap]{r}{d_2'} & Q_2 \arrow[swap]{r}{d_1'} & Q_1 \arrow[swap]{r}{d_0'} & Q_0 \arrow[swap]{r}{q} & N \arrow{r} & 0
\end{tikzcd}
$$
commutes. Then there exist homomorphisms $ s_i : P_i \to Q_{i + 1} $ such that
$$ g_i - f_i =
\begin{cases}
s_{i - 1} \circ d_{i - 1} + d_i' \circ s_i & i > 0 \\
d_0' \circ s_0 & i = 0
\end{cases},
$$
so
$$
\begin{tikzcd}
\dots \arrow{r}{d_2} & P_2 \arrow{r}{d_1} \arrow[dashed, swap]{dl}{s_2} & P_1 \arrow{r}{d_0} \arrow[dashed, swap]{dl}{s_1} & P_0 \arrow{r}{p} \arrow[dashed, swap]{dl}{s_0} & M \arrow{r} \arrow{d}{\phi} & 0 \\
\dots \arrow[swap]{r}{d_2'} & Q_2 \arrow[swap]{r}{d_1'} & Q_1 \arrow[swap]{r}{d_0'} & Q_0 \arrow[swap]{r}{q} & N \arrow{r} & 0
\end{tikzcd}.
$$
\end{enumerate}
\end{proposition}

\pagebreak

\begin{proof}
\hfill
\begin{enumerate}
\item The map $ q : Q_0 \to N $ is surjective. There is a map $ p : P_0 \to N $, given by composing $ P_0 \to M $ with $ \phi $. Since $ P_0 $ is projective there exists $ f_0 : P_0 \to Q_0 $ such that $ p = q \circ f_0 $. Suppose the maps $ f_0, \dots, f_{t - 1} $ have been constructed, so
$$
\begin{tikzcd}
\dots \arrow{r}{d_t} & P_t \arrow{r}{d_{t - 1}} \arrow[dashed]{d}{f_t} & P_{t - 1} \arrow{r}{d_{t - 2}} \arrow{d}{f_{t - 1}} & P_{t - 2} \arrow{d}{f_{t - 2}} \arrow{r} & \dots \\
\dots \arrow[swap]{r}{d_t'} & Q_t \arrow[swap]{r}{d_{t - 1}'} & Q_{t - 1} \arrow[swap]{r}{d_{t - 2}'} & Q_{t - 2} \arrow[swap]{r} & \dots
\end{tikzcd}.
$$
Observe that $ d_{t - 2}' \circ f_{t - 1} \circ d_{t - 1} = f_{t - 2} \circ d_{t - 2} \circ d_{t - 1} $, since the existing squares of the diagram commute. But $ d_{t - 2} \circ d_{t - 1} = 0 $. So $ d_{t - 2}' \circ f_{t - 1} \circ d_{t - 1} = 0 $, so $ \Im \br{f_{t - 1} \circ d_{t - 1}} \le \Ker d_{t - 2}' = \Im d_{t - 1}' $. Now the map $ d_{t - 1}' : Q_t \to \Im d_{t - 1}' $ is obviously surjective, and $ P_t $ is projective. So there is a map $ f_t : P_t \to Q_t $ such that $ f_{t - 1} \circ d_{t - 1} = d_{t - 1}' \circ f_t $. Now inductively, maps $ f_i $ exist for all $ i $.
\item We want $ s_i $ such that $ g_i - f_i = d_i' \circ s_i + s_{i - 1} \circ d_{i - 1} $. Let $ h_i = g_i - f_i $. We see that the diagram
$$
\begin{tikzcd}
\dots \arrow{r}{d_2} & P_2 \arrow{r}{d_1} \arrow{d}{h_2} & P_1 \arrow{r}{d_0} \arrow{d}{h_1} & P_0 \arrow{r}{p} \arrow{d}{h_0} & M \arrow{r} \arrow{d}{0} & 0 \\
\dots \arrow[swap]{r}{d_2'} & Q_2 \arrow[swap]{r}{d_1'} & Q_1 \arrow[swap]{r}{d_0'} & Q_0 \arrow[swap]{r}{q} & N \arrow{r} & 0
\end{tikzcd}
$$
commutes, since we want $ h_i \circ d_i = d_i' \circ h_{i + 1} $, but we have
$$ h_i \circ d_i = g_i \circ d_i - f_i \circ d_i = d_i' \circ g_{i + 1} - d_i' \circ f_{i + 1} = d_i' \circ h_{i + 1}', $$
so we are fine.
\begin{itemize}[leftmargin=1in]
\item[Base case.] Let $ x \in P_0 $. Then $ \br{q \circ h_0}\br{x} = \br{0 \circ p}\br{x} = 0 $ so $ \Im h_0 \le \Ker q = \Im d_0' $. We have a surjective map $ d_0' : Q_1 \to \Im d_0' $, and a map $ h_0 : P_0 \to \Im d_0' $. Since $ P_0 $ is projective, there exists $ s_0 : P_0 \to Q_1 $ such that $ h_0 = d_0' \circ s_0 $.
\item[Inductive step.] Suppose we have maps $ s_0, \dots, s_{t - 1} $, with $ s_i : P_i \to Q_{i + 1} $, and $ h_i = d_i' \circ s_i + s_{i - 1} \circ d_{i - 1} $ for $ i = 1, \dots, t - 1 $, so
$$
\begin{tikzcd}
\dots \arrow{r}{d_{t + 1}} & P_{t + 1} \arrow{r}{d_t} \arrow[swap]{d}{h_{t + 1}} & P_t \arrow{r}{d_{t - 1}} \arrow[dashed, swap]{dl}{s_t} \arrow[swap]{d}{h_t} & P_{t - 1} \arrow{r}{d_{t - 2}} \arrow[swap]{dl}{s_{t - 1}} \arrow[swap]{d}{h_{t - 1}} & P_{t - 2} \arrow{r}{d_{t - 3}} \arrow[swap]{dl}{s_{t - 2}} \arrow[swap]{d}{h_{t - 2}} & \dots \\
\dots \arrow[swap]{r}{d_{t + 1}'} & Q_{t + 1} \arrow[swap]{r}{d_t'} & Q_t \arrow[swap]{r}{d_{t - 1}'} & Q_{t - 1} \arrow[swap]{r}{d_{t - 2}'} & Q_{t - 2} \arrow[swap]{r}{d_{t - 3}'} & \dots
\end{tikzcd}.
$$
Look at $ h_t - s_{t - 1} \circ d_{t - 1} $. We want to show that the image of this map is contained in $ \Im d_t' = \Ker d_{t - 1}' $. So check
\begin{align*}
d_{t - 1}' \circ \br{h_t - s_{t - 1} \circ d_{t - 1}}
& = d_{t - 1}' \circ h_t - d_{t - 1}' \circ s_{t - 1} \circ d_{t - 1} \\
& = h_{t - 1} \circ d_{t - 1} - \br{h_{t - 1} - s_{t - 2} \circ d_{t - 2}} \circ d_{t - 1} \\
& = h_{t - 1} \circ d_{t - 1} - h_{t - 1} \circ d_{t - 1} + s_{t - 2} \circ d_{t - 2} \circ d_{t - 1}.
\end{align*}
Now $ d_{t - 2} \circ d_{t - 1} = 0 $, so we have $ d_{t - 1}' \circ \br{h_t - s_{t - 1} \circ d_{t - 1}} = 0 $. So $ h_t - s_{t - 1} \circ d_{t - 1} \in \Ker d_{t - 1}' $. Now we have the situation
$$
\begin{tikzcd}
& P_t \arrow[dashed, swap]{dl}{s_t} \arrow{d}{h_t - s_{t - 1} \circ d_{t - 1}} \\
Q_{t + 1} \arrow[swap]{r}{d_t'} & \Im d_t'
\end{tikzcd},
$$
and since $ P_t $ is projective, there exists $ s_t $ such that $ d_t' \circ s_t = h_t - s_{t - 1} \circ d_{t - 1} $, so $ h_t = d_t' \circ s_t + s_{t - 1} \circ d_{t - 1} $ as required.
\end{itemize}
\end{enumerate}
\end{proof}

\pagebreak

\subsection{Uniqueness of injective resolutions}

The following is the equivalent result for injectives.

\begin{proposition}
Let $ M $ and $ N $ be $ R $-modules, and $ \phi : M \to N $ a homomorphism. Let $ \br{I_t} $ be an injective resolution for $ M $, and $ \br{J_t} $ another injective resolution for $ N $. Then
\begin{itemize}
\item there exist maps $ f_i : I_i \to J_i $ such that the diagram
$$
\begin{tikzcd}
0 \arrow{r} & M \arrow{r}{i} \arrow{d}{\phi} & I_0 \arrow{r}{d_0} \arrow[dashed]{d}{f_0} & I_1 \arrow{r}{d_1} \arrow[dashed]{d}{f_1} & I_2 \arrow{r}{d_2} \arrow[dashed]{d}{f_2} & \dots \\
0 \arrow{r} & N \arrow[swap]{r}{j} & J_0 \arrow[swap]{r}{d_0'} & J_1 \arrow[swap]{r}{d_1'} & J_2 \arrow[swap]{r}{d_2'} & \dots
\end{tikzcd}
$$
commutes, and
\item if $ \br{g_i} $ is another set of maps $ g_i : I_i \to J_i $ such that the diagram
$$
\begin{tikzcd}
0 \arrow{r} & M \arrow{r}{i} \arrow{d}{\psi} & I_0 \arrow{r}{d_0} \arrow[bend right=30, swap]{d}{f_0} \arrow[bend left=30]{d}{g_0} & I_1 \arrow{r}{d_1} \arrow[bend right=30, swap]{d}{f_1} \arrow[bend left=30]{d}{g_1} & I_2 \arrow{r}{d_2} \arrow[bend right=30, swap]{d}{f_2} \arrow[bend left=30]{d}{g_2} & \dots \\
0 \arrow{r} & N \arrow[swap]{r}{j} & J_0 \arrow[swap]{r}{d_0'} & J_1 \arrow[swap]{r}{d_1'} & J_2 \arrow[swap]{r}{d_2'} & \dots
\end{tikzcd}
$$
commutes, then there exist maps $ s_i : I_{i + 1} \to J_i $ such that
$$ g_i - f_i =
\begin{cases}
s_i \circ d_i + d_{i - 1}' \circ s_{i - 1} & i > 0 \\
s_0 \circ d_0 & i = 0
\end{cases},
$$
so
$$
\begin{tikzcd}
0 \arrow{r} & M \arrow{r}{i} \arrow{d}{\psi} & I_0 \arrow{r}{d_0} & I_1 \arrow{r}{d_1} \arrow[dashed, swap]{dl}{s_0} & I_2 \arrow{r}{d_2} \arrow[dashed, swap]{dl}{s_1} & \dots \arrow[dashed, swap]{dl}{s_2} \\
0 \arrow{r} & N \arrow[swap]{r}{j} & J_0 \arrow[swap]{r}{d_0'} & J_1 \arrow[swap]{r}{d_1'} & J_2 \arrow[swap]{r}{d_2'} & \dots
\end{tikzcd}.
$$
\end{itemize}
\end{proposition}

\begin{proof}
Very similar to Proposition \ref{prop:projectiveresolution}.
\end{proof}

\lecture{19}{Friday}{21/02/20}

Lecture 19 is a problems class.

\pagebreak

\section{Complexes and homology}

\subsection{Chain complexes}

\lecture{20}{Monday}{24/02/20}

\begin{definition}
A \textbf{chain complex} is a series $ A_* = \br{A_i} $, with maps $ d_i^A = d_i = d : A_{i + 1} \to A_i $ such that $ d^2 = 0 $, that is $ d_{i + 1} \circ d_i = 0 $, or $ \Im d_{i + 1} \le \Ker d_i $.
\end{definition}

\begin{definition}
A \textbf{cochain complex} is a series $ A^* = \br{A^i} $ with maps $ d_i^A = d_i = d : A^i \to A^{i + 1} $ such that $ d^2 = 0 $, or $ \Im d_i \le \Ker d_{i + 1} $.
\end{definition}

Let $ A_* $ and $ B_* $ be chain complexes. Let $ f = \br{f_i} $ be a family of $ R $-module homomorphisms $ f_i : A_i \to B_i $. Say that $ f $ is a \textbf{map of chain complexes} if $ f \circ d = d \circ f $, that is $ f_i \circ d_i^A = d_i^B \circ f_{i + 1} $. So
$$
\begin{tikzcd}
\dots \arrow{r}{d_{n + 1}} & A_{n + 1} \arrow{r}{d_n} \arrow{d}{f_{n + 1}} & A_n \arrow{r}{d_{n - 1}} \arrow{d}{f_n} & A_{n - 1} \arrow{r}{d_{n - 2}} \arrow{d}{f_{n - 1}} & \dots \\
\dots \arrow[swap]{r}{d_{n + 1}} & B_{n + 1} \arrow[swap]{r}{d_n} & B_n \arrow[swap]{r}{d_{n - 1}} & A_{n - 1} \arrow[swap]{r}{d_{n - 2}} & \dots
\end{tikzcd}
$$
commutes. Say that $ f $ \textbf{has property $ \PPP $} if all $ f_i $ have property $ \PPP $, where $ \PPP $ is injective, surjective, etc. A sequence
$$ A_* \xrightarrow{f} B_* \xrightarrow{g} C_* $$
is \textbf{exact} at $ B_* $ if
$$ A_n \xrightarrow{f_n} B_n \xrightarrow{g_n} C_n $$
is exact at $ B_n $ for all $ n $. A sequence of chain complexes is \textbf{exact} if it is exact everywhere. An \textbf{exact sequence}
$$ 0 \to A_* \to B_* \to C_* \to 0 $$
is a short exact sequence of chain complexes.

\subsection{Homology groups}

\begin{definition}
Let $ A_* $ be a chain complex. The \textbf{$ n $-th homology group} of $ A_* $ is $ \Ker d_{n - 1} / \Im d_n $. We write $ \H_n\br{A_*} $. Also write $ \H_*\br{A_*} = \br{\H_n\br{A_*}} $.
\end{definition}

\begin{definition}
Let $ A^* $ be a cochain complex. The \textbf{$ n $-th cohomology group} of $ A^* $ is $ \Ker d_n / \Im d_{n - 1} $. We write $ \H^n\br{A^*} $, and $ \H^*\br{A^*} = \br{\H^n\br{A^*}} $.
\end{definition}

\begin{example*}
Let $ A_i = \ZZ^3 $ for all $ i $, and let $ d\br{a, b, c} = \br{0, 0, a} $. Certainly $ d^2 = 0 $, so this is a chain complex. Then
$$ \Ker d = \cbr{\br{0, b, c}} = 0 \oplus \ZZ^2, \qquad \Im d = \cbr{\br{0, 0, a}} = 0^2 \oplus \ZZ. $$
Now
$$ \Ker d_{n - 1} / \Im d_n = \cbr{\br{0, b, 0} + 0^2 \oplus \ZZ}. $$
\end{example*}

\begin{proposition}
A map of chain complexes $ f : A_* \to B_* $ induces a map on the homology,
$$ f_* : \H_*\br{A_*} \to \H_*\br{B_*}, $$
given by
$$ \function[f_{*i}]{\H_i\br{A_*}}{\H_i\br{B_*}}{x + \Im d_i^A}{f_i\br{x} + \Im d_i^B}. $$
\end{proposition}

\begin{proof}
Let $ x \in \Ker d_{i - 1}^A $. Then $ \br{f_{i - 1} \circ d_{i - 1}^A}\br{x} = 0 $, so $ \br{d_{i - 1}^B \circ f_i}\br{x} = 0 $. Hence $ f_i\br{x} \in \Ker d_{i - 1}^B $. So $ f_i $ certainly induces a map $ \overline{f_i} : \Ker d_{i - 1}^A \to \Ker d_{i - 1}^B / \Im d_i^B $. So there exists $ y \in A_{i + 1} $ with $ d_i^A\br{y} = x $. Now $ f_i\br{x} = \br{f_i \circ d_i^A}\br{y} = \br{d_i^B \circ f_{i + 1}}\br{y} \in \Im d_i^B $, so $ \overline{f_i}\br{x} = 0 $. Hence $ \Im d_i^A \le \Ker \overline{f_i} $ so $ \overline{f_i} $ induces a map
$$ \Ker d_{i - 1}^A / \Im d_i^A = \H_i\br{A_*} \to \Ker d_{i - 1}^B / \Im d_i^B = \H_i\br{B_*}. $$
\end{proof}

\pagebreak

Let $ A_* $ and $ B_* $ be chain complexes, and let $ f $ and $ g $ be maps between them. We say that $ f $ and $ g $ are \textbf{equal up to homotopy} if there exist maps $ s_i : A_i \to B_{i + 1} $ such that
$$ g_i - f_i = s_{i - 1} \circ d_{i - 1}^A + d_i^B \circ s_i. $$

\begin{proposition}
If $ f, g : A_* \to B_* $ are equal up to homotopy, then $ f_* = g_* $, so $ f $ and $ g $ induce the same map on homology.
\end{proposition}

\begin{proof}
Exercise. \footnote{Exercise}
\end{proof}

\subsection{The long exact sequence in homology}

\begin{proposition}
Let
$$ 0 \to A_* \xrightarrow{f} B_* \xrightarrow{g} C_* \to 0 $$
be a short exact sequence. This induces a long exact sequence
$$ \dots \to \H_{n + 1}\br{A_*} \to \H_{n + 1}\br{B_*} \to \H_{n + 1}\br{C_*} \to \H_n\br{A_*} \to \H_n\br{B_*} \to \H_n\br{C_*} \to \dots. $$
\end{proposition}

\begin{proof}
We have a commuting diagram with exact rows
$$
\begin{tikzcd}
0 \arrow{r} & A_{n + 1} \arrow{r}{f_{n + 1}} \arrow{d}{d_n^A} & B_{n + 1} \arrow{r}{g_{n + 1}} \arrow{d}{d_n^B} & C_{n + 1} \arrow{r} \arrow{d}{d_n^C} & 0 \\
0 \arrow{r} & A_n \arrow[swap]{r}{f_n} & B_n \arrow[swap]{r}{g_n} & C_n \arrow{r} & 0
\end{tikzcd}.
$$
Notice $ \Im d_n \le \Ker d_{n - 1} $, so we can change this to
$$
\begin{tikzcd}
0 \arrow{r} & A_{n + 1} \arrow{r}{f_{n + 1}} \arrow{d}{d_n^A} & B_{n + 1} \arrow{r}{g_{n + 1}} \arrow{d}{d_n^B} & C_{n + 1} \arrow{r} \arrow{d}{d_n^C} & 0 \\
0 \arrow{r} & \Ker d_{n - 1}^A \arrow[swap]{r}{f_n} & \Ker d_{n - 1}^B \arrow[swap]{r}{g_n} & \Ker d_{n - 1}^C &
\end{tikzcd}.
$$
Now $ \Im d_{n + 1} \le \Ker d_n $, so the maps $ A_{n + 1} \to \Ker d_{n + 1} $ induce maps $ A_{n + 1} / \Im d_{n + 1} \to \Ker d_{n - 1} $. So we get a diagram
$$
\begin{tikzcd}
& A_{n + 1} / \Im d_{n + 1}^A \arrow{r}{f_{n + 1}} \arrow{d}{\overline{d_n^A}} & B_{n + 1} / \Im d_{n + 1}^B \arrow{r}{g_{n + 1}} \arrow{d}{\overline{d_n^B}} & C_{n + 1} / \Im d_{n + 1}^C \arrow{r} \arrow{d}{\overline{d_n^C}} & 0 \\
0 \arrow{r} & \Ker d_{n - 1}^A \arrow[swap]{r}{f_n} & \Ker d_{n - 1}^B \arrow[swap]{r}{g_n} & \Ker d_{n - 1}^C &
\end{tikzcd}.
$$
We are now in the position to apply the snake lemma, so
$$ \Ker \overline{d_n^A} \to \Ker \overline{d_n^B} \to \Ker \overline{d_n^C} \to \Coker \overline{d_n^A} \to \Coker \overline{d_n^B} \to \Coker \overline{d_n^C} $$
is an exact sequence. Then
$$ \Ker \overline{d_n^A} = \Ker d_n^A / \Im d_{n + 1}^A = \H_{n + 1}\br{A_*}, \qquad \Coker \overline{d_n^A} = \Ker d_{n - 1}^A / \Im d_n^A = \H_n\br{A_*}. $$
Similarly for $ B_* $ and $ C_* $. So we have an exact sequence
$$ \H_{n + 1}\br{A_*} \to \H_{n + 1}\br{B_*} \to \H_{n + 1}\br{C_*} \to \H_n\br{A_*} \to \H_n\br{B_*} \to \H_n\br{C_*}. $$
Since consecutive values of $ i $ give a sequence overlapping in three terms we can glue them together, to give the long exact sequence in the proposition.
\end{proof}

\pagebreak

\section{Derived functors}

\subsection{Covariant and contravariant functors}

\lecture{21}{Tuesday}{25/02/20}

The following are two variations.

\begin{definition}
A \textbf{covariant functor} $ F $ from the category of left or right $ R $-modules to the category of abelian groups is a map from $ R $-modules to abelian groups such that if $ \phi : M \to N $ is an $ R $-module homomorphism then there exists an abelian group homomorphism
$$ F\br{\phi} : F\br{M} \to F\br{N}, $$
which respects identity maps, so $ F\br{\id_M} = \id_{F\br{M}} $, and respects composition, so
$$ F\br{\phi_1 \circ \phi_2} = F\br{\phi_1} \circ F\br{\phi_2}. $$
\end{definition}

The map $ F $ on homomorphisms is \textbf{additive} if $ F\br{\phi_1 + \phi_2} = F\br{\phi_1} + F\br{\phi_2} $. If
$$ 0 \to A \to B \to C \to 0 $$
be a short exact sequence, then $ F $ is \textbf{right exact} if
$$ F\br{A} \to F\br{B} \to F\br{C} \to 0 $$
is exact, \textbf{left exact} if
$$ 0 \to F\br{A} \to F\br{B} \to F\br{C} $$
is exact. Then $ F $ is \textbf{exact} if both left and right exact.

\begin{definition}
A \textbf{contravariant functor} $ F $ from the category of left or right $ R $-modules to the category of abelian groups is a map from $ R $-modules to abelian groups such that if $ \phi : M \to N $ is an $ R $-module homomorphism then there exists an abelian group homomorphism
$$ F\br{\phi} : F\br{N} \to F\br{M}, $$
which respects identity maps, so $ F\br{\id_M} = \id_{F\br{M}} $, and respects composition, so
$$ F\br{\phi_1 \circ \phi_2} = F\br{\phi_2} \circ F\br{\phi_1}. $$
\end{definition}

Similarly, if
$$ 0 \to A \to B \to C \to 0 $$
be a short exact sequence, then $ F $ is \textbf{right exact} if
$$ F\br{C} \to F\br{B} \to F\br{A} \to 0 $$
is exact, and \textbf{left exact} if
$$ 0 \to F\br{C} \to F\br{B} \to F\br{A} $$
is exact.

\begin{example*}
Some functors we have seen. Fix a left $ R $-module $ M $.
\begin{itemize}
\item $ F\br{A} = \Hom_R\br{M, A} $, where
$$ \function[F\br{\phi}]{F\br{A} = \Hom_R\br{M, A}}{F\br{B} = \Hom_R\br{M, B}}{f}{\phi \circ f}, \qquad \phi : A \to B, $$
is covariant, left exact, and exact if and only if $ M $ is projective.
\item $ F\br{A} = \Hom_R\br{A, M} $, where
$$ \function[F\br{\phi}]{F\br{B} = \Hom_R\br{B, M}}{F\br{A} = \Hom_R\br{A, M}}{f}{f \circ \phi}, \qquad \phi : A \to B, $$
is contravariant, left exact, and exact if and only if $ M $ is injective.
\item For a right $ R $-module $ A $, $ F\br{A} = A \otimes_R M $ is covariant, right exact, and exact if and only if $ M $ is flat.
\end{itemize}
\end{example*}

\pagebreak

\subsection{Left derived functors}

Let $ F $ be the functor $ F\br{A} = A \otimes_R M $, where $ M $ is a fixed $ R $-module. Let $ P_* \to A $ be a projective resolution for $ A $. So $ P_* = \br{P_i}_{i \ge 0} $ for projective $ P_i $, and
$$ \dots \xrightarrow{d_2} P_2 \xrightarrow{d_1} P_1 \xrightarrow{d_0} P_0 \xrightarrow{\phi} A \to 0 $$
is exact. Consider the sequence
$$ \dots \to P_2 \to P_1 \to P_0 \to 0. $$
This is no longer exact, but it is a chain complex. And if we apply $ F $, we get a chain complex $ F\br{P_*} $,
$$ \dots \to F\br{P_2} \to F\br{P_1} \to F\br{P_0} \to 0. $$
Define \textbf{left derived functors}
$$ \L_nF\br{A} = \H_n\br{F\br{P_*}}. $$

\begin{theorem}
\hfill
\begin{enumerate}
\item $ \L_nF\br{A} $ does not depend on the choice of resolution $ P_* $.
\item $ \L_nF $ is an additive functor from right $ R $-modules to abelian groups.
\item $ \L_0F\br{A} = F\br{A} $.
\end{enumerate}
\end{theorem}

\lecture{22}{Friday}{28/02/20}

\begin{proof}
\hfill
\begin{enumerate}
\item Let $ P_* \to A $ and $ Q_* \to A $ be projective resolutions. Then there exist maps of chain complexes $ f : P_* \to Q_* $ and $ g : Q_* \to P_* $. So $ g \circ f : P_* \to P_* $, so
$$
\begin{tikzcd}
\dots \arrow{r}{d_2} & P_2 \arrow{r}{d_1} \arrow{d}{g_2 \circ f_2} & P_1 \arrow{r}{d_0} \arrow{d}{g_1 \circ f_1} & P_0 \arrow{r} \arrow{d}{g_0 \circ f_0} & A \arrow{r} \arrow{d}{\id} & 0 \\
\dots \arrow[swap]{r}{d_2} & P_2 \arrow[swap]{r}{d_1} & P_1 \arrow[swap]{r}{d_0} & P_0 \arrow{r} & A \arrow{r} & 0
\end{tikzcd},
$$
and $ g \circ f $ is equal to $ \id $ up to homotopy. Apply $ F $ to everything. Since $ F $ is right exact,
$$
\begin{tikzcd}
\dots \arrow{r}{F\br{d_2}} & F\br{P_2} \arrow{r}{F\br{d_1}} \arrow{d}{F\br{g_2} \circ F\br{f_2}} & F\br{P_1} \arrow{r}{F\br{d_0}} \arrow{d}{F\br{g_1} \circ F\br{f_1}} & F\br{P_0} \arrow{r} \arrow{d}{F\br{g_0} \circ F\br{f_0}} & F\br{A} \arrow{r} \arrow{d}{\id} & 0 \\
\dots \arrow[swap]{r}{F\br{d_2}} & F\br{P_2} \arrow[swap]{r}{F\br{d_1}} & F\br{P_1} \arrow[swap]{r}{F\br{d_0}} & F\br{P_0} \arrow{r} & F\br{A} \arrow{r} & 0
\end{tikzcd}.
$$
The diagram remains commutative, since $ F $ preserves composition. Now
$$ g_i \circ f_i - \id = s_{i - 1} \circ d_{i - 1} + d_i \circ s_i, $$
for suitable maps $ s_i $. Then
$$ F\br{g_i} \circ F\br{f_i} - \id = F\br{s_{i - 1}} \circ F\br{d_{i - 1}} + F\br{d_i} \circ F\br{s_i}. $$
So $ F\br{g_i} \circ F\br{f_i} $ is $ \id $ up to homotopy. Hence $ F\br{g} \circ F\br{f} $ induces the identity on homology $ \H_*\br{F\br{P_*}} $. Also $ F\br{f} \circ F\br{g} $ induces the identity on $ \H_*\br{F\br{Q_*}} $. Now we have
$$ \overline{F\br{f_i}} : \H_i\br{F\br{P_*}} \to \H_i\br{F\br{Q_*}}, \qquad \overline{F\br{g_i}} : \H_i\br{F\br{Q_*}} \to \H_i\br{F\br{P_*}}, $$
and $ \overline{F\br{f_i}} \circ \overline{F\br{g_i}} = \id $ and $ \overline{F\br{g_i}} \circ \overline{F\br{f_i}} = \id $, so $ \overline{F\br{f_i}} $ and $ \overline{F\br{g_i}} $ are isomorphisms. So
$$ \H_n\br{F\br{P_*}} \cong \H_n\br{F\br{Q_*}}, $$
as required. This argument tells us nothing about $ \H_0\br{F\br{P_*}} $.

\pagebreak

\item Let $ \phi : A \to B $. Let $ P_* \to A $ and $ Q_* \to B $ be projective resolutions. Then there exists $ f : P_* \to Q_* $ such that
$$
\begin{tikzcd}
P_* \arrow{r} \arrow[swap]{d}{f} & A \arrow{r} \arrow{d}{\phi} & 0 \\
Q_* \arrow{r} & B \arrow{r} & 0
\end{tikzcd}
$$
commutes. Then $ F $ is covariant and right exact. So
$$
\begin{tikzcd}
F\br{P_*} \arrow{r} \arrow[swap]{d}{F\br{f}} & F\br{A} \arrow{r} \arrow{d}{F\br{\phi}} & 0 \\
F\br{Q_*} \arrow{r} & F\br{B} \arrow{r} & 0
\end{tikzcd}
$$
is commutative, where $ F\br{f} = \br{F\br{f_i}} $. If $ g : P_* \to Q_* $ is such that
$$
\begin{tikzcd}
P_* \arrow{r} \arrow[swap]{d}{g} & A \arrow{r} \arrow{d}{\phi} & 0 \\
Q_* \arrow{r} & B \arrow{r} & 0
\end{tikzcd}
$$
commutes, then $ \overline{f} $ and $ \overline{g} $, the induced maps on homology, are equal. So there exists a map $ \overline{F\br{f_i}} : \L_iF\br{A} \to \L_iF\br{B} $, and is independent of the choice of $ f $. So we can write $ \L_nF\br{\phi} = \overline{F\br{f_i}} $. Then $ \L_nF $ preserves identity and compositions and is additive, since $ F $ is an additive functor. \footnote{Exercise}
\item We have a short exact sequence
$$ 0 \to \Im d_0 \xrightarrow{\subset} P_0 \xrightarrow{\phi} A \to 0. $$
Since $ F $ is right exact, we get an exact sequence
$$ F\br{\Im d_0} \to F\br{P_0} \to F\br{A} \to 0. $$
Now $ d_0 : P_1 \to \Im d_0 $ is surjective, and $ F $ preserves surjectivity. So $ F\br{d_0} : F\br{P_1} \to F\br{\Im d_0} $ is surjective. So
$$ F\br{P_1} \to F\br{P_0} \to F\br{A} \to 0 $$
is exact. So, setting $ P_{-1} = 0 $, we get $ \L_0F\br{P_*} = F\br{P_0} / \Im F\br{d_0} = F\br{A} $.
\end{enumerate}
\end{proof}

\pagebreak

\subsection{The long exact sequence of left derived functors}

\begin{proposition}[Horseshoe lemma]
Suppose
$$ 0 \to A \to B \to C \to 0 $$
is an exact sequence of $ R $-modules. Suppose $ P_* \to A $ and $ R_* \to C $ are projective resolutions. Define $ Q_i = P_i \oplus R_i $. Then there exist maps $ Q_{i + 1} \to Q_i $ and $ Q_0 \to B $ such that $ Q_* \to B $ is a projective resolution, and such that
$$
\begin{tikzcd}[row sep=small]
& 0 \arrow{d} & 0 \arrow{d} & 0 \arrow{d} & 0 \arrow{d} & \\
\dots \arrow{r} & P_2 \arrow{r} \arrow{d}{\iota} & P_1 \arrow{r} \arrow{d}{\iota} & P_0 \arrow{r} \arrow{d}{\iota} & A \arrow{r} \arrow{d} & 0 \\
\dots \arrow[dashed]{r} & Q_2 \arrow[dashed]{r} \arrow{d}{\pi} & Q_1 \arrow[dashed]{r} \arrow{d}{\pi} & Q_0 \arrow[dashed]{r} \arrow{d}{\pi} & B \arrow[dashed]{r} \arrow{d} & 0 \\
\dots \arrow{r} & R_2 \arrow{r} \arrow{d} & R_1 \arrow{r} \arrow{d} & R_0 \arrow{r} \arrow{d} & C \arrow{r} \arrow{d} & 0 \\
& 0 & 0 & 0 & 0 &
\end{tikzcd}
$$
commutes, where if $ x \in P_i $ and $ y \in R_i $ then $ \iota\br{x} = \br{x, 0} $ and $ \pi\br{x, y} = y $.
\end{proposition}

\begin{note*}
$ Q_i $ is a direct sum of projectives, so is itself projective.
\end{note*}

\begin{proof}
We have the setup
$$
\begin{tikzcd}[row sep=small]
0 \arrow{d} & 0 \arrow{d} & \\
P_0 \arrow{r}{\phi} \arrow[swap]{d}{\iota} & A \arrow{r} \arrow{d}{f} & 0 \\
Q_0 \arrow[swap]{d}{\pi} & B \arrow{d}{g} & \\
R_0 \arrow[swap]{r}{\psi} \arrow{d} & C \arrow{r} \arrow{d} & 0 \\
0 & 0 &
\end{tikzcd}.
$$
Since $ B \to C $ is surjective, and $ R_0 $ is projective, there exists $ h : R_0 \to B $ such that $ g \circ h = \psi $. Now define
$$ \function[\chi]{Q_0}{B}{\br{x, y}}{\br{f \circ \phi}\br{x} + h\br{y}}, \qquad x \in P_0, \qquad y \in R_0. $$
This construction guarantees that the squares are commutative. It is easy to see that $ \chi $ is surjective, so
$$
\begin{tikzcd}[row sep=small]
0 \arrow{d} & 0 \arrow{d} & \\
P_0 \arrow{r}{\phi} \arrow[swap]{d}{\iota} & A \arrow{r} \arrow{d}{f} & 0 \\
Q_0 \arrow[dashed]{r}{\chi} \arrow[swap]{d}{\pi} & B \arrow[dashed]{r} \arrow{d}{g} & 0 \\
R_0 \arrow[dashed]{ur}{h} \arrow[swap]{r}{\psi} \arrow{d} & C \arrow{r} \arrow{d} & 0 \\
0 & 0 &
\end{tikzcd}.
$$
Now we have a short exact sequence
$$ 0 \to \Ker \phi \xrightarrow{\iota} \Ker \chi \xrightarrow{\pi} \Ker \psi \to 0, $$
by the snake lemma. So now we can iterate, replacing $ A, B, C $ with these kernels, to construct a map $ Q_1 \to Q_0 $, and so on.
\end{proof}

\pagebreak

\begin{proposition}
Let $ F $ be an additive functor, and let $ A $ and $ B $ be $ R $-modules. There is a canonical isomorphism $ F\br{A} \oplus F\br{B} \to F\br{A \oplus B} $.
\end{proposition}

\begin{proof}
Let $ M = A \oplus B $. Consider functions
$$ \function[p_1]{M}{M}{\br{a, b}}{\br{a, 0}}, \qquad \function[p_2]{M}{M}{\br{a, b}}{\br{0, b}}. $$
Then $ p_i^2 = p_i $, $ p_1 \circ p_2 = p_2 \circ p_1 = 0 $, and $ p_1 + p_2 = \id_M $. If $ q_1 $ and $ q_2 $ are maps on a module $ M $ satisfying these relations, then $ M = q_1\br{M} \oplus q_2\br{M} $.
\end{proof}

\lecture{23}{Monday}{02/03/20}

\begin{proposition}
Let
$$ 0 \to A \to B \to C \to 0 $$
be a short exact sequence of right $ R $-modules. This gives rise to a long exact sequence
$$ \dots \to \L_nF\br{A} \to \L_nF\br{B} \to \L_nF\br{C} \to \dots \to \L_0F\br{A} \to \L_0F\br{B} \to \L_0F\br{C} \to 0. $$
\end{proposition}

\begin{proof}
Let $ P_* \to A $ be a projective resolution and $ R_* \to C $ be a projective resolution. By the horseshoe lemma, there exists a projective resolution $ Q_* \to B $ such that
$$ 0 \to P_* \to Q_* \to R_* \to 0 $$
is a split short exact sequence of chain complexes, that is $ Q_i = P_i \oplus R_i $. Since $ Q_i = P_i \oplus R_i $, and since $ F $ is an additive functor, we have $ F\br{Q_i} = F\br{P_i} \oplus F\br{R_i} $. So
$$ 0 \to F\br{P_*} \to F\br{Q_*} \to F\br{R_*} \to 0 $$
is a short exact sequence. Therefore we get a long exact sequence on homology,
$$ \dots \to \H_n\br{F\br{P_*}} \to \H_n\br{F\br{Q_*}} \to \H_n\br{F\br{R_*}} \to \dots. $$
Since $ \H_n\br{F\br{P_*}} = \L_nF\br{A} $ this gives the long sequence that we need. Since $ \L_0F\br{A} = F\br{A} $, and $ F $ is right exact, the sequence terminates
$$ \L_0F\br{A} \to \L_0F\br{B} \to \L_0F\br{C} \to 0, $$
as required.
\end{proof}

\subsection{General derived functors}

\begin{proposition}
\hfill
\begin{itemize}
\item Let $ F $ be any covariant, right exact, additive functor from left or right $ R $-modules to abelian groups. Then the left derived functors $ \L_nF $ can be defined in just the same way as we did for the case $ F\br{A} = A \otimes_R M $. All of the results we have proved follow in the more general case, by the same arguments.
\item If $ F $ is a covariant, left exact, additive functor from $ R $-modules to abelian groups, then we can define \textbf{right derived functors} $ \R^iF $ in a similar manner. Instead of working with a projective resolution, we use an injective resolution,
$$ 0 \to A \to I_0 \to I_1 \to I_2 \to \dots. $$
By similar arguments, we show that $ \R^iF\br{A} $ is independent of the choice of injective resolution. All of the results we proved for left derived functors have natural analogies for right derived functors. The argument requires a version of the horseshoe lemma for injective resolutions, which is exactly what one might expect.
\item We can even construct derived functors for contravariant functors. If $ F $ is contravariant and right exact, so
$$ 0 \to A \to I_0 \to I_1 \to I_2 \to \dots $$
is exact implies that
$$ \dots \to F\br{I_2} \to F\br{I_1} \to F\br{I_0} \to F\br{A} \to 0 $$
is exact, we get a left derived functor, which is defined using an injective resolution. If $ F $ is contravariant and left exact, we get a right derived functor, which is defined using a projective resolution.
\end{itemize}
\end{proposition}

\pagebreak

\section{Tor and Ext}

\subsection{Balancing theorems}

\begin{definition}
Let $ F $ be the functor $ F\br{A} = A \otimes_R B $. Then $ F $ is covariant, right exact, and additive. So $ \L_nF $ exists. Define
$$ \Tor_i^R\br{A, B} = \L_iF\br{A}. $$
\end{definition}

\begin{fact*}
Let $ F' $ be the functor $ F'\br{B} = A \otimes_R B $. Then $ F' $ is covariant, right exact, and additive. So $ \L_nF' $ exists. We have
$$ \L_iF'\br{B} \cong \L_iF\br{A} = \Tor_i^R\br{A, B}. $$
\end{fact*}

\begin{definition}
Let $ F $ be the functor $ F\br{B} = \Hom_R\br{A, B} $. Then $ F $ is covariant, left exact, and additive, so $ \R^nF $ exists. Define
$$ \Ext_R^i\br{A, B} = \R^iF\br{B}. $$
\end{definition}

\begin{fact*}
Let $ F' $ be the functor $ F'\br{A} = \Hom_R\br{A, B} $. Then $ F' $ is contravariant, left exact, and additive, so $ \R^nF' $ exists. We have
$$ \R^iF'\br{A} \cong \R^iF\br{B} = \Ext_R^i\br{A, B}. $$
\end{fact*}

The two facts above are the \textbf{balancing theorems} for Tor and Ext. Their proof is beyond the scope of the course.

\subsection{Tor, flatness, and torsion}

The following is an observation. Suppose $ A $ is projective. Then a projective resolution for $ A $ is
$$ 0 \to \dots \to 0 \to A \xrightarrow{\id} A \to 0. $$
So $ \L_iF\br{A} = 0 $ for $ i \ge 1 $, and $ \L_0F\br{A} = F\br{A} $, for $ F $ possessing left derived functors. Similarly, if $ A $ is injective, then an injective resolution is
$$ 0 \to A \xrightarrow{\id} A \to 0 \to \dots \to 0, $$
so $ \R^iF\br{A} = 0 $ for $ i \ge 1 $, and $ \R^0F\br{A} = F\br{A} $, for $ F $ possessing right derived functors. In fact the property $ \Tor_i^R\br{A, B} = 0 $ for all $ i \ge 0 $ characterises flat modules, so either $ A $ or $ B $ is flat.

\begin{proposition}
Let $ F\br{A} = A \otimes_R B $. Then $ \L_iF\br{A} = \Tor_i^R\br{A, B} = 0 $ for all $ i \ge 1 $ and for all $ A $ if and only if $ B $ is flat.
\end{proposition}

Similarly if $ F'\br{B} = A \otimes_R B $, then $ \L_iF'\br{B} = 0 $ for all $ i \ge 1 $ and for all $ B $ if and only if $ A $ is flat.

\lecture{24}{Tuesday}{03/03/20}

\begin{proof}
\hfill
\begin{itemize}
\item[$ \impliedby $] If $ B $ is flat then $ F\br{A} = A \otimes_R B $ is exact, so
$$ 0 \to L \to M \to N \to 0 $$
is exact implies that
$$ 0 \to F\br{L} \to F\br{M} \to F\br{N} \to 0 $$
is exact, or $ F $ maps kernels to kernels and cokernels to cokernels. Let $ P_* \to A $ be a projective resolution. Then
$$ \dots \to P_2 \to P_1 \to P_0 \to 0 $$
is exact everywhere except $ P_0 $. So
$$ \dots \to F\br{P_2} \to F\br{P_1} \to F\br{P_0} \to 0 $$
is exact everywhere except $ F\br{P_0} $. So $ \L_nF\br{P_*} = 0 $ for $ n \ge 1 $. But $ \L_nF\br{P_*} = \Tor_n^R\br{A, B} $.

\pagebreak

\item[$ \implies $] Conversely, suppose $ \Tor_i^R\br{A, B} = 0 $ for all $ A $. Let
$$ 0 \to L \to M \to N \to 0 $$
be exact. This gives a long exact sequence of homology groups
$$
\begin{tikzcd}[column sep=small, row sep=tiny]
\dots \arrow{r} & \L_1F\br{L} \arrow{r} & \L_1F\br{M} \arrow{r} & \L_1F\br{N} \arrow{r} \arrow[cong]{d} & L \otimes_R B \arrow{r} & M \otimes_R B \arrow{r} & N \otimes_R B \arrow{r} & 0 \\
& & & \Tor_1^R\br{N, B} & & & &
\end{tikzcd}.
$$
Since $ \Tor_1^R\br{N, B} = 0 $, we get a short exact sequence
$$ 0 \to L \otimes_R B \to M \otimes_R B \to N \otimes_R B \to 0. $$
So $ F\br{A} = A \otimes_R B $ is left exact, and so $ B $ is flat.
\end{itemize}
\end{proof}

\begin{proposition}
Let $ A $ and $ B $ be abelian groups. Then
$$ \Tor_n^\ZZ\br{A, B} = 0, \qquad n > 1. $$
\end{proposition}

\begin{proof}
$ A $ is a quotient of some free module $ K $, say
$$ K \xrightarrow{f} A \to 0. $$
Now $ \Ker f \le K $, and since $ \ZZ $ is a PID, $ \Ker f $ is free, since it is a submodule of a free module. So
$$ \dots \to 0 \to \Ker f \to K \to A \to 0 $$
is a projective resolution for $ A $. Since all of the modules above $ P_1 $ in the resolution are zero, clearly $ \H_n\br{P_*} = 0 $ for $ n > 1 $.
\end{proof}

\begin{fact*}
$$ \Tor_1^\ZZ\br{A, \QQ / \ZZ} = \T\br{A} = \cbr{a \in A \st a \ \text{has finite order}}. $$
The proof is omitted.
\end{fact*}

\subsection{Baer sums of extensions}

\begin{proposition}
Let $ A $ and $ B $ be abelian groups. Then
$$ \Ext_\ZZ^n\br{A, B} = 0, \qquad n > 1. $$
\end{proposition}

\begin{proof}
Problem sheet question.
\end{proof}

More generally, $ \Ext_R^1\br{A, C} $ tells us about \textbf{extensions} of $ C $ by $ A $, that is $ B $ such that
$$ 0 \to A \to B \to C \to 0. $$
Let $ B_1 $ and $ B_2 $ be two extensions of $ C $ by $ A $. Write $ B_1 \sim B_2 $ if there exists a \textbf{map of extensions} $ f : B_1 \to B_2 $ such that
$$
\begin{tikzcd}[row sep=tiny]
& & B_1 \arrow{dr}{\beta_1} \arrow{dd}{f} & & \\
0 \arrow{r} & A \arrow{ur}{\alpha_1} \arrow[swap]{dr}{\alpha_2} & & C \arrow{r} & 0 \\
& & B_2 \arrow[swap]{ur}{\beta_2} & &
\end{tikzcd}
$$
commutes.

\pagebreak

\begin{proposition}
Any such $ f $ is an isomorphism.
\end{proposition}

\begin{proof}
\hfill
\begin{itemize}
\item $ f $ is surjective. Suppose $ y \in B_2 $. Then $ \beta_2\br{y} \in C $, and $ \beta_1 $ is surjective, so $ \beta_2\br{y} = \beta_1\br{x} $ for some $ x \in B_1 $. Now $ f\br{x} - y \in \Ker \beta_2 = \Im \alpha_2 $, so $ f\br{x} - y = \alpha_2\br{a} $ for some $ a \in A $. So $ f\br{x} - y = \br{f \circ \alpha_1}\br{a} $, and so $ y = f\br{x} - \br{f \circ \alpha_1}\br{a} = f\br{x - \alpha_1\br{a}} $.
\item $ f $ is injective. Suppose $ f\br{x} = f\br{y} $ for $ x, y \in B_1 $. Then $ f\br{x - y} = 0 $, so $ \br{\beta_2 \circ f}\br{x - y} = 0 $, so $ \beta_1\br{x - y} = 0 $. So $ x - y \in \Ker \beta_1 = \Im \alpha_1 $, so $ x - y = \alpha_1\br{a} $ for some $ a \in A $. Now $ \alpha_2\br{a} = \br{f \circ \alpha_1}\br{a} = f\br{x - y} = 0 $. But $ \alpha_2 $ is injective, so $ a = 0 $, so $ x - y = 0 $.
\end{itemize}
\end{proof}

Hence the relation $ \sim $ is an equivalence relation. Write $ \E_C\br{A} $ for the set of $ \sim $-equivalence classes. We will put an abelian group structure on $ \E_C\br{A} $. Let $ B_1 $ and $ B_2 $ be extensions, so
$$ 0 \to A \xrightarrow{\alpha_1} B_1 \xrightarrow{\beta_1} C \to 0, \qquad 0 \to A \xrightarrow{\alpha_2} B_2 \xrightarrow{\beta_2} C \to 0. $$
Define maps $ \alpha^* $ and $ \beta^* $ by
$$ \function[\alpha^*]{A}{B_1 \oplus B_2}{a}{\br{\alpha_1\br{a}, -\alpha_2\br{a}}}, \qquad \function[\beta^*]{B_1 \oplus B_2}{C}{\br{b_1, b_2}}{\beta_1\br{b_1} - \beta_2\br{b_2}}. $$
Now $ \beta^* \circ \alpha^* = 0 $. So
$$ 0 \to A \xrightarrow{\alpha^*} B_1 \oplus B_2 \xrightarrow{\beta^*} C \to 0 $$
is a chain complex. Define
$$ H = \H\br{B_1, B_2}, $$
the \textbf{Baer sum} of $ \sbr{B_1} $ and $ \sbr{B_2} $, to be the homology group at $ B_1 \oplus B_2 $, that is $ H = \Ker \beta^* / \Im \alpha^* $. More explicitly,
$$ H = \cbr{\br{b_1, b_2} \in B_1 \oplus B_2 \st \beta_1\br{b_1} = \beta_2\br{b_2}} / \cbr{\br{\alpha_1\br{a}, -\alpha_2\br{a}} \st a \in A}. $$
Clearly $ H $ is an $ R $-module. Now define maps
$$ \function[\alpha]{A}{H}{a}{\br{\alpha_1\br{a}, 0} + \Im \alpha^*}, \qquad \function[\beta]{H}{C}{\br{b_1, b_2} + \Im \alpha^*}{\beta_1\br{b_1}}. $$

\lecture{25}{Friday}{06/03/20}

\begin{note*}
$ \br{b_1, b_2} \in \Ker \beta^* $, so $ \beta_1\br{b_1} = \beta_2\br{b_2} $. Also $ \br{\alpha_1\br{a}, 0} = \br{0, \alpha_2\br{a}} + \br{\alpha_1\br{a}, -\alpha_2\br{a}} $, so $ \br{\alpha_1\br{a}, 0} + \Im \alpha^* = \br{0, \alpha_2\br{a}} + \Im \alpha^* $.
\end{note*}

\begin{proposition}
$$ 0 \to A \xrightarrow{\alpha} H \xrightarrow{\beta} C \to 0 $$
is a short exact sequence.
\end{proposition}

\begin{proof}
\hfill
\begin{itemize}
\item First check that $ \beta $ is well-defined. If $ \br{b_1, b_2} \in \br{b_1', b_2'} + \Im \alpha^* $ then $ \br{b_1, b_2} = \br{b_1', b_2'} + \br{\alpha_1\br{a}, -\alpha_2\br{a}} $ for some $ a \in A $. So
$$ \beta\br{\br{b_1, b_2} + \Im \alpha^*} = \beta_1\br{b_1} = \beta_1\br{b_1 - \alpha_1\br{a}} = \beta\br{\br{b_1', b_2'} + \Im \alpha^*}, $$
since $ \beta_1 \circ \alpha_1 = 0 $.
\item Next check $ \alpha $ is injective. Suppose $ \alpha\br{a} = \br{0, 0} + \Im \alpha^* $. Then $ \br{\alpha_1\br{a}, 0} = \alpha^*\br{a'} $ for some $ a' $. So $ \br{\alpha_1\br{a}, 0} = \br{\alpha_1\br{a'}, -\alpha_2\br{a'}} $. Since $ \alpha_1 $ and $ \alpha_2 $ are injective, $ a = a' = 0 $.
\item Next, show $ \beta $ is surjective. Take $ c \in C $. Then $ c = \beta_1\br{b_1} $ for some $ b_1 \in B_1 $. Since $ \beta_2 $ is surjective, there exists $ b_2 \in B_2 $ with $ \beta_2\br{b_2} = \beta_1\br{b_1} = c $. Now $ \br{b_1, b_2} \in \Ker \beta^* $, and $ \beta\br{\br{b_1, b_2} + \Im \alpha^*} = \beta_1\br{b_1} = c $.

\pagebreak

\item Finally, show that
$$ 0 \to A \to H \to C \to 0 $$
is exact, that is $ \Ker \beta = \Im \alpha $. It is clear that $ \Im \alpha \le \Ker \beta $, since $ \beta_1 \circ \alpha_1 = 0 $. For the reverse containment, let $ \br{b_1, b_2} + \Im \alpha^* \in \Ker \beta $. So $ \br{b_1, b_2} \in \Ker \beta^* $, so $ \beta_1\br{b_1} = \beta_2\br{b_2} $. And $ \beta_1\br{b_1} = 0 $, so $ \beta_2\br{b_2} = 0 $ as well. But $ \Ker \beta_i = \Im \alpha_i $ for $ i = 1, 2 $, so there exist $ a_1, a_2 \in A $ with $ \alpha_1\br{a_1} = b_1 $ and $ \alpha_2\br{a_2} = b_2 $. Now
\begin{align*}
\br{b_1, b_2}
& = \br{\alpha_1\br{a_1}, \alpha_2\br{a_2}}
= \br{\alpha_1\br{a_1 + a_2}, 0} + \br{-\alpha_1\br{a_2}, \alpha_2\br{a_2}} \\
& \in \br{\alpha_1\br{a_1 + a_2}, 0} + \Im \alpha^*
= \alpha\br{a_1 + a_2}
\in \Im \alpha.
\end{align*}
\end{itemize}
\end{proof}

We have shown that $ H $ is an extension of $ C $ by $ A $.

\begin{proposition}
If $ B_1 \sim B_1' $ and $ B_2 \sim B_2' $ then $ \H\br{B_1, B_2} \sim \H\br{B_1', B_2'} $, where $ B \sim B' $ if there exists a map of extensions $ f : B \to B' $ such that
$$
\begin{tikzcd}[row sep=tiny]
& & B \arrow{dr} \arrow{dd}{f} & & \\
0 \arrow{r} & A \arrow{ur} \arrow[swap]{dr} & & C \arrow{r} & 0 \\
& & B' \arrow[swap]{ur} & &
\end{tikzcd}
$$
commutes.
\end{proposition}

\begin{proof}
Suppose $ f_1 : B_1 \to B_1' $ and $ f_2 : B_2 \to B_2' $ are maps of extensions. Then there exists a map of chain complexes
$$
\begin{tikzcd}[row sep=tiny]
& & B_1 \oplus B_2 \arrow{dr} \arrow{dd}{\br{f_1, f_2}} & & \\
0 \arrow{r} & A \arrow{ur} \arrow[swap]{dr} & & C \arrow{r} & 0 \\
& & B_1' \oplus B_2' \arrow[swap]{ur} & &
\end{tikzcd}.
$$
This induces a map on homology, $ \overline{f} : \H\br{B_1, B_2} \to \H\br{B_1', B_2'} $. It is easy to check
$$
\begin{tikzcd}[row sep=tiny]
& & \H\br{B_1, B_2} \arrow{dr} \arrow{dd}{\overline{f}} & & \\
0 \arrow{r} & A \arrow{ur} \arrow[swap]{dr} & & C \arrow{r} & 0 \\
& & \H\br{B_1', B_2'} \arrow[swap]{ur} & &
\end{tikzcd}
$$
commutes, so $ \H\br{B_1, B_2} \sim \H\br{B_1', B_2'} $.
\end{proof}

Write $ \sbr{B} $ for the equivalence class of $ B $. If $ H = \H\br{B_1, B_2} $, write $ \sbr{H} = \sbr{B_1} + \sbr{B_2} $, or $ \sbr{H} = \sbr{B_1} +_\B \sbr{B_2} $.

\begin{proposition}
$ + $ gives an abelian group operation on the set $ \E_C\br{A} $ of equivalence classes of extensions.
\end{proposition}

\begin{proof}
\hfill
\begin{itemize}
\item Check $ + $ is commutative. This follows easily from the facts that
$$ \alpha\br{a} = \br{\alpha_1\br{0}, 0} + \Im \alpha^* = \br{0, \alpha_2\br{a}} + \Im \alpha^*, \qquad \beta\br{\br{b_1, b_2} + \Im \alpha^*} = \beta_1\br{b_1} = \beta_2\br{b_2}. $$
\item Associativity is an exercise. \footnote{Exercise}
\item The identity is $ \sbr{A \oplus C} $, the \textbf{split extension}. Let
$$ 0 \to A \xrightarrow{\alpha} A \oplus C \xrightarrow{\beta} C \to 0, \qquad 0 \to A \xrightarrow{\alpha'} B \xrightarrow{\beta'} C \to 0. $$
There is a map $ \pi : A \oplus C \to A $ such that $ \pi \circ \alpha = \id_A $. Consider a map
$$ \function[f]{\H\br{B, A \oplus C}}{B}{\br{b_1, b_2} + \Im \alpha^*}{b_1 + \alpha'\br{a}}, \qquad \beta'\br{b_1} = \beta\br{b_2}, \qquad b_2 = \br{a, c} \in A \oplus C. $$
It is easy to check this gives a map of extensions.

\pagebreak

\item Inverses. Suppose
$$ 0 \to A \xrightarrow{\alpha} B \xrightarrow{\beta} C \to 0. $$
Then the inverse of $ \sbr{B} $ is given by the extension
$$ 0 \to A \xrightarrow{\alpha} B \xrightarrow{-\beta} C \to 0. $$
\end{itemize}
\end{proof}

\subsection{Ext and classes of extensions}

\lecture{26}{Monday}{09/03/20}

\begin{definition}
Let
$$ 0 \to A \to B \to C \to 0 $$
be an extension of $ C $ by $ A $. The \textbf{class} of this extension is simply defined as $ \eta\br{\id_C} $ in the long exact sequence
$$ 0 \to \Hom_R\br{C, A} \to \Hom_R\br{C, B} \to \Hom_R\br{C, C} \xrightarrow{\eta} \Ext_R^1\br{C, A} \to \dots. $$
\end{definition}

\begin{proposition}
\label{prop:extensionclass}
\hfill
\begin{itemize}
\item Equivalent extensions have the same class.
\item The map between equivalence classes of extensions and $ \Ext_R^1\br{C, A} $ is a bijection.
\item In fact class is an isomorphism $ \br{\E_C\br{A}, +_\B} \to \Ext_R^1\br{C, A} $.
\end{itemize}
\end{proposition}

\begin{lemma}
\label{lem:extensionclass}
Suppose
$$
\begin{tikzcd}
0 \arrow{r} & L \arrow{r} \arrow{d} & M \arrow{r} \arrow{d} & N \arrow{r} \arrow{d} & 0 \\
0 \arrow{r} & X \arrow{r} & Y \arrow{r} & Z \arrow{r} & 0
\end{tikzcd}
$$
commutes, where the rows are exact. We get long exact sequences
$$
\begin{tikzcd}
0 \arrow{r} & \Ext_R^0\br{C, L} \arrow{r} \arrow{d} & \Ext_R^0\br{C, M} \arrow{r} \arrow{d} & \Ext_R^0\br{C, N} \arrow{r} \arrow{d} & \Ext_R^1\br{C, L} \arrow{r} \arrow{d} & \dots \\
0 \arrow{r} & \Ext_R^0\br{C, X} \arrow{r} & \Ext_R^0\br{C, Y} \arrow{r} & \Ext_R^0\br{C, Z} \arrow{r} & \Ext_R^1\br{C, X} \arrow{r} & \dots
\end{tikzcd},
$$
where the vertical arrows are given by the functoriality of $ \Ext_R^1\br{C, \cdot} $. This diagram commutes.
\end{lemma}

\begin{proof}
Omitted.
\end{proof}

\begin{proof}[Proof of Proposition \ref{prop:extensionclass}]
We show that class gives a map $ \E_C\br{A} \to \Ext_R^1\br{C, A} $, which is bijective.
\begin{itemize}
\item Every element of $ \Ext_R^1\br{C, A} $ is the class of an extension. Take $ x \in \Ext_R^1\br{C, A} $. Let $ I $ be an injective module containing $ A $ as a submodule. Then
$$ 0 \to A \to I \to I / A \to 0 $$
is a short exact sequence, which gives a long exact sequence
$$ 0 \to \Hom_R\br{C, A} \to \Hom_R\br{C, I} \to \Hom_R\br{C, I / A} \xrightarrow{\mu} \Ext_R^1\br{C, A} \to \Ext_R^1\br{C, I} \to \dots. $$
Then $ \Ext_R^1\br{C, I} = 0 $ since $ I $ is injective. So $ \mu $ is surjective. Let $ \phi \in \Hom_R\br{C, I / A} $ be such that $ \mu\br{\phi} = x $, and let
$$ X_\phi = \cbr{\br{i, c} \in I \oplus C \st i + A = \phi\br{c}} $$
be the pullback via $ \phi $, so
$$
\begin{tikzcd}[row sep=tiny]
& & X_\phi \arrow{r}{\pi_C} \arrow{dd}{\pi_I} & C \arrow{r} \arrow{dd}{\phi} & 0 \\
0 \arrow{r} & A \arrow{ur}{\iota_I} \arrow[swap]{dr}{\le} & & \\
& & I \arrow{r} & I / A \arrow{r} & 0
\end{tikzcd}.
$$

\pagebreak

From Lemma \ref{lem:extensionclass}, there is a commuting square
$$
\begin{tikzcd}[row sep=tiny]
\Hom_R\br{C, C} \arrow{dr}{\eta} \arrow[swap]{dd}{\overline{\phi}} & \\
& \Ext_R^1\br{C, A} \\
\Hom_R\br{C, I / A} \arrow[swap]{ur}{\mu} &
\end{tikzcd}.
$$
For $ f \in \Hom_R\br{C, C} $, $ \overline{\phi}\br{f} = \phi \circ f $. So the class of the extension
$$ 0 \to A \to B \to C \to 0 $$
is $ \eta\br{\id_C} = \mu\br{\phi \circ \id_C} = \mu\br{\phi} = x $.
\item Extensions giving the same class are equivalent. Suppose that $ \psi $ is another element of $ \Hom_R\br{C, I / A} $ such that $ \mu\br{\psi} = x $. Tracing back through the definition of the connecting homomorphism, in the proof of the snake lemma, it can be shown that $ \psi = \phi + q \circ f $, where $ f : C \to I $, and $ q $ is the quotient map $ I \to I / A $. Now it is easy to show that the map given by
$$ \function{I \oplus C}{I \oplus C}{\br{i, c}}{\br{i + f\br{c}, c}} $$
is bijective, and it maps $ X_\phi \to X_\psi $. The diagram
$$
\begin{tikzcd}[row sep=tiny]
& & X_\phi \arrow{dr} \arrow{dd}{f} & & \\
0 \arrow{r} & A \arrow{ur} \arrow[swap]{dr} & & C \arrow{r} & 0 \\
& & X_\psi \arrow[swap]{ur} & &
\end{tikzcd}
$$
commutes, and so the extensions are equivalent. We need to show that every extension arises as $ X_\phi $ for some $ \phi $. Suppose
$$ 0 \to A \xrightarrow{\alpha} B \to C \to 0 $$
is an extension. Let $ A \le I $ where $ I $ is injective. Then there exists $ \lambda : B \to I $ such that $ \br{\lambda \circ \alpha}\br{a} = a $ for all $ a \in A $. We have $ \lambda' : C \cong B / \alpha\br{A} \to I / A $. We get short exact sequences
$$
\begin{tikzcd}[row sep=tiny]
& & B \arrow{r} \arrow{dd}{\lambda} & C \arrow{r} \arrow{dd}{\lambda'} & 0 \\
0 \arrow{r} & A \arrow{ur} \arrow{dr} & & \\
& & I \arrow{r} & I / A \arrow{r} & 0
\end{tikzcd}.
$$
Now we have $ B \cong X_{\lambda'} $, since this is the same construction as before.

\lecture{27}{Tuesday}{10/03/20}

\item Equivalent extensions have the same class. Suppose
$$
\begin{tikzcd}[row sep=tiny]
& & B_1 \arrow{dr} \arrow{dd}{f} & & \\
0 \arrow{r} & A \arrow{ur} \arrow[swap]{dr} & & C \arrow{r} & 0 \\
& & B_2 \arrow[swap]{ur} & &
\end{tikzcd}
$$
commutes. We get maps
$$
\begin{tikzcd}[row sep=tiny]
\Hom_R\br{C, C} \arrow[bend left=15]{r}{\mu_1} \arrow[bend right=15, swap]{r}{\mu_2} & \Ext_R^1\br{C, A}
\end{tikzcd}
$$
commuting. So $ \mu_1 = \mu_2 $. Hence the extensions $ B_1 $ and $ B_2 $ have the same class.
\end{itemize}

\pagebreak

It remains to show that it is a group homomorphism. Let
$$ 0 \to A \to B_i \to C \to 0, \qquad i = 1, 2. $$
Suppose $ B_i = X_{\phi_i} $ for $ \phi_i : C \to I / A $, where $ I $ is an injective containing $ A $. From the arguments earlier, we have
$$
\begin{tikzcd}[row sep=tiny]
& & B_i \arrow{r} \arrow{dd}{\rho_i} & C \arrow{r} \arrow{dd}{\phi_i} & 0 \\
0 \arrow{r} & A \arrow{ur} \arrow{dr} & & \\
& & I \arrow{r} & I / A \arrow{r} & 0
\end{tikzcd}.
$$
Use the diagram above for $ i = 1, 2 $ to construct a new commuting diagram
$$
\begin{tikzcd}
0 \arrow{r} & A \oplus A \arrow{r} \arrow{d}{+} & B_1 \oplus B_2 \arrow{r} \arrow{d}{\rho_1 + \rho_2} & C \oplus C \arrow{r} \arrow{d}{\phi_1 + \phi_2} & 0 \\
0 \arrow{r} & A \arrow{r} & I \arrow{r} & I / A \arrow{r} & 0
\end{tikzcd}.
$$
Define
$$ A^+ = \cbr{\br{a, a} \st a \in A} \le A \oplus A, \qquad A^- = \cbr{\br{a, -a} \st a \in A} \le A \oplus A, \qquad C^+ = \cbr{\br{c, c} \st c \in C} \le C \oplus C. $$
Quotienting by $ A^- $, $ \br{A \oplus A} / A^- \cong A $, since $ \br{a_1, a_2} = \br{a_1 + a_2, 0} - \br{a_2, -a_2} $. Then
$$
\begin{tikzcd}[row sep=tiny]
& & \br{B_1 \oplus B_2} / A' \arrow{r} \arrow{dd} & C \oplus C \arrow{r} \arrow{dd}{\phi_1 + \phi_2} & 0 \\
0 \arrow{r} & A \arrow{ur} \arrow{dr} & & \\
& & I \arrow{r} & I / A \arrow{r} & 0
\end{tikzcd},
$$
where $ A' $ is the image of $ A^- $ in $ B_1 \oplus B_2 $, so if
$$ A \xrightarrow{\alpha_1} B_1 \xrightarrow{\beta_1} C, \qquad A \xrightarrow{\alpha_2} B_2 \xrightarrow{\beta_2} C, $$
then $ A' = \cbr{\br{\alpha_1\br{a}, -\alpha_2\br{a}}} $. Let $ X \le \br{B_1 \oplus B_2} / A' $ be the preimage of $ C^+ $ in the map $ \br{B_1 \oplus B_2} / A' \to C \oplus C $. Then
$$ 0 \to A \to X \to C^+ \to 0 $$
is exact, and we have $ C^+ \cong C $. We get
$$
\begin{tikzcd}[row sep=tiny]
& & X \arrow{r} \arrow{dd} & C \arrow{r} \arrow{dd}{\phi_1 + \phi_2} & 0 \\
0 \arrow{r} & A \arrow{ur} \arrow{dr} & & \\
& & I \arrow{r} & I / A \arrow{r} & 0
\end{tikzcd},
$$
identifying the maps
$$ \function[\phi_1 + \phi_2]{C \oplus C}{I / A}{\br{c, c}}{\phi_1\br{c} + \phi_2\br{c}}, \qquad \function[\phi_1 + \phi_2]{C}{I / A}{c}{\phi_1\br{c} + \phi_2\br{c}}, $$
so $ X = X_{\phi_1 + \phi_2} $. Recall from the definition of the Baer sum,
$$ 0 \to A \xrightarrow{\br{\alpha_1, -\alpha_2}} B_1 \oplus B_2 \xrightarrow{\beta_1 - \beta_2} C \to 0, $$
and $ H = \Ker \br{\beta_1 - \beta_2} / \Im \br{\alpha_1, -\alpha_2} $. But $ \Im \br{\alpha_1, -\alpha_2} $ is precisely the module $ A' $, and $ \Ker \br{\beta_1 - \beta_2} $ is the preimage of $ C^+ $ in $ B_1 \oplus B_2 $. So $ X = H $, and so $ \sbr{X_{\phi_1}} + \sbr{X_{\phi_2}} = \sbr{X_{\phi_1 + \phi_2}} $.
\end{proof}

\pagebreak

We have shown that elements of $ \Ext_R^1\br{C, A} $ corresponds to equivalence classes of extensions. Since the identity in $ \E_C\br{A} $ is the class of split extensions, it follows that $ 0 \in \Ext_R^1\br{C, A} $ corresponds to split extensions $ C \oplus A $.

\begin{example*}
Take $ R = \ZZ $. Calculate $ \Ext_R^1\br{\ZZ_n, H} $ for $ H $ an abelian group. Use the functor $ F\br{A} = \Hom_\ZZ\br{A, H} $. This is contravariant, so we need a projective resolution of $ \ZZ_n $. This is given by
$$ 0 \to \ZZ \xrightarrow{n} \ZZ \to \ZZ_n \to 0. $$
This gives a long exact sequence
$$ 0 \to \Hom_\ZZ\br{\ZZ_n, H} \to \Hom_\ZZ\br{\ZZ, H} \xrightarrow{n} \Hom_\ZZ\br{\ZZ, H} \to \Ext_R^1\br{\ZZ_n, H} \to 0, $$
since $ \Ext_n^i\br{\ZZ, H} = 0 $ for $ i > 1 $ since $ \ZZ $ is projective. Now
$$ \Hom_\ZZ\br{\ZZ_n, H} \cong H_n = \cbr{h \in H \st nh = 0}, \qquad \Hom_\ZZ\br{\ZZ, H} \cong H. $$
So
$$ 0 \to H_n \to H \xrightarrow{n} H \to \Ext_R^1\br{\ZZ_n, H} \to 0, $$
so $ \Ext_R^1\br{\ZZ_n, H} \cong H / nH $.
\end{example*}

\lecture{28}{Friday}{13/03/20}

Lecture 28 is a problems class.

\pagebreak

\section{Dimension}

\subsection{Projective, injective, and flat dimensions}

\lecture{29}{Monday}{16/03/20}

\begin{definition}
Let $ M $ be a $ R $-module. The \textbf{projective dimension} $ \pd M $ is the smallest $ d $ such that there exists a projective resolution $ P_* \to M $ such that $ P_{d + 1} \to 0 $, or infinity if no such $ d $ exists. The \textbf{injective dimension} $ \id M $ is similar for injective resolutions. The \textbf{flat dimension} is similar for flat resolutions.
\end{definition}

Every projective is flat, so $ \fd M \le \pd M $.

\begin{example*}
\hfill
\begin{itemize}
\item $ \ZZ $ as a module for itself. Then $ \ZZ $ is projective, and flat, so a projective or flat resolution is
$$ 0 \to \ZZ \to \ZZ \to 0, $$
so $ \fd \ZZ = \pd \ZZ = 0 $. Since $ \ZZ $ is not injective, an injective resolution is
$$ 0 \to \ZZ \to \QQ / \ZZ \to \QQ / \ZZ \to 0, $$
so $ \id \ZZ = 1 $.
\item $ \QQ $ as a module for $ \ZZ $. This is flat but not projective, so $ \fd \QQ = 0 $ and $ \pd \QQ = 1 $.
\end{itemize}
\end{example*}

\begin{proposition}
\label{prop:projectivedimension}
The following are equivalent.
\begin{enumerate}
\item $ \pd M \le d $.
\item $ \Ext_R^{d + 1}\br{M, N} = 0 $ for all $ N $.
\end{enumerate}
\end{proposition}

\begin{proof}
\hfill
\begin{itemize}
\item[$ \implies $] Assume $ 1 $. Then there exists a projective resolution
$$ 0 \to P_d \to \dots \to P_0 \to M \to 0. $$
Let $ F $ be the functor $ F\br{A} = \Hom_R\br{A, N} $. Then $ \Ext_R^*\br{M, N} $ is calculated from the chain complex
$$ 0 \to F\br{P_d} \to \dots \to F\br{P_{d - 1}} \to F\br{P_0} \to 0, $$
so clearly $ \Ext_R^n\br{M, N} = \L_nF\br{P_*} = 0 $ for $ n > d $.
\item[$ \impliedby $] For the converse, suppose that $ \Ext_R^{d + 1}\br{M, N} = 0 $ for all $ N $. Suppose
$$ P_{d - 1} \to P_{d - 2} \to \dots \to P_0 \to M \to 0 $$
is exact. Let $ K_{d - 1} $ be the kernel of $ P_{d - 1} \to P_{d - 2} $, the $ \br{d - 1} $-dimensional \textbf{syzygy} of $ M $. So
$$ 0 \to K_{d - 1} \to P_{d - 1} \to P_{d - 2} \to \dots \to P_0 \to M \to 0. $$
A fact is that
$$ \Ext_R^{d + 1}\br{M, N} \cong \Ext_R^1\br{K_{d - 1}, N}. $$
Suppose $ \Ext_R^{d + 1}\br{M, N} = 0 $. Then $ \Ext_R^1\br{K_{d - 1}, N} = 0 $. So $ K_{d - 1} $ is projective. Hence
$$ 0 \to K_{d - 1} \to P_{d - 1} \to P_{d - 2} \to \dots \to P_0 \to M \to 0 $$
is a projective resolution. So $ \pd M \le d $.
\end{itemize}
\end{proof}

\pagebreak

\begin{proposition}
The following are equivalent.
\begin{itemize}
\item $ \id N \le d $.
\item $ \Ext_R^{d + 1}\br{M, N} = 0 $ for all $ M $.
\end{itemize}
\end{proposition}

\begin{proof}
Similar to Proposition \ref{prop:projectivedimension}. Use the \textbf{cosyzygy}.
\end{proof}

\begin{proposition}
The following are equivalent.
\begin{itemize}
\item $ \fd M \le d $.
\item $ \Tor_{d + 1}^R\br{M, N} = 0 $ for all $ N $.
\end{itemize}
\end{proposition}

\begin{fact*}
Any flat resolution for $ M $ can be used to calculate Tor.
\end{fact*}

\begin{proof}
Using the fact, the proof is the same as above.
\end{proof}

\subsection{Global dimension}

We will be interested in defining dimension for the ring $ R $.

\begin{definition}
Claim that
$$ \sup \cbr{\pd M \st M \ \text{a left $ R $-module}} = \sup \cbr{\id M \st M \ \text{a left $ R $-module}} = \sup \cbr{d \st \exists M, N, \ \Ext_R^d\br{M, N} \ne 0}, $$
where the supremums are in $ \NN \cup \cbr{\infty} $. This number is the \textbf{left global dimension} $ \lgd R $ of $ R $. The \textbf{right global dimension} $ \rgd R $ is defined similarly, but using right modules.
\end{definition}

There exist rings $ R $ such that $ \lgd R \ne \rgd R $.

\begin{definition}
Say that $ R $ satisfies the \textbf{ascending chain condition on right ideals} if whenever $ I_0 \le I_1 \le \dots $ is a chain of right ideals, there exists $ d $ such that $ I_d = I_{d + 1} = \dots $. The condition that $ R $ satisfies the \textbf{ascending chain condition on left ideals} is similar. If $ R $ satisfies the ascending chain condition on both left and right ideals, it is \textbf{noetherian}.
\end{definition}

\begin{fact*}
For any noetherian ring $ R $, $ \lgd R = \rgd R $.
\end{fact*}

\begin{definition}
So in this context we can refer to \textbf{global dimension}, $ \gd R $. Claim that
$$ \sup \cbr{\fd N \st N \ \text{a left $ R $-module}} = \sup \cbr{\fd M \st M \ \text{a right $ R $-module}} = \sup \cbr{d \st \exists M, N, \ \Tor_d^R\br{M, N} \ne 0}. $$
This number is the \textbf{weak global dimension} $ \wgd R $.
\end{definition}

Since $ \fd M \le \pd M $, $ \wgd R \le \gd R $.

\subsection{Krull dimension}

\lecture{30}{Tuesday}{17/03/20}

The following is another ring dimension. Let $ R $ be a commutative ring.

\begin{definition}
The \textbf{Krull dimension} $ \dim R $ is the length of the longest chain of prime ideals of $ R $, where $ I \le R $ is \textbf{prime} if $ I \ne R $, and $ ab \in I $ implies that $ a \in I $ or $ b \in I $.
\end{definition}

In particular, any maximal ideal of $ R $ is prime.

\begin{example*}
Let $ V $ be an \textbf{affine variety} in $ F^n $, defined by the zeros of a set of polynomials in $ F\sbr{x_1, \dots, x_n} $. Then $ V $ corresponds to an ideal $ I_V $ in $ F\sbr{x_1, \dots, x_n} $, and $ V $ is \textbf{irreducible} if $ I_V $ is prime. Then
$$ \dim F\sbr{x_1, \dots, x_n} / I_V = \dim V. $$
\end{example*}

\begin{fact*}
$ \dim R \le \gd R $.
\end{fact*}

\pagebreak

\begin{definition}
A ring is \textbf{local} if it has a unique maximal ideal, so the non-units of $ R $ form an ideal. Let $ I \le R $ be a prime ideal. The \textbf{localisation} of $ R $ at $ I $ is the ring
$$ \cbr{\dfrac{r}{q} \st r \in R, \ q \in R \setminus I}. $$
\end{definition}

The unique maximal ideal is
$$ \cbr{\dfrac{i}{q} \st i \in I, \ q \in R \setminus I}, $$
so this ring is local. This is a basic tool in algebraic geometry.

\begin{theorem}[Serre]
Let $ R $ be a noetherian local ring such that $ \dim R $ is finite. Then
$$ \dim R = \gd R. $$
\end{theorem}

\begin{example*}
$ R = F\sbr{x_1, \dots, x_n} $ corresponds to the zero variety. This is not local, but $ \dim R = \gd R = n $. The fact that $ \gd R = n $ is \textbf{Hilbert's syzygy theorem}.
\begin{itemize}
\item Let $ n = 3 $. Note that $ F $ is a module for $ R $, by the multiplication $ x_i\lambda = 0 $ for all $ x_i $ and $ \lambda \in F $. Let us calculate a projective resolution, keeping track of the syzygies. If
$$ 0 \to K_1 \to R \to F \to 0, $$
then
\begin{align*}
K_1
& = \Ker \br{\functions{R}{F}{x_i}{0}{1}{1}} \\
& = \abr{x_1, x_2, x_3}
\le R.
\end{align*}
If
$$ 0 \to K_2 \to R^3 \to K_1 \to 0, $$
then
\begin{align*}
K_2
& = \Ker \br{\function{R^3}{K_1}{\br{r_1, r_2, r_3}}{r_1x_1 + r_2x_2 + r_3x_3}} \\
& = \cbr{\br{r_1, r_2, r_3} \st r_1x_1 + r_2x_2 + r_3x_3 = 0} \\
& = \abr{\br{0, x_3, -x_2}, \br{-x_3, 0, x_1}, \br{x_2, -x_1, 0}}
\le R^3.
\end{align*}
If
$$ 0 \to K_3 \to R^3 \to K_2 \to 0, $$
then
\begin{align*}
K_3
& = \Ker \br{\function{R^3}{K_2}{\br{r_1, r_2, r_3}}{\br{r_3x_2 - r_2x_3, r_1x_3 - r_3x_1, r_2x_1 - r_1x_2}}} \\
& = \abr{\br{x_1, x_2, x_3}}
\cong R.
\end{align*}
Our projective resolution is
$$ 0 \to R \to R^3 \to R^3 \to R \to F \to 0. $$
\item Generally for arbitrary $ n $, this construction gives
$$ P_j = R^{\binom{n}{j}}. $$
Generators of $ K_j \le P_{j - 1} $ correspond to subsets of size $ j $ of $ \cbr{1, \dots, n} $. The generator corresponding to a subset $ S $ of size $ j $ will have a coordinate for each subset $ T $ of size $ j - 1 $. This coordinate is zero if $ T \not\subseteq S $ and $ \pm x_i $ if $ S = T \cup \cbr{i} $.
\end{itemize}
This is an example of a \textbf{Koszul complex}, and is a technique used for calculating syzygies explicitly in certain situations.
\end{example*}

\end{document}