\def\module{M4P33 Algebraic Geometry}
\def\lecturer{Prof Kevin Buzzard}
\def\term{Spring 2020}
\def\cover{
$$
\begin{tikzpicture}
\draw [thick] (-1, 11) to (-1, 10);
\draw [in=-90, out=-90, thick] (-1, 10) to (-3, 7);
\draw [in=150, out=90, thick] (-3, 7) to (-2, 7.5);
\draw [in=120, out=-30, thick] (-1, 7) to (0, 6);
\draw [in=90, out=-60, thick] (0.5, 4.5) to (0.5, 4);
\draw [thick] (0.5, 4) to (0.5, 3);
\draw [thick] (1, 12) to (1, 11);
\draw [in=90, out=-90, thick] (1, 11) to (3, 7);
\draw [in=90, out=-90, thick] (3, 7) to (-0.5, 3);
\draw [thick] (-0.5, 3) to (-0.5, 2);
\draw [dotted, thick] (0, 11.8) to (0, 6);
\draw [dotted, thick] (0, 4.2) to (0, 2.2);
\draw [dashed] (-1, 10.5) to (1, 11.5);
\draw [dashed] (-1, 10) to (1, 11);
\draw [dashed] (-1, 9.5) to (1, 10.5);
\draw [dashed] (-1.2, 9) to (1.2, 10);
\draw [dashed] (-1.4, 8.4) to (1.4, 9.6);
\draw [dashed] (-1.8, 7.8) to (1.9, 9.1);
\draw [dashed] (-2.2, 7.2) to (2.4, 8.5);
\draw [dashed] (-2.8, 6.6) to (2.8, 7.8);
\draw [dashed] (-3, 7) to (-2.3, 7);
\draw [dashed] (-1, 7) to (3, 7);
\draw [dashed] (-2.8, 7.4) to (-2.15, 7.25);
\draw [dashed] (-1, 7) to (2.8, 6.2);
\draw [dashed] (-1, 7) to (2.2, 5.6);
\draw [dashed] (-0.2, 6.3) to (1.3, 5);
\draw [dashed] (0, 6) to (0.4, 4.5);
\draw [dashed] (0, 6) to (-0.4, 3.5);
\draw [dashed] (-0.5, 3) to (0.5, 4);
\draw [dashed] (-0.5, 2.5) to (0.5, 3.5);
\draw [in=0, out=-120, very thick] (1.9, 9.1) to (0, 7.8);
\draw [in=90, out=-180, very thick] (0, 7.8) to (-0.5, 7);
\draw [in=-180, out=-90, very thick] (-0.5, 7) to (0, 6.6);
\draw [in=120, out=0, very thick] (0, 6.6) to (1.3, 5);
\fill (1.9, 9.1) circle (0.05);
\fill (0, 7.8) circle (0.05);
\fill (0, 6.6) circle (0.05);
\fill (1.3, 5) circle (0.05);
\draw [thick] (0, 0) ellipse (3 and 1);
\draw [dashed] (3, 0) to (-3, 0);
\draw [dashed] (2.7, 0.4) to (-2.7, -0.4);
\draw [dashed] (2, 0.7) to (-2, -0.7);
\draw [dashed] (1, 0.9) to (-1, -0.9);
\draw [dashed] (0, 1) to (0, -1);
\draw [dashed] (-1, 0.9) to (1, -0.9);
\draw [dashed] (-2, 0.7) to (2, -0.7);
\draw [dashed] (-2.7, 0.4) to (2.7, -0.4);
\draw [in=30, out=-120, very thick] (1, 0.9) to (0, 0);
\draw [in=-90, out=-150, very thick] (0, 0) to (-1, 0);
\draw [in=150, out=90, very thick] (-1, 0) to (0, 0);
\draw [in=120, out=-30, very thick] (0, 0) to (1, -0.9);
\fill (1, 0.9) circle (0.05);
\fill (0, 0) circle (0.1);
\fill (1, -0.9) circle (0.05);
\draw (-2, 6) node{$ \overline{\pi^{-1}\br{\CCC \setminus \cbr{\br{0, 0}}}} $};
\draw [->, dashed, thick] (2, 4) to node[right]{$ \pi $} (2, 2);
\draw (0, -2) node{$ \CCC = \cbr{\br{x, y} \in \AA^2 \st y^2 = x^2\br{x + 1}} \subseteq \AA^2 $};
\end{tikzpicture}
$$
}
\def\syllabus{Affine algebraic sets. Projective algebraic sets. Regular functions and maps. Rational functions and maps. Equivalence of algebra and geometry. The weak and strong Nullstellensatz. Rigidity and images of maps. Completeness and Chevalley's theorem. Dimension and transcendence degree. Dimension of hypersurfaces. Topological definition of dimension. Counting dimensions of parameter spaces.}
\def\thm{subsection}

\input{../style/header}

% Macros
\newcommand{\rational}[5][]{
  \ifx &#1&
    \begin{array}{rcl}
      #2 & \dashrightarrow & #3 \\
      #4 & \longmapsto     & #5
    \end{array}
  \else
    \begin{array}{ccrcl}
      #1 & : & #2 & \dashrightarrow & #3 \\
         &   & #4 & \longmapsto     & #5
    \end{array}
  \fi
}

\begin{document}

\input{../style/cover}

\section{Introduction}

\subsection{B\'ezout's theorem}

\lecture{1}{Monday}{13/01/20}

Here is an example of a theorem in algebraic geometry and an outline of a geometric method for proving it which illustrates some of the main themes in algebraic geometry.

\begin{theorem}[B\'ezout]
Let $ C $ be a plane algebraic curve $ \cbr{\br{x, y} \st f\br{x, y} = 0} $ where $ f $ is a polynomial of degree $ m $. Let $ D $ be a plane algebraic curve $ \cbr{\br{x, y} \st g\br{x, y} = 0} $ where $ g $ is a polynomial of degree $ n $. Suppose that $ C $ and $ D $ have no component in common, since if they had a component in common, then their intersection would obviously be infinite. Then $ C \cap D $ consists of $ mn $ points, provided that
\begin{itemize}
\item we work over the complex numbers $ \CC $,
\item we work in the projective plane, which consists of the ordinary plane together with some points at infinity, and
\item we count intersections with the correct multiplicities, so if the curves are tangent at a point, it counts as more than one intersection.
\end{itemize}
\end{theorem}

Consider the cases where $ C $ is a line of degree one and $ D $ has either degree one or two. The projective plane will be formally defined later in the course. We will not define intersection multiplicities in this course, but the idea is that multiple intersections resemble multiple roots of a polynomial in one variable.

\begin{proof}
We prove a special case, where $ C $ is the union of $ m $ lines, then use this to prove the general case of the theorem.
\begin{itemize}
\item First for the special case, suppose we have $ m $ lines in the plane, with equations
$$ a_1x + b_1y + c_1 = 0, \qquad \dots, \qquad a_mx + b_my + c_m = 0. $$
We can multiply these equations together to get
$$ \br{a_1x + b_1y + c_1} \dots \br{a_mx + b_my + c_m} = 0. $$
This is an equation of degree $ m $ and its solution set is the union of the lines. Each line intersects $ D $ in $ n $ points, counted with multiplicities, because we can rearrange the equation of the line into the form $ x = \dots $ or $ y = \dots $ then substitute into the equation for $ D $. This usually gives a polynomial of degree $ n $ in one variable, and this has $ n $ roots if we count them correctly. There are also special cases to worry about where the line intersects $ D $ at infinity. Combining all the $ m $ lines, we deduce that their union intersects $ D $ in $ mn $ points.
\item Now we deduce the general case from the special case. We let the curve $ C $ vary in a family of curves of degree $ m $. What exactly we mean by varying in a family will be defined later in the course. As an example, consider the family of curves
$$ \FFF : \cbr{\br{x, y} \st x^2 - y^2 = t}, $$
where $ t $ is a parameter, so for different values of $ t $ we get different curves. When the curve $ C $ varies in a family like this, the number of intersection points in $ C \cap D $ does not change, counting with multiplicity. This is the core of the proof. It requires a lot of work to justify which we will not do here. For any degree $ m $ curve $ C $, it is possible to find a family of curves which contains both $ C $ itself and a union of $ m $ lines $ X $. For example, if $ C $ is the hyperbola defined by the equation $ x^2 - y^2 = 1 $, then it is found in the family $ \FFF $, with $ t = 1 $. If we let $ t = 0 $ in this family, then the equation factors as $ \br{x - y}\br{x + y} $ and this defines the union of two lines in the plane. We have already proved that $ X \cap D $ has $ mn $ points, and we stated that $ X \cap D $ has the same number of points as $ C \cap D $ because $ C $ and $ X $ are in the same family. We conclude that $ C \cap D $ has $ mn $ points.
\end{itemize}
\end{proof}

\pagebreak

The idea that something stays the same everywhere, or almost everywhere, in a family of varying algebraic sets is a key theme in algebraic geometry. Note that this proof uses not just curves but also higher-dimensional algebraic sets, since instead of thinking about a family of curves such as $ \FFF $, with coordinates $ \br{x, y} $ and a parameter $ t $, we can regard $ x, y, t $ all as coordinates in three-dimensional space and consider the surface
$$ \cbr{\br{x, y, t} \st x^2 - y^2 = t}. $$
Then we use facts about this surface as part of the proof. We will not prove B\'ezout's theorem in this course. In particular, we will not define intersection multiplicities. But we will set up many of the tools needed to fill in the gaps in this outline proof.

\subsection{Practical information about the course}

The following are books.
\begin{itemize}
\item M Reid, Undergraduate algebraic geometry, 1988
\item R Hartshorne, Algebraic geometry, 1977
\end{itemize}
During the course we will sometimes assume results from commutative algebra. Books which contain these results, and much much more, include the following.
\begin{itemize}
\item H Matsumura, Commutative ring theory, 1986
\item M F Atiyah and I G Macdonald, Introduction to commutative algebra, 1969
\item D Eisenbud, Commutative algebra: with a view toward algebraic geometry, 2011
\end{itemize}
The following is the course outline.
\begin{itemize}
\item Affine varieties.
\begin{itemize}
\item Definition and examples.
\item Maps between varieties.
\item Translating between geometry and commutative algebra and the Nullstellensatz.
\end{itemize}
\item Projective varieties.
\begin{itemize}
\item Definition and examples.
\item Maps between varieties.
\item Rigidity and images of maps.
\end{itemize}
\item Dimension.
\begin{itemize}
\item Several different definitions, all equivalent, but useful for different purposes.
\item Calculating dimensions of examples.
\end{itemize}
\end{itemize}
What is not in the course?
\begin{itemize}
\item Schemes.
\item Sheaves and cohomology.
\item Curves, divisors, and the Riemannâ€“Roch theorem.
\end{itemize}

\begin{note*}
The official notes are integrated in these unofficial notes.
\end{note*}

\pagebreak

\section{Affine varieties}

\subsection{Affine algebraic sets}

Let $ k $ be an algebraically closed field. We are going to be thinking about solutions to polynomials, so everything is much simpler over algebraically closed fields. We already saw this in B\'ezout's theorem. Number theorists might be interested in other fields, but you generally have to start by understanding the algebraically closed case first. In this course we will stop with the algebraically closed case too. Apart from being algebraically closed, it usually does not matter much which field we use to do algebraic geometry, except sometimes it matters whether the characteristic is zero or positive. In this course I will take care to mention results which depend on the characteristic, and sometimes we might consider only the characteristic zero case. You will not lose much if you just assume that $ k = \CC $ throughout the course, except when it will be explicitly something else. Indeed it is often useful to think about $ k = \CC $ because then you can use your usual geometric intuition. When I draw pictures on the whiteboard, I am usually only drawing the real solutions because it is hard to draw shapes in $ \CC^2 $. This is cheating but it is often very useful. The real solutions are not the full picture but in many cases we can still see the important features there.

\subsubsection{Affine space}

\begin{definition*}
Algebraic geometers write $ \AA^n $ to mean $ k^n $, and call it \textbf{affine $ n $-space}.
\end{definition*}

You may think of this as just a funny choice of notation, but there are at least two reasons for it.
\begin{itemize}
\item When we write $ k^n $, it makes us think of a vector space, equipped with operations of addition and scalar multiplication. But $ \AA^n $ means just a set of points, described by coordinates $ \br{x_1, \dots, x_n} $ with $ x_i \in k $, without the vector space structure.
\item Because it usually does not matter much what our base field $ k $ is, as long as it is algebraically closed, it is convenient to have notation which does not prominently mention $ k $.
\end{itemize}
On occasions when it is important to specify which field $ k $ we are using, we write $ \AA_k^n $ for affine $ n $-space.

\subsubsection{Definition and examples}

\lecture{2}{Thursday}{16/01/20}

\begin{definition*}
An \textbf{affine algebraic set} is a subset $ V \subseteq \AA^n $ which consists of the common zeroes of some finite set of polynomials $ f_1, \dots, f_m $ with coefficients in $ k $. More formally, an affine algebraic set is a set of the form
$$ V = \cbr{\br{x_1, \dots, x_n} \in \AA^n \st f_1\br{x_1, \dots, x_n} = \dots = f_m\br{x_1, \dots, x_n} = 0}, \qquad f_1, \dots, f_m \in k\sbr{X_1, \dots, X_n}. $$
\end{definition*}

\begin{example*}
Examples.
\begin{itemize}
\item The empty set, defined by the polynomial $ f_1 = 3 $, for example.
\item The whole space $ \AA^n $, defined by the polynomial $ f_1 = 0 $, or by the empty set of polynomials.
\item Any finite subset $ \cbr{a_1, \dots, a_n} $ in $ \AA^1 $, defined by the polynomial $ f_1 = \br{X - a_1} \dots \br{X - a_n} $.
\item Any single-point set $ \cbr{\br{a_1, \dots, a_n}} $ in $ \AA^n $, defined by the polynomials $ f_i = X_i - a_i $. Note that this is different from the example of a finite set in $ \AA^1 $, because that example had a single polynomial in one variable of degree $ n $, while here we have $ n $ distinct polynomials in $ n $ variables of degree one.
\item Any algebraic curve in $ \AA^n $, that is, a set of the form
$$ \cbr{\br{x_1, \dots, x_n} \in \AA^n \st f\br{x_1, \dots, x_n} = 0}, \qquad f \in k\sbr{X_1, \dots, X_n}. $$
\item Embeddings of $ \AA^m $ in $ \AA^n $ where $ m < n $,
$$ \cbr{\br{x_1, \dots, x_m, 0, \dots, 0} \in \AA^n} = \cbr{\br{x_1, \dots, x_n} \in \AA^n \st x_{m + 1} = \dots = x_n = 0}. $$
More generally, the image of a linear map $ \AA^m \to \AA^n $,
$$ \cbr{\br{x_1, \dots, x_n} \in \AA^n \st \text{some linear conditions}}. $$
\end{itemize}
\end{example*}

\pagebreak

\begin{example*}
Non-examples.
\begin{itemize}
\item Any infinite subset of $ \AA^1 $, other than $ \AA^1 $ itself, such as a line segment, a line with a double point, or an infinite discrete set. This is because a one-variable polynomial with infinitely many roots must be the zero polynomial. This also tells us that $ \cbr{x \in \AA^1 \st x \ne 0} $ is not an affine algebraic set. However there is an affine algebraic set which is isomorphic to $ \AA^1 \setminus \cbr{0} $, namely $ \cbr{\br{x, y} \in \AA^2 \st xy - 1 = 0} $. By looking at just the $ x $ coordinate, this set bijects to $ \AA^1 \setminus \cbr{0} $.
\item A sine wave. If $ \cbr{\br{x, y} \st y = \sin x} $ were an affine algebraic set, then $ \cbr{\br{x, y} \st y = \sin x, \ y = 0} $ would also be an affine algebraic set because it is defined by imposing an extra polynomial condition, but the latter is an infinite discrete set.
\item The example of the image of a linear map $ \AA^m \to \AA^n $ does not generalise to images of maps where each coordinate is given by a polynomial. For example, consider the map
$$ \function[\phi]{\AA^2}{\AA^2}{\br{x, y}}{\br{x, xy}}. $$
The image of $ \phi $ is $ S = \AA^2 \setminus \cbr{\br{0, y}} \cup \cbr{\br{0, 0}} $. To prove that $ S $ is not an affine algebraic set, consider a polynomial $ g\br{X, Y} \in k\sbr{X, Y} $ which vanishes on $ S $. For each fixed $ y \in k $, the one-variable polynomial $ g\br{X, y} $ vanishes at all $ x \ne 0 $. This implies that $ g\br{X, y} $ is the zero polynomial. Thus $ g\br{x, y} = 0 $ for all $ \br{x, y} \in k^2 $, that is, $ g $ is the zero polynomial.
\end{itemize}
\end{example*}

\begin{remark}
The words affine variety mean more or less the same thing as affine algebraic set but there is an ontological difference. Affine algebraic set means a subset which lives inside $ \AA^n $ and knows how it lives inside $ \AA^n $, while affine variety means an object in its own right which is considered outside of $ \AA^n $. I will try to use these words consistently, but the difference is quite subtle and books may not always use it consistently. For the first few weeks, we will talk about affine algebraic sets only. Note that some books, such as Reid and Hartshorne, have another difference between affine varieties and affine algebraic sets. They require varieties to be irreducible, which we will define next time. Other books, such as Shafarevich, do not require varieties to be irreducible. In this course we will not require varieties to be irreducible.
\end{remark}

\subsubsection{New algebraic sets from old}

Now we prove that the union of two affine algebraic sets is an affine algebraic set. Consider two points $ \br{a_1, \dots, a_n} $ and $ \br{b_1, \dots, b_n} $ in $ \AA^n $. The two-point set $ \cbr{\br{a_1, \dots, a_n}, \br{b_1, \dots, b_n}} $ can be defined by taking the product for each possible pair of equations, one from each list, so $ \br{X_i - a_i}\br{X_j - b_j} = 0 $ for all $ i, j \in \cbr{1, \dots, n} $.

\begin{note*}
It is necessary to consider all the pairs between the lists, not just the ones with $ i = j $, because otherwise we would be allowing points like $ \br{a_1, \dots, a_{n - 1}, b_n} $.
\end{note*}

\begin{lemma}
If $ V, W \subseteq \AA^n $ are affine algebraic sets, then their union $ V \cup W \subseteq \AA^n $ is also an affine algebraic set.
\end{lemma}

\begin{proof}
We have to take the product for each possible pair of defining polynomials, since if
$$ V = \cbr{\underline{x} \in \AA^n \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = 0}, \qquad W = \cbr{\underline{x} \in \AA^n \st g_1\br{\underline{x}} = \dots = g_s\br{\underline{x}} = 0}, $$
then
$$ V \cup W = \cbr{\underline{x} \in \AA^n \st \forall 1 \le i \le r, \ \forall 1 \le j \le s, \ f_i\br{\underline{x}}g_j\br{\underline{x}} = 0}. $$
Let us check that these equations really do define $ V \cup W $. First, suppose that $ \underline{x} \in V \cup W $. Then either $ \underline{x} \in V $, so $ f_i\br{\underline{x}} = 0 $ for every $ i $, so we can multiply by $ g_j\br{\underline{x}} $ to get $ f_i\br{\underline{x}}g_j\br{\underline{x}} = 0 $ for every $ i $ and $ j $, or $ \underline{x} \in W $, in which case the same argument works with $ g_j $ in place of $ f_i $. The reverse direction is a little trickier. Suppose that we have $ \underline{x} \in \AA^n $ satisfying $ f_i\br{\underline{x}}g_j\br{\underline{x}} = 0 $ for all $ i $ and $ j $. Looking just at $ f_1 $, we get
$$ f_1\br{\underline{x}}g_1\br{\underline{x}} = 0 \implies f_1\br{\underline{x}} = 0 \ \text{or} \ g_1\br{\underline{x}} = 0, \qquad \dots, \qquad f_1\br{\underline{x}}g_s\br{\underline{x}} = 0 \implies f_1\br{\underline{x}} = 0 \ \text{or} \ g_s\br{\underline{x}} = 0. $$
Putting these all together, we get $ f_1\br{\underline{x}} = 0 $ or $ g_j\br{\underline{x}} = 0 $ for every $ j $. We can do the same thing for $ f_2 $ to get $ f_2\br{\underline{x}} = 0 $ or $ g_j\br{\underline{x}} = 0 $ for every $ j $, and so on for each $ f_i $. Putting all these together, we get $ f_i\br{\underline{x}} = 0 $ for every $ i $ or $ g_j\br{\underline{x}} = 0 $ for every $ j $. This says precisely that $ \underline{x} \in V \cup W $.
\end{proof}

\pagebreak

It is even easier to check that the intersection of finitely many affine algebraic sets is an affine algebraic set.

\begin{lemma}
If $ V, W \subseteq \AA^n $ are affine algebraic sets, then their intersection $ V \cap W \subseteq \AA^n $ is also an affine algebraic set.
\end{lemma}

\begin{proof}
Just combine the lists of defining equations. That is, say
$$ V = \cbr{\underline{x} \in \AA^m \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = 0}, \qquad W = \cbr{\underline{y} \in \AA^n \st g_1\br{\underline{y}} = \dots = g_s\br{\underline{y}} = 0}. $$
Then $ V \cap W $ is simply the set where all the polynomials in both lists vanish, that is
$$ V \cap W = \cbr{\underline{x} \in \AA^n \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = g_1\br{\underline{x}} = \dots = g_s\br{\underline{x}} = 0}. $$
\end{proof}

Just a remark on one other way of constructing new affine algebraic sets from existing ones.

\begin{lemma}
If $ V \subseteq \AA^m $ and $ W \subseteq \AA^n $ are affine algebraic sets, then their Cartesian product $ V \times W \subseteq \AA^{m + n} $ is an affine algebraic set.
\end{lemma}

\begin{proof}
Write
$$ V = \cbr{\underline{x} \in \AA^m \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = 0}, \qquad W = \cbr{\underline{y} \in \AA^n \st g_1\br{\underline{y}} = \dots = g_s\br{\underline{y}} = 0}. $$
Then
$$ V \times W = \cbr{\br{\underline{x}, \underline{y}} \in \AA^{m + n} \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = g_1\br{\underline{y}} = \dots = g_s\br{\underline{y}} = 0}. $$
\end{proof}

This looks a bit like the equations defining $ V \cap W $, but here the $ f_i $ involve different variables from the $ g_j $, while for $ V \cap W $ both used the same variables.

\subsubsection{Ideals and algebraic sets}

\lecture{3}{Friday}{17/01/20}

The union of infinitely many affine algebraic sets is not always an affine algebraic set. I do not mean that it is never an affine algebraic set, just that there exist counter-examples. Indeed, any subset of $ \AA^n $ can be written as a union of single-point sets. The intersection of infinitely many affine algebraic sets always an affine algebraic set. If we try to prove this by combining the lists of defining equations, we run into a problem, since in our definition of affine algebraic sets we only allowed a finite list of polynomial equations. We introduce ideals to remove this restriction.

\begin{definition*}
Recall from commutative algebra that, if $ R $ is a ring, an \textbf{ideal} is a subset $ I \subseteq R $ with the properties that
\begin{itemize}
\item if $ f, g \in I $, then $ f + g \in I $, and
\item if $ f \in I $ and $ q \in R $, then $ qf \in I $.
\end{itemize}
Given any subset $ S \subseteq R $, we define the \textbf{ideal generated by $ S $} to be the smallest ideal which contains $ S $, and denote it by $ \abr{S} $. In particular, if $ S $ is the finite set $ \cbr{f_1, \dots, f_m} $ then it generates the ideal
$$ \abr{f_1, \dots, f_m} = \cbr{q_1f_1 + \dots + q_mf_m \st q_1, \dots, q_m \in R}. $$
\end{definition*}

Let us introduce some notation.

\begin{definition*}
For any set $ S \subseteq k\sbr{X_1, \dots, X_n} $, let
$$ \VV\br{S} = \cbr{\underline{x} \in \AA^n \st \forall f \in S, \ f\br{\underline{x}} = 0}. $$
\end{definition*}

\begin{lemma}
\label{lem:vs}
If $ S \subseteq k\sbr{X_1, \dots, X_n} $ generates the ideal $ I $, then $ \VV\br{S} = \VV\br{I} $.
\end{lemma}

\begin{proof}
We have $ S \subseteq I $ and so it is easy to see that $ \VV\br{I} \subseteq \VV\br{S} $. Suppose that $ \underline{x} \in \VV\br{S} $, and $ f \in \VV\br{I} $. Then there are $ f_1, \dots, f_m \in S $ and $ q_1, \dots, q_m \in k\sbr{X_1, \dots, X_n} $ such that $ f = q_1f_1 + \dots + q_mf_m $. Since $ f_1\br{\underline{x}} = \dots = f_m\br{\underline{x}} = 0 $, it follows that $ f\br{\underline{x}} = 0 $. Since this holds for every $ f \in I $, $ \underline{x} \in \VV\br{I} $.
\end{proof}

\pagebreak

\begin{theorem}[Hilbert basis theorem]
From commutative algebra, if $ k $ is any field, then the polynomial ring $ k\sbr{X_1, \dots, X_n} $ is noetherian. That means that the following two equivalent conditions hold.
\begin{itemize}
\item Let $ I $ be an ideal in $ k\sbr{X_1, \dots, X_n} $. Then there exists a finite set $ \cbr{f_1, \dots, f_m} \subseteq k\sbr{X_1, \dots, X_n} $ which generates $ I $.
\item Let $ I_1 \subseteq I_2 \subseteq \dots $ be an ascending chain of ideals in $ k\sbr{X_1, \dots, X_n} $. Then there is some $ N $ such that $ I_n = I_N $ for every $ n > N $.
\end{itemize}
\end{theorem}

Using the Hilbert basis theorem, we can deduce that the restriction to finite lists of polynomials in the definition of affine algebraic sets is unnecessary.

\begin{corollary}
\label{cor:vs}
$ \VV\br{S} $ is an affine algebraic set for any set of polynomials $ S \subseteq k\sbr{X_1, \dots, X_n} $.
\end{corollary}

\begin{proof}
Let $ I $ be the ideal in $ k\sbr{X_1, \dots, X_n} $ generated by $ S $. By the Hilbert basis theorem, $ k\sbr{X_1, \dots, X_n} $ is noetherian and so we can choose a finite set $ \cbr{f_1, \dots, f_m} $ which generates $ I $. Then Lemma \ref{lem:vs} tells us that $ \VV\br{S} = \VV\br{I} = \VV\br{f_1, \dots, f_m} $.
\end{proof}

\begin{corollary}
The intersection of finitely many affine algebraic sets is an affine algebraic set.
\end{corollary}

\begin{proof}
Combine the lists of defining polynomials for all the algebraic sets, and apply Corollary \ref{cor:vs}.
\end{proof}

We can also go in the other direction, from affine algebraic sets to ideals. Say $ V_n = \VV\br{I_n} $. Does $ V_1 \supseteq V_2 $ imply that $ I_1 \subseteq I_2 $? No. The problem is that there is more than one ideal defining the same algebraic set.

\begin{example*}
Let $ I_1 = \abr{X} $ and $ I_2 = \abr{X^2} $ in $ k\sbr{X} $. We have $ \VV\br{I_1} = \cbr{0} = \VV\br{I_2} $.
\end{example*}

However, there is a natural choice we can make for one ideal canonically associated with an affine algebraic set, the set of all polynomials which vanish on that set.

\begin{definition*}
Formally, if $ A $ is any subset of $ \AA^n $, usually $ A $ will be an affine algebraic set, we define
$$ \II\br{A} = \cbr{f \in k\sbr{X_1, \dots, X_n} \st \forall \underline{x} \in A, \ f\br{\underline{x}} = 0}. $$
\end{definition*}

\begin{note*}
$ \II\br{A} $ is an ideal in $ k\sbr{X_1, \dots, X_n} $.
\end{note*}

We have now defined two functions
$$ \VV : \cbr{\text{ideals in} \ k\sbr{X_1, \dots, X_n}} \to \cbr{\text{affine algebraic sets in} \ \AA^n}, $$
$$ \II : \cbr{\text{affine algebraic sets in} \ \AA^n} \to \cbr{\text{ideals in} \ k\sbr{X_1, \dots, X_n}}. $$
These functions are not inverses of each other, since the example of $ \abr{X} $ and $ \abr{X^2} $ shows that $ \II\br{\VV\br{\abr{X^2}}} = \abr{X} \ne \abr{X^2} $. But composing $ \VV $ and $ \II $ in the other order gives the identity.

\begin{lemma}
\label{lem:viv}
If $ V $ is an affine algebraic set, then $ \VV\br{\II\br{V}} = V $.
\end{lemma}

\begin{proof}
It is clear that $ V \subseteq \VV\br{\II\br{V}} $, and this works when $ V $ is any subset of $ \AA^n $, not necessarily algebraic. For the reverse inclusion, we have to use the hypothesis that $ V $ is an affine algebraic set. By the definition of affine algebraic sets, $ V = \VV\br{J} $ for some ideal $ J \subseteq k\sbr{X_1, \dots, X_n} $. Suppose that $ \underline{y} \notin V $. We shall show that $ \underline{y} \notin \VV\br{\II\br{V}} $. Because $ \underline{y} \notin V = \VV\br{J} $, there exists $ f \in J $ such that $ f\br{\underline{y}} \ne 0 $. By definition, $ J \subseteq \II\br{V} $ and so $ f \in \II\br{V} $. Hence $ f\br{\underline{y}} \ne 0 $ tells us that $ \underline{y} \notin \VV\br{\II\br{V}} $.
\end{proof}

What is the geometric interpretation of the Hilbert basis theorem?

\begin{note*}
It is clear that $ \VV $ and $ \II $ reverse the direction of inclusions, since if $ I_1 \subseteq I_2 $, then $ \VV\br{I_2} \subseteq \VV\br{I_1} $.
\end{note*}

Hence the ascending chain condition for ideals translates into the descending chain condition for affine algebraic sets. The following statement is the translation into affine algebraic sets of the Hilbert basis theorem.

\begin{lemma}
\label{lem:descendingchain}
Let $ V_1 \supseteq V_2 \supseteq \dots $ be a descending chain of affine algebraic sets in $ \AA^n $. Then there exists $ N $ such that $ V_n = V_N $ for all $ n > N $.
\end{lemma}

\begin{proof}
The fact that $ V_1 \supseteq V_2 \supseteq \dots $ implies that $ \II\br{V_1} \subseteq \II\br{V_2} \subseteq \dots $. Because $ k\sbr{X_1, \dots, X_n} $ is noetherian, there exists $ N $ such that $ \II\br{V_n} = \II\br{V_N} $ for all $ n > N $. By Lemma \ref{lem:viv}, $ V_n = \VV\br{\II\br{V_n}} $ for every $ n $ and so this proves Lemma \ref{lem:descendingchain}.
\end{proof}

\pagebreak

\subsubsection{Statement of the Nullstellensatz}

When does $ \II\br{\VV\br{I}} = I $? It turns out that the only reason that this can fail is where elements of the ideal $ I $ have $ n $-th roots which are not in $ I $, just as with the example of $ I = \abr{X^2} $ where $ X^2 \in I $ has a square root $ X $ which is not in $ I $. To state this precisely, we need to recall the definition of the radical of an ideal from commutative algebra.

\begin{definition*}
Let $ I $ be an ideal in a ring $ R $. The \textbf{radical} of $ I $ is
$$ \rad I = \sqrt{I} = \cbr{f \in R \st \exists n > 0, \ f^n \in I}. $$
We say that $ I $ is a \textbf{radical ideal} if $ \rad I = I $.
\end{definition*}

\begin{note*}
If $ I $ is any ideal, then $ \rad I $ is always a radical ideal.
\end{note*}

\begin{theorem}[Hilbert's Nullstellensatz]
\label{thm:strongnullstellensatz}
Let $ I $ be any ideal in the polynomial ring $ k\sbr{X_1, \dots, X_n} $ over an algebraically closed field $ k $. Then we have
$$ \II\br{\VV\br{I}} = \rad I. $$
\end{theorem}

This is a substantial theorem, fundamental to algebraic geometry. We will prove it in a few lectures' time, not because we need to develop more theory, just because I would like to introduce some more concepts first which will allow us to do more with examples.

\begin{note*}
To calculate $ \rad I $, we need to add in $ n $-th roots of all elements of $ I $, not just the generators.
\end{note*}

\begin{example*}
If $ I = \abr{X, Y^2 - X} \subseteq k\sbr{X, Y} $, then we can rewrite this as $ I = \abr{X, Y^2} $ and so $ \rad I = \abr{X, Y} \ne I $, even though neither of the original generators of $ I $ had any non-trivial $ n $-th roots.
\end{example*}

\subsubsection{Basic facts about the Zariski topology}

We have seen that affine algebraic sets in $ \AA^n $ satisfy the following conditions.
\begin{itemize}
\item $ \AA^n $ and $ \emptyset $ are affine algebraic sets, since the empty set is the vanishing set of a non-zero constant polynomial.
\item A finite union of affine algebraic sets is an affine algebraic set.
\item An arbitrary intersection of affine algebraic sets is an affine algebraic set.
\end{itemize}
These are precisely the conditions satisfied by the closed sets in a topological space. Therefore, we can define a topological space in which the underlying set is $ \AA^n $ and closed sets are the affine algebraic sets. This is called the \textbf{Zariski topology}. This is a very different topology from the ones you are used to in analysis. In particular, it is a very long way from being Hausdorff. For any affine algebraic set $ V \subseteq \AA^n $, we define the \textbf{Zariski topology} on $ V $ to be the subspace topology on $ V $ induced by the Zariski topology on $ \AA^n $. Thus, a subset of $ V $ is Zariski closed in $ V $ if and only if it is Zariski closed in $ \AA^n $. Thus for closed sets it does not matter whether we say Zariski closed in $ V $ or Zariski closed in $ \AA^n $.

\lecture{4}{Monday}{20/01/20}

\begin{example*}
The Zariski topology on $ \AA^1 $ is the same as the cofinite topology. Prove that the Zariski topology on $ \AA^1 $ is not Hausdorff. \footnote{Exercise}
\end{example*}

Thus we see that the Zariski topology has much fewer closed sets, or much fewer open sets, than for example the Euclidean topology.

\begin{lemma}
Suppose that $ k = \CC $, so there is a Euclidean topology on $ \AA_\CC^n $. If $ V $ is a Zariski closed subset of $ \AA_\CC^n $, then $ V $ is closed in the Euclidean topology, so the Euclidean topology is finer than the Zariski topology.
\end{lemma}

\begin{proof}
Let $ f \in \CC\sbr{X_1, \dots, X_n} $ be a polynomial. It is a continuous function $ \AA_\CC^n \to \CC $ for the Euclidean topology. Since $ \cbr{0} $ is a closed subset of $ \CC $, $ \VV\br{f} = f^{-1}\br{0} $ is a closed subset of $ \AA_\CC^n $ in the Euclidean topology. We conclude by noting that intersections of closed sets are closed.
\end{proof}

\pagebreak

On the other hand, for open sets Zariski open in $ V $ does not mean the same thing as Zariski open in $ \AA^n $. A Zariski open subset of $ V $ need not be Zariski open in $ \AA^n $.

\begin{example*}
Let $ V $ be the $ x $-axis in $ \AA^2 $. Then $ V \setminus \cbr{0} $ is open in $ V $, but not open in $ \AA^2 $.
\end{example*}

The open subsets of the Zariski topology are all very big. This is made precise, for $ \AA^1 $, by the following lemma.

\begin{lemma}
Prove that every pair $ U_1 $ and $ U_2 $ of non-empty open sets in $ \AA^1 $ has a non-empty intersection $ U_1 \cap U_2 $.
\end{lemma}

Hence the Zariski topology on $ \AA^1 $ is not Hausdorff. A subset of $ \AA^1 $ is dense in the Zariski topology if and only if it is infinite. At the moment, the Zariski topology is likely to seem very strange. It might also seem like, what is the point of such a strange topology? We will not use it in a very deep way, it is just a convenient language to be able to talk about open and closed sets. It does get used more seriously in the theory of schemes.

\subsubsection{Connected and irreducible sets}

Recall the definition of a connected topological space.

\begin{definition*}
A topological space $ S $ is \textbf{connected} if it is not possible to write it as the union of two disjoint non-empty open sets. This is equivalent to, it is not possible to write $ S $ as the union of two disjoint non-empty closed sets.
\end{definition*}

It is possible to talk about connectedness in the Zariski topology.

\begin{example*}
A finite set of points of size greater than one is not connected in the Zariski topology, since every subset is closed.
\end{example*}

Consider the following affine algebraic sets in $ \AA^2 $. Do they have one or two pieces? Do they have one or two pieces? I have deliberately not specified what I mean by pieces. There are multiple sensible interpretations, so there is not always a unique correct answer.
\begin{itemize}
\item The union of two disjoint lines $ \VV\br{X\br{X - 1}} $.
\item The union of two intersecting lines $ \VV\br{XY} $.
\item The hyperbola $ \VV\br{XY - 1} $.
\end{itemize}

\begin{example*}
The union of two disjoint lines $ \VV\br{X\br{X - 1}} $ is not connected, since it unambiguously has two pieces, the two lines $ \VV\br{X} $ and $ \VV\br{X - 1} $, and each line is a non-empty closed subset.
\end{example*}

But there is a more refined notion for the Zariski topology.

\begin{example*}
The set $ \VV\br{XY} $ has more than one answer. The two axes form two pieces. It is a union of two lines, intersecting at the origin, joining them into one piece. Describe the Zariski closed subsets. \footnote{Exercise}
\end{example*}

The following notion gives us a way of formally understanding the example described.

\begin{definition*}
A topological space $ S $ is \textbf{reducible} if it is empty, or there exist closed sets $ S_1, S_2 \subseteq S $ such that $ S = S_1 \cup S_2 $, and neither $ S_1 $ nor $ S_2 $ is equal to $ S $. A topological space $ S $ is \textbf{irreducible} if it is non-empty and it is not possible to write it as the union $ S_1 \cup S_2 $ of two closed sets, unless at least one of $ S_1 $ and $ S_2 $ is equal to $ S $ itself. Compared to the second definition of connected, we no longer require $ S_1 $ and $ S_2 $ to be disjoint.
\end{definition*}

This is not a very useful notion for the topological spaces we consider in analysis.

\begin{example*}
Considering the real line with the Euclidean topology, we can write it as a union of proper closed subsets,
$$ \RR = \cbr{x \in \RR \st x \le 0} \cup \cbr{x \in \RR \st x \ge 0}. $$
These subsets are not disjoint because they intersect at zero. Of course, there are many other ways to write $ \RR $ as a union of proper closed subsets in the usual topology. The same is true for any other Hausdorff space.
\end{example*}

\pagebreak

\begin{example*}
The drawing of $ \VV\br{XY - 1} $ in $ \RR^2 $ is misleading, since it looks like it has two pieces, but, as mentioned before, we are missing a lot by only looking at real solutions. For algebraic geometry, we need to look at complex solutions, and then over $ \CC $ it unambiguously has one piece. One way to visualise this is to note that, if we project down to the $ x $ coordinate, $ \VV\br{XY - 1} $ looks like the set $ \AA^1 \setminus \cbr{0} $. This is not a formal statement. We have not yet defined a notion of isomorphism of affine algebraic sets, and even if we had, $ \AA^1 \setminus \cbr{0} $ is not an affine algebraic set. In a few weeks we will develop technology to make this into a rigorous statement. But for now we use it as a heuristic. Then $ \RR \setminus \cbr{0} $ unambiguously has two pieces, but $ \CC \setminus \cbr{0} $ is connected in the usual analytic topology on $ \CC $ and unambiguously has one piece. So the hyperbola, over an algebraically closed field, should have only one piece.
\end{example*}

We prove below in the lecture that $ \VV\br{XY - 1} $ is irreducible, and also connected.

\begin{lemma}
The hyperbola $ H = \VV\br{XY - 1} $ is irreducible.
\end{lemma}

\begin{proof}
We need to describe the Zariski closed subsets of $ H $. So let $ V \subseteq H $ be a proper Zariski closed subset. Since $ V \ne H $ there must be some polynomial $ f \in k\sbr{X, Y} $ which vanishes on $ V $ but does not vanish on all of $ H $. Because $ V \subseteq H $ and $ y = 1 / x $ on $ H $, we have $ f\br{x, y} = f\br{x, 1 / x} $ when $ \br{x, y} \in V $. Now $ f\br{X, 1 / X} $ is almost a polynomial in the single variable $ X $, except that it may contain negative powers of $ X $, so
$$ f\br{X, \dfrac{1}{X}} = \sum_{n \in \ZZ} a_nX^n. $$
We can multiply up by $ X^m $ where $ -m $ is the lowest exponent of $ X $ which appears in this expression. Then $ X^mf\br{X, 1 / X} $ is a polynomial in $ X $, which vanishes on $ V $. Furthermore $ f\br{X, 1 / X} $ is not identically zero because $ f $ does not vanish identically on $ H $. Hence $ X^mf\br{X, 1 / X} $ is a non-zero single-variable polynomial, therefore it has only finitely many roots. The roots of $ X^mf\br{X, 1 / X} = 0 $ are the possible $ x $ coordinates for points in $ V $. For each value of $ x $, there is at most one possible $ y $ such that $ \br{x, y} \in V $ because $ y = 1 / x $ on $ V $. Therefore $ V $ is finite. Thus we have shown that all proper Zariski closed subsets of $ H $ are finite. In particular, if $ V_1 $ and $ V_2 $ are two proper Zariski closed subsets of $ H $, they are both finite and so their union is finite. Hence $ V_1 \cup V_2 \ne H $ so $ H $ is irreducible.
\end{proof}

Thus the Zariski topology on $ H $ is the cofinite topology. Here is a bonus fact about connected sets in the Zariski topology which I did not mention in the lecture. The proof is surprisingly hard.

\begin{theorem}
Over $ \CC $, an affine algebraic set is connected in the Zariski topology if and only if it is connected in the Euclidean topology.
\end{theorem}

\subsubsection{Prime ideals and irreducible sets}

If $ V $ is an affine algebraic set, what condition on the ideal $ \II\br{V} $ is equivalent to $ V $ being irreducible?

\lecture{5}{Thursday}{23/01/20}

\begin{definition*}
From commutative algebra, an ideal $ I $ in a ring $ R $ is a \textbf{prime ideal} if $ I \ne R $ and for every $ f, g \in R $, if $ fg \in I $, then $ f \in I $ or $ g \in I $, or both.
\end{definition*}

\begin{lemma}
\label{lem:irreducibleprime}
An affine algebraic set $ V \subseteq \AA^n $ is irreducible if and only if $ \II\br{V} $ is a prime ideal in $ k\sbr{X_1, \dots, X_n} $.
\end{lemma}

\begin{proof}
First suppose that $ V $ is irreducible. Suppose we have $ f, g \in k\sbr{X_1, \dots, X_n} $ such that $ fg \in \II\br{V} $. Let
$$ V_1 = \cbr{\underline{x} \in V \st f\br{\underline{x}} = 0}, \qquad V_2 = \cbr{\underline{x} \in V \st g\br{\underline{x}} = 0}. $$
For every $ \underline{x} \in V $, $ f\br{\underline{x}}g\br{\underline{x}} = 0 $ and hence either $ f\br{\underline{x}} = 0 $ or $ g\br{\underline{x}} = 0 $. Thus for every $ \underline{x} \in V $, either $ \underline{x} \in V_1 $ or $ \underline{x} \in V_2 $. In other words, $ V = V_1 \cup V_2 $. Furthermore $ V_1 $ and $ V_2 $ are closed subsets of $ V $. Hence as $ V $ is irreducible, either $ V_1 = V $ or $ V_2 = V $. If $ V_1 = V $ then $ f \in \II\br{V} $ and if $ V_2 = V $ then $ g \in \II\br{V} $. Now suppose that $ V $ is reducible. Then we can write it as a union $ V_1 \cup V_2 $ of proper closed subsets. Since $ V_1 $ is a proper closed subset of $ V $, there exists some $ f \in k\sbr{X_1, \dots, X_n} $ vanishing on $ V_1 $ but not on all of $ V $. Similarly there exists $ g $ vanishing on $ V_2 $ but not on all of $ V $. Thus neither $ f $ nor $ g $ is in $ \II\br{V} $, but the product $ fg $ vanishes on $ V_1 \cup V_2 $ and hence we have $ fg \in \II\br{V} $. Thus $ \II\br{V} $ is not prime. Then $ V $ is empty if and only if $ \II\br{V} = k\sbr{X_1, \dots, X_n} $, which is explicitly defined to not be a prime ideal. So it was ok to ignore this case above.
\end{proof}

\pagebreak

\begin{definition*}
A \textbf{hypersurface} is an affine algebraic set in $ \AA^n $ defined by one polynomial equation, that is,
$$ \cbr{\underline{x} \in \AA^n \st f\br{\underline{x}} = 0}, \qquad f \in k\sbr{X_1, \dots, X_n}. $$
\end{definition*}

It follows from Lemma \ref{lem:irreducibleprime} together with Hilbert's Nullstellensatz that a hypersurface defined by a polynomial $ f $ is irreducible if and only if $ f $ is a power of an irreducible polynomial. See problem sheet $ 1 $.

\begin{example*}
We can use this to prove that the circle $ \cbr{\br{x, y} \st x^2 + y^2 = 1} $ is irreducible, by proving that the polynomial $ X^2 + Y^2 - 1 $ is irreducible. This is because, if $ f = X^2 + Y^2 - 1 = f_1f_2 $ then we can scale $ f_1 $ and $ f_2 $ by constants to get
$$ f_1 = X + g_1\br{Y}, \qquad f_2 = X + g_2\br{Y}, $$
since $ f $ has degree two in $ X $ and its $ X^2 $ term has coefficient one. Since $ f $ has no $ X $ term, we must have $ g_1 + g_2 = 0 $. But then
$$ f_1f_2 = \br{X + g_1\br{Y}}\br{X - g_1\br{Y}} = X^2 - g_1\br{Y}^2, $$
so $ g_1\br{Y}^2 = -Y^2 + 1 $, and $ -Y^2 + 1 $ is not a square. On the other hand, the hypersurface $ \cbr{\br{x, y} \st x^2 + y^2 = 0} $ is reducible, because $ X^2 + Y^2 $ factors as $ \br{X - iY}\br{X + iY} $.
\end{example*}

It can often be convenient to rewrite the definition of irreducible spaces in terms of open sets instead of closed sets.

\begin{lemma}
\label{lem:irreducibleopen}
The following conditions on a topological space $ S $ are equivalent to irreducibility.
\begin{itemize}
\item $ S $ is non-empty, and every pair of non-empty open subsets $ U_1, U_2 \subseteq S $ have non-empty intersection $ U_1 \cap U_2 $.
\item $ S $ is non-empty, and every non-empty open subset of $ S $ is dense in $ S $.
\end{itemize}
\end{lemma}

\begin{proof}
Just manipulation of the topological definition.
\end{proof}

\begin{corollary}
\label{cor:irreducibleopen}
Let $ S $ be a irreducible topological space and $ U \subseteq S $ a non-empty open subset. Then $ U $ is irreducible, in the subspace topology.
\end{corollary}

Lemma \ref{lem:irreducibleopen} says that irreducible is a very long way from Hausdorff. The Hausdorff condition says that a space has lots of pairs of disjoint non-empty open subsets, while an irreducible space has none.

\begin{example*}
We saw that $ \RR $, with the Euclidean topology, is reducible in many ways.
\end{example*}

Corollary \ref{cor:irreducibleopen} implies that $ \AA^1 \setminus \cbr{0} $ is irreducible, in the subspace topology induced by the Zariski topology on $ \AA^1 $, because it is open in $ \AA^1 $. Compare this to the fact that the hyperbola $ H $ is irreducible. This lends support to the heuristic argument that the hyperbola $ H $ is irreducible, but it is not a proof. Checking that the subspace topology on $ \AA^1 \setminus \cbr{0} $ is the same as the Zariski topology on $ H $ would require exactly the same work as the proof that $ H $ is irreducible to prove that the Zariski topology on $ H \subseteq \AA^2 $.

\subsubsection{Irreducible components}

Just like the definition of connected components, we can define the following.

\begin{definition*}
Let $ S $ be a topological space. An \textbf{irreducible component} of $ S $ is a maximal irreducible subset of $ S $.
\end{definition*}

Unlike connected components, irreducible components need not be disjoint.

\begin{example*}
The irreducible components of $ \cbr{\br{x, y} \st xy = 0} $ are the lines $ x = 0 $ and $ y = 0 $, which intersect in $ \cbr{\br{0, 0}} $.
\end{example*}

More generally, the irreducible components of a hypersurface $ \VV\br{f} $ correspond to the irreducible factors of $ f $, since if $ f = f_1^{a_1} \dots f_m^{a_m} $, where the $ f_i $ are distinct irreducible polynomials, then the irreducible components of $ \VV\br{f} $ are $ \VV\br{f_1}, \dots, \VV\br{f_m} $. Irreducible components have the following key properties.

\pagebreak

\begin{proposition}
\label{prop:irreduciblecomponent}
Let $ V $ be an affine algebraic set. Then
\begin{enumerate}
\item the union of the irreducible components of $ V $ is all of $ V $, and
\item $ V $ has only finitely many irreducible components.
\end{enumerate}
\end{proposition}

Proposition \ref{prop:irreduciblecomponent}.$ 1 $ matches a property of connected components. Proposition \ref{prop:irreduciblecomponent}.$ 2 $ does not apply to the connected components of an arbitrary topological space.

\begin{example*}
$ \ZZ $ or $ \QQ $ with the subspace topology from $ \RR $.
\end{example*}

\begin{note*}
Proposition \ref{prop:irreduciblecomponent}.$ 2 $ does imply that an affine algebraic set has only finitely many connected components for the Zariski topology, because each connected component must be a union of irreducible components.
\end{note*}

Proposition \ref{prop:irreduciblecomponent}.$ 2 $ is a finiteness statement, so it is not surprising that it follows from the noetherian property, the descending chain condition on closed subsets. The key idea in the proof is as follows. If an affine algebraic set is reducible, then we can write it as a union of proper closed subsets. If these subsets are reducible, then we can write them in turn as unions of proper closed subsets. The following lemma says that this process eventually stops, since after finitely many steps, we reach irreducible sets.

\begin{lemma}
\label{lem:irreducibleclosed}
Every affine algebraic set can be written as a union of finitely many irreducible closed subsets.
\end{lemma}

\begin{proof}
Suppose that $ V $ is an affine algebraic set which cannot be written as a union of finitely many irreducible closed subsets. Then $ V $ must be reducible, otherwise we could write it as a union of one irreducible closed subset. So $ V = V_1 \cup W_1 $, with $ V_1 $ and $ W_1 $ proper closed subsets of $ V $. Then $ V_1 $ and $ W_1 $ cannot both be unions of finitely many irreducible closed subsets, because taking the union of those decompositions would give us $ V $ as a union of finitely many irreducible closed subsets. Thus at least one of $ V_1 $ and $ W_1 $ does not satisfy Lemma \ref{lem:irreducibleclosed}. Without loss of generality, we may suppose that $ V_1 $ does not satisfy Lemma \ref{lem:irreducibleclosed}. Then $ V_1 $ must be reducible, so we can write $ V_1 = V_2 \cup W_2 $. We can repeat the argument, since at least one of $ V_2 $ and $ W_2 $ does not satisfy Lemma \ref{lem:irreducibleclosed}, without loss of generality $ V_2 $, etc. Thus we build up a chain of closed subsets $ V \supset V_1 \supset V_2 \supset \dots $ where all these sets do not satisfy Lemma \ref{lem:irreducibleclosed}, and all the inclusions are strict. This contradicts Lemma \ref{lem:descendingchain}, the descending chain condition for affine algebraic sets.
\end{proof}

In order to prove Proposition \ref{prop:irreduciblecomponent}, we want to show that the finitely many irreducible closed subsets in Lemma \ref{lem:irreducibleclosed} are the irreducible components. There is just one wrinkle. Consider $ V = \VV\br{XY} $. The irreducible components are $ \VV\br{X} $ and $ \VV\br{Y} $. But we could write $ V $ as a union of finitely many irreducible closed subsets by saying, $ V = \VV\br{X} \cup \VV\br{Y} \cup \cbr{\br{0, 2}} $. Thus we can always add in extra sets to a decomposition as in Lemma \ref{lem:irreducibleclosed}, where the extra sets are contained in one of the other sets in the decomposition. Of course we can always just throw away these empty sets from the list without changing the union. Let $ V = V_1 \cup \dots \cup V_r $, as in Lemma \ref{lem:irreducibleclosed}. By throwing away any $ V_i $ which is contained in another $ V_j $, we can assume that $ V_i \not\subseteq V_j $ whenever $ i \ne j $, and still the union of the $ V_j $'s will be $ V $. Subject to this non-redundancy condition, there is only one way to write $ V $ as a finite union of irreducible closed subsets and we can prove the following.

\begin{proposition}
\label{prop:irreducibleclosed}
Let $ V $ be an affine algebraic set. Write $ V = V_1 \cup \dots \cup V_r $, where the $ V_i $ are irreducible closed subsets and $ V_i \not\subseteq V_j $ for $ i \ne j $. Then $ V_1, \dots, V_r $ are precisely the irreducible components of $ V $.
\end{proposition}

\begin{proof}
First we show that each $ V_i $ is an irreducible component. By hypothesis, $ V_i $ is irreducible. So if $ V_i $ is not an irreducible component, it is not a maximal irreducible set and must be contained in a larger irreducible set $ W \subseteq V $. But then
$$ W = \br{V_1 \cap W} \cup \dots \cup \br{V_r \cap W}, $$
where $ V_1 \cap W, \dots, V_r \cap W $ are closed subsets of $ W $. Because $ W $ is irreducible, we must have $ W = V_j \cap W $ for some $ j $. Thus $ V_i \subseteq W \subseteq V_j $. By the condition $ V_i \not\subseteq V_j $ for any $ j \ne i $, we must have $ i = j $ and $ W = V_i $. Thus $ V_i $ is an irreducible component of $ V $. Conversely, let $ C $ be an irreducible component of $ V $. Then
$$ C = \br{V_1 \cap C} \cup \dots \cup \br{V_r \cap C}. $$
By the same argument as before, the irreducibility of $ C $ implies that $ C \subseteq V_i $ for some $ i $. Then the maximality of $ C $ implies that $ C = V_i $.
\end{proof}

The combination of Lemma \ref{lem:irreducibleclosed} and Proposition \ref{prop:irreducibleclosed} proves both of Proposition \ref{prop:irreduciblecomponent}.

\pagebreak

\subsubsection{Primary decomposition of ideals}

The irreducible component decomposition of an affine algebraic set can give a geometric understanding of the primary decomposition of ideals in the noetherian ring $ k\sbr{X_1, \dots, X_n} $. However, the irreducible decomposition gives only partial information about the primary decomposition of an ideal, because ideals contain more information than affine algebraic sets. Recall that the algebraic set depends only on the radical of the ideal.

\begin{example*}
Let $ I = \abr{X^2, XY} \subseteq k\sbr{X, Y} $. Then $ \VV\br{I} $ is simply the line $ X = 0 $, which of course is irreducible. However a primary decomposition of $ I $ is
$$ I = \abr{X} \cap \abr{X^2, XY, Y^2}. $$
Here $ \abr{X} $ is the ideal of the line $ X = 0 $, the unique irreducible component of $ V = \VV\br{I} $. The ideal $ \abr{X^2, XY, Y^2} $ defines the point $ \cbr{\br{0, 0}} $, which is contained in $ V $ so is not an irreducible component.
\end{example*}

Thus the minimal associated primes of the primary decomposition of $ I $ corespond to the irreducible components of $ \VV\br{I} $, while non-minimal associated primes correspond to additional smaller sets strictly contained in the irreducible components, called \textbf{embedded components}. In scheme theory, we can think of $ \VV\br{I} $ as containing multiple copies of these embedded components.

\begin{example*}
The ideal $ I = \abr{X^2, XY} $ corresponds, in the world of schemes, to the line $ X = 0 $ with two copies of the origin.
\end{example*}

\subsection{Regular and rational maps}

\subsubsection{Regular functions}

\lecture{6}{Friday}{24/01/20}

So far we have only considered algebraic sets as sets, sitting individually. Now we look at functions between them. Just as one uses continuous functions for topological spaces, holomorphic functions for complex manifolds, homomorphisms for groups, etc, algebraic geometry has its own type of functions, regular functions. Of course, these are given by polynomials.

\begin{definition*}
Let $ V \subseteq \AA^n $ be an affine algebraic set. A \textbf{regular function} on $ V $ is a function $ f : V \to k $ such that there exists a polynomial $ F \in k\sbr{X_1, \dots, X_n} $ with $ f\br{\underline{x}} = F\br{\underline{x}} $ for all $ \underline{x} \in V $.
\end{definition*}

\begin{note*}
The polynomial $ F $ is not uniquely determined by the function $ f $, since $ F, G \in k\sbr{X_1, \dots, X_n} $ determine the same regular function on $ V $ if and only if $ F - G $ vanishes on $ V $, that is if and only if $ F - G \in \II\br{V} $.
\end{note*}

\begin{definition*}
The regular functions on $ V $ form a $ k $-algebra, since they can be added and multiplied by each other, and multiplied by scalars in $ k $. This is called the \textbf{coordinate ring} of $ V $ and denoted $ k\sbr{V} $.
\end{definition*}

There is a ring homomorphism $ k\sbr{X_1, \dots, X_n} \to k\sbr{V} $ which sends a polynomial $ F $ to the function $ \eval{F}_V $ which it defines on $ V $. This homomorphism is surjective and its kernel is $ \II\br{V} $, so
$$ k\sbr{V} \cong k\sbr{X_1, \dots, X_n} / \II\br{V}. $$

\begin{example*}
What are the coordinate rings of the following affine algebraic sets?
\begin{itemize}
\item The coordinate ring of $ \AA^n $ is $ k\sbr{X_1, \dots, X_n} $.
\item The coordinate ring of a point is $ k $. A regular function on a point is just a single value.
\item The coordinate ring of two points $ \cbr{x \in \AA^1 \st x\br{x - 1} = 0} $ is $ k \times k $. A regular function on two points is determined by two scalars, namely its value on each of the two points. For any pair of values $ \br{a, b} \in k \times k $, one can easily write down a polynomial $ f \in k\sbr{X} $ such that $ f\br{1} = a $ and $ f\br{0} = b $. Alternatively, one can check algebraically that the map
$$ \function{k \times k}{k\sbr{X} / \abr{X\br{X - 1}}}{\br{a, b}}{\br{a - 1}X + b \mod \abr{X\br{X - 1}}} $$
is a $ k $-algebra isomorphism. This example generalises, since if $ V $ is a disconnected affine algebraic set, we can write $ V $ as a union $ V_1 \cup V_2 $ of disjoint Zariski closed subsets, and then $ k\sbr{V} = k\sbr{V_1} \times k\sbr{V_2} $. On the other hand, if $ V $ is reducible but connected, so that the sets $ V_1 $ and $ V_2 $ are not disjoint, then $ k\sbr{V} $ is a proper subset of $ k\sbr{V_1} \times k\sbr{V_2} $.

\pagebreak

\item The coordinate ring of two intersecting lines $ \cbr{\br{x, y} \in \AA^2 \st xy = 0} $ is
$$ \cbr{\br{f, g} \in k\sbr{X} \times k\sbr{Y} \st f\br{0} = g\br{0}}. $$
To prove this, one can also interpret this as
$$ k\sbr{X, Y} / \abr{XY} \cong \cbr{a_0 + \sum_{r = 1}^m b_rX^r + \sum_{s = 1}^n c_sY^s \st a_0, b_1, \dots, b_m, c_1, \dots, c_n \in k, \ m, n \in \NN}. $$
We can compare these two descriptions by observing that
$$ k\sbr{X} = \cbr{a_0 + \sum_{r = 1}^m b_rX^r}, \qquad k\sbr{Y} = \cbr{a_0 + \sum_{s = 1}^n c_sY^s}, $$
and the condition that $ f\br{0} = g\br{0} $ is equivalent to insisting that these two polynomials have the same constant coefficient $ a_0 $. This example does not generalise to arbitrary reducible algebraic sets. We may have $ V = V_1 \cup V_2 $ where $ V_1 $ and $ V_2 $ are closed subsets, but
$$ k\sbr{V} \ne \cbr{\br{f, g} \in k\sbr{V_1} \times k\sbr{V_2} \st \eval{f}_{V_1 \cap V_2} = \eval{g}_{V_1 \cap V_2}}. $$
There will be an example of this on problem sheet $ 2 $.
\item The coordinate ring of a hyperbola $ \cbr{\br{x, y} \in \AA^2 \st xy - 1 = 0} $ is the quotient ring $ k\sbr{X, Y} / \abr{XY - 1} $. To describe this more explicitly, note that any term of a two-variable polynomial is
$$ a_{r, s}X^rY^s \equiv
\begin{cases}
a_{r, s}X^{r - s} & r \ge s \\
a_{r, s}Y^{s - r} & s > r
\end{cases}
\mod \abr{XY - 1}.
$$
Thus every coset in $ k\sbr{X, Y} / \abr{XY - 1} $ has a representative of the form
$$ \sum_{i = 0}^m a_iX^i + \sum_{j = 1}^n a_jY^j. $$
The polynomials of this form determine different functions on $ V $, so we have written down exactly one representative of each coset. Furthermore, since $ XY = 1 $ in $ k\sbr{V} $, we may relabel $ Y $ as $ X^{-1} $. Then the multiplication rule will be what the notation leads us to expect. So we can write
$$ k\sbr{V} = k\sbr{X, X^{-1}} = \cbr{\sum_{j = -n}^m a_jX^m \st a_{-n}, \dots, a_m \in k, \ m, n \in \NN}. $$
\end{itemize}
\end{example*}

\begin{lemma}
An affine algebraic set $ V $ is irreducible if and only if $ k\sbr{V} $ is an integral domain.
\end{lemma}

\begin{proof}
$ V $ is irreducible if and only if $ \II\br{V} $ is a prime ideal in $ k\sbr{X_1, \dots, X_n} $.
\end{proof}

\subsubsection{Regular maps}

A regular function goes from an algebraic set $ V $ to the field $ k $. We can also define regular maps, which go from one algebraic set $ V $ to another algebraic set $ W $.

\begin{definition*}
Let $ V \subseteq \AA^m $ and $ W \subseteq \AA^n $ be affine algebraic sets. A \textbf{regular map} $ \phi : V \to W $ is a function $ V \to W $ such that there exist polynomials $ F_1, \dots, F_n \in k\sbr{X_1, \dots, X_m} $ such that $ \phi\br{\underline{x}} = \br{F_1\br{\underline{x}}, \dots, F_n\br{\underline{x}}} $ for all $ \underline{x} \in V $. Regular maps are often called \textbf{morphisms}.
\end{definition*}

\begin{note*}
In order to check that a given list of polynomials $ F_1, \dots, F_n $ defines a regular map $ V \to W $, it is necessary to check that $ \br{F_1\br{\underline{x}}, \dots, F_n\br{\underline{x}}} \in W $ for every $ \underline{x} \in V $. Equivalently, we need to check that the regular functions $ \eval{F_1}_V, \dots, \eval{F_n}_V \in k\sbr{V} $ satisfy the equations $ g\br{\eval{F_1}_V, \dots, \eval{F_n}_V} = 0 $ in the coordinate ring $ k\sbr{V} $, for each polynomial $ g \in \II\br{W} $.
\end{note*}

\pagebreak

\begin{example*}
\hfill
\begin{itemize}
\item Let $ V \subseteq \AA^m $ be an affine algebraic set. For any $ n < m $, the projection defined by
$$ \function[\pi]{V}{\AA^n}{\br{x_1, \dots, x_m}}{\br{x_1, \dots, x_n}} $$
is a regular map.
\item A regular function on $ V $ is the same thing as a regular map $ V \to \AA^1 $.
\item Let $ C = \cbr{\br{x, y} \st y^2 = x^3} $. Then
$$ \function{\AA^1}{C}{t}{\br{t^2, t^3}} $$
is a regular map.
\item Consider $ \SL_n $, the set of $ n \times n $ matrices with determinant one. This is an affine algebraic set in $ \AA^{n^2} $ because the determinant is a polynomial in the entries of a matrix. The map
$$ \function{\SL_n}{\SL_n}{a}{a^{-1}} $$
is a regular map, since Cramer's rule tells us how to write each entry of $ a^{-1} $ as a polynomial in the entries of $ a $ divided by $ \det a $, and because we are only considering $ a \in \SL_n $ we can drop the division.
\end{itemize}
\end{example*}

A regular map $ \phi : V \to W $ is a continuous function with respect to the Zariski topology. This is because, if $ A \subseteq W $ is a Zariski closed subset defined by polynomials $ f_1, \dots, f_r $, then $ \phi^{-1}\br{A} $ is the zero set
$$ \phi^{-1}\br{A} = \cbr{x \in V \st \br{f_1 \circ \phi}\br{x} = 0, \ \dots, \ \br{f_r \circ \phi}\br{x} = 0}, $$
and therefore $ \phi^{-1}\br{A} $ is a Zariski closed subset of $ V $. In complex analysis, holomorphic is a much stricter condition than continuous in the Euclidean topology, and similarly regular is much stricter than continuous in the Zariski topology. The following fact is very useful.

\begin{lemma}
\label{lem:affinedense}
Let $ \phi, \psi : V \to W $ be regular maps. If there exists a Zariski dense subset $ A \subseteq V $ such that $ \eval{\phi}_A = \eval{\psi}_A $, then $ \phi = \psi $ on all of $ V $.
\end{lemma}

\begin{note*}
If $ X $ and $ Y $ are Hausdorff topological spaces, then any continuous maps $ X \to Y $ which agree on a dense set must agree everywhere. However Lemma \ref{lem:affinedense} does not follow immediately from the fact that regular maps are continuous, because the Zariski topology is not Hausdorff, and is definitely false if we try to generalise it to all continuous maps with respect to the Zariski topology. Thus in order to prove Lemma \ref{lem:affinedense}, we have to use something special about regular maps as opposed to general continuous maps.
\end{note*}

\begin{proof}
Write $ \phi = \br{F_1, \dots, F_m} $ and $ \psi = \br{G_1, \dots, G_m} $, where $ F_1, \dots, F_m, G_1, \dots, G_m $ are polynomials. Then $ F_i - G_i $ is also a polynomial for each $ i $, and so
$$ V' = \cbr{\underline{x} \in V \st \phi\br{\underline{x}} = \psi\br{\underline{x}}} = \cbr{\underline{x} \in V \st \forall i, \ \br{F_i - G_i}\br{\underline{x}} = 0} $$
is a Zariski closed subset of $ V $. But we know that $ V' $ contains $ A $, which is Zariski dense in $ V $. Hence $ V' = V $.
\end{proof}

\subsubsection{Isomorphisms}

\lecture{7}{Monday}{27/01/20}

\begin{definition*}
A regular map $ \phi : V \to W $ is an \textbf{isomorphism} if there exists a regular map $ \psi : W \to V $ such that $ \psi \circ \phi = \id_V $ and $ \phi \circ \psi = \id_W $.
\end{definition*}

\begin{example*}
If $ V $ is the parabola $ \cbr{\br{x, y} \st y - x^2 = 0} $, then the regular map given by
$$ \function[\phi]{V}{\AA^1}{\br{x, y}}{x} $$
is an isomorphism because it has an inverse given by
$$ \function[\psi]{\AA^1}{V}{x}{\br{x, x^2}}. $$
\end{example*}

\pagebreak

\begin{example*}
On the other hand, if $ H $ is the hyperbola $ \cbr{\br{x, y} \st xy = 1} $, then the projection
$$ \function{H}{\AA^1}{\br{x, y}}{x} $$
is not an isomorphism because it is not surjective so it cannot possibly have an inverse. This is not enough to prove that $ H $ is not isomorphic to $ \AA^1 $, because maybe there is some other regular map $ H \to \AA^1 $ which is an isomorphism. We will soon prove that $ H $ is not isomorphic to $ \AA^1 $.
\end{example*}

\begin{example*}
Consider the affine algebraic set $ W = \cbr{\br{x, y} \st y^2 - x^3 = 0} $. The regular map given by
$$ \function[\phi]{\AA^1}{W}{t}{\br{t^2, t^3}} $$
is a bijection but it is not an isomorphism. Note that we should expect $ W $ not to be isomorphic to $ \AA^1 $ because it has a singularity at the origin. To prove that $ \phi : \AA^1 \to W $ is not an isomorphism, consider a regular map $ \psi : W \to \AA^1 $. It must be given by a polynomial $ g\br{X, Y} \in k\sbr{X, Y} $ and so $ \br{\psi \circ \phi}\br{t} = \psi\br{t^2, t^3} $ is a polynomial in $ t $ which can have a constant term and terms of degree two or greater, but no term of degree one. Hence we cannot find $ \psi $ such that $ \br{\psi \circ \phi}\br{t} = t $.
\end{example*}

\subsubsection{Regular maps and \texorpdfstring{$ k $}{k}-algebra homomorphisms}

Suppose we have a regular map $ \phi : V \to W $ between affine algebraic sets. For each regular function $ g $ on $ W $, we get a regular function $ \phi^*g $ on $ V $ defined by
$$ \function[\phi^*]{k\sbr{W}}{k\sbr{V}}{g}{g \circ \phi}. $$
We call $ \phi^*g \in k\sbr{V} $ the \textbf{pull-back} of $ g \in k\sbr{W} $. Thus $ \phi $ induces a $ k $-algebra homomorphism $ \phi^* : k\sbr{W} \to k\sbr{V} $.

\begin{note*}
$ \phi^* $ goes in the opposite direction to $ \phi $.
\end{note*}

If we have two regular maps $ \phi : V \to W $ and $ \psi : W \to Z $, then we can compose them to get $ \psi \circ \phi : V \to Z $. One can easily check that the associated pull-back maps on coordinate rings satisfy
$$ \br{\psi \circ \phi}^* = \phi^* \circ \psi^* : k\sbr{Z} \to k\sbr{V}. $$
For those who know category theory, we say that $ V \mapsto k\sbr{V} $ is a contravariant functor
$$ \cbr{\text{affine algebraic sets}} \to \cbr{\text{$ k $-algebras}}. $$
In particular, this tells us that if $ \phi : V \to W $ is an isomorphism with inverse $ \psi : W \to V $, then $ \psi^* \circ \phi^* = \id $ and $ \phi^* \circ \psi^* = \id $. Thus if $ V $ and $ W $ are isomorphic affine algebraic sets, then their coordinate rings $ k\sbr{V} $ and $ k\sbr{W} $ are isomorphic as $ k $-algebras.

\begin{example*}
Now we can prove that the hyperbola $ H $ is not isomorphic to $ \AA^1 $, because $ k\sbr{H} = k\sbr{X, X^{-1}} $ is not isomorphic to $ k\sbr{\AA^1} = k\sbr{X} $. To verify that these $ k $-algebras are not isomorphic, observe that in $ k\sbr{X} $ the only invertible elements are the scalars, while $ k\sbr{X, X^{-1}} $ contains non-scalar invertible elements, such as $ X $.
\end{example*}

\begin{example*}
We can similarly prove that $ \AA^1 $ is not isomorphic to the singular cubic $ W = \cbr{\br{x, y} \st y^2 = x^3} $. We saw earlier that $ k\sbr{W} $ is the ring of polynomials in one variable with no term of degree one, that is
$$ k\sbr{W} = \cbr{a_0 + \sum_{r = 2}^m a_rX^r \st a_0, a_2, \dots, a_m \in k}. $$
To prove that $ k\sbr{W} $ is not isomorphic to $ k\sbr{\AA^1} = k\sbr{X} $, observe that $ k\sbr{X} $ is a unique factorisation domain but $ k\sbr{W} $ is not because $ \abr{X^2}^3 = \abr{X^3}^2 $, and $ X^2 $ and $ X^3 $ are both irreducible in $ k\sbr{W} $.
\end{example*}

\pagebreak

\subsubsection{Rational functions}

Informally, rational functions are functions on varieties defined by polynomial fractions, for example the function $ x \mapsto 1 / x $ on $ \AA^1 $. Observe that this is not really a function $ \AA^1 \to \AA^1 $ because it is not defined at $ x = 0 $, but it is a genuine function on the Zariski open subset $ \AA^1 \setminus \cbr{0} $. These are analogues of meromorphic functions in complex analysis. Just as with regular functions and regular maps, we first define rational functions, which take values in $ k $, then rational maps, which go into any algebraic set. We make this definition only for irreducible affine algebraic sets because, as we saw in the example of $ 1 / x $, a rational function defines a genuine function on a Zariski open subset of $ V $, and irreducibility guarantees that all open subsets of $ V $ are dense in $ V $, so that a function defined on an open subset really is defined almost everywhere on $ V $.

\begin{definition*}
Let $ V $ be an irreducible affine algebraic set. The \textbf{function field} of $ V $ is the field of fractions of the coordinate ring $ k\sbr{V} $. We denote this by $ k\br{V} $.
\end{definition*}

\begin{note*}
$ k\sbr{V} $ is an integral domain because $ V $ is irreducible, and therefore $ k\sbr{V} $ has a field of fractions.
\end{note*}

\begin{example*}
The function field of $ \AA^1 $ is $ k\br{X} $, the fraction field of the polynomial ring $ k\sbr{X} $.
\end{example*}

\begin{definition*}
A \textbf{rational function} on $ V $ is an element of the function field $ k\br{V} $. Thus a rational function can be written in the form $ f / g $, where $ f $ and $ g $ are regular functions. There may be many different choices for $ f $ and $ g $ which define the same rational function $ f / g $.
\end{definition*}

\begin{definition*}
We say that a rational function $ \phi \in k\br{V} $ is \textbf{regular} at a point $ x \in V $ if there exist regular functions $ f, g \in k\sbr{V} $ such that $ \phi = f / g $ and $ g\br{x} \ne 0 $.
\end{definition*}

Thus regular points are precisely the points at which we can assign a value to $ \phi\br{x} $, since if $ g\br{x} \ne 0 $, then we can define $ \phi\br{x} = f\br{x} / g\br{x} $.

\begin{note*}
We are allowed to choose different fractions $ f / g $ representing $ \phi $ at different points $ x \in V $, in order to show that those points are regular. The value $ \phi\br{x} $ is independent of which fraction representing $ \phi $ we choose, as long as it has $ g\br{x} \ne 0 $.
\end{note*}

\begin{example*}
Consider the algebraic set defined by the equation $ XY = ZT $ in $ \AA^4 $. Let $ \phi = X / Z \in k\br{V} $. The defining equation implies that we also have $ \phi = T / Y $. Looking at the fraction $ X / Z $ shows us that $ \phi $ is regular wherever $ Z \ne 0 $, and looking at the fraction $ T / Y $ shows us that $ \phi $ is regular wherever $ Y \ne 0 $. On the other hand, $ \phi $ is not regular on the closed subset $ Y = Z = 0 $. One can verify that there is no other fraction representing $ \phi $ which is non-zero on this closed subset.
\end{example*}

\lecture{8}{Thursday}{30/01/20}

Let $ V $ be an irreducible affine algebraic set. Let $ \phi \in k\br{V} $ be a rational function.

\begin{definition*}
The set of points where $ \phi $ is regular is called the \textbf{domain of definition} of $ \phi $, and denoted $ \dom \phi $.
\end{definition*}

This is the set of points where it makes sense to assign a value to $ \phi\br{x} $. For $ x \in \dom \phi $, the value $ \phi\br{x} $ is independent of which fraction $ f / g $ we choose to represent $ \phi $, as long as $ g\br{x} \ne 0 $.

\begin{lemma}
\label{lem:domaindefinition}
The domain of definition of a rational function $ \phi \in k\br{V} $ is a non-empty Zariski open subset of $ V $.
\end{lemma}

\begin{proof}
Consider the set of all possible fractions $ f / g $ with $ f, g \in k\sbr{V} $ representing $ \phi \in k\br{V} $. The set of points at which $ \phi $ is not regular is the intersection of the Zariski closed sets $ \cbr{x \in V \st g\br{x} = 0} $ across all these fractions. Hence the set of points at which $ \phi $ is not regular is a Zariski closed subset of $ V $. The domain of definition is the complement of this set, and therefore is Zariski open. To show that the domain of definition is non-empty, pick a single fraction $ f / g $ representing $ \phi \in k\br{V} $. The regular function $ g $ is not equal to zero as an element of $ k\sbr{V} $, by the definition of the field of fractions, so $ \cbr{x \in V \st g\br{x} = 0} $ is a proper closed subset of $ V $. The domain of definition contains the complement of this set, namely $ \cbr{x \in V \st g\br{x} \ne 0} $, and hence is non-empty.
\end{proof}

\begin{note*}
Every regular function $ f \in k\sbr{V} $ is also a rational function $ f / 1 \in k\br{V} $, and its domain of definition is all of $ V $.
\end{note*}

\pagebreak

The converse also holds.

\begin{lemma}
\label{lem:rationalregular}
Let $ \phi \in k\br{V} $ be a rational function whose domain of definition is equal to $ V $. Then $ \phi $ is a regular function on $ V $.
\end{lemma}

\begin{proof}
Since $ \dom \phi = V $, for each point $ x \in V $, we can choose regular functions $ f_x, g_x \in k\sbr{V} $ such that $ \phi = f_x / g_x $ and $ g_x\br{x} \ne 0 $. Let $ I \subseteq k\sbr{V} $ denote the ideal generated by the functions $ g_x $. Because $ k\sbr{V} $ is noetherian, we can pick finitely many of these functions $ g_{x_1}, \dots, g_{x_m} $ which still generate $ I $. For each $ x \in V $, there is some $ g_x \in I $ which is non-zero at $ x $. Hence the Zariski closed subset of $ V $ defined by $ \cbr{x \in V \st \forall h \in I, \ h\br{x} = 0} $ is empty. Then the Nullstellensatz implies that $ I $ is all of $ k\sbr{V} $. In particular, $ 1 \in I $. Since $ I = \abr{g_{x_1}, \dots, g_{x_m}} $, there exist $ u_1, \dots, u_m \in k\sbr{V} $ such that $ 1 = u_1g_{x_1} + \dots + u_mg_{x_m} $ in $ k\sbr{V} $. We can now calculate
$$ \phi = \br{u_1g_{x_1} + \dots + u_mg_{x_m}}\phi = u_1g_{x_1}\dfrac{f_{x_1}}{g_{x_1}} + \dots + u_mg_{x_m}\dfrac{f_{x_m}}{g_{x_m}} = u_1f_{x_1} + \dots + u_mf_{x_m}. $$
Since $ u_i, f_{x_i} \in k\sbr{V} $, so is $ \phi $. Note that it might appear that we have only proved the above equation $ \phi = u_1f_{x_1} + \dots + u_mf_{x_m} $ on a Zariski open subset of $ V $, namely the intersections of the domains of definition of $ f_{x_1} / g_{x_1}, \dots, f_{x_m} / g_{x_m} $. Because $ V $ is irreducible, this open subset must be dense, but the subset where an equation of polynomials holds is closed, so it is equal to all of $ V $.
\end{proof}

\subsubsection{Rational maps}

Let $ V \subseteq \AA^m $ and $ W \subseteq \AA^n $ be irreducible affine algebraic sets.

\begin{definition*}
A \textbf{rational map} $ \phi : V \dashrightarrow W $ is an $ n $-tuple of rational functions $ \phi_1, \dots, \phi_n \in k\br{V} $ such that, for every point $ x \in V $ where $ \phi_1, \dots, \phi_n $ are all regular, the point $ \br{\phi_1\br{x}, \dots, \phi_n\br{x}} $ is in $ W $.
\end{definition*}

We use the broken arrow symbol instead of the usual arrow because a rational map is not a function on $ V $ in the usual set-theoretic sense. It only defines a genuine function $ U \to W $, where $ U $ is the domain of definition of $ \phi $. This is defined as follows.

\begin{definition*}
The \textbf{domain of definition} of a rational map $ \phi : V \dashrightarrow W $ is the intersection of the domains of definition of the component rational functions $ \br{\phi_1, \dots, \phi_n} $.
\end{definition*}

The two lemmas we proved for rational functions also hold for rational maps. The domain of definition of a rational map $ \phi : V \dashrightarrow W $ is a non-empty Zariski open subset of $ V $, and if a rational map is regular everywhere then it is a regular map. In order to prove that the domain of definition of a rational map is non-empty, we have to use the fact that $ V $ is irreducible, and therefore every open subset of $ V $ is dense.

\begin{example*}
An important example of a rational map is the projection from a point onto a hyperplane. Let $ H $ be a hyperplane in $ \AA^n $, that is a set defined by a single linear equation. Let $ p $ be a point in $ \AA^n \setminus H $. For simplicity, we shall assume that $ p $ is the origin and that
$$ H = \cbr{\br{x_1, \dots, x_n} \in \AA^n \st x_n = 1}, $$
since we could always reduce to this case by a suitable change of coordinates. Let us write $ H_p $ for the hyperplane through $ p $ parallel to $ H $, that is
$$ H_p = \cbr{\br{x_1, \dots, x_n} \in \AA^n \st x_n = 0}. $$
For each point $ x \in \AA^n \setminus H_p $, let $ L_x $ denote the line which passes through $ p $ and $ x $. Since $ x \notin H_p $, $ L_x $ intersects $ H $ in exactly one point. Call this point $ \phi\br{x} $. We can write this algebraically as
$$ \rational[\phi]{\AA^n}{H}{\br{x_1, \dots, x_n}}{\br{\dfrac{x_1}{x_n}, \dots, \dfrac{x_{n - 1}}{x_n}, 1}}, $$
and so $ \phi $ is a rational map. This map is called the \textbf{projection from $ p $ onto $ H $}. We have $ \dom \phi = \AA^n \setminus H_p $. Note that we have not proved this, because we have not proved that there is no other list of fractions which define the same rational map but have non-zero denominators at points in $ H_p $. One can prove this. For any affine algebraic set $ V \subseteq \AA^n $ such that $ V \not\subseteq H_p $, we can restrict $ \phi $ to get a rational map $ V \dashrightarrow H $. Note that $ p $ might be in $ V $, or it might not.
\end{example*}

\pagebreak

\begin{example*}
Let $ V $ be the circle $ \cbr{\br{x, y} \st x^2 + y^2 = 1} $. Consider the projection from the point $ p = \br{1, 0} $ on to the line $ x = 0 $. This is a rational map with the formula
$$ \rational[\pi]{V}{\AA^1}{\br{x, y}}{\dfrac{y}{1 - x}}. $$
We can see geometrically that this projection induces a bijection between the circle, excluding $ p $, and the line, at least for real points. If we compute the formula for the inverse map, we get
$$ \rational[\psi]{\AA^1}{V}{t}{\br{\dfrac{t^2 - 1}{t^2 + 1}, \dfrac{2t}{t^2 + 1}}}, $$
a well-known parameterisation of the circle. Thus we see that the inverse is a rational map. Note that $ \psi $ is not regular at $ t = \pm i $. We do not see this on the picture, which only shows the real points.
\end{example*}

We would like to define formally what it means to say that the rational maps $ \pi $ and $ \psi $ are inverse to each other, taking into account that they are not true functions between the sets $ V $ and $ \AA^1 $ because they are not regular everywhere. These maps are inverses in that composing them, either way round, gives the identity, if we ignore the points where the maps are not regular.

\subsubsection{Birational equivalences}

\lecture{9}{Friday}{31/01/20}

In order to do this, we first define what it means to compose rational maps. But it does not always make sense to compose rational maps. In order to rigorously define composition of rational maps, we need to notice that sometimes the set of points where a composite map is undefined is everywhere and exclude that situation.

\begin{example*}
Consider the rational map defined by
$$ \rational[\xi]{\AA^2}{\AA^1}{\br{x, y}}{\dfrac{1}{1 - x^2 - y^2}}. $$
This map is not regular anywhere on the circle $ V $, and hence it does not make sense to try to define the composite map $ \xi \circ \psi : \AA^1 \dashrightarrow \AA^1 $, since it is not defined anywhere.
\end{example*}

This problem can occur because the image of $ \psi $ is not dense in $ \AA^2 $. So to rule it out this problem, we make the following definition of dominant rational maps.

\begin{definition*}
The \textbf{image} of a rational map $ \phi : V \dashrightarrow W $ is the set of points
$$ \cbr{\phi\br{x} \in W \st x \in \dom \phi}. $$
A rational map is \textbf{dominant} if its image is Zariski dense in $ W $.
\end{definition*}

\begin{example*}
$ \psi $ from the end of the previous lecture is dominant if we consider it as a rational map $ \AA^1 \dashrightarrow V $ but it is not dominant if we consider it as a rational map $ \AA^1 \dashrightarrow \AA^2 $. This is like surjectivity, since whether a function is surjective or not depends on what codomain you declare it to have.
\end{example*}

Let $ V, W, T $ be irreducible affine algebraic sets. If $ \phi : V \dashrightarrow W $ is a dominant rational map and $ \psi : W \dashrightarrow T $ is a rational map, where $ \psi $ is not required to be dominant, then it makes sense to compose them because we know that $ \dom \psi $ is a Zariski open subset of $ W $, while $ \im \phi $ is a Zariski dense subset of $ W $ and so $ \dom \psi \cap \im \phi \ne \emptyset $. Thus there are at least some points where $ \psi \circ \phi $ is defined. One can check, by writing out $ \psi $ in terms of fractions of polynomials, then substituting in fractions of polynomials representing $ \phi $, that $ \psi \circ \phi $ is a rational map $ V \dashrightarrow T $.

\begin{definition*}
Rational maps $ \phi : V \dashrightarrow W $ and $ \psi : W \dashrightarrow V $ are \textbf{rational inverses} if both are dominant and $ \phi \circ \psi = \id_W $ and $ \psi \circ \phi = \id_V $, everywhere these composite rational maps are well-defined. A rational map $ \phi : V \dashrightarrow W $ is a \textbf{birational equivalence} if it is dominant and has a rational inverse. We say that irreducible algebraic sets $ V $ and $ W $ are \textbf{birational}, or \textbf{birationally equivalent}, if there exists a birational equivalence $ V \dashrightarrow W $.
\end{definition*}

\pagebreak

\begin{example*}
Our example from the previous lecture showed that the circle is birational to $ \AA^1 $.
\end{example*}

\begin{example*}
Another example is the cuspidal cubic $ W = \cbr{\br{x, y} \st y^2 = x^3} $. This is also birational to $ \AA^1 $, as shown by the rational maps
$$ \rational{W}{\AA^1}{\br{x, y}}{\dfrac{y}{x}}, \qquad \rational{\AA^1}{W}{t}{\br{t^2, t^3}}. $$
\end{example*}

Birationally equivalent affine algebraic sets look the same almost everywhere.

\begin{example*}
The cuspidal cubic is the same as the affine line everywhere except at the origin.
\end{example*}

\begin{example*}
$ \AA^1 $ is not birationally equivalent to $ \AA^2 $ or to an elliptic curve $ \cbr{\br{x, y} \st y^2 = f\br{x}} $ where $ f $ is a cubic polynomial with no repeated roots. We will prove this later in the course once we have more tools.
\end{example*}

\subsubsection{Dominant rational maps and \texorpdfstring{$ k $}{k}-field homomorphisms}

If $ \phi : V \dashrightarrow W $ is a dominant rational map, then we can use it to pull back rational functions from $ W $ to $ V $, just like we earlier used regular maps to pull back regular functions. We get a $ k $-homomorphism of fields defined by
$$ \function[\phi^*]{k\br{W}}{k\br{V}}{g}{g \circ \phi}. $$
A \textbf{$ k $-homomorphism} means that $ \phi^* $ restricts to the identity on the copies of $ k $ which are contained in $ k\br{W} $ and $ k\br{V} $, namely the constant functions. If $ \phi $ is a birational equivalence, then $ \phi^* $ is a $ k $-isomorphism of fields.

\subsection{Equivalence of algebra and geometry}

\subsubsection{From algebra homomorphisms to regular maps}

We have seen that each regular map $ f : V \to W $ induces a $ k $-algebra homomorphism $ f^* : k\sbr{W} \to k\sbr{V} $, and that each dominant rational map $ \phi : V \dashrightarrow W $ induces a $ k $-field homomorphism $ \phi^* : k\br{W} \to k\br{V} $. We can also carry out these constructions in the reverse direction. Starting with a $ k $-algebra homomorphism and getting a regular map, or similarly for rational maps. Observe that if $ f : V \to W $ is a regular map and $ W \subseteq \AA^n $, we can recover $ f $ from $ f^* : k\sbr{W} \to k\sbr{V} $ by taking the coordinate functions $ X_1, \dots, X_n \in k\sbr{W} $ on $ W $ and pulling them back to get $ f_1 = f^*X_1, \dots, f_n = f^*X_n \in k\sbr{V} $. These are precisely the regular functions on $ V $ such that $ f = \br{f_1, \dots, f_n} $. We generalise this procedure for any $ k $-algebra homomorphism $ \alpha : k\sbr{W} \to k\sbr{V} $. Starting from an arbitrary $ k $-algebra homomorphism $ \alpha : k\sbr{W} \to k\sbr{V} $, we define a regular map $ s : V \to W $ by
$$ s = \br{\alpha\br{X_1}, \dots, \alpha\br{X_n}}. $$
Here $ \alpha\br{X_1}, \dots, \alpha\br{X_n} \in k\sbr{V} $. Then $ \alpha = s^* : k\sbr{W} \to k\sbr{V} $. Thus every $ k $-algebra homomorphism $ k\sbr{W} \to k\sbr{V} $ is the pull-back by some regular map $ V \to W $. We conclude the following.

\begin{proposition}
$ \phi \mapsto \phi^* $ is a bijection
$$ \correspondence{\text{regular maps} \ V \to W}{\text{$ k $-algebra homomorphisms} \ k\sbr{W} \to k\sbr{V}}. $$
\end{proposition}

\begin{corollary}
Affine algebraic sets $ V $ and $ W $ are isomorphic if and only if their coordinate rings $ k\sbr{V} $ and $ k\sbr{W} $ are isomorphic as $ k $-algebras.
\end{corollary}

The moral is that if we only care about affine algebraic sets up to isomorphism, then coordinate rings contain exactly the same information as algebraic sets themselves. In the language of category theory, the functor $ V \to k\sbr{V} $ is fully faithful. One can do the same thing for rational maps.

\begin{proposition}
$ \phi \mapsto \phi^* $ is a bijection
$$ \correspondence{\text{dominant rational maps} \ V \dashrightarrow W}{\text{$ k $-field homomorphisms} \ k\br{W} \to k\br{V}}. $$
\end{proposition}

\begin{corollary}
\label{cor:algebrageometry}
Irreducible affine algebraic sets $ V $ and $ W $ are birationally equivalent if and only if their function fields $ k\br{V} $ and $ k\br{W} $ are $ k $-isomorphic.
\end{corollary}

\pagebreak

\subsubsection{Dictionary between algebraic subsets and ideals}

Can we do something similar with Zariski closed subsets of $ V $, and work them out from the algebra of $ k\sbr{V} $? Suppose that $ V \subseteq \AA^n $. In $ \AA^n $, the Nullstellensatz tells us that the functions $ \II $ and $ \VV $ are bijections
$$ \correspondence{\text{Zariski closed subsets of} \ \AA^n}{\text{radical ideals in} \ k\sbr{X_1, \dots, X_n}}. $$
Since $ \II $ and $ \VV $ reverse the direction of inclusions, we deduce that they restrict to bijections
$$ \correspondence{\text{Zariski closed subsets of} \ V}{\text{radical ideals in} \ k\sbr{X_1, \dots, X_n} \ \text{containing} \ \II\br{V}}. $$
We know that $ k\sbr{V} \cong k\sbr{X_1, \dots, X_n} / \II\br{V} $. It is a basic algebraic fact that
$$ \correspondence{\text{ideals in} \ k\sbr{X_1, \dots, X_n} \ \text{containing} \ \II\br{V}}{\text{ideals in} \ k\sbr{X_1, \dots, X_n} / \II\br{V}}. $$
Under this correspondence, radical ideals on one side correspond to radical ideals on the other side and similarly for prime ideals. We conclude that the natural maps are bijections
$$ \correspondence{\text{Zariski closed subsets of} \ V}{\text{radical ideals in} \ k\sbr{V}}, $$
and
$$ \correspondence{\text{irreducible Zariski closed subsets of} \ V}{\text{prime ideals in} \ k\sbr{V}}. $$
Can we describe the points of an affine algebraic set $ V $ in terms of the algebra of $ k\sbr{V} $? The points of $ V $ are the smallest non-empty Zariski closed subsets. Since the bijection between Zariski closed subsets and ideals reverses direction of inclusion, they correspond to maximal ideals, so
$$ \correspondence{\text{points of} \ V}{\text{maximal ideals in} \ k\sbr{V}}. $$

\lecture{10}{Monday}{03/02/20}

Lecture 10 is a problems class.

\subsubsection{Reduced finitely generated \texorpdfstring{$ k $}{k}-algebras}

\lecture{11}{Thursday}{06/02/20}

We have seen that $ V \mapsto k\sbr{V} $ leads to bijections on maps between affine algebraic sets. To fully understand the relationship between affine algebraic sets and $ k $-algebras, there is one more question to answer. Which $ k $-algebras can occur as $ k\sbr{V} $ where $ V $ is an affine algebraic set? We write down some algebraic properties which obviously hold for $ A = k\sbr{V} $, the coordinate ring of an affine algebraic set $ V $.
\begin{itemize}
\item $ A $ is finitely generated, because if $ V \subseteq \AA^n $ then $ A $ is generated by the coordinate functions $ X_1, \dots, X_n $.
\item $ A $ is \textbf{reduced}, meaning that if $ f \in A $ and $ f^k = 0 $ for some $ k > 0 $, then $ f = 0 $. This is because $ A $ is a ring of functions in the usual set-theoretic sense, since if $ f^k = 0 $ then $ f\br{x}^k = 0 $ for all $ x \in V $, so $ f\br{x} = 0 $ for all $ x \in V $.
\end{itemize}
Using the Nullstellensatz, we can prove that these properties are enough to characterise the $ k $-algebras which are coordinate rings of affine algebraic sets.

\begin{proposition}
\label{prop:kva}
Let $ A $ be a finitely generated reduced $ k $-algebra. Then there exists an affine algebraic set $ V $ such that $ k\sbr{V} \cong A $.
\end{proposition}

\begin{proof}
Pick a finite set $ f_1, \dots, f_n \in A $ which generates $ A $ as a $ k $-algebra. We can define a homomorphism
$$ \function[\alpha]{k\sbr{X_1, \dots, X_n}}{A}{\br{X_1, \dots, X_n}}{\br{f_1, \dots, f_n}}. $$
Let $ I = \ker \alpha $ and let $ V = \VV\br{I} \subseteq \AA^n $. The homomorphism $ \alpha $ is surjective because $ f_1, \dots, f_n $ generate $ A $, and so $ A \cong k\sbr{X_1, \dots, X_n} / I $. Thus $ k\sbr{X_1, \dots, X_n} / I $ is a reduced $ k $-algebra. It follows that $ I $ is a radical ideal. Hence the Nullstellensatz tells us that $ I = \II\br{V} $. Thus
$$ k\sbr{V} \cong k\sbr{X_1, \dots, X_n} / \II\br{V} \cong k\sbr{X_1, \dots, X_n} / I \cong A. $$
\end{proof}

\pagebreak

\subsubsection{The notion of an affine variety}

Often in mathematics, it is convenient to consider objects only up to isomorphism.

\begin{example*}
One might talk about the group with seven elements, ignoring the fact that there are many different groups with seven elements because they are all isomorphic to each other, and therefore they all behave in the same ways.
\end{example*}

Similarly, in algebraic geometry we often want to consider affine algebraic sets up to isomorphism. But affine algebraic sets are always defined in a concrete way, since they are a subset of some specific affine space $ \AA^n $. It is as if we had defined all finite groups to be subgroups of a symmetric group $ \SSS_n $. And we have seen that affine algebraic sets can be isomorphic even when they appear to be quite different as subsets of affine space.

\begin{example*}
The line $ \AA^1 $ is isomorphic to the parabola $ \VV\br{Y - X^2} \subseteq \AA^2 $.
\end{example*}

Thus it is useful to use different terminology. We talk about affine algebraic sets when we mean subsets of $ \AA^n $, and we talk about \textbf{affine varieties} when we mean an affine algebraic set up to isomorphism, forgetting its embedding into $ \AA^n $. Proposition \ref{prop:kva} is more naturally stated in terms of affine varieties rather than affine algebraic sets, since in the proof we had to choose a generating set for $ A $, for which there is no distinguished choice. Different choices of generating set would lead to isomorphic affine algebraic sets, but embedded differently into affine space. So it is better to say that each finitely generated reduced $ k $-algebra $ A $ is the coordinate ring of some affine variety $ V $, with no distinguished choice of embedding into $ \AA^n $. I mentioned this philosophy about affine varieties before, and I will mention it again after we have defined quasi-projective varieties. For those who know some fancy categorical language, we can sum up all the results on the equivalence between affine geometric objects and their coordinate rings by saying that $ V \mapsto k\sbr{V} $ is an equivalence of categories
$$ \cbr{\text{affine varieties over} \ k} \to \cbr{\text{reduced finitely generated $ k $-algebras}}^{\op}, $$
where the superscript $ \op $ indicates that the directions of morphisms are reversed. Let $ A $ be a reduced finitely generated $ k $-algebra and $ V $ an affine variety such that $ A \cong k\sbr{V} $. How can we work out the geometry of $ V $ from the algebra of $ A $? If we choose an embedding of $ V $ into $ \AA^n $, then we get an isomorphism $ k\sbr{X_1, \dots, X_n} / \II\br{V} \to A $. We conclude that
$$ \correspondence{\text{Zariski closed subsets of} \ V}{\text{radical ideals in} \ A}, $$
$$ \correspondence{\text{irreducible Zariski closed subsets of} \ V}{\text{prime ideals in} \ A}, $$
$$ \correspondence{\text{points of} \ V}{\text{maximal ideals in} \ A}. $$

\subsubsection{The weak and strong Nullstellensatz}

Now we aim to prove Hilbert's Nullstellensatz. There are many different proofs, all of which require some difficult algebra. We will roughly follow the method in Shafarevich appendix A, which incorporates the hard algebra into one statement which we can quote, and then do the rest as geometrically as possible. Recall the statement of Hilbertâ€™s Nullstellensatz, Theorem \ref{thm:strongnullstellensatz}, also called the strong Nullstellensatz. In order to prove this, we will first prove a weaker version, which is called the weak Nullstellensatz, then use that to deduce the strong Nullstellensatz.

\begin{theorem}[Weak Nullstellensatz]
Let $ I $ be an ideal in the polynomial ring $ k\sbr{X_1, \dots, X_n} $ over an algebraically closed field $ k $. If $ \VV\br{I} = \emptyset $, then $ I = k\sbr{X_1, \dots, X_n} $.
\end{theorem}

This is a statement about the existence of solutions to polynomial equations, so it is necessary to require $ k $ to be algebraically closed.

\begin{example*}
To show that it fails when $ k $ is not algebraically closed, consider the ideal $ \abr{X^2 + Y^2 + 1} $ in $ \RR\sbr{X, Y} $. This ideal is not the full polynomial ring, but there are no real solutions to the equation $ x^2 + y^2 + 1 = 0 $.
\end{example*}

\begin{note*}
The strong Nullstellensatz easily implies the weak Nullstellensatz. If $ \VV\br{I} = \emptyset $ then the strong Nullstellensatz tells us that $ \rad I = \II\br{\emptyset} = k\sbr{X_1, \dots, X_n} $. In particular, $ 1 \in \rad I $ but then $ 1 \in I $ so $ I = k\sbr{X_1, \dots, X_n} $.
\end{note*}

\pagebreak

\begin{proof}[Proof of Theorem \ref{thm:strongnullstellensatz}]
We use a method called the Rabinowitsch trick, introducing an extra variable. Let $ I $ be an ideal in $ k\sbr{X_1, \dots, X_n} $ and let $ V = \VV\br{I} \subseteq \AA^n $. It is easy to see that $ \rad I \subseteq \II\br{V} $. Thus we have to prove that $ \II\br{V} \subseteq \rad I $. Let $ f \in \II\br{V} $. Define a new polynomial $ g $ with an extra variable $ Y $ by
$$ g\br{X_1, \dots, X_n, Y} = f\br{X_1, \dots, X_n} \cdot Y - 1. $$
Let $ J $ be the ideal in $ k\sbr{X_1, \dots, X_n, Y} $ generated by $ I $ and $ g $, and consider the affine algebraic set $ W = \VV\br{J} \subseteq \AA^{n + 1} $. Every point $ \br{x_1, \dots, x_n, y} \in W $ satisfies $ f\br{x_1, \dots, x_n} \ne 0 $, in order for there to exist some $ y $ such that $ f\br{x_1, \dots, x_n}y - 1 = 0 $. This is generalising the fact that the hyperbola projects down to $ \AA^1 \setminus \cbr{0} $. Since $ I \subseteq J $, points $ \br{x_1, \dots, x_n, y} $ of $ W $ also satisfy $ \br{x_1, \dots, x_n} \in V $. Therefore, if $ \pi : \AA^{n + 1} \to \AA^n $ is the projection map, forgetting the extra $ Y $ coordinate, then
$$ \pi\br{W} \subseteq \cbr{\br{x_1, \dots, x_n} \in V \st f\br{x_1, \dots, x_n} \ne 0}. $$
Since $ f \in \II\br{V} $, the set on the right is empty. Thus $ \pi\br{W} = \emptyset $. This implies that $ W $ itself is empty. Therefore, by the weak Nullstellensatz, $ J = k\sbr{X_1, \dots, X_n, Y} $. In particular, $ 1 \in J $ and thus $ 1 = a + bg $ for some $ a \in I \cdot k\sbr{X_1, \dots, X_n, Y} $ and $ b \in k\sbr{X_1, \dots, X_n, Y} $. Expanding out $ a $ and $ b $ as sums over powers of $ Y $,
$$ a = \sum_{j \ge 0} a_jY^j, \qquad b = \sum_{j \ge 0} b_jY^j, \qquad a_j \in I, \qquad b_j \in k\sbr{X_1, \dots, X_n}. $$
The equation $ 1 = a + bg $ can be expanded and rearranged to give
$$ 1 = a_0 - b_0 + \sum_{j \ge 1} \br{a_j + b_{j - 1}f - b_j}Y^j. $$
Looking at the terms of degree zero in $ Y $ gives $ b_0 = a_0 - 1 \in I - 1 $, then terms of degree one in $ Y $ gives $ b_1 = a_1 + b_0f \in I - f $, using $ a_1 \in I $ and $ b_0 \in I - 1 $. Continuing by induction on $ j $, these imply that
$$ b_j = a_j + b_{j - 1}f \in I - f^j, \qquad j \ge 0, $$
where $ I - f^j $ means the coset $ \cbr{t - f^j \st t \in I} $. But $ b $ is a polynomial, so $ b_j = 0 $ once $ j $ gets large enough. Thus for some $ j $, we get $ 0 \in I - f^j $, that is $ f^j \in I $. This proves that $ f \in \rad I $.
\end{proof}

\lecture{12}{Friday}{07/02/20}

We can restate the weak Nullstellensatz in elementary terms as, if $ f_1, \dots, f_m \in k\sbr{X_1, \dots, X_n} $ are a finite set of polynomials, and the ideal $ I $ which they generate is not the whole polynomial ring, then there exists a common solution $ \br{x_1, \dots, x_n} \in k^n $ to the equations
$$ f_1\br{x_1, \dots, x_n} = 0, \qquad \dots, \qquad f_m\br{x_1, \dots, x_n} = 0. $$
We prove this in two steps.
\begin{enumerate}[leftmargin=0.5in, label=Step \arabic*.]
\item There exists a larger field $ K $ containing $ k $ such that these equations have a common solution in $ K^n $.
\item If the equations have a common solution in $ K^n $, then they also have a common solution in $ k^n $.
\end{enumerate}

\subsubsection{Finding a solution in a bigger field}

The proof of step $ 1 $ is fairly short, and relies on Zorn's lemma.

\begin{lemma}
Let $ f_1, \dots, f_m $ be polynomials in $ k\sbr{X_1, \dots, X_n} $, such that the ideal $ I = \abr{f_1, \dots, f_m} $ is not equal to $ k\sbr{X_1, \dots, X_n} $. Then there exists a field $ K $ which is a finitely generated extension of $ k $ such that the equations $ f_1 = \dots = f_m = 0 $ have a common solution $ \br{x_1, \dots, x_n} \in K^n $.
\end{lemma}

Because $ I \ne k\sbr{X_1, \dots, X_n} $, we can use Zorn's lemma to show that $ I $ is contained in some maximal ideal $ M \subseteq k\sbr{X_1, \dots, X_n} $. This is a natural way to start, since we are trying to show that $ \VV\br{I} $ has a point, and last time we saw that points in $ \VV\br{I} $ correspond to maximal ideals in $ k\sbr{X_1, \dots, X_n} $ containing $ I $. We cannot just quote the correspondence from the previous lecture because we used the Nullstellensatz in proving that correspondence, but this justifies why obtaining a maximal ideal is a good first step.

\begin{proof}
Let $ K = k\sbr{X_1, \dots, X_n} / M $. Let $ x_1, \dots, x_n $ denote the images of $ X_1, \dots, X_n $ in $ K $. Then $ K $ is a field because $ M $ is a maximal ideal, and it is finitely generated as an extension of $ k $ because it is generated by $ x_1, \dots, x_n $. Since $ f_j\br{X_1, \dots, X_n} \in I \subseteq M $, we get that $ f_j\br{x_1, \dots, x_n} = 0 $ in $ K $ for each $ j $. Thus $ \br{x_1, \dots, x_n} $ is the required common solution to $ f_1, \dots, f_m $ in $ K^n $.
\end{proof}

\pagebreak

\subsubsection{Shrinking the field required}

Before proving step $ 2 $, we begin by quoting an algebraic result.

\begin{lemma}
\label{lem:algebraicallyindependent}
Let $ k $ be an algebraically closed field and let $ K $ be a finitely generated extension field of $ k $. Then there exist $ t_1, \dots, t_d, u \in K $ such that
\begin{itemize}
\item $ K = k\br{t_1, \dots, t_d, u} $,
\item $ t_1, \dots, t_d $ are algebraically independent over $ k $, that is there is no non-zero polynomial in $ d $ variables with coefficients in $ k $ whose value at $ \br{t_1, \dots, t_d} $ is zero, and
\item $ u $ is algebraic over $ k\br{t_1, \dots, t_d} $, that is there exists a non-zero polynomial in one variable with coefficients in the field $ k\br{t_1, \dots, t_d} $ which is zero at $ u $.
\end{itemize}
\end{lemma}

\begin{proof}
This follows from the primitive element theorem in field theory. For a full proof, see Proposition A.7 in the appendix of Shafarevich basic algebraic geometry.
\end{proof}

Lemma \ref{lem:algebraicallyindependent} has a nice geometric interpretation. Every finitely generated extension of $ k $ is isomorphic to the field of fractions of a hypersurface. We need to use the Nullstellensatz to prove this geometric interpretation, so that is postponed until after we have finished the proof of the Nullstellensatz.

\begin{theorem}
\label{thm:shrinkingfield}
Let $ k $ be an algebraically closed field and let $ K $ be a finitely generated extension field of $ k $. Let $ f_1, \dots, f_m \in k\sbr{X_1, \dots, X_n} $. Suppose there exists a common solution $ \br{x_1, \dots, x_n} \in K^n $ to the equations $ f_1 = \dots = f_m = 0 $. Then there exists a common solution $ \br{y_1, \dots, y_n} \in k^n $ to the equations $ f_1 = \dots = f_m = 0 $.
\end{theorem}

\begin{proof}
Write $ K = k\br{t_1, \dots, t_d, u} $ as in Lemma \ref{lem:algebraicallyindependent}. Let $ K' = k\br{t_1, \dots, t_d} $. Because $ t_1, \dots, t_d $ are algebraically independent, we can identify $ K' $ with $ k\br{T_1, \dots, T_d} $, the field of fractions of the polynomial ring $ k\sbr{T_1, \dots, T_d} $. This will allow us to substitute a vector $ \underline{z} \in k^d $ into an element $ \alpha \in K' $ and get out an element $ \alpha\br{\underline{z}} \in k $, as long as the denominator of $ \alpha $ does not vanish at $ \underline{z} $. We use two facts about the finite algebraic extension $ K / K' $.
\begin{enumerate}[leftmargin=0.5in, label=Fact \arabic*.]
\item There exists a minimal polynomial $ p\br{U} \in K'\sbr{U} $ for $ u $. That is, $ p\br{u} = 0 $, $ p $ has leading coefficient one, and $ p $ divides every other polynomial $ q\br{U} \in K'\sbr{U} $ such that $ q\br{u} = 0 $.
\item Every element of $ K $ can be written in the form $ a\br{u} $ for some polynomial $ a\br{U} \in K'\sbr{U} $.
\end{enumerate}
The idea of the proof is to consider the almost hypersurface
$$ H = \cbr{\br{z_1, \dots, z_d, s} \in k^{d + 1} \st p\br{z_1, \dots, z_d, s} = 0}. $$
The almost is because $ p $ is not a polynomial in $ k\sbr{T_1, \dots, T_d, U} $ but rather may have denominators, so we have to ignore the places where these denominators vanish. Then we construct a rational map $ \phi : H \dashrightarrow \VV\br{f_1, \dots, f_m} $. The domain of definition of $ \phi $ is an open subset of an almost hypersurface, and we can easily check that this is non-empty. Then a point in the image of $ \phi $ gives us a point in $ \VV\br{f_1, \dots, f_m} $, as desired. In particular, we apply fact $ 2 $ to $ x_1, \dots, x_n \in K $, our common solution to $ f_1 = \dots = f_m = 0 $, so we can write $ x_i = a_i\br{u} $ where $ a_i\br{U} \in K'\sbr{U} $. In the informal outline, these $ a_i \in k\br{T_1, \dots, T_d}\sbr{U} $ define a rational map $ \phi : H \dashrightarrow \AA^n $. Next we check that the image of this rational map is contained in $ \VV\br{f_1, \dots, f_m} $. We know that $ \br{x_1, \dots, x_n} $ is a common solution to the polynomials $ f_1, \dots, f_m $. Hence
$$ f_j\br{a_1\br{u}, \dots, a_n\br{u}} = 0 \in K, \qquad j = 1, \dots, m. $$
In other words, the single-variable polynomial $ f_j\br{a_1\br{U}, \dots, a_n\br{U}} \in K'\sbr{U} $ has $ u $ as a root. Therefore, fact $ 1 $ tells us that this polynomial is divisible by $ p\br{U} $. Thus there exist polynomials $ q_1, \dots, q_m \in K'\sbr{U} $ such that
\begin{equation}
\label{eq:1}
f_j\br{a_1\br{U}, \dots, a_n\br{U}} = q_j\br{U}p\br{U} \in K'\sbr{U}, \qquad j = 1, \dots, m.
\end{equation}
Now, if $ \br{z_1, \dots, z_d, s} \in k^{d + 1} $ satisfies $ p\br{z_1, \dots, z_d, s} = 0 $, then $ \br{\ref{eq:1}} $ implies that
$$ f_j\br{a_1\br{z_1, \dots, z_d, s}, \dots, a_n\br{z_1, \dots, z_d, s}} = 0, \qquad j = 1, \dots, m, $$

\pagebreak

so long as all the denominators involved are non-zero. Thus we just have to find $ \br{z_1, \dots, z_d, s} $ where all these denominators will be non-zero. So consider the polynomials $ p\br{U}, a_i\br{U}, q_j\br{U} \in K'\sbr{U} $.
Their coefficients are elements of the field $ K' $ which we are identifying with the field of fractions $ k\br{T_1, \dots, T_d} $. Let $ \sigma \in k\sbr{T_1, \dots, T_d} $ denote the product of the denominators of all these fractions. Because the denominator of a fraction is never zero, $ \sigma $ is not the zero polynomial in $ k\sbr{T_1, \dots, T_d} $. Therefore, there exists $ \br{s_1, \dots, s_d} \in k^d $ such that $ \sigma\br{s_1, \dots, s_d} \ne 0 $. Then the denominators of the coefficients of $ p, a_i, q_j $ do not vanish at $ s_1, \dots, s_d $, so we can substitute $ \br{s_1, \dots, s_d} $ into each of these coefficients, as elements of $ K' $, and get out values in $ k $. Thus we get new polynomials $ \widetilde{p}\br{U}, \widetilde{a_i}\br{U}, \widetilde{q_j}\br{U} \in k\sbr{U} $. The leading coefficient of $ \widetilde{p}\br{U} $ is one, which is unchanged by this process. So $ \widetilde{p}\br{U} $ has the same degree as $ p\br{U} $. In particular $ \widetilde{p}\br{U} $ is not a constant polynomial. Hence as $ k $ is algebraically closed, there exists $ s \in k $ such that $ \widetilde{p}\br{s} = 0 $. Let $ y_i = \widetilde{a_i}\br{s} \in k $. Then $ \br{\ref{eq:1}} $ tells us that
$$ f_j\br{y_1, \dots, y_n} = \widetilde{q_j}\br{s}\widetilde{p}\br{s}, \qquad j = 1, \dots, m. $$
But we chose $ s $ such that $ \widetilde{p}\br{s} = 0 $, and so we conclude that $ \br{y_1, \dots, y_n} \in k^n $ is a common solution to $ f_1 = \dots = f_m = 0 $.
\end{proof}

Combining Lemma \ref{lem:algebraicallyindependent} and Theorem \ref{thm:shrinkingfield} proves the weak Nullstellensatz.

\subsubsection{Hypersurfaces and birational equivalence}

Now we prove the geometrical interpretation of Lemma \ref{lem:algebraicallyindependent}.

\begin{proposition}
\label{prop:irreduciblehypersurface}
Let $ K $ be a finitely generated extension of $ k $. Then there exists an irreducible hypersurface $ H \subseteq \AA^{d + 1} $ for some $ d $ such that $ K $ is isomorphic to the field of functions $ k\br{H} $.
\end{proposition}

\begin{corollary}
\label{cor:irreduciblehypersurface}
Let $ V \subseteq \AA^n $ be an irreducible affine algebraic set. Then there exists an irreducible hypersurface $ H \subseteq \AA^{d + 1} $ for some $ d $ such that $ V $ is birationally equivalent to $ H $.
\end{corollary}

Corollary \ref{cor:irreduciblehypersurface} tells us that, even if $ V $ is a complicated algebraic set defined by many equations, provided we only care about properties of $ V $ which are preserved by birational equivalence, we can replace $ V $ by a simpler set defined by just one equation, that is a hypersurface.

\begin{note*}
It is not true that every irreducible affine algebraic set is isomorphic to a hypersurface.
\end{note*}

\begin{proof}[Proof of Proposition \ref{prop:irreduciblehypersurface}]
Write $ K = k\br{t_1, \dots, t_d, u} $ as in Lemma \ref{lem:algebraicallyindependent}, and let $ K' = k\br{t_1, \dots, t_d} $. Because $ u $ is algebraic over $ K' $, let $ p\br{U} \in K'\sbr{U} $ be the minimal polynomial of $ u $ over $ K' $. Each coefficient of $ p\br{U} $ is a fraction whose numerator and denominator are polynomials in $ t_1, \dots, t_d $. We can multiply up by a suitable element of $ k\sbr{t_1, \dots, t_d} $ to clear the denominators, and also replace $ t_1, \dots, t_d $ by indeterminates $ T_1, \dots, T_d $ to get a polynomial $ g \in k\sbr{T_1, \dots, T_d, U} $ such that $ g\br{t_1, \dots, t_d, u} = 0 $ in the field $ K $. Assuming we multiplied up by a lowest common denominator for the coefficients of $ p $, $ g $ is irreducible. Let $ H $ be the hypersurface in $ \AA^{d + 1} $ defined by the polynomial $ g $. Because $ g $ is irreducible, it generates a radical ideal in $ k\sbr{X_1, \dots, X_n} $ and so the strong Nullstellensatz implies that $ \II\br{H} = \abr{g} $. Thus the coordinate ring is given by
$$ k\sbr{H} = k\sbr{T_1, \dots, T_d, U} / \abr{g}. $$
There is a $ k $-algebra homomorphism
$$ \function[\alpha]{k\sbr{T_1, \dots, T_d, U}}{K}{\br{T_1, \dots, T_d, U}}{\br{t_1, \dots, t_d, u}}. $$
A little algebra, using Gauss' lemma, shows that the kernel of $ \alpha $ is generated by $ g $, so $ \alpha $ induces an injection $ k\sbr{H} \hookrightarrow K $. Furthermore, the image of $ \alpha $ generates $ K $ as a field, so $ \alpha $ induces an isomorphism from the fraction field of $ k\sbr{H} $ to $ K $. The fraction field of $ k\sbr{H} $ is the function field $ k\br{H} $. Thus we have shown that $ k\br{H} \cong k\br{V} $. By Corollary \ref{cor:algebrageometry}, this implies that $ V $ is birationally equivalent to $ H $.
\end{proof}

\begin{proof}[Proof of Corollary \ref{cor:irreduciblehypersurface}]
Apply Proposition \ref{prop:irreduciblehypersurface} to the function field $ K = k\br{V} $.
\end{proof}

\lecture{13}{Monday}{10/02/20}

Lecture 13 is a class test.

\pagebreak

\section{Projective varieties}

\subsection{Projective algebraic sets}

\subsubsection{Projective space}

\lecture{14}{Thursday}{13/02/20}

Projective space consists of affine space together with points at infinity, one for each direction. The purpose for adding extra points is that it avoids special cases where a point disappears to infinity.

\begin{example*}
A pair of parallel lines do not intersect in affine space but they do intersect at a point at infinity in projective space.
\end{example*}

\begin{definition*}
\textbf{Projective $ n $-space}, $ \PP^n $, is the set of lines through the origin in $ \AA^{n + 1} $.
\end{definition*}

A convenient way to label points in $ \PP^n $ is via homogeneous coordinates. These are just coordinates in $ k^{n + 1} \setminus \cbr{\br{0, \dots, 0}} $, since any sequence of coordinates $ \underline{x} \in k^{n + 1} \setminus \cbr{\br{0, \dots, 0}} $ represents the unique line through the origin and $ \underline{x} $ in $ \AA^{n + 1} $. Two sequences of homogeneous coordinates $ \br{x_0, \dots, x_n} $ and $ \br{y_0, \dots, y_n} $ represent the same point in $ \PP^n $ if and only if there exists $ \lambda \in k \setminus \cbr{0} $ such that $ \br{x_0, \dots, x_n} = \br{\lambda y_0, \dots, \lambda y_n} $. Thus projective $ n $-space is the quotient of $ k^{n + 1} \setminus \cbr{\br{0, \dots, 0}} $ by the equivalence relation
$$ \br{x_0, \dots, x_n} \sim \br{\lambda x_0, \dots, \lambda x_n}, \qquad \lambda \in k \setminus \cbr{0}. $$
We call a representative for an equivalence class the \textbf{homogeneous coordinates} of that point in $ \PP^n $, and there are many choices for each point, by scaling by $ \lambda $. To avoid confusion between homogeneous coordinates for $ \PP^n $ and ordinary coordinates for $ \AA^n $, we usually write homogeneous coordinates as $ \sbr{x_0 : \dots : x_n} $. Observe that we can embed
$$ \function{\AA^n}{\PP^n}{\br{x_1, \dots, x_n}}{\sbr{1 : x_1 : \dots : x_n}}. $$
Any other homogeneous coordinates where the first coordinate is non-zero can be re-scaled to have first coordinate one. So we are left with the points with first coordinate equal to zero. These are the \textbf{points at infinity}. A point $ \sbr{0 : x_1 : \dots : x_n} $ can be seen as a point in $ \PP^{n - 1} $, by just dropping the initial zero. Thus
$$ \PP^n = \AA^n \cup \PP^{n - 1}. $$
Similarly, we can embed $ \AA^1 $ by the map $ x \mapsto \sbr{1 : x} $, and then the point at infinity is $ \sbr{0 : 1} $, so
$$ \PP^1 = \AA^1 \cup \cbr{\sbr{0 : 1}}. $$
Over the complex numbers, $ \PP_\CC^1 $ is also called the \textbf{Riemann sphere}. Thinking about projective space as affine space plus points at infinity can be useful if we want to make use of our geometric intuition about affine space or the algebraic tools we have developed for working with affine algebraic sets. On the other hand, thinking about projective space in terms of homogeneous coordinates emphasises that all points of projective space look the same, since we can only distinguish points at infinity from points in affine space after choosing a convention for how we embed $ \AA^n $ into $ \PP^n $.

\begin{example*}
We could have used $ \sbr{x_1 : \dots : x_n : 1} $ instead.
\end{example*}

Throughout this lecture we will use the convention above.

\subsubsection{Definition and examples}

A projective algebraic set is a subset of projective space defined by the vanishing of a finite list of polynomials. What does it mean for a polynomial to vanish at a point in projective space? Because a single point in $ \PP^n $ can be represented by many different homogeneous coordinates, it does not make sense to evaluate a polynomial in $ k\sbr{X_0, \dots, X_n} $ at a point of $ \PP^n $. We have to restrict attention to homogeneous polynomials.

\begin{definition*}
A polynomial $ f \in k\sbr{X_0, \dots, X_n} $ is \textbf{homogeneous} if every term of $ f $ has the same degree.
\end{definition*}

\begin{example*}
$ X_0^3 + X_0^2X_1 + 3X_2^3 - X_0X_1X_2 $ is homogeneous of degree three while $ X_0X_1 - X_2 $ is not homogeneous because it has a term of degree two and a term of degree one.
\end{example*}

If $ \sbr{x_0 : \dots : x_n} $ and $ \sbr{y_0 : \dots : y_n} $ represent the same point $ p \in \PP^n $, then
$$ \br{x_0, \dots, x_n} = \lambda\br{y_0, \dots, y_n}, \qquad \lambda \in k \setminus \cbr{0}. $$

\pagebreak

Hence if $ f \in k\sbr{X_0, \dots, X_n} $ is a homogeneous polynomial of degree $ d $, then
$$ f\br{x_0, \dots, x_n} = \lambda^df\br{y_0, \dots, y_n}. $$
Thus the actual value of $ f $ at $ p $ is not well-defined, but it is well-defined to ask whether or not $ f $ is zero at $ p $.

\begin{definition*}
A \textbf{projective algebraic set} is a set of the form
$$ \cbr{\sbr{x_0 : \dots : x_n} \in \PP^n \st f_1\br{x_0, \dots, x_n} = \dots = f_m\br{x_0, \dots, x_n} = 0}, $$
for some finite list of homogeneous polynomials $ f_1, \dots, f_m \in k\sbr{X_0, \dots, X_n} $.
\end{definition*}

By definition, a projective algebraic set is the vanishing of finitely many homogeneous polynomials. We can use the Hilbert basis theorem to show that the vanishing set of an infinite collection of homogeneous polynomials is a projective algebraic set. This is similar to the analogous result for affine algebraic sets, but a little trickier due to the word homogeneous.

\begin{example*}
An example of a projective algebraic set is
$$ V' = \cbr{\sbr{w : x : y} \in \PP^2 \st wx - y^2 = 0}. $$
What is $ V = V' \cap \AA^2 $, using the embedding $ \AA^2 \to \PP^2 $ which we considered before? To find this, we just substitute $ w = 1 $ into the equation for $ V' $, so
$$ V = \cbr{\br{x, y} \in \AA^2 \st x - y^2 = 0}, $$
that is an affine parabola. The polynomial $ X - Y^2 $ is not homogeneous. Therefore consider instead the homogeneous polynomial $ WX - Y^2 $. When $ W = 1 $, this restricts to $ X - Y^2 $. That takes care of the points of $ V' $ where $ w \ne 0 $, since we can scale the homogeneous coordinates of such a point to get $ w = 1 $. But $ V' $ contains extra points where $ w = 0 $. We can also work out the intersection of $ V' $ with the $ \PP^1 $ at infinity. Substituting $ w = 0 $ into the equation $ wx - y^2 = 0 $ for $ V' $ gives also $ y = 0 $. There is only one point of $ \PP^2 $ with $ w = y = 0 $, the point $ \sbr{0 : 1 : 0} $, since any other value for $ x $ could be scaled to one. So we get
$$ V' = V \cup \cbr{\sbr{0 : 1 : 0}}. $$
Thus geometrically, $ V' $ consists of the parabola $ V $ together with a point at infinity in the direction $ \br{1, 0} $, that is along the $ x $-axis. Informally, the two arms of the parabola close up at infinity.
\end{example*}

We would like to reverse this process, and go from an affine algebraic set to a projective algebraic set.

\begin{example*}
Consider the affine hyperbola
$$ H = \cbr{\br{x, y} \in \AA^2 \st xy - 1 = 0}. $$
We need to turn the polynomial $ XY - 1 $ into a homogeneous polynomial, using a new variable $ W $ in $ k\sbr{W, X, Y} $, which restricts to $ XY - 1 $ when $ W = 1 $. To do this, note that the highest degree term in $ XY - 1 $ has degree two. We multiply each term by an appropriate power of $ W $ to get all terms of degree two, so we have to replace the constant one by $ W^2 $. Thus we get $ XY - W^2 = 0 $. Thus we consider
$$ H' = \cbr{\sbr{w : x : y} \in \PP^2 \st xy - w^2 = 0}. $$
Again, when $ w \ne 0 $, we can scale to get $ w = 1 $, so we can substitute that in and see that we just get back $ H $. When $ w = 0 $, the equation becomes $ xy = 0 $, so we now get two points at infinity. Either $ x = 0 $, giving the point $ \sbr{0 : 0 : 1} \in \PP^2 $, or $ y = 0 $, giving the point $ \sbr{0 : 1 : 0} \in \PP^2 $. Thus
$$ H' = H \cup \cbr{\sbr{0 : 0 : 1}, \sbr{0 : 1 : 0}}. $$
Geometrically, $ H' $ consists of $ H $ together with points at infinity along the $ x $-axis and $ y $-axis. These axes are the asymptotes of $ H $.
\end{example*}

Compare the two above examples, where $ V' $ had equation $ wx - y^2 $, and $ H' $ had equation $ xy - w^2 $. These equations differ only by relabelling the coordinates. Thus $ V' $ and $ H' $ are isomorphic. We have not yet defined isomorphism of projective algebraic sets, but just relabelling the coordinates should certainly be an isomorphism. From the point of view of projective geometry, the only difference between the hyperbola and the parabola is that the parabola has one point at infinity while the hyperbola has two points at infinity. It turns out that $ V' $ and $ H' $ are also isomorphic to the projective line $ \PP^1 $. We will need to define isomorphism of projective algebraic sets before we can prove this.

\pagebreak

\subsubsection{Homogenisation}

The process we went through above to obtain $ V' $ from $ V $ and $ H' $ from $ H $ can be generalised.

\begin{definition*}
For any polynomial $ f \in k\sbr{X_1, \dots, X_n} $, we define the \textbf{homogenisation} of $ f $ to be the polynomial $ \overline{f} \in k\sbr{X_0, \dots, X_n} $ obtained by the following procedure. Let $ d $ be the maximum degree of terms of $ f $. Then multiply each term of $ f $ by $ X_0^{d - e} $, where $ e $ is the degree of this term in $ f $.
\end{definition*}

\begin{example*}
If
$$ f\br{X_1, X_2, X_3} = X_1^3 + 4X_1X_2X_3 - X_1^2 - X_2^2 + 5X_3 + 8, $$
then the homogenisation is
$$ \overline{f}\br{X_0, X_1, X_2, X_3} = X_1^3 + 4X_1X_2X_3 - X_1^2X_0 - X_2^2X_0 + 5X_3X_0^2 + 8X_0^3. $$
\end{example*}

Let $ V \subseteq \AA^n $ be an affine algebraic set. Let $ W \subseteq \PP^n $ be the set defined by the homogenisations of all polynomials in $ \II\br{V} $. Then $ W $ is the smallest projective algebraic set containing $ V $. This is not entirely obvious, because we have defined it using infinitely many homogeneous polynomials. When we substitute $ x_0 = 1 $ into the polynomials defining $ W $, we just get back $ \II\br{V} $, so
$$ W \cap \cbr{\sbr{1 : x_1 : \dots : x_n}} = V. $$
This proves that every affine algebraic set $ V $ is of the form $ W \cap \AA^n $ for some projective algebraic set $ W $. We call $ W $ the \textbf{projective closure} of $ V $. When defining the projective closure, it is not enough to just take the homogenisations of some finite list of polynomials which define $ V $. You must take all of $ \II\br{V} $. The standard example of this below shows that if we just use homogenisations of a generating set, instead of all of $ \II\br{V} $, we still get a projective algebraic set $ V' $ such that $ V' \cap \AA^n = V $, but it might not be the smallest such set.

\begin{example*}
Here is a more complex example, the twisted cubic curve. Let
$$ C = \cbr{\br{t, t^2, t^3} \in \AA^3} = \VV\br{Y - X^2, Z - XY} \subseteq \AA^3. $$
Parametrically, we can write this as
$$ C = \cbr{\sbr{1 : t : t^3 : t^3} \in \PP^3}. $$
Homogenising the parametric description, we might expect the projective closure to be
$$ C' = \cbr{\sbr{s^3 : s^2t : st^2 : t^3} \in \PP^3} = C \cup \cbr{\sbr{0 : 0 : 0 : 1}}. $$
One can check that $ C' $ is a projective algebraic set. But if we homogenise the two defining polynomials $ Y - X^2 $ and $ Z - XY $, we get the projective algebraic set
$$ C'' = \cbr{\sbr{w : x : y : z} \in \PP^3 \st wy - x^2 = wz - xy = 0}. $$
It is still true that we can reverse this by just setting $ w = 1 $, so $ C'' \cap \AA^3 = C $. But what happens at infinity? Substituting in $ w = 0 $, one can check that
$$ C'' = C \cup \cbr{\sbr{0 : x : y : z} \in \PP^3 \st -x^2 = -xy = 0} = C \cup \cbr{\sbr{0 : 0 : y : z} \in \PP^3}. $$
Thus the intersection of $ C'' $ with the plane at infinity is a copy of $ \PP^1 $. Thus $ C'' \ne C' $, since it contains an extra line at infinity. This is not what we should expect, if $ C'' $ were the projective closure of $ C $, since the dimension of the intersection with the plane at infinity should be smaller than the dimension of the initial affine algebraic set, speaking informally. If we homogenised all polynomials in $ \II\br{C} $ and not just the two generators, then you can calculate that the projective closure of $ C $ is in fact
$$ C' = \cbr{\sbr{w : x : y : z} \in \PP^3 \st wy - x^2 = wz - xy = xz - y^2 = 0} = C \cup \cbr{\sbr{0 : 0 : 0 : 1}}. $$
The three polynomials $ Y - X^2, Z - XY, XZ - Y^2 $ are a generating set for $ \II\br{C} $ and their homogenisations define $ C' $. The extra polynomial involves only $ x, y, z $ and is in the ideal generated by $ Y - X^2 $ and $ Z - XY $. I am not giving a procedure to find the projective closure of a given affine algebraic set. I just assert that this happens to work in this case. There is an algorithm but you would not want to have to use it by hand.
\end{example*}

\pagebreak

\subsubsection{Zariski topology on projective space}

We can define the Zariski topology on $ \PP^n $ by saying that the closed subsets are the projective algebraic sets. Observe that $ \AA^n $ is embedded as a Zariski open subset in $ \PP^n $, because the complement $ \PP^n \setminus \AA^n $ is described by the homogeneous polynomial equation $ X_0 = 0 $. The existence of projective closures shows that the Zariski topology on $ \AA^n $ is the same as the subspace topology coming from the Zariski topology on $ \AA^n \subseteq \PP^n $. The terminology projective closure is justified by noting that the smallest projective algebraic set containing $ V \subseteq \AA^n $ which we just described is the same as the closure of $ V $ in the Zariski topology on $ \PP^n $.

\subsubsection{Homogeneous ideals}

I did not actually prove that the projective closure $ \overline{V} $ of $ V \subseteq \AA^n $ is a projective algebraic set, because we constructed $ V $ as the zero set of infinitely many homogeneous polynomials, but said that a projective algebraic set must be defined using finitely many homogeneous polynomials. We can prove that these are equivalent using the Hilbert basis theorem, but it is a little more subtle than in the affine case.

\begin{definition*}
A \textbf{homogeneous ideal} in $ k\sbr{X_0, \dots, X_n} $ is an ideal which can be generated by homogeneous polynomials.
\end{definition*}

\begin{note*}
A homogeneous ideal does not contain only homogeneous polynomials, since one can take a homogeneous polynomial $ f $ in the ideal and multiply it by $ X_0 + 1 $ to get a non-homogeneous ideal in $ I $.
\end{note*}

If $ f $ is any polynomial in $ k\sbr{X_0, \dots, X_n} $, we can write $ f $, uniquely, as
$$ f = \sum_{i = 0}^d f_i, $$
where $ f_i $ is homogeneous of degree $ i $. The $ f_i $ are called the \textbf{homogeneous components} of $ f $.

\begin{lemma}
\label{lem:homogeneousideal}
An ideal $ I \subseteq k\sbr{X_0, \dots, X_n} $ is a homogeneous ideal if and only if, for each $ f \in I $, every homogeneous component of $ f $ is in $ I $.
\end{lemma}

\begin{proof}
Just some algebraic manipulation.
\end{proof}

\begin{proposition}
\label{prop:homogeneousideal}
Let $ I \subseteq k\sbr{X_0, \dots, X_n} $ be a homogeneous ideal. Then there exists a finite set $ f_1, \dots, f_m $ of homogeneous polynomials which generate $ I $.
\end{proposition}

\begin{proof}
By the Hilbert basis theorem, there exists a finite set $ g_1, \dots, g_r $ of polynomials, not necessarily homogeneous, which generate $ I $. In total, the $ g_i $ have finitely many homogeneous components. By Lemma \ref{lem:homogeneousideal}, all homogeneous components are in $ I $. Clearly they generate $ I $.
\end{proof}

Thus any set of homogeneous polynomials, even an infinite set, defines a projective algebraic set. We can use Proposition \ref{prop:homogeneousideal} to prove that every projective algebraic set is a finite union of irreducible components, by the same proof as for affine algebraic sets.

\subsubsection{The projective Nullstellensatz}

\lecture{15}{Friday}{14/02/20}

Which homogeneous ideals can occur as the ideal of functions vanishing on a projective algebraic set? Clearly they have to be radical ideals. Is there a projective version of the Nullstellensatz? Yes, but it turns out that there is an exceptional case to deal with. Consider the homogeneous ideal
$$ I_1 = \abr{X_0, \dots, X_n} \subseteq k\sbr{X_0, \dots, X_n}. $$
The only solution in $ k^{n + 1} $ to the equations $ x_0 = 0, \dots, x_n = 0 $ is $ \br{0, \dots, 0} $. But this is not the homogeneous coordinates of any point in $ \PP^n $. So the projective algebraic set defined by $ I_1 $ is the empty set. Thus the ideals $ I_1 $ and $ k\sbr{X_0, \dots, X_n} $ both define the empty set in $ \PP^n $, even though they are both radical homogeneous ideals. So we have to modify the statement of the Nullstellensatz slightly from the affine case. Thus turns out to be the only special case.

\pagebreak

\begin{proposition}[Projective weak Nullstellensatz]
Let $ I \subseteq k\sbr{X_0, \dots, X_n} $ be a homogeneous ideal such that $ \rad I $ is not equal to either $ k\sbr{X_0, \dots, X_n} $ or $ I_1 = \abr{X_0, \dots, X_n} $. Then the projective algebraic set defined by $ I $ is non-empty.
\end{proposition}

\begin{proof}
Let $ V \subseteq \PP^n $ denote the projective algebraic set defined by $ I $. We can also consider the affine algebraic set $ \VV\br{I} \subseteq \AA^{n + 1} $ defined by $ I $, which we label $ C $. Since $ \rad I \ne k\sbr{X_0, \dots, X_n} $ and $ \rad I \ne I_1 $, the affine strong Nullstellensatz tells us that $ C $ is not equal to their associated affine algebraic sets, namely $ \emptyset $ or $ \cbr{\br{0, \dots, 0}} $. Therefore $ C $ contains some point $ \br{x_0, \dots, x_n} \in \AA^{n + 1} $ other than the origin. But then the point of $ \PP^n $ with homogeneous coordinates $ \sbr{x_0 : \dots : x_n} $ is in $ V $.
\end{proof}

We saw the projective weak Nullstellensatz, and we saw that the radical homogeneous ideal $ \abr{X_0, \dots, X_n} $ defines the empty projective algebraic set, the same as $ \abr{1} $. However, this turns out to be the only exception to the bijection between radical homogeneous ideals and projective algebraic sets.

\begin{theorem}
The map sending a homogeneous ideal to the corresponding projective algebraic set is a bijection between the sets
$$ \correspondence{\text{radical homogeneous ideals in} \ k\sbr{X_0, \dots, X_n} \\ \text{other than} \ \abr{X_0, \dots, X_n}}{\text{projective algebraic sets in} \ \PP^n}. $$
\end{theorem}

The set $ C $ which appears in the above proof is called the \textbf{affine cone} of $ V $. It is the union of the lines through the origin in $ \AA^{n + 1} $ which correspond to points of $ V \subseteq \PP^n $.

\begin{proof}
Apply the affine Nullstellensatz to the affine cones of projective algebraic sets in $ \AA^{n + 1} $ defined by the same ideal.
\end{proof}

\subsubsection{A remark on compactness}

Over the complex numbers, every projective algebraic set is compact in the analytic topology. This is because they are closed subsets of $ \PP_\CC^n $, which is compact. In the Zariski topology, the notion of compactness is not very interesting, since every algebraic set is compact in the Zariski topology, even affine algebraic sets. Affine algebraic sets definitely do not behave in ways matching our intuition about compactness, since this intuition and most of the usual theory of compact sets is only valid when the spaces are Hausdorff. There is a converse to this, which tells us that there is a very close relationship between analytic and algebraic geometry in $ \PP_\CC^n $.

\begin{theorem}[Chow's theorem]
\label{thm:chowtheorem}
Let $ V $ be an analytic subset of $ \PP_\CC^n $ which is closed in the analytic topology. Then $ V $ is a projective algebraic set.
\end{theorem}

I will not define analytic subsets here, but roughly it means a set defined by zeroes of holomorphic functions. Theorem \ref{thm:chowtheorem} is much harder to prove than to state, and requires too much complex analytic geometry beyond this course to prove here. One can prove analytically that every holomorphic function on a connected compact complex manifold is constant.

\begin{example*}
This holds on the Riemann sphere, which is equal to $ \PP_\CC^1 $.
\end{example*}

Polynomials are holomorphic, so every regular function on a connected projective algebraic set over $ \CC $ is constant. Once we define regular functions on projective algebraic sets, it will turn out that the same is true over any field.

\pagebreak

\subsection{Regular and rational maps}

In the affine case, we defined regular functions first and then used them to define regular maps. However, as remarked above the only regular functions on an irreducible projective algebraic set are constants so they are not useful for defining regular maps. Therefore we will jump directly to defining regular maps between projective algebraic sets.

\subsubsection{Regular maps between projective algebraic sets}

Let $ V \subseteq \PP^m $ and $ W \subseteq \PP^n $ be projective algebraic sets. We expect a regular map $ \phi : V \to W $ to be a function which can be expressed as polynomials in the homogeneous coordinates, so
$$ \phi\br{\sbr{x_0 : \dots : x_m}} = \sbr{f_0\br{x_0, \dots, x_m} : \dots : f_n\br{x_0, \dots, x_m}}. $$
Because we are working with homogeneous coordinates, in order for this to be a well-defined function, all the $ f_i $ must be homogeneous polynomials of the same degree. Then, if we re-scale the input coordinates $ \sbr{x_0 : \dots : x_m} $ by $ \lambda $, we get
\begin{align*}
\sbr{f_0\br{\lambda x_0, \dots, \lambda x_m} : \dots : f_n\br{\lambda x_0, \dots, \lambda x_m}}
& = \sbr{\lambda^df_0\br{x_0, \dots, x_m} : \dots : \lambda^df_n\br{x_0, \dots, x_m}} \\
& = \sbr{f_0\br{x_0, \dots, x_m} : \dots : f_n\br{x_0, \dots, x_m}}.
\end{align*}
Thus all the output coordinates are multiplied by the same value $ \lambda^d $, so they define the same point in $ \PP^n $. There is another condition which must be imposed to get a well-defined function $ V \to \PP^m $. We must never have
$$ f_0\br{x_0, \dots, x_m} = \dots = f_m\br{x_0, \dots, x_m} = 0, $$
because $ \sbr{0 : \dots : 0} $ is not the homogeneous coordinates of a point in $ \PP^n $. However it turns out that often, there is not a single sequence of polynomials which will define a regular map at every point of $ V $. Whatever polynomials we try, there might be some points where they all vanish. This is a very strong condition and there are too few lists of polynomials which satisfy it. However, we can get round it to some extent by imitating rational maps between affine algebraic sets, and allowing different sequences of polynomials to represent our regular map at different points of $ V $, so that, at each point, there is some list of polynomials which is always non-zero. It is the homogeneous nature of the coordinates that allows us to do this in such a way that the different sequences of polynomials represent the same regular map at places wherever they overlap. To help explain this, we consider an example.

\begin{example*}
Let $ V $ be the projective closure of the parabola, that is
$$ V = \cbr{\sbr{w : x : y} \in \PP^2 \st wy = x^2}. $$
Let
$$ V' = V \cap \cbr{\sbr{w : x : y} \st w \ne 0} = \cbr{\br{x, y} \in \AA^2 \st y = x^2}. $$
There is a regular map given by
$$ \function[\phi']{V'}{\AA^1}{\br{x, y}}{x}. $$
Does this extend to a regular map $ \phi : V \to \PP^1 $? We guess it should send the point at infinity $ \sbr{0 : 0 : 1} \in V $ to the point at infinity $ \sbr{0 : 1} \in \PP^1 $. To attempt to construct such a map, write $ \phi' $ in homogeneous coordinates using the embedding $ \AA^2 \hookrightarrow \PP^2 $, so
$$ \function[\phi']{V'}{\AA^1}{\sbr{1 : x : y}}{\sbr{1 : x}}. $$
Now we homogenise, that is multiply by powers of the extra coordinate $ w $ to make all the polynomials homogeneous of degree one, so
$$ \function[\phi]{V}{\PP^1}{\sbr{w : x : y}}{\sbr{w : x}}. $$

\pagebreak

This maps $ \sbr{0 : 0 : 1} $ to $ \sbr{0 : 0} $ which is not allowed. But we can fix this by expressing the same map differently. Using the homogeneous nature of the coordinates, and the equation $ x^2 = wy $ defining $ V $, we have
$$ \sbr{w : x} = \sbr{wx : x^2} = \sbr{wx : wy} = \sbr{x : y}, $$
whenever the values we multiplied or divided by, $ w $ and $ x $, are non-zero. The expression $ \sbr{x : y} $ is well-defined at $ \sbr{0 : 0 : 1} $, with value $ \sbr{0 : 1} $. On the other hand, $ \sbr{x : y} $ gives $ \sbr{0 : 0} $ at the point $ \sbr{1 : 0 : 0} \in V $, so we cannot use $ \sbr{x : y} $ alone to define a map $ V \to \PP^1 $. The two expressions together give a well-defined regular map
$$ \function[\phi]{V}{\PP^1}{\sbr{w : x : y}}{
\begin{cases}
\sbr{w : x} & w \ne 0 \\
\sbr{x : y} & y \ne 0
\end{cases}
}. $$
To check that this does indeed define a map $ V \to \PP^1 $, we have the check the following.
\begin{itemize}
\item We have defined the map at every point of $ \PP^1 $. This is true because every point of $ V $ must have to satisfy at least one of $ w \ne 0 $ or $ y \ne 0 $, since if $ w = y = 0 $, then the equation $ wy = x^2 $ implies that $ x = 0 $ but $ \sbr{0 : 0 : 0} $ is not a point of $ \PP^2 $. Thus at least one of these two expressions is defined everywhere on $ V $.
\item On the overlap between the two open sets, both expressions define the same map. This is true because, if $ w $ and $ y $ are both non-zero and $ \sbr{w : x : y} \in V $, then $ x $ is also non-zero. We can then see that $ \sbr{x : y} = \sbr{w : x} $.
\end{itemize}
In this example, there is no single sequence of homogeneous polynomials which defines $ \phi $ everywhere on $ \PP^1 $. Note that each of these expressions is well-defined on a Zariski open subset of $ V $, since they are made up of homogeneous polynomials of the same degree, and they never give a point with homogeneous coordinates $ \sbr{0 : 0} $ within the specified open sets. This is important because it is how we ensure that the value of $ \phi $ at each point is polynomially related to its value at nearby points. Open sets are the natural way to talk about nearby points in a topological space. This still applies in the Zariski topology, even though open sets are very big.
\end{example*}

\begin{note*}
Questions $ 5 $ and $ 6 $ on problem sheet $ 2 $ give examples of regular maps defined everywhere except at a single point of an affine algebraic set, where there is an obvious value the map should take at the missing point, but the map is not regular at that point because there is no way to extend it to that point using polynomials. This is why we are not allowed just to write down polynomials on arbitrary non-open subsets of $ V $ and claim they define a regular map.
\end{note*}

Therefore, a regular map is defined to be a map which can be represented by some homogeneous polynomials at every point of $ V $. It is not enough just to say that for each point $ x \in V $, there exist some polynomials which give the correct value at $ x $, because then we could get every set-theoretic map by choosing different polynomials at different points. To relate the values of the map at different points, we require that there is some list of polynomials which defines the map on an open neighbourhood of $ x $. The formal definition of a regular map between projective algebraic sets $ V \subseteq \PP^m $ and $ W \subseteq \PP^n $ is the following.

\begin{definition*}
A \textbf{regular map} $ \phi : V \to W $ is a function $ V \to W $ such that for every point $ x \in V $, there exist a Zariski open set $ U \subseteq V $ containing $ x $ and a sequence of polynomials $ f_0, \dots, f_n \in k\sbr{X_0, \dots, X_m} $ such that,
\begin{itemize}
\item $ f_0, \dots, f_n $ are homogeneous of the same degree,
\item for every $ y \in U $, $ f_0, \dots, f_n $ are not all zero at $ y $, and
\item for every $ y = \sbr{y_0 : \dots : y_m} \in U $, $ \phi\br{y} = \sbr{f_0\br{y_0, \dots, y_m} : \dots : f_n\br{y_0, \dots, y_m}} $.
\end{itemize}
\end{definition*}

In practice, every regular map can be written down by specifying lists of polynomials on just finitely many open sets, like $ \phi $. This follows ultimately from the Hilbert basis theorem. To check that a purported definition like $ \phi $ really does define a regular map $ V \to W $, you have to check

\pagebreak

\begin{itemize}
\item each set on which an expression is defined is Zariski open,
\item an expression never gives $ \sbr{0 : \dots : 0} $ on its associated set,
\item two expressions agree wherever they are both defined, and
\item the image of the map is contained in $ W $.
\end{itemize}

\begin{example*}
As another example, taking $ V $ and $ V' $ as in the previous example, let us try to extend the inverse of $ \phi $ from affine to projective algebraic sets. On affine algebraic sets, the inverse of $ \phi' $ is given by
$$ \function[\psi']{\AA^1}{V'}{t}{\br{t, t^2}}. $$
In projective coordinates, this is
$$ \function[\psi']{\AA^1}{V'}{\sbr{1 : t}}{\sbr{1 : t : t^2}}. $$
Homogenising, by inserting powers of $ s $ to make all the polynomials on right hand side degree two, we get
$$ \function[\psi]{\PP^1}{V}{\sbr{s : t}}{\sbr{s^2 : st : t^2}}. $$
Now recalling that $ s $ and $ t $ cannot both be zero at the same point, $ s^2, st, t^2 $ are never simultaneously zero for $ \sbr{s : t} \in \PP^1 $, so in this case the single expression $ \sbr{s^2 : st : t^2} $ is enough to define a regular map $ \psi : \PP^1 \to V $ everywhere on $ \PP^1 $. Note that the image of $ \phi $ is indeed contained in $ V $.
\end{example*}

\begin{note*}
This homogenisation procedure often allows us to extend a regular map between affine algebraic sets into a regular map between their projective closures, but it does not always work. Sometimes there are regular maps between affine algebraic sets which it is impossible to extend to regular maps between their projective closures, since there are points for which it is impossible to avoid sending them to $ \sbr{0 : \dots : 0} $, or we might find that the homogeneous polynomials
involved become simultaneously zero at some point at infinity.
\end{note*}

\lecture{16}{Monday}{17/02/20}

\begin{definition*}
A regular map $ \phi : V \to W $ between projective algebraic sets is an \textbf{isomorphism} if there exists a regular map $ \psi : W \to V $ such that $ \phi \circ \psi = \id_W $ and $ \psi \circ \phi = \id_V $.
\end{definition*}

Observe that the two maps $ \phi : V \to \PP^1 $ and $ \psi : \PP^1 \to V $ which we just defined are inverses, so we conclude that the projective parabola $ V $ is isomorphic to $ \PP^1 $. We already remarked that the projective parabola is isomorphic to the projective hyperbola
$$ H = \cbr{\sbr{w : x : y} \in \PP^2 \st xy = w^2}, $$
by relabelling coordinates, so we deduce that the projective hyperbola is also isomorphic to $ \PP^1 $. In fact, we can show that all irreducible \textbf{conics} in $ \PP^2 $, subsets of $ \PP^2 $ defined by a homogeneous polynomial of degree two, are isomorphic to $ \PP^1 $, by using a projection as in problem $ 5 $ on problem sheet $ 2 $, and checking that in the projective setting, in this case, the projection gives regular maps and not just rational ones.

\subsubsection{Regular maps equal on a dense subset}

We already proved and made use of the following lemma previously for regular maps between affine algebraic sets. It is even more useful for regular maps between projective algebraic sets as it tells us that we only need to test equality between regular maps on a dense subset, since we will need it in the definition of rational maps.

\begin{lemma}
\label{lem:projectivedense}
Let $ \phi, \psi : V \to W $ be regular maps. If there exists a Zariski dense subset $ A \subseteq V $ such that $ \eval{\phi}_A = \eval{\psi}_A $, then $ \phi = \psi $.
\end{lemma}

\begin{example*}
Lemma \ref{lem:projectivedense} is especially useful if $ V $ is irreducible, because then Zariski open subsets of $ V $ are dense. So Lemma \ref{lem:projectivedense} tells us that, given a list of polynomials on a Zariski open subset of $ V $, there is at most one regular map which is given by that list of polynomials on that set, then it is sufficient to look at the open set where a single expression for the regular map is defined.
\end{example*}

\pagebreak

We will use the following topological fact.

\begin{fact*}
Let $ S $ be any topological space, not necessarily Hausdorff. Let $ \cbr{U_\alpha} $ be a collection of open subsets of $ S $, whose union is all of $ S $. Let $ Z $ be any subset of $ S $ such that $ Z \cap U_\alpha $ is closed in the subspace topology on $ U_\alpha $ for every $ \alpha $. Then $ Z $ is closed as a subset of $ S $.
\end{fact*}

\begin{proof}
Let
$$ Z = \cbr{x \in V \st \phi\br{x} = \psi\br{x}}. $$
By hypothesis, $ Z $ contains a dense subset of $ V $. Hence in order to show that $ Z = V $, it suffices to show that $ Z $ is closed in $ V $. From the definition of regular maps, we know that we can cover $ V $ by Zariski open sets $ U_\alpha $ such that on each $ U_\alpha $, both $ \phi $ and $ \psi $ are defined by sequences of homogeneous polynomials, so
$$ \eval{\phi}_{U_\alpha} = \sbr{f_{\alpha, 0} : \dots : f_{\alpha, m}}, \qquad \eval{\psi}_{U_\alpha} = \sbr{g_{\alpha, 0} : \dots : g_{\alpha, m}}. $$
By the general topological fact, it suffices to show that $ Z \cap U_\alpha $ is relatively closed in the subspace topology on $ U_\alpha $ for every $ \alpha $. Now
$$ Z \cap U_\alpha = \cbr{x \in U_\alpha \st \sbr{f_{\alpha, 0}\br{x} : \dots : f_{\alpha, m}\br{x}} = \sbr{g_{\alpha, 0}\br{x} : \dots : g_{\alpha, m}\br{x}}}. $$
This is the same as the set of $ x \in U_\alpha $ where the vectors $ \br{f_{\alpha, 0}\br{x}, \dots, f_{\alpha, m}\br{x}} $ and $ \br{g_{\alpha, 0}\br{x}, \dots, g_{\alpha, m}\br{x}} $ are proportional, for any choice of homogeneous coordinates for $ x $, or in other words where the matrix
$$ \twobyone{f_{\alpha, 0}\br{x} \qquad \dots \qquad f_{\alpha, m}\br{x}}{g_{\alpha, 0}\br{x} \qquad \dots \qquad g_{\alpha, m}\br{x}} $$
has rank one. A little linear algebra shows that this condition is equivalent to all the $ 2 \times 2 $ minors of this matrix vanishing, that is
$$ f_{\alpha, i}\br{x}g_{\alpha, j}\br{x} - f_{\alpha, j}\br{x}g_{\alpha, i}\br{x} = 0, \qquad i, j \in \cbr{0, \dots, m}. $$
This last condition is given by homogeneous polynomials, and therefore defines a closed subset in the subspace topology on $ U_\alpha $.
\end{proof}

\subsubsection{Quasi-projective algebraic sets}

So far, we have defined affine algebraic sets and projective algebraic sets, as separate types of objects. It is very convenient to have a single notion that unifies both affine and projective algebraic sets, for example to save us from having to prove a lemma for affine algebraic sets, then the same lemma for projective algebraic sets.

\begin{definition*}
A \textbf{quasi-projective algebraic set} is the intersection between an open subset and a closed subset of $ \PP^n $, in the Zariski topology.
\end{definition*}

A projective algebraic set is quasi-projective, by just taking the open subset to be $ \PP^n $ itself. An affine algebraic set $ V $ is also quasi-projective, since it is the intersection between $ \AA^n $, which is open in $ \PP^n $, and the projective closure $ \overline{V} $. There are other quasi-projective algebraic sets, for example $ \AA^1 \setminus \cbr{0} $ which is an open subset of $ \PP^1 $. We define a regular map between quasi-projective algebraic sets by the same definition as a regular map between projective algebraic sets, so it is a map which has a well-defined expression by homogeneous polynomials on a neighbourhood of every point. If $ V $ and $ W $ are affine algebraic sets, we now have two ways to define regular maps $ V \to W $.
\begin{itemize}
\item The original definition of regular maps between affine algebraic sets.
\item View $ V $ and $ W $ as quasi-projective algebraic sets, and use the new definition of regular maps between quasi-projective algebraic sets.
\end{itemize}
Fortunately, these two definitions turn out to be equivalent. One has to do a bit of work to check this. The problem is that a regular map of affine algebraic sets must be defined by the same list of polynomials at every point, but a regular map of quasi-projective algebraic sets may be defined by different polynomials at every point. Proving that actually one list of polynomials is enough if the set happens to be affine is similar to the proof of Lemma \ref{lem:rationalregular}. This gives us for free a notion of regular maps from a projective algebraic set to an affine algebraic set or vice versa. Just view them both as quasi-projective algebraic sets.

\pagebreak

\begin{example*}
We can now define a regular function on a projective algebraic set $ V $ to be a regular map $ V \to \AA^1 $, thus it is a function from the algebraic set $ V $ taking values in the base field $ k $. As remarked last lecture, we will later prove that the only regular functions on a projective algebraic set are the constants.
\end{example*}

\begin{example*}
We can now make rigorous the claim that $ \AA^1 \setminus \cbr{0} $ looks the same as the affine hyperbola
$$ H = \cbr{\br{x, y} \in \AA^2 \st xy = 1}. $$
The set $ \AA^1 \setminus \cbr{0} = \PP^1 \setminus \cbr{\sbr{1 : 0}, \sbr{0 : 1}} $ is a Zariski open subset of $ \PP^1 $, because its complement is finite. Hence $ \AA^1 \setminus \cbr{0} $ is a quasi-projective algebraic set. The map
$$ \function[\phi]{\AA^1 \setminus \cbr{0}}{H}{t}{\br{t, \dfrac{1}{t}}} $$
can be written in homogeneous coordinates as
$$ \function[\phi]{\AA^1 \setminus \cbr{0}}{H}{\sbr{1 : t}}{\sbr{1 : t : \dfrac{1}{t}} = \sbr{t : t^2 : 1}}, $$
so homogenising, we get
$$ \function[\phi]{\AA^1 \setminus \cbr{0}}{H}{\sbr{s : t}}{\sbr{st : t^2 : s^2}}. $$
So long as $ \sbr{s : t} \in \AA^1 \setminus \cbr{0} $, this does give a point in
$$ H = \cbr{\sbr{w : x : y} \in \PP^2 \st xy = w^2} \cap \AA^2, $$
so $ \phi $ is a regular map $ \AA^1 \setminus \cbr{0} \to H $. The projection $ \br{x, y} \mapsto x $ is a regular inverse to $ \phi $. Hence $ \AA^1 \setminus \cbr{0} $ and $ H $ are isomorphic as quasi-projective algebraic sets.
\end{example*}

\subsubsection{Varieties}

As mentioned previously, we use the word \textbf{variety} to mean an algebraic set considered up to isomorphism, not caring about how it is embedded into affine or projective space.

\begin{example*}
$ \AA^1 \setminus \cbr{0} $ is isomorphic, as a quasi-projective algebraic set, to the affine algebraic set $ H $, so we may say that $ \AA^1 \setminus \cbr{0} $ is an affine variety, even though $ \AA^1 \setminus \cbr{0} $ is definitely not an affine algebraic set.
\end{example*}

There exist quasi-projective algebraic sets which are not isomorphic to anything either projective or affine.

\begin{example*}
$ \AA^2 \setminus \cbr{\br{0, 0}} $. See problem sheet $ 3 $.
\end{example*}

\subsubsection{Rational maps between quasi-projective algebraic sets}

Let $ V \subseteq \PP^m $ and $ W \subseteq \PP^n $ be irreducible quasi-projective algebraic sets. The formal definition of a rational map $ V \dashrightarrow W $ looks quite complicated, but the underlying idea is the same as for regular maps. Just like for affine algebraic sets, a rational map is something which is almost a regular map, except that it is allowed to have some points where it is not defined. Rational maps of affine algebraic sets were non-regular at points where the denominator was zero. For quasi-projective algebraic sets, they are non-regular at points where the coordinates of the image become $ \sbr{0 : \dots : 0} $.

\begin{note*}
Unlike for affine sets, there is no need to use fractions of polynomials in the definition of rational maps between quasi-projective algebraic sets. Because our coordinates are homogeneous, we can always multiply up by a common denominator and get an expression involving only polynomials.
\end{note*}

Once again, somehow we have to make a definition which takes account of the fact that rational maps can be expressed in terms of different lists of polynomials at different points, and it might be necessary to use more than one expression to see the full domain of definition of the rational map. But unlike with regular maps of projective algebraic sets, we cannot tie the different expressions together into a single object by saying a rational map is a function $ V \to W $, because a rational map is not a function $ V \to W $. Instead we define rational maps as equivalence classes for a certain equivalence relation.

\pagebreak

\begin{note*}
Before defining rational maps as equivalence classes, let us ask, why is that a sensible thing to do? Thinking back to the definition of rational functions on an affine variety $ V $, this happens under the hood in defining rational functions on affine varieties too. They are defined as the elements of the field of fractions of $ k\sbr{V} $. The field of fractions of an integral domain $ R $ is defined as a set of equivalence classes, namely, you take the set $ \cbr{\br{a, b} \in R^2 \st b \ne 0} $, and the equivalence relation $ \br{a, b} \sim \br{c, d} $ if $ ad = bc $. The field of fractions of $ R $ is defined to be the set of equivalence classes for this relation. But normally we do not think of fractions as equivalence classes. We just write down one representative, with the special notation $ a / b $, and then manipulate it by the normal rules for manipulating fractions. In the ring $ R = \ZZ $, then often it may make sense to reduce fractions to lowest terms representatives, and if we impose the condition $ b > 0 $, then every fraction has a unique lowest terms representative. But if $ R $ is not a UFD, then we do not have special lowest terms representatives for fractions. This matches the fact that we might need different expressions to define a rational map at different points.
\end{note*}

So our definition begins by saying which sequences of polynomials determine rational maps, and then specifies when two sequences of polynomials determine the same rational map.

\begin{definition*}
A \textbf{rational map} $ \phi : V \dashrightarrow \PP^n $ is defined by a sequence of homogeneous polynomials $ f_0, \dots, f_n \in k\sbr{X_0, \dots, X_m} $ of the same degree such that $ f_0, \dots, f_n $ are not identically zero on $ V $. We write this as $ \phi = \sbr{f_0 : \dots : f_n} $. Two sequences of polynomials $ \sbr{f_0 : \dots : f_n} $ and $ \sbr{g_0 : \dots : g_n} $ represent the same rational map if the homogeneous coordinates $ \sbr{f_0\br{x} : \dots : f_n\br{x}} $ and $ \sbr{g_0\br{x} : \dots : g_n\br{x}} $ represent the same point in $ \PP^n $ wherever both expressions make sense. Using the fact that $ V $ is irreducible, we can check that this is an equivalence relation on sequences of homogeneous polynomials.
\end{definition*}

This is exactly the same as the definition of a regular map $ V \to \PP^n $, except that we are allowing there to be points where no expression for the map is defined. Now we define rational maps $ V \dashrightarrow W $, where $ W \subseteq \PP^n $ is any quasi-projective algebraic set. The definition is mostly what you would expect. A rational map is determined by a sequence of homogeneous polynomials $ \sbr{f_0 : \dots : f_n} $. There are points where these polynomials are allowed to be all zero, but they cannot be all zero everywhere on $ V $ so that the rational map is defined somewhere. When we say that the rational map goes into $ W $ instead of into $ \PP^n $, we require there to be a Zariski dense set $ A \subseteq V $ on which $ \sbr{f_0\br{x} : \dots : f_n\br{x}} $ lies in $ W $, but we do not require $ \sbr{f_0\br{x} : \dots : f_n\br{x}} \in W $ at every point of $ V $. This is the difference between regular and rational maps.

\begin{definition*}
Let $ V \subseteq \PP^m $ and $ W \subseteq \PP^n $ be irreducible quasi-projective algebraic sets. Let $ S $ denote the set of sequences $ \br{f_0, \dots, f_n} \in k\sbr{X_0, \dots, X_m}^{n + 1} $ such that,
\begin{itemize}
\item $ f_0, \dots, f_n $ are homogeneous of the same degree,
\item $ f_0, \dots, f_n $ are not all identically zero on $ V $, noting that this looks a little like the $ b \ne 0 $ condition in defining the field of fractions, and
\item there exists a non-empty Zariski dense open set $ A \subseteq V $ such that, for all $ x \in A $, the homogeneous coordinates $ \sbr{f_0\br{x} : \dots : f_n\br{x}} $ make sense and define a point in $ W $.
\end{itemize}
Define an equivalence relation $ \sim $ on $ S $ by,
$$ \br{f_0, \dots, f_n} \sim \br{g_0, \dots, g_n} \qquad \iff \qquad \sbr{f_0\br{x} : \dots : f_n\br{x}} = \sbr{g_0\br{x} : \dots : g_n\br{x}} \in \PP^n, $$
for all $ x \in V $ where both expressions make sense. We could write this more algebraically as,
$$ \br{f_0, \dots, f_n} \sim \br{g_0, \dots, g_n} \qquad \iff \qquad f_ig_j = f_jg_i, \qquad i, j \in \cbr{0, \dots, n}. $$
Having defined $ S $ and $ \sim $, we then define a \textbf{rational map} $ \phi : V \dashrightarrow W $ to be an equivalence class in $ S $ for $ \sim $.
\end{definition*}

These two definitions of $ S $ and $ \sim $ are more formal ways of writing the two parts of the definition of a rational map. Observe that this resembles the equivalence relation used in defining the field of fractions. One needs to check that $ \sim $ really is an equivalence relation. This is a detail which was hidden in my informal statement of the definition. This uses the fact that $ V $ is irreducible and Lemma \ref{lem:projectivedense} that if two polynomials are equal on a Zariski dense set, then they are equal everywhere. Just as with fractions, we usually just write down a single representative for a rational map. There is a special notation for representatives of rational maps in $ S $, namely $ \sbr{f_0 : \dots : f_n} $. We have seen examples on problem sheets of UFD-like situations where one can choose a lowest terms representative for the rational map, but this is not always possible.

\lecture{17}{Thursday}{20/02/20}

Lecture 17 is a problems class.

\pagebreak

\subsubsection{Domain of definition of rational maps}

\lecture{18}{Friday}{21/02/20}

\begin{definition*}
A rational map $ \phi : V \dashrightarrow W $ is \textbf{regular} at a point $ x \in V $ if there exists at least one list of polynomials $ \br{f_0, \dots, f_n} \in S $ representing $ \phi $ such that $ \sbr{f_0\br{x} : \dots : f_n\br{x}} \ne \sbr{0 : \dots : 0} $ and $ \sbr{f_0\br{x} : \dots : f_n\br{x}} \in W $. If $ \phi $ is regular at $ x \in V $, then the equivalence relation $ \sim $ ensures that the value $ \phi\br{x} \in W $ makes sense and is well-defined, with homogeneous coordinates given by $ \sbr{f_0\br{x} : \dots : f_n\br{x}} $. This point is independent of the choice of polynomials representing $ \phi $, as well as independent of the choice of homogeneous coordinates for $ x $. Just as for affine algebraic sets, we define the \textbf{domain of definition} of a rational map to be the set of points where it is regular, the union of the sets where each representative of the equivalence class makes sense as a map.
\end{definition*}

\begin{note*}
Just as in the affine case, when checking whether $ \phi $ is regular at a point $ x $, it is not enough to check whether the representation $ \sbr{f_0 : \dots : f_n} $ which we first used to define the map is regular at $ x $. We have to check whether there exists any representation $ \sbr{g_0 : \dots : g_n} $ for $ \phi $ which is defined at $ x $.
\end{note*}

\begin{note*}
Furthermore, the domain of definition of a rational map can change if we change the target set $ W $.
\end{note*}

\begin{example*}
Consider the map defined by
$$ \function{\PP^1}{\PP^2}{\sbr{s : t}}{\sbr{s^2 : st : t^2}}. $$
This is regular at every point. We could interpret the same formula as defining a rational map $ \PP^1 \dashrightarrow W $ where $ W \subseteq \PP^2 $ is the open set $ W = \cbr{\sbr{w : x : y} \st w \ne 0} $. As a rational map $ \PP^1 \dashrightarrow W $, this is not regular at the point $ \sbr{0 : 1} $ because this point maps to $ \sbr{0 : 0 : 1} \notin W $.
\end{example*}

\begin{lemma}
Let $ \phi : V \dashrightarrow W $ be a rational map. The domain of definition of $ \phi $ is a non-empty Zariski open subset of $ V $.
\end{lemma}

\begin{proof}
Similar to the affine case, in Lemma \ref{lem:domaindefinition}.
\end{proof}

It follows immediately from the definition of regular maps between quasi-projective algebraic sets that if a rational map is regular at every point, then it is a regular map. In the affine case, in Lemma \ref{lem:rationalregular}, we had to work to prove that if a rational map is regular at every point, then there is a single polynomial expression which defines the map everywhere. In the quasi-projective case, we do not need to do this because our definition of regular map allows different expressions at different points.

\begin{example*}
Let $ C $ denote the affine algebraic set
$$ C = \cbr{\br{x, y} \in \AA^2 \st y = x^3}. $$
This has projective closure
$$ \overline{C} = \cbr{\sbr{w : x : y} \in \PP^2 \st w^2y = x^3} = C \cup \cbr{\sbr{0 : 0 : 1}}. $$
Consider the regular map of affine algebraic sets given by
$$ \function[\phi]{C}{\AA^1}{\br{x, y}}{x}. $$
If we try to extend this to a map of projective algebraic sets $ \overline{\phi} : \overline{C} \to \PP^1 $, we would say that for points $ \sbr{1 : x : y} \in C \subseteq \overline{C} $,
$$ \function[\phi]{C}{\AA^1}{\sbr{1 : x : y}}{\sbr{1 : x}}, $$
and this homogenises to
$$ \rational[\overline{\phi}]{\overline{C}}{\PP^1}{\sbr{w : x : y}}{\sbr{w : x}}. $$
Thus $ \overline{\phi} $ is a rational map $ \overline{C} \dashrightarrow \PP^1 $. The above expression for $ \overline{\phi} $ is not defined at the point $ \sbr{0 : 0 : 1} \in \overline{C} $. We can prove that there is no other expression for $ \overline{\phi} $ which is defined at that point, and so $ \overline{\phi} $ is not regular at $ \sbr{0 : 0 : 1} $. See problem sheet $ 3 $, question $ 3 $.
\end{example*}

Thus a regular map of affine algebraic sets extends to a rational map between their projective closures, but the extended map is not necessarily regular at the points at infinity.

\pagebreak

\subsubsection{Birational maps}

Just as in the affine case, if we have irreducible quasi-projective sets $ V, W, T $ and rational maps $ \phi : V \dashrightarrow W $ and $ \psi : W \dashrightarrow T $, if the image of $ \phi $ is dense in $ W $, then the composite $ \psi \circ \phi $ is a rational map $ V \dashrightarrow T $. The following definitions are the same as the affine case.

\begin{definition*}
A rational map $ \phi : V \dashrightarrow W $ is \textbf{dominant} if its image is dense in $ W $. A rational map $ \phi : V \dashrightarrow W $ is a \textbf{birational equivalence} if it is dominant and there exists a dominant rational map $ \psi : W \dashrightarrow V $ such that $ \psi \circ \phi = \id_V $ and $ \phi \circ \psi = \id_W $, where these composite rational maps are defined. Irreducible algebraic sets $ V $ and $ W $ are \textbf{birational} if there exists a birational equivalence $ V \dashrightarrow W $.
\end{definition*}

\begin{note*}
$ \AA^n $ is birational to $ \PP^n $. Consider the regular map
$$ \function[\phi]{\AA^n}{\PP^n}{\br{x_1, \dots, x_n}}{\sbr{1 : x_1 : \dots : x_n}}, $$
and the rational map
$$ \rational[\psi]{\PP^n}{\AA^n}{\sbr{x_0 : \dots : x_n}}{\br{\dfrac{x_1}{x_0}, \dots, \dfrac{x_n}{x_0}}}. $$
Each of these is dominant and composing them in either direction gives the identity, so these are birational equivalences. Observe that $ \phi $ is an isomorphism from $ \AA^n $ to an open subset of $ \PP^n $.
\end{note*}

We can generalise this to show that if $ V $ is any irreducible quasi-projective variety and $ U $ is a Zariski open subset of $ V $, thus $ U $ is also an irreducible quasi-projective variety, then $ U $ is birational to $ V $. Indeed, this is a corollary of the following stronger result, which makes precise the intuition that varieties are birational if and only if they are the same almost everywhere.

\begin{note*}
We need the concept of quasi-projective varieties to state this lemma, even if $ V $ and $ W $ are both affine or both projective, because it is necessary to interpret the statement that $ A $ and $ B $ are isomorphic.
\end{note*}

\begin{lemma}
Irreducible quasi-projective varieties $ V $ and $ W $ are birational if and only if there exist non-empty Zariski open subsets $ A \subseteq V $ and $ B \subseteq W $ such that $ A $ is isomorphic to $ B $, as quasi-projective varieties.
\end{lemma}

\begin{proof}
Let $ \phi : V \dashrightarrow W $ and $ \psi : W \dashrightarrow V $ be an inverse pair of rational maps. Let $ A_1 = \dom \phi $ and $ B_1 = \dom \psi $. Then $ B_1 $ is a non-empty open subset of $ W $. Since $ \phi $ induces a continuous map $ A_1 \to W $, $ A = \eval{\phi}_{A_1}^{-1}\br{B_1} $ is an open subset of $ V $. Furthermore, since $ \phi $ is dominant, its image intersects the open set $ B_1 \subseteq W $. Therefore $ A $ is non-empty. Similarly $ B = \eval{\psi}_{B_1}^{-1}\br{A_1} $ is a non-empty open subset of $ W $. One can now check that $ \eval{\phi}_A $ and $ \eval{\psi}_B $ form an inverse pair of isomorphisms between $ A $ and $ B $.
\end{proof}

If $ V $ is a quasi-projective algebraic set, we define a \textbf{rational function} on $ V $ to be a rational map $ \phi : V \dashrightarrow \AA^1 $. By definition, this is the same as a rational map $ \phi' : V \dashrightarrow \PP^1 $ except that we declare $ \phi $ to be non-regular at points where $ \phi'\br{x} = \infty = \sbr{0 : 1} \in \PP^1 $. We can therefore say
$$ \phi\br{x} = \sbr{f\br{x} : g\br{x}} = \sbr{1 : \dfrac{g\br{x}}{f\br{x}}} = \dfrac{g\br{x}}{f\br{x}} \in \AA^1, $$
whenever $ f\br{x} \ne 0 $, for suitable polynomials $ f $ and $ g $. Of course, as always with rational maps, we might need to use different polynomials to evaluate it at different points. The rational functions on $ V $ form a field $ k\br{V} $. Just as in the affine case, $ V $ is birational to $ W $ if and only if $ k\br{V} $ is $ k $-isomorphic to $ k\br{W} $. This allows us to calculate
$$ k\br{\PP^n} = k\br{\AA^n} = k\br{X_1, \dots, X_n}. $$

\pagebreak

\subsection{Rigidity and images of maps}

\subsubsection{Linear spaces in projective space}

We want to define a fundamental example of a rational map, the projection from a point to a hyperplane. First, we need to make a few other definitions.

\begin{definition*}
A \textbf{hyperplane} in $ \PP^n $ is the projective algebraic set defined by a single homogeneous linear equation,
$$ H = \cbr{\sbr{x_0 : \dots : x_n} \in \PP^n \st h_0x_0 + \dots + h_nx_n = 0}, $$
for some $ h_0, \dots, h_n \in k $, not all zero. More generally, a \textbf{linear subspace} of $ \PP^n $ is a subset defined by any set of homogeneous linear equations.
\end{definition*}

\begin{example*}
Examples of linear subspaces are $ \PP^n $ itself with the empty set of equations, $ \emptyset $ with too many equations, and singletons. We cannot define the singleton $ \cbr{\sbr{p_0 : \dots : p_n}} $ by the equations $ x_0 = p_0, \dots, x_n = p_n $ because these are not homogeneous. Instead, we can write homogeneous equations asserting that the ratios between pairs of coordinates are correct, so
$$ \cbr{\sbr{p_0 : \dots : p_n}} = \cbr{\sbr{x_0 : \dots : x_n} \in \PP^n \st \forall i, j, \ p_ix_j = p_jx_i}. $$
\end{example*}

If $ \Lambda $ is a linear subspace of $ \PP^n $, then the affine cone $ \C\br{\Lambda} $, the set of points in $ \AA^{n + 1} $ satisfying the same equations as $ \Lambda $, is a vector subspace of $ k^{n + 1} $. As a vector space, we know what is meant by $ \dim \C\br{\Lambda} $. We define
$$ \dim \Lambda = \dim \C\br{\Lambda} - 1. $$
We have not yet defined the dimension of an arbitrary algebraic set. This definition is only for linear subspaces of projective space. The $ -1 $ is because $ \C\br{\Lambda} $ contains a line for each point in $ \Lambda $.

\begin{example*}
$ \PP^n $ has dimension $ n $, a hyperplane has dimension $ n - 1 $, and a point has dimension zero.
\end{example*}

If $ \Lambda $ is a linear subspace of $ \PP^n $ of dimension $ d $, then $ \C\br{\Lambda} \cong k^{d + 1} $, as a vector space, and
$$ \Lambda = \br{\C\br{\Lambda} \setminus \cbr{0}} / \text{scalars} \cong \PP^d. $$

\begin{definition*}
A \textbf{line} in $ \PP^n $ is a linear subspace of dimension one.
\end{definition*}

\lecture{19}{Monday}{24/02/20}

\begin{lemma}
For any two distinct points $ p, q \in \PP^n $, there exists a unique line $ \L_{pq} $ through $ p $ and $ q $.
\end{lemma}

One could prove this by saying, $ \PP^n $ can be written as a union $ \AA^n \cup \PP^{n - 1} $, and going through the cases $ p, q \in \AA^n $, $ p, q \in \PP^{n - 1} $, and $ p \in \AA^n $ and $ q \in \PP^{n - 1} $. In order to make this into a full proof, we would need to check that a line in $ \PP^n $, intersected with $ \AA^n $, is the same as the ordinary definition of a line in $ \AA^n $, which is true. Instead we shall give a proof using linear algebra. A benefit of this proof is that it gives a description of the homogeneous coordinates of points in the line $ \L_{pq} $.

\begin{proof}
Let $ p = \sbr{p_0 : \dots : p_n} $ and $ q = \sbr{q_0 : \dots : q_n} $. The affine cones $ \C\br{p} $ and $ \C\br{q} $ are the one-dimensional vector spaces of generated by $ \br{p_0, \dots, p_n} $ and $ \br{q_0, \dots, q_n} $ respectively. Since $ p \ne q $, these vector spaces are linearly independent so there is a unique two-dimensional vector subspace $ W \subseteq k^{n + 1} $ which contains $ \C\br{p} $ and $ \C\br{q} $. The image of $ W \setminus \cbr{0} $ in $ \PP^n $ is the unique line through $ p $ and $ q $. Explicitly, $ W $ consists of all linear combinations of the vectors $ \br{p_0, \dots, p_n} $ and $ \br{q_0, \dots, q_n} $. It follows that
$$ \L_{pq} = \cbr{\sbr{p_0s + q_0t : \dots : p_ns + q_nt} \in \PP^n \st \sbr{s : t} \in \PP^1}. $$
\end{proof}

\subsubsection{Projections of projective algebraic sets}

A fundamental example of a rational map is the projection from a point to a hyperplane. Let $ p = \sbr{p_0 : \dots : p_n} \in \PP^n $ and let $ H \subseteq \PP^n $ be a hyperplane such that $ p \notin H $. To simplify the calculations, we shall assume that
$$ H = \cbr{\sbr{x_0 : \dots : x_n} \in \PP^n \st x_n = 0}. $$

\pagebreak

Any line in $ \PP^n $ which is not contained in $ H $ meets $ H $ in exactly one point. This is geometrically clear. One can prove it algebraically via linear algebra using the affine cones, or by the following calculation. Let $ x \in \PP^n \setminus \cbr{p} $. Then
$$ \L_{px} = \cbr{\sbr{p_0s + x_0t : \dots : p_ns + x_nt} \in \PP^n \st \sbr{s : t} \in \PP^1}. $$
Hence, to find $ \L_{px} \cap H $, we need to choose $ \sbr{s : t} $ such that $ p_ns + x_nt = 0 $. We can choose $ \sbr{s : t} = \sbr{x_n : -p_n} $, noting that $ p_n \ne 0 $ because $ p \notin H $, so we do not get $ \sbr{0 : 0} $. Substituting in to $ \L_{px} $, the unique point of $ \L_{px} \cap H $ is
$$ \sbr{p_0x_n - x_0p_n : \dots : p_{n - 1}x_n - x_{n - 1}p_n : 0}. $$
The final $ 0 = p_nx_n - x_np_n $ is what we expect for a point in $ H $.

\begin{note*}
If $ p \ne x $, then this is not $ \sbr{0 : \dots : 0} $ so it is well-defined.
\end{note*}

Thus, for $ x \in \PP^n \setminus \cbr{p} $, it makes sense to define $ \pi\br{x} $ to be the unique point of $ \L_{px} \cap H $. The above calculation shows that $ \pi $ is a rational map $ \PP^n \dashrightarrow H $, regular on $ \PP^n \setminus \cbr{p} $. We show below that $ \pi $ is not regular at $ p $. This rational map is called the \textbf{projection from $ p $ to $ H $}. One could replace this particular fixed $ H $ by any hyperplane not containing $ p $, and carry out the same recipe.

\begin{lemma}
Let $ n \ge 2 $. The projection of $ \PP^n $ from $ p $ to $ H $ is not regular at $ p $.
\end{lemma}

Intuitively, there are many lines passing through $ p $ and $ p $, so the projection would have to map $ p $ to everywhere at once. We can make this rigorous.

\begin{proof}
Pick a point $ s \in H $ and consider the line $ \L_{ps} $. For any $ x \in \L_{ps} \setminus \cbr{p} $, the geometric description of $ \pi $ shows that $ \pi\br{x} = s $. If we assume that $ \pi $ is regular at $ p $, then it restricts to a regular map $ \L_{ps} \to H $. We have just shown that this map is constant on $ \L_{ps} \setminus \cbr{p} $ and therefore it is constant on $ \L_{ps} $. Hence $ \pi\br{p} = s $. We could pick another point $ t \in H $ and repeat exactly the same argument using $ \L_{pt} $, so that $ \pi\br{p} = t $. This is a contradiction.
\end{proof}

The condition $ n \ge 2 $ is needed to ensure that $ H \cong \PP^{n - 1} $ has two distinct points $ s $ and $ t $. If $ n = 1 $, then $ H $ is just a point and $ \pi $ is a constant map, so it is regular everywhere.

\subsubsection{Products of projective algebraic sets}

Many sets that we want to work with, for example, the graph of a regular map $ V \to W $, are naturally defined as subsets of products $ V \times W $ of algebraic sets. Therefore we would like to be able to say that the product of algebraic sets are also algebraic sets. We saw that this is easy for affine algebraic sets, since $ V \times W $ is an affine algebraic subset of $ \AA^{m + n} $. The key point here is the isomorphism $ \AA^m \times \AA^n \cong \AA^{m + n} $. For projective algebraic sets, it is harder to define products because $ \PP^m \times \PP^n \ncong \PP^{m + n} $.

\begin{example*}
To see informally why $ \PP^1 \times \PP^1 \ncong \PP^2 $, recall that $ \PP^1 = \AA^1 \cup \cbr{\text{point}} $ so
$$ \PP^1 \times \PP^1 = \br{\AA^1 \times \AA^1} \cup \br{\AA^1 \times \cbr{\text{point}}} \cup \br{\cbr{\text{point}} \times \AA^1} \cup \br{\cbr{\text{point}} \times \cbr{\text{point}}} = \AA^2 \cup \AA^1 \cup \AA^1 \cup \cbr{\text{point}}. $$
Meanwhile $ \PP^2 = \AA^2 \cup \PP^1 = \AA^2 \cup \AA^1 \cup \cbr{\text{point}} $. Thus $ \PP^1 \times \PP^1 $ contains an extra copy of $ \AA^1 $ compared to $ \PP^2 $. This is only an informal argument. A rigorous proof will be on problem sheet $ 4 $.
\end{example*}

We could try giving an ad hoc definition for $ \PP^m \times \PP^n $ by hand. It is fairly clear what algebraic subsets of $ \PP^m \times \PP^n $, sets defined by polynomials in the two sets of homogeneous coordinates $ \sbr{x_0 : \dots : x_m} $ and $ \sbr{y_0 : \dots : y_n} $, should mean. In order for the zero set of such a polynomial to be well-defined, it must be \textbf{bihomogeneous}, that is homogeneous in the $ x $ variables and homogeneous in the $ y $ variables, but the $ x $ and $ y $ degrees can potentially be different. Similarly, we could give a definition of regular maps between subvarieties of $ \PP^m \times \PP^n $ involving bihomogeneous polynomials. But it would be annoying to have just defined quasi-projective varieties, unifying affine and projective varieties, and then immediately have to introduce ad hoc definitions for another different kind of variety. So we aim to construct the product in a way which makes it a quasi-projective set, and then we can just reuse the definitions from before. Furthermore, projective varieties have special properties of their own. In particular, we will prove that the image of a projective variety under a regular map is always closed. By showing that the product of projective varieties is itself a projective variety, we will be able to apply these properties to products too.

\pagebreak

\subsubsection{The Segre embedding}

To construct the product $ \PP^m \times \PP^n $ as a projective algebraic set, we will embed it inside some larger $ \PP^N $. The homogeneous coordinates of a point in $ \PP^m \times \PP^n $ will be given by an $ \br{m + 1} \times \br{n + 1} $ matrix, so we need
$$ N = \br{m + 1}\br{n + 1} - 1 = mn + m + n. $$
Thus the number of homogeneous coordinates needed to specify a point in $ \PP^N $ is $ \br{m + 1}\br{n + 1} $. We will arrange the homogeneous coordinates of points in $ \PP^N $ as if they were entries of a matrix. Thus we label them as
$$ \sbr{\br{z_{ij} \st 0 \le i \le m, \ 0 \le j \le n}}, $$
rather than the usual $ \sbr{z_0 : \dots : z_N} $. Define a map given by
$$ \function[\sigma_{m, n}]{\PP^m \times \PP^n}{\PP^N}{\br{\sbr{x_0 : \dots : x_m}, \sbr{y_0 : \dots : y_n}}}{\sbr{\br{z_{ij} = x_iy_j \st 0 \le i \le m, \ 0 \le j \le n}}}. $$
Another way to describe this is to say that the homogeneous coordinates of $ \sigma_{m, n}\br{\sbr{x_0 : \dots : x_m}, \sbr{y_0 : \dots : y_n}} $ are given by the product matrix
$$ \br{z_{ij}} = \threebyone{x_0}{\vdots}{x_m}\onebythree{y_0}{\dots}{y_n}. $$
Observe that this matrix has rank one. Let
$$ \Sigma_{m, n} = \cbr{\sbr{z_{00} : \dots : z_{mn}} \in \PP^N \st \rk \br{z_{ij}} = 1}. $$
Some linear algebra shows that we can describe $ \Sigma_{m, n} $ as the subset of $ \PP^N $ where all $ 2 \times 2 $ submatrices of the matrix $ \br{z_{ij}} $ have zero determinant. Thus $ \Sigma_{m, n} $ is a projective algebraic set, defined by the equations
$$ z_{ij}z_{kl} = z_{kj}z_{il}, \qquad 0 \le i, k \le m, \qquad 0 \le j, l \le n. $$

\begin{lemma}
$ \sigma_{m, n} $ is a bijection from $ \PP^m \times \PP^n $ to $ \Sigma_{m, n} $.
\end{lemma}

This proof is not part of the course.

\begin{proof}
We can define an inverse to $ \sigma_{m, n} $ as follows. Let $ a \in \Sigma_{m, n} $, and let $ A $ be a matrix giving homogeneous coordinates for $ a $. Then $ A $ is not the zero matrix, because it is a set of homogeneous coordinates, so we can pick $ j $ such that the $ j $-th column of $ A $ contains a non-zero entry. Define $ \pi_1\br{a} \in \PP^m $ to be the point with homogeneous coordinates given by the $ j $-th column of $ A $, that is $ \pi_1\br{a} = \sbr{A_{1j} : \dots : A_{mj}} $. This is independent of the choice of $ j $ because the matrix has rank one, since every non-zero column is a multiple of every other non-zero column. Similarly we can pick $ i $ such that the $ i $-th row of $ A $ contains a non-zero entry, and define $ \pi_2\br{a} \in \PP^n $ to be the point with homogeneous coordinates given by the $ i $-th row of $ A $. Again this is independent of the choice of $ i $. Now $ \br{\pi_1, \pi_2} : \Sigma_{m, n} \to \PP^m \times \PP^n $ is an inverse to $ \sigma_{m, n} $.
\end{proof}

This construction shows that the projections $ \pi_1 : \Sigma_{m, n} \to \PP^m $ and $ \pi_2 : \Sigma_{m, n} \to \PP^n $ are regular maps, since each column of the matrix is non-zero on a Zariski open subset of $ \Sigma_{m, n} $. The map $ \sigma_{m, n} : \PP^m \times \PP^n \to \PP^N $ is called the \textbf{Segre embedding} and its image $ \Sigma_{m, n} \subseteq \PP^N $ is called the \textbf{Segre variety}.

\lecture{20}{Thursday}{27/02/20}

\begin{example*}
When $ m = n = 1 $, $ N = 3 $. The Segre variety $ \Sigma_{m, n} \subseteq \PP^3 $ is defined by the single equation
$$ \det \twobytwo{z_{00}}{z_{01}}{z_{10}}{z_{11}} = z_{00}z_{11} - z_{10}z_{01} = 0. $$
The Segre embedding is given by
$$ \sigma_{m, n}\br{\sbr{x_1 : x_2}, \sbr{y_1 : y_2}} = \sbr{x_1y_1 : x_1y_2 : x_2y_1 : x_2y_2}. $$
We see that $ \Sigma_{m, n} $ is an irreducible quadric hypersurface in $ \PP^3 $. Therefore by problem sheet $ 3 $, question $ 4 $, it is birational to $ \PP^2 $ and $ \AA^2 $. This is not surprising, because of course $ \PP^1 \times \PP^1 $ should have an open subset isomorphic to $ \AA^1 \times \AA^1 \cong \AA^2 $, which in turn is an open subset of $ \PP^2 $. We gave an informal argument earlier that $ \PP^1 \times \PP^1 $ should not be isomorphic to $ \PP^2 $. A rigorous proof of this will be on the next problem sheet.
\end{example*}

\pagebreak

Because $ \Sigma_{m, n} $ is a projective algebraic set, it has a subspace topology induced by the Zariski topology on $ \PP^N $ and so we get a Zariski topology on $ \PP^m \times \PP^n $. One can check that this topology is the same as what we expect, namely the following.

\begin{lemma}
Let $ V \subseteq \PP^m \times \PP^n $. Then $ \sigma_{m, n}\br{V} \subseteq \Sigma_{m, n} $ is closed if and only if
$$ V = \cbr{\br{\sbr{x_0 : \dots : x_m}, \sbr{y_0 : \dots : y_n}} \st \forall 1 \le i \le s, \ f_i\br{x_0, \dots, x_m, y_0, \dots, y_n} = 0}, $$
where $ f_1, \dots, f_s \in k\sbr{X_0, \dots, X_m, Y_0, \dots, Y_n} $ are bihomogeneous polynomials.
\end{lemma}

This proof is not part of the course. We say that a polynomial $ f \in k\sbr{X_0, \dots, X_m, Y_0, \dots, Y_n} $ is \textbf{bihomogeneous of degree $ \br{d, e} $} if every term of $ f $ has degree $ d $ with respect to the $ X $ variables and degree $ e $ with respect to the $ Y $ variables.

\begin{proof}
Suppose that $ \sigma_{m, n}\br{V} $ is Zariski closed in $ \PP^N $. Then it is defined by some homogeneous polynomials $ g_r\br{z_{00}, \dots, z_{mn}} $. Making the substitutions $ z_{ij} = x_iy_j $, as in the definition of $ \sigma_{m, n} $, we get a finite set of polynomials which define $ V $. If $ g_r $ is homogeneous in $ z_{ij} $ of degree $ d_r $, then $ g_r \circ \sigma_{m, n} $ is bihomogeneous of degree $ \br{d_r, d_r} $. It is easy to see that if $ V $ is defined by polynomials $ f_r $, where $ f_r $ is bihomogeneous of degree $ \br{d_r, d_r} $, then we can reverse this process to get homogeneous polynomials in $ z_{ij} $ which define $ \sigma_{m, n}\br{V} $. But what if the defining polynomials for $ V $ include some $ f $ which is bihomogeneous of degree $ \br{d, e} $, where $ d \ne e $? Without loss of generality, suppose that $ d > e $. Then $ f = 0 $ is equivalent to the system of equations
$$ x_0^{d - e}f = 0, \qquad \dots, \qquad x_m^{d - e}f = 0, $$
and these equations are bihomogeneous of degree $ \br{d, d} $.
\end{proof}

\subsubsection{Graphs of regular functions}

If $ V \subseteq \PP^m $ and $ W \subseteq \PP^n $ are projective algebraic sets, then their product $ V \times W \subseteq \PP^m \times \PP^n $ is a Zariski closed subset of $ \PP^m \times \PP^n $, since the homogeneous polynomials defining $ V $ become bihomogeneous polynomials of degree $ \br{d, 0} $ while those defining $ W $ become bihomogeneous polynomials of degree $ \br{0, e} $, and therefore $ V \times W $ is itself a projective variety. Similarly, if $ V \subseteq \PP^m $ and $ W \subseteq \PP^n $ are quasi-projective algebraic sets, then the product $ V \times W $ is also quasi-projective, since it is the intersection of an open subset and a closed subset in $ \PP^m \times \PP^n $, and therefore in $ \PP^N $ via the Segre embedding.

\begin{example*}
One useful example of a subvariety of a product is the graph of a regular function. Let $ V \subseteq \PP^n $ and $ W \subseteq \PP^m $ be quasi-projective algebraic sets, and let $ \phi : V \to W $ be a regular map. The \textbf{graph} of $ \phi $ is
$$ \Gamma = \cbr{\br{x, y} \in V \times W \st y = \phi\br{x}}. $$
To check that this is closed in $ V \times W $, observe that $ \Gamma $ is the preimage of the diagonal $ \Delta \subseteq \PP^m \times \PP^m $ under the regular map
$$ \br{\iota \circ \phi, \iota} : V \times W \to \PP^m \times \PP^m, $$
where $ \iota $ denotes the inclusion map $ W \to \PP^m $. Since $ \br{\iota \circ \phi, \iota} $ is a regular map, it is continuous. Therefore it suffices to check that the diagonal is a Zariski closed subset of $ \PP^m \times \PP^m $. This is true because we can describe the diagonal by bihomogeneous equations as
$$ \Delta = \cbr{\br{\sbr{x_0 : \dots : x_m}, \sbr{y_0 : \dots : y_m}} \st \forall i, j, \ x_iy_j = x_jy_i}. $$
\end{example*}

\subsubsection{Images of projective varieties}

The following is a key property of projective algebraic varieties, which is analogous to compactness for Hausdorff topological spaces.

\begin{theorem}
\label{thm:imageclosed}
Let $ V $ be a projective variety. Let $ \phi : V \to W $ be a regular map into any quasi-projective variety. Then the image of $ \phi $ is Zariski closed.
\end{theorem}

Clearly Theorem \ref{thm:imageclosed} is false if $ V $ is not projective.

\begin{example*}
Consider the projection of the hyperbola $ \cbr{\br{x, y} \st xy = 1} $ onto one of the axes.
\end{example*}

\pagebreak

Theorem \ref{thm:imageclosed} shows that projective varieties are similar to compact spaces in topology, since if $ S $ is a compact topological space and $ T $ is a Hausdorff topological space, then the image of any continuous map $ S \to T $ is closed. By applying Theorem \ref{thm:imageclosed} to $ \iota \circ \phi $, where $ \iota $ is an embedding $ W \to \PP^m $, we see that the image of a projective variety under a regular map is again a projective variety. Before proving Theorem \ref{thm:imageclosed}, we shall state some important corollaries.

\begin{corollary}
\label{cor:regularconstant}
Every regular function on an irreducible projective variety is constant.
\end{corollary}

\begin{proof}
Let $ V $ be an irreducible projective variety and $ \phi : V \to \AA^1 $ a regular function. Let $ \iota : \AA^1 \to \PP^1 $ be the natural inclusion. Then $ \iota \circ \phi : V \to \PP^1 $ is a regular map, so by Theorem \ref{thm:imageclosed}, its image is a closed subset of $ \PP^1 $. But the image of $ \iota \circ \phi $ is contained in $ \AA^1 $, so it cannot be all of $ \PP^1 $. Therefore the image of $ \phi $ is finite. Since $ V $ is irreducible, its image is also irreducible and therefore consists of a single point.
\end{proof}

Thus projective algebraic sets are essentially opposite to affine ones, since an affine algebraic set is determined by its ring of regular functions while a projective algebraic set has no regular functions except constants.

\begin{corollary}
\label{cor:regularpoint}
The image of a regular map from an irreducible projective variety to an affine variety is a point.
\end{corollary}

\begin{proof}
Suppose we have a regular map $ \phi : V \to W $, where $ V $ is projective and irreducible and $ W $ is affine. We can suppose that $ W \subseteq \AA^m $, and let $ X_1, \dots, X_m $ denote the coordinate functions on $ W $. Then $ X_1 \circ \phi, \dots, X_m \circ \phi $ are all constant by Corollary \ref{cor:regularconstant}, and so $ \phi $ is constant.
\end{proof}

\begin{lemma}
\label{lem:hyperplaneintersection}
Let $ V \subseteq \PP^n $ be an infinite projective algebraic set and let $ H \subseteq \PP^n $ be a hyperplane. Then the intersection $ V \cap H $ is non-empty.
\end{lemma}

We use the following fact. This fact is proved for $ \PP^2 $ on problem sheet $ 3 $ using the Veronese embedding, and the proof generalises to arbitrary $ \PP^n $.

\begin{fact*}
If $ H \subseteq \PP^n $ is a hypersurface, then the complement $ \PP^n \setminus H $ is isomorphic to an affine algebraic set.
\end{fact*}

\begin{proof}
Suppose for contradiction that Lemma \ref{lem:hyperplaneintersection} were false, then $ V \cap H = \emptyset $. Then $ V \subseteq \PP^n \setminus H $, which is isomorphic to an affine algebraic set $ \AA^n $ for some $ n $. Hence we get an injective regular map $ \iota : V \to \AA^n $. Pick an infinite irreducible component $ V_1 \subseteq V $. Then $ V_1 $ is a projective algebraic set so, by Corollary \ref{cor:regularpoint}, $ \iota $ is constant on $ V_1 $, and since $ \iota $ is injective, $ V_1 $ maps to a point. But $ V $ has only finitely many irreducible components, so this contradicts the hypothesis that $ V $ is infinite.
\end{proof}

\subsubsection{Completeness of varieties}

To prove Theorem \ref{thm:imageclosed}, we will use the graph $ \Gamma \subseteq V \times W $ of $ \phi $. The image of $ \phi $ is the same as the projection of $ \Gamma $ onto $ W $. Hence Theorem \ref{thm:imageclosed} can be deduced from the following theorem, which will be a more convenient statement to prove.

\begin{theorem}
\label{thm:projectionclosed}
Let $ V $ be a projective variety. For any quasi-projective variety $ W $, the second projection map $ \pi_2 : V \times W \to W $ maps closed sets to closed sets.
\end{theorem}

Again, we can see that Theorem \ref{thm:projectionclosed} does not apply when $ V $ is not projective by taking $ V = W = \AA^1 $ and taking the hyperbola as a closed subset of $ V \times W $. At first sight, Theorem \ref{thm:projectionclosed} looks stronger than Theorem \ref{thm:imageclosed} because it applies to all closed subsets of $ V \times W $, not just the graphs $ \Gamma $ of regular maps $ \phi : V \to W $, using that $ \im \phi = \pi_2\br{\Gamma} $. In fact it is easy to deduce Theorem \ref{thm:projectionclosed} from Theorem \ref{thm:imageclosed}, by applying it to $ \pi_2 \circ \iota : Z \to W $ where $ \iota $ is the inclusion map $ Z \to V \times W $ for any closed subset $ Z \subseteq V \times W $.

\begin{definition*}
A variety $ V $ is \textbf{complete} if it satisfies the conclusion of Theorem \ref{thm:projectionclosed}. In other words, for every quasi-projective variety $ W $, the second projection $ \pi_2 : V \times W \to W $ maps closed sets to closed sets.
\end{definition*}

For quasi-projective varieties, complete is equivalent to projective, but if we go beyond the world of quasi-projective varieties, and we have not defined non-quasi-projective varieties at all in this course, then it is possible to find algebraic varieties which are complete but not projective. Completeness is the natural analogue in algebraic geometry for compactness in topology. This is justified by the following result from topology.

\begin{lemma}
\label{lem:projectionclosed}
Let $ S $ be a topological space. Then $ S $ is compact if and only if, for every topological space $ T $, the second projection map $ S \times T \to T $ maps closed sets to closed sets.
\end{lemma}

\pagebreak

\begin{note*}
In Lemma \ref{lem:projectionclosed}, we use closed sets for the product topology on $ S \times T $, while in Theorem \ref{thm:projectionclosed} we use closed sets for the Zariski topology on $ V \times W $, coming from the Segre embedding. These are not the same thing, since we have seen, in the case $ \AA^1 \times \AA^1 $, that the Zariski topology on a product has more closed sets than the product topology.
\end{note*}

We remark that, over the complex numbers, an algebraic variety is complete if and only if it is compact for the analytic topology. This is hard to prove.

\subsubsection{Images of quasi-projective varieties}

Completeness tells us that images of regular maps of projective algebraic sets are closed. We know that this is false for affine algebraic sets, by considering our favourite example of the hyperbola and its projection to $ \AA^1 $. So what can we say about the images of regular maps of affine, or more generally quasi-projective algebraic sets? We might speculate that they would always be quasi-projective, that is the intersection of an open and a closed set. But this is not true either. Consider the regular map given by
$$ \function[\phi]{\AA^2}{\AA^2}{\br{x, y}}{\br{x, xy}}. $$
The image of $ \phi $ is $ \cbr{\br{x, y} \st x \ne 0} \cup \cbr{\br{0, 0}} $. This is the union of an open set with a closed set, not their intersection. It turns out that this is more or less as bad as things can get.

\begin{definition*}
Let $ S $ be any topological space. A \textbf{locally closed} subset of $ S $ is the intersection between an open and a closed set. A \textbf{constructible} subset of $ S $ is a finite union of locally closed sets.
\end{definition*}

\begin{example*}
Quasi-projective algebraic sets are locally closed subsets of $ \PP^n $.
\end{example*}

Equivalently, a constructible set is any set which can be obtained by starting with a finite list of open and closed sets, and combining them in any way using unions and intersections. The image of the map $ \br{x, y} \mapsto \br{x, xy} $ considered above is the typical example to keep in mind for a constructible set which is not locally closed. Chevalley's theorem tells us that the image of a regular map between quasi-projective varieties is constructible. Indeed it tells us slightly more. The image of a constructible set is constructible.

\begin{theorem}[Chevalley's theorem]
\label{thm:chevalleytheorem}
Let $ \phi : V \to W $ be a regular map of quasi-projective algebraic sets. The image of any constructible set in $ V $ is a constructible set in $ W $.
\end{theorem}

We will prove completeness of projective varieties and Chevalley's theorem in the next lecture. Their proofs are linked but neither theorem is an easy consequence of the other.

\subsubsection{Chevalley's theorem and mathematical logic}

This is not a formal part of the course, so I will not define things carefully. For anyone with an interest in mathematical logic, we remark on a logical interpretation of Chevalley's theorem. In logic, we consider formulas made out of some algebraic operations. In the context of algebraic geometry, these will be polynomial equations over an algebraically closed field. Combine these using logical operations, $ \land, \lor, \lnot, \exists, \forall $.

\begin{example*}
A logical formula might look like $ \br{\lnot\br{xy = z}} \land \exists\br{u, v}\br{\br{x = u^2} \land \br{y = uv} \land \br{z = v^2}} $.
\end{example*}

If we allow just $ \land, \lor, \lnot $ then formulas like this define unions and intersections of Zariski open and closed sets in $ \AA^n $, that is constructible sets. If we also allow quantifiers, then we can also get images of regular maps.

\begin{example*}
The part of the formula above starting with $ \exists\br{u, v} $ defines the image of the regular map $ \br{u, v} \mapsto \br{u^2, uv, v^2} $.
\end{example*}

But Chevalley's theorem tells us that images of regular maps are actually also constructible sets, so we deduce the following.

\begin{fact*}
Every formula, made out of polynomials over an algebraically closed field, is equivalent to a formula without quantifiers.
\end{fact*}

This is called \textbf{elimination of quantifiers for algebraically closed fields}.

\pagebreak

\subsubsection{Affine open covers}

\lecture{21}{Friday}{28/02/20}

By definition, every quasi-projective algebraic set is contained in a projective algebraic set. We can use this to reduce some proofs for quasi-projective algebraic sets to the projective case, proving from the outside in. On the other hand, it is often useful to know that we can find affine varieties as open sets inside each quasi-projective algebraic set. This can be used to reduce some proofs to the affine case, proving from the inside out.

\begin{lemma}
\label{lem:quasiprojectiveaffine}
Let $ V $ be a quasi-projective variety. For every point $ x \in V $, there exists an open set $ U \subseteq V $ which contains $ x $ and is isomorphic to an affine variety.
\end{lemma}

\begin{proof}
Write $ V = V_0 \cap U_0 $ where $ V_0 \subseteq \PP^n $ is closed and $ U_0 \subseteq \PP^n $ is open. Given a point $ x \in V $, we may assume that $ x $ is in $ \AA^n \subseteq \PP^n $, embedded by setting $ X_0 = 1 $. We can achieve this by changing the coordinate system if necessary. Since $ \PP^n \setminus U_0 $ is a projective algebraic set which does not contain $ x $, there is some homogeneous polynomial $ f $ which vanishes on $ \PP^n \setminus U_0 $ but not at $ x $. Then $ x $ is contained in the set $ U = V_0 \cap D\br{f} = V \cap D\br{f} $, where
$$ D\br{f} = \cbr{\br{y_1, \dots, y_n} \in \AA^n \st f\br{1, y_1, \dots, y_n} \ne 0}. $$
We have $ V_0 \cap D\br{f} = V \cap D\br{f} $ because $ D\br{f} \subseteq U_0 $. Then $ U $ is an open subset of $ V $ because $ D\br{f} $ is an open subset of $ \PP^n $, and $ U $ is a closed subset of $ D\br{f} $, so in order to show that $ U $ is an affine variety, it suffices to show that $ D\br{f} $ is an affine variety. We can prove this using the hyperbola trick. Consider the set
$$ E\br{f} = \cbr{\br{y_1, \dots, y_n, z} \in \AA^{n + 1} \st zf\br{1, y_1, \dots, y_n} = 1}. $$
Then $ E\br{f} $ is an affine algebraic set in $ \AA^{n + 1} $, and projection onto the first $ n $ coordinates gives an isomorphism between $ E\br{f} $ and $ D\br{f} $.
\end{proof}

\subsubsection{Proof of completeness}

We will now prove the completeness of projective varieties, in the form of Theorem \ref{thm:projectionclosed}. Let $ Z $ be a closed subset of $ V \times W $. By Lemma \ref{lem:quasiprojectiveaffine}, we may cover $ W $ by open sets $ U_\alpha $ such that each $ U_\alpha $ is an affine variety. According to the topological fact from the proof of Lemma \ref{lem:projectivedense}, in order to show that $ \pi_2\br{Z} $ is closed in $ W $, it suffices to show that $ \pi_2\br{Z} \cap U_\alpha $ is closed in $ U_\alpha $ for every $ \alpha $. In other words, since $ \pi_2\br{Z} \cap U_\alpha = \pi_2\br{Z \cap \br{V \times U_\alpha}} $, replacing $ W $ by $ U_\alpha $, we conclude that it suffices to prove Theorem \ref{thm:projectionclosed} for the case where $ W $ is affine. Then we can replace $ V \subseteq \PP^m $ by $ \PP^m $ and $ W \subseteq \AA^n $ by $ \AA^n $, because $ V $ is closed in $ \PP^m $ and $ W $ is closed in $ \AA^n $, so $ Z \subseteq V \times W $ is closed in $ \PP^m \times \AA^n $. The benefit of doing this is that it simplifies the algebra when we change everything into coordinates. Thus it suffices to prove the following special case of Theorem \ref{thm:projectionclosed}.

\begin{theorem}
\label{thm:projectionclosed2}
The second projection map $ \pi_2 : \PP^m \times \AA^n \to \AA^n $ maps closed sets to closed sets.
\end{theorem}

\begin{proof}
We can concretely describe a Zariski closed subset $ Z \subseteq \PP^m \times \AA^n $ as the zero set of some polynomials $ f_0, \dots, f_r \in k\sbr{X_0, \dots, X_m, Y_1, \dots, Y_n} $ which are homogeneous with respect to $ X_0, \dots, X_m $. The coordinates $ Y_1, \dots, Y_n $ are affine coordinates, so there is no homogeneity condition with respect to them. For each point $ \underline{y} \in \AA^n $, we can substitute the values $ \underline{y} $ into these polynomials and get a projective algebraic set
$$ Z_{\underline{y}} = \cbr{\sbr{x_0 : \dots : x_m} \in \PP^m \st \forall i, \ f_i\br{x_0, \dots, x_m, \underline{y}} = 0}. $$
Observe that $ \underline{y} \in \pi_2\br{Z} $ if and only if $ Z_{\underline{y}} $ is non-empty. Let $ I_{\underline{y}} $ denote the ideal in $ k\sbr{X_0, \dots, X_m} $ generated by the polynomials
$$ f_0\br{X_0, \dots, X_m, \underline{y}}, \qquad \dots, \qquad f_r\br{X_0, \dots, X_m, \underline{y}}. $$
By the projective Nullstellensatz, $ Z_{\underline{y}} $ is non-empty if and only if $ \rad I_{\underline{y}} $ is not equal to either the full ring $ k\sbr{X_0, \dots, X_m} $ or to the ideal $ \abr{X_0, \dots, X_m} $. It is easy to see that this is equivalent to, $ I_{\underline{y}} $ does not contain $ S_d $ for any $ d \in \NN $, where $ S_d $ denotes the set of all homogeneous polynomials of degree $ d $ in $ k\sbr{X_0, \dots, X_m} $. For each $ d \in \NN $, write
$$ W_d = \cbr{\underline{y} \in \AA^n \st I_{\underline{y}} \not\supseteq S_d}. $$

\pagebreak

We have shown that $ \pi_2\br{Z} = \bigcap_{d \in \NN} W_d $. Let the polynomials $ f_0, \dots, f_r $ have degrees $ d_0, \dots, d_r $ with respect to the $ X $ variables. We shall show that $ W_d $ is closed for $ d \ge \max\br{d_0, \dots, d_r} $. Since the $ W_d $ are a descending chain of sets, this is sufficient to show that $ \pi_2\br{Z} $ is closed. Now we just need some linear algebra to finish the proof. If $ g \in S_d $, then $ g \in I_{\underline{y}} $ if and only if we can write
$$ g\br{X_0, \dots, X_m} = \sum_{i = 1}^r f_i\br{X_0, \dots, X_m, \underline{y}}h_i\br{X_0, \dots, X_m}, $$
for some homogeneous polynomials $ h_1, \dots, h_r $, where $ \deg h_i = d - d_i $. Hence $ S_d \cap I_{\underline{y}} $ is the image of the linear map given by
$$ \function[\alpha_{d, \underline{y}}]{\bigoplus_{i = 1}^r S_{d - d_i}}{S_d}{\br{h_1, \dots, h_r}}{\sum_{i = 1}^r f_i\br{X_0, \dots, X_m, \underline{y}}h_i\br{X_0, \dots, X_m}}. $$
Therefore
\begin{align*}
W_d
& = \cbr{\underline{y} \in \AA^n \st \alpha_{d, \underline{y}} \ \text{is not surjective}} \\
& = \cbr{\underline{y} \in \AA^n \st \rk \alpha_{d, \underline{y}} < \dim S_d} \\
& = \cbr{\underline{y} \in \AA^n \st \text{all} \ \br{\dim S_d \times \dim S_d} \ \text{submatrices of} \ \alpha_{d, \underline{y}} \ \text{have determinant zero}},
\end{align*}
where we fix bases for $ S_d $ and $ \bigoplus_i S_{d - d_i} $ and use these to write $ \alpha_{d, \underline{y}} $ as a matrix with respect to these bases. The determinants of these submatrices are polynomials in $ y_1, \dots, y_n $, proving that $ W_d $ is Zariski closed in $ \AA^n $.
\end{proof}

\subsubsection{The resultant}

Theorem \ref{thm:projectionclosed2} has the following application to roots of polynomials. We want to describe the set of pairs of polynomials $ f, g \in k\sbr{S, T} $, homogeneous of degrees $ d $ and $ e $ respectively, for which the set of common zeroes
$$ \cbr{\sbr{s : t} \in \PP^1 \st f\br{s, t} = 0, \ g\br{s, t} = 0} $$
is non-empty. We can identify the space of homogeneous polynomials of degree $ d $ in two variables with $ \AA^{d + 1} $, by associating $ \underline{a} = \br{a_0, \dots, a_d} \in \AA^{d + 1} $ with the polynomial
$$ f_{\underline{a}}\br{S, T} = \sum_{i = 0}^d a_iS^iT^{d - i}. $$
We can define a Zariski closed subset of $ \PP^1 \times \AA^{\br{d + 1} + \br{e + 1}} $ by
$$ Z_{d, e} = \cbr{\br{\sbr{s : t}, \underline{a}, \underline{b}} \in \PP^1 \times \AA^{\br{d + 1} + \br{e + 1}} \st \sum_{i = 0}^d a_is^it^{d - i} = 0, \ \sum_{i = 0}^e b_is^it^{e - i} = 0}. $$
For any point $ \br{\underline{a}, \underline{b}} \in \AA^{\br{d + 1} + \br{e + 1}} $ the fibre $ \pi_2^{-1}\br{\underline{a}, \underline{b}} \cap Z_{d, e} $ is simply the set of common zeroes of $ f_{\underline{a}} $ and $ f_{\underline{b}} $ in $ \PP^1 $. Hence
$$ \pi_2\br{Z_{d, e}} = \cbr{\br{\underline{a}, \underline{b}} \in \AA^{\br{d + 1} + \br{e + 1}} \st f_{\underline{a}} \ \text{and} \ f_{\underline{b}} \ \text{have a common zero in} \ \PP^1}. $$
By Theorem \ref{thm:projectionclosed2}, $ \pi_2\br{Z_{d, e}} $ is a Zariski closed subset of $ \AA^{\br{d + 1} + \br{e + 1}} $. In other words, there is some list of polynomials $ p_1, \dots, p_r $ such that the condition, homogeneous polynomials $ f $ and $ g $ in two variables of given degrees have a common zero in $ \PP^1 $, is equivalent to $ p_1, \dots, p_r $ all vanishing at the coefficients of $ f $ and $ g $. It turns out that this condition is equivalent not just to the vanishing of a list of polynomials in the coefficients, but to a single polynomial called the \textbf{resultant} $ \Res_{d, e} $.

\pagebreak

\begin{theorem}
\label{thm:fieldresultant}
Fix $ d, e \in \ZZ_{> 0} $. There exists a polynomial
$$ \Res_{d, e} \in k\sbr{A_0, \dots, A_d, B_0, \dots, B_e}, $$
such that the polynomials
$$ \sum_{i = 0}^d a_iS^iT^{d - i}, \qquad \sum_{i = 0}^e b_iS^iT^{e - i} $$
have a common root in $ \PP^1 $ if and only if
$$ \Res_{d, e}\br{a_0, \dots, a_d, b_0, \dots, b_e} = 0. $$
\end{theorem}

This can be proved by going through the linear algebra from the end of the proof of Theorem \ref{thm:projectionclosed2}. Indeed it is possible to work out the polynomial $ \Res_{d, e} $ explicitly in this way. We shall just quote this as a result of algebra. The algebra actually gives us something more, since this works not just for polynomials over an algebraically closed field, but for polynomials over any integral domain, provided we replace have a common zero by have a common factor of positive degree.

\begin{theorem}
\label{thm:domainresultant}
Fix $ d, e \in \ZZ_{> 0} $. There exists a universal polynomial
$$ \Res_{d, e} \in \ZZ\sbr{A_0, \dots, A_d, B_0, \dots, B_e}, $$
such that, for any integral domain $ R $ and any values $ a_0, \dots, a_d, b_0, \dots, b_e \in R $, the homogeneous polynomials
$$ f = \sum_{i = 0}^d a_iS^iT^{d - i} \in R\sbr{S, T}, \qquad g = \sum_{i = 0}^e b_iS^iT^{e - i} \in R\sbr{S, T} $$
have a common factor of positive degree in $ R\sbr{S, T} $ if and only if
$$ \Res_{d, e}\br{a_0, \dots, a_d, b_0, \dots, b_e} = 0. $$
\end{theorem}

From the perspective of elementary algebra, when stating Theorem \ref{thm:fieldresultant}, it is simpler to look at inhomogeneous polynomials in one variable and roots in $ \AA^1 $ instead of homogeneous polynomials in two variables and roots in $ \PP^1 $. Of course, we can convert back and forth by homogenising and dehomogenising the polynomials, replacing $ f\br{S, T} $ by $ f\br{1, T} $ and vice versa, but we have to be a little bit careful. We have to worry about the possibility that $ f\br{S, T} $ and $ g\br{S, T} $ might have a common root at $ \infty = \sbr{0 : 1} \in \PP^1 $ but not anywhere in $ \AA^1 = \PP^1 \setminus \cbr{\infty} $. It turns out that $ f\br{S, T} $ has a root at $ \infty $ if and only if the dehomogenised polynomial $ f\br{1, T} $ has degree strictly less than $ \deg f\br{S, T} $. Thus, Theorem \ref{thm:fieldresultant} implies that $ \Res_{d, e} $ vanishes on the coefficients of two single variable polynomials
$$ f\br{T} = \sum_{i = 0}^d a_iT^i, \qquad g\br{T} = \sum_{i = 0}^e b_iT^i $$
if and only if $ f $ and $ g $ have a common root in $ k $, as long as $ f $ and $ g $ have degrees exactly $ d $ and $ e $ respectively. If $ \deg f < d $, but we still write out $ f $ as in the above with $ a_d = 0 $, then looking at $ \Res_{d, e} $ might give the wrong answer for whether $ f $ and $ g $ have a common root, and similarly if $ \deg g < e $.

\subsubsection{Proof of Chevalley's theorem}

\lecture{22}{Monday}{02/03/20}

We shall now prove Chevalley's theorem. We will reduce the proof to projections by using graphs, in a similar way to what we did for completeness. We can also reduce to the case where $ V $ and $ W $ are affine spaces, and perform a few more simplifications. The real work of the proof lies in the first two lemmas. After proving these lemmas, we will show the sequence of simpler steps to get from there to Theorem \ref{thm:chevalleytheorem}.

\pagebreak

\begin{lemma}
\label{lem:projectioneither}
Let $ \pi : \PP^1 \times \AA^m \to \AA^m $ denote the second projection map. Let $ V $ be an irreducible closed subset of $ \PP^1 \times \AA^m $ and let $ T $ be a proper closed subset of $ V $. Then either
\begin{enumerate}
\item $ \pi\br{T} $ is strictly contained in $ \pi\br{V} $, or
\item $ V = \PP^1 \times \pi\br{V} $.
\end{enumerate}
\end{lemma}

\begin{proof}
Let $ W = \pi\br{V} $. By the completeness of $ \PP^1 $, $ W $ is closed in $ \AA^m $, by Theorem \ref{thm:projectionclosed}. Since $ V $ is irreducible, $ W $ is also irreducible. Hence the ring of regular functions $ k\sbr{W} $ is an integral domain. We write $ k\sbr{W}\sbr{X, Y} $ for the ring of polynomials in two variables $ X $ and $ Y $ with coefficients in $ k\sbr{W} $. Let $ I \subseteq k\sbr{W}\sbr{X, Y} $ denote the homogeneous ideal of polynomials which vanish on $ V \subseteq \PP^1 \times W $. Assume that $ V \ne \PP^1 \times W $, otherwise conclusion $ 2 $ holds so we have nothing to prove. Thus $ I \ne \cbr{0} $. Let $ f $ be a homogeneous polynomial in $ I $ which has minimum degree with respect to $ X $ and $ Y $. Since $ V $ is irreducible, $ f $ has no factorisation into factors of positive degree, since if $ f = f_1f_2 $, then $ V \cup \cbr{f_1 = 0} $ and $ V \cup \cbr{f_2 = 0} $ would be two closed subsets which cover $ V $. Since $ T $ is closed and properly contained in $ V $, there exists $ g \in k\sbr{W}\sbr{X, Y} $ which vanishes on $ T $ but not on $ V $. Since $ g $ does not vanish on $ V $, $ f $ does not divide $ g $. Since $ f $ has no factors of positive degree, we conclude that $ f $ and $ g $ have no common factors of positive degree. Hence we can use the resultant over the integral domain $ k\sbr{W} $, by Theorem \ref{thm:domainresultant}, to say that
$$ \Res_{d, e}\br{f, g} \ne 0, \qquad d = \deg f, \qquad e = \deg g $$
in $ k\sbr{W} $. Now $ \Res_{d, e}\br{f, g} $ is an element of $ k\sbr{W} $, that is it is a regular function on $ W $. Since it is not identically zero, we can choose $ w \in W $ such that $ \Res_{d, e}\br{f, g}\br{w} \ne 0 $. This is the same as saying that
$$ \Res_{d, e}\br{f_w, g_w} \ne 0, $$
where $ f_w, g_w \in k\sbr{X, Y} $ are the polynomials obtained from $ f $ and $ g $ by evaluating their coefficients at $ w $. By the defining property of the resultant over the algebraically closed field $ k $, we conclude that $ f_w $ and $ g_w $ have no common root in $ \PP^1 $. But $ \pi^{-1}\br{w} \cap T $ is contained in the set of common roots of $ f_w $ and $ g_w $. Thus $ \pi^{-1}\br{w} \cap T = \emptyset $, that is $ w \notin \pi\br{T} $.
\end{proof}

We embed $ \AA^{1 + m} = \AA^1 \times \AA^m $ into $ \PP^1 \times \AA^m $, in order to be able to use Lemma \ref{lem:projectioneither}. Lemma \ref{lem:projectioneither} needed $ \PP^1 \times \AA^m $ in order to use completeness, here we need $ \AA^{1 + m} \to \AA^m $ so that we can set up an induction
$$ \AA^{2 + m} \to \AA^{1 + m} \to \AA^m, $$
etc.

\begin{lemma}
\label{lem:projectionopen}
Let $ \pi : \AA^{1 + m} \to \AA^m $ denote projection onto the last $ m $ coordinates. Let $ Z \subseteq \AA^{1 + m} $ be an irreducible locally closed subset. Let $ W $ be the Zariski closure of $ \pi\br{Z} $ in $ \AA^m $. Then $ \pi\br{Z} $ contains a non-empty open subset of $ W $.
\end{lemma}

\begin{proof}
Let $ V $ be the closure of $ Z $ in $ \PP^1 \times \AA^m $. By completeness, in Theorem \ref{thm:projectionclosed}, $ \pi\br{V} $ is closed in $ \AA^m $, so $ \pi\br{V} = W $. Let $ T = V \setminus Z $. Since $ Z $ is locally closed, $ T $ is a closed subset of $ \PP^1 \times \AA^m $. We can now apply Lemma \ref{lem:projectioneither}. We get two cases.
\begin{enumerate}[leftmargin=0.5in, label=Case \arabic*.]
\item $ \pi\br{T} $ is strictly contained in $ \pi\br{V} $. Completeness tells us that $ \pi\br{T} $ is closed in $ \AA^m $. Hence $ W \setminus \pi\br{T} $ is an open subset of $ W $. Since $ Z = V \setminus T $, it is clear that $ W \setminus \pi\br{T} $ is contained in $ \pi\br{Z} $. And $ W \setminus \pi\br{T} $ is non-empty because $ \pi\br{T} \ne W $.
\item $ V = \PP^1 \times W $. In this case, an element $ w \in W $ is in the image of $ Z $ if and only if $ \PP^1 \times \cbr{w} $ is not contained in $ T $. That is,
$$ \pi\br{Z} = \cbr{w \in W \st \PP^1 \times \cbr{w} \not\subseteq T}. $$
It is easy to see that the complement
$$ W \setminus \pi\br{Z} = \cbr{w \in W \st \PP^1 \times \cbr{w} \subseteq T} $$
is a closed subset of $ W $, so $ \pi\br{Z} $ is open in $ W $. And $ \pi\br{Z} $ is certainly non-empty.
\end{enumerate}
\end{proof}

\pagebreak

\begin{corollary}
\label{cor:projectionopen}
Let $ \pi : \AA^{n + m} \to \AA^m $ denote projection onto the last $ m $ coordinates. Let $ Z \subseteq \AA^{n + m} $ be a constructible subset. Let $ W $ be the Zariski closure of $ \pi\br{Z} $ in $ \AA^m $. Then $ \pi\br{Z} $ contains a dense open subset of $ W $.
\end{corollary}

\begin{proof}
It suffices to assume that $ Z $ is an irreducible locally closed set. If it was not, we could simply break it up first into finitely many locally closed sets, by the definition of constructible sets, and then break up each of these into finitely many irreducible components. The proof is by induction on $ n $. The base case is Lemma \ref{lem:projectionopen}. We factor $ \pi : \AA^{n + m} \to \AA^m $ as
$$ \AA^{n + m} \xrightarrow{p} \AA^{1 + m} \xrightarrow{q} \AA^m. $$
Let $ W' $ be the Zariski closure of $ p\br{Z} $. By induction, $ p\br{Z} $ contains a dense open subset $ U \subseteq W' $. Since $ U $ is dense in $ W' $, $ q\br{U} $ is dense in $ q\br{W'} = \pi\br{Z} $ which in turn is dense in $ W $. Therefore $ W $ is equal to the closure of $ q\br{U} $ in $ \AA^m $. Then $ U $ is an open subset of the closed subset $ W' $ in $ \AA^{1 + m} $, so $ U $ is locally closed in $ \AA^{1 + m} $. Hence we can apply Lemma \ref{lem:projectionopen} to conclude that $ q\br{U} $ contains a non-empty open subset of $ W $. Because $ Z $, and hence $ W $, is irreducible, this non-empty open subset is dense in $ W $.
\end{proof}

\begin{lemma}
\label{lem:projectionconstructible}
Let $ \pi : \AA^{n + m} \to \AA^m $ denote projection onto the last $ m $ coordinates. If $ Z \subseteq \AA^{n + m} $ is a constructible subset, then $ \pi\br{Z} $ is constructible.
\end{lemma}

\begin{proof}
Let $ W_1 $ be the Zariski closure of $ \pi\br{Z} $. By Corollary \ref{cor:projectionopen}, $ \pi\br{Z} $ contains a dense open subset $ U_1 \subseteq W_1 $. Then $ Z_1 = \pi^{-1}\br{W_1 \setminus U_1} $ is a proper closed subset of $ Z $. In particular $ Z_1 $ is itself constructible. Now repeat this argument. Let $ W_2 $ be the Zariski closure of $ \pi\br{Z_1} $. By Corollary \ref{cor:projectionopen}, $ \pi\br{Z_1} $ contains a dense open subset $ U_2 \subseteq W_2 $. Then $ Z_2 = \pi^{-1}\br{W_2 \setminus U_2} $ is a proper closed subset of $ Z_1 $. We repeat this, getting $ W_3, U_3, Z_3 $, etc. Now $ \pi\br{Z_1} $ is contained in the closed set $ W_1 \setminus U_1 $, so $ W_2 \subseteq W_1 \setminus U_1 $. Since $ U_1 \ne \emptyset $, $ W_2 \ne W_1 $. Similarly, $ W_3 \ne W_2 $ etc. Hence we get a strictly descending chain of closed subsets of $ \AA^m $,
$$ W_1 \supsetneq W_2 \supsetneq \dots. $$
By the noetherian property of the Zariski topology, in Lemma \ref{lem:descendingchain}, this chain must terminate. So we eventually get to $ W_r = \emptyset $. But then $ \pi\br{Z_{r - 1}} \subseteq W_r $, so $ Z_{r - 1} $ is empty. We cannot go back any further than that, since it is entirely possible that $ U_{r - 1} = W_{r - 1} $. Then
$$ \pi\br{Z} = U_1 \cup \pi\br{Z_1} = \dots = U_1 \cup \dots \cup U_{r - 1}. $$
Each $ U_i $ is an open subset of a closed subset of $ \AA^n $, so we conclude that $ \pi\br{Z} $ is constructible. Since $ q\br{U} \subseteq \pi\br{Z} $, this completes the proof.
\end{proof}

This argument, building a descending chain of closed subsets and concluding that it terminates, is called \textbf{noetherian induction}. Now we can finish the proof of Theorem \ref{thm:chevalleytheorem}. By considering the graph of a regular map $ \phi : V \to W $, just as for completeness, we can reduce it to the following.

\begin{theorem}
\label{thm:projectionconstructible}
Let $ V $ and $ W $ be quasi-projective algebraic sets. The second projection $ \pi_2 : V \times W \to W $ maps constructible sets to constructible sets.
\end{theorem}

\begin{proof}
Let $ Z $ be a constructible subset of $ V \times W $. Suppose that $ V \subseteq \PP^n $ and $ W \subseteq \PP^m $. Then $ Z $ is also constructible as a subset of $ \PP^n \times \PP^m $, so we can replace $ V $ and $ W $ by $ \PP^n $ and $ \PP^m $. Let
$$ U_i = \cbr{\sbr{x_0 : \dots : x_m} \in \PP^m \st x_i \ne 0}. $$
The $ U_i $ form an open cover for $ \PP^m $, and each of them is isomorphic to $ \AA^m $. If each set $ Z \cap \br{V \times U_i} $ has a constructible image, then $ \pi\br{Z} $ is a finite union of constructible sets, so is itself constructible. So it suffices to prove Theorem \ref{thm:projectionconstructible} for $ W = \AA^m $. A similar argument allows us to replace $ V = \PP^n $ by $ V = \AA^n $. Thus the proof of Theorem \ref{thm:projectionconstructible} is reduced to Lemma \ref{lem:projectionconstructible}.
\end{proof}

The real hard work in this argument was in the proof of Lemma \ref{lem:projectioneither} and Lemma \ref{lem:projectionopen}, while the rest consisted of a series of relatively simple steps allowing us to gradually simplify the varieties and regular maps which we had to work with. A sequence of reductions like this, before you do the hard work on a simpler case of the original problem, is a very common technique in algebraic geometry, common enough to be given its own name, \textbf{d\'evissage}.

\pagebreak

\section{Dimension}

\subsection{Definitions and examples}

\subsubsection{Dimension and transcendence degree}

\lecture{23}{Thursday}{05/03/20}

We want to define the dimension of algebraic varieties. There are several different definitions, all equivalent but each being useful in different situations. None of these definitions is particularly obvious, so we begin by listing some properties that the dimension of an irreducible quasi-projective variety $ V $ ought to have. We only consider irreducible varieties here, because a reducible variety might have components of different dimensions so it is harder to be confident about what properties it should have.
\begin{enumerate}
\item $ \dim V \in \NN $.
\item $ \dim V = 0 $ if and only if $ V $ is a point. Remember that we are assuming that $ V $ is irreducible.
\item $ \dim \AA^n = \dim \PP^n = n $.
\item A hypersurface in $ \AA^n $ or $ \PP^n $ has dimension $ n - 1 $.
\item If $ U $ is an open subset of $ V $, then $ \dim U = \dim V $. Note that this holds for manifolds in differential geometry.
\item If $ V $ and $ W $ are birational, then $ \dim V = \dim W $. This follows from $ 5 $.
\end{enumerate}
Actually, we can generalise property $ 6 $ to something stronger than this. We do not need a birational map $ V \dashrightarrow W $, just generically finite dominant rational maps, which are defined as follows.

\begin{definition*}
Let $ V $ and $ W $ be irreducible quasi-projective varieties. A dominant rational map $ \phi : V \dashrightarrow W $ is \textbf{generically finite} if there is a non-empty open set $ U \subseteq W $ such that $ \phi^{-1}\br{x} $ is finite for every $ x \in U $.
\end{definition*}

\begin{note*}
There is more than one possible reasonable definition of generically finite for non-dominant rational maps. I shall avoid the issue by only using the words generically finite when the map is dominant.
\end{note*}

Now we expect the following.
\begin{itemize}
\item[$ 7 $.] If there exists a generically finite dominant rational map $ \phi : V \dashrightarrow W $, then $ \dim V = \dim W $.
\end{itemize}
It turns out that these properties are enough to tell us the dimension of every irreducible quasi-projective variety, thanks to the following lemma.

\begin{lemma}
Let $ V $ be an irreducible quasi-projective variety. Then there exists a generically finite dominant rational map $ V \dashrightarrow \PP^d $ for some $ d $.
\end{lemma}

\begin{proof}
By Lemma \ref{lem:quasiprojectiveaffine}, $ V $ has a non-empty affine open subset $ U \subseteq V $. By Corollary \ref{cor:irreduciblehypersurface}, which we used in the proof of the Nullstellensatz, $ U $ is birational to a hypersurface $ H $ in some affine space $ \AA^n $. Taking the projective closure $ \overline{H} $ of $ H $ in $ \PP^n $, we conclude that $ V $ is birational to $ \overline{H} $. Now projection from any point $ p \in \PP^n \setminus \overline{H} $ gives a generically finite dominant rational map $ \overline{H} \dashrightarrow \PP^{n - 1} $.
\end{proof}

Using properties $ 3 $ and $ 7 $, we can calculate $ \dim V $ by finding a generically finite dominant rational map $ V \dashrightarrow \PP^d $ and then saying that $ \dim V = d $. There is one problem with this definition. Maybe we can find generically finite dominant rational maps from $ V $ to two different projective spaces, giving two values for $ \dim V $. How do we know that they will all live in affine space of the same dimension? Fortunately this cannot happen, which is proved using the notion of transcendence degree from algebra.

\begin{theorem}
\label{thm:algebraicallyindependent}
Let $ k $ and $ K $ be fields, with $ k \subseteq K $. All maximal $ k $-algebraically independent sets in $ K $ have the same cardinality.
\end{theorem}

\begin{definition*}
Let $ k $ and $ K $ be fields, with $ k \subseteq K $. The \textbf{transcendence degree} of the extension $ K $ over $ k $ is the cardinality of a maximal $ k $-algebraically independent set in $ K $.
\end{definition*}

\begin{note*}
We already made use of the idea of transcendence degree in the proof of Corollary \ref{cor:irreduciblehypersurface}, even if we did not prove it. In the proof of Corollary \ref{cor:irreduciblehypersurface}, we took a maximal $ k $-algebraically independent set $ z_1, \dots, z_d $ in $ k\br{V} $, then proved that $ V $ is birational to a hypersurface in $ \AA^{d + 1} $. Theorem \ref{thm:algebraicallyindependent} shows that the value of $ d $ here is the same for all maximal $ k $-algebraically independent sets in $ k\br{V} $.
\end{note*}

\pagebreak

\begin{definition*}
The \textbf{dimension} of an irreducible quasi-projective variety $ V $ is the transcendence degree, over $ k $, of the field of rational functions $ k\br{V} $.
\end{definition*}

It is easy to see that this definition satisfies all the above desired properties. This definition satisfies property $ 3 $ above, since $ k\br{\PP^n} = k\br{\AA^n} = k\br{X_1, \dots, X_n} $ has transcendence degree $ n $ because $ \cbr{X_1, \dots, X_n} $ is a maximal algebraically independent set, so $ \dim \AA^n = n $. It clearly also satisfies property $ 6 $. In particular, if $ V $ and $ W $ are birational, then they have the same dimension because $ k\br{V} \cong k\br{W} $. We need to prove that it satisfies property $ 7 $. It will then be easy to deduce the rest of the properties listed above.

\begin{lemma}
Let $ V $ and $ W $ be irreducible quasi-projective varieties. If $ \phi : V \dashrightarrow W $ is a generically finite dominant rational map, then
$$ \trdeg\br{k\br{V} / k} = \trdeg\br{k\br{W} / k}. $$
\end{lemma}

\begin{proof}
We can replace $ V $ by the open subset $ \dom \phi $, so that $ \phi $ becomes a regular map. Using Lemma \ref{lem:quasiprojectiveaffine}, we can replace $ V $ and $ W $ by affine open subsets, and then replace $ V $ by the graph of $ \phi $ in $ V \times W $. Hence it suffices to assume that $ \phi = \eval{\pi_2}_V $, where $ \pi_2 $ is the projection $ \AA^{m + n} \to \AA^n $, $ V $ is a closed subset of $ \AA^{m + n} $, and $ W $ is the Zariski closure of $ \pi_2\br{V} $. By induction, by breaking up $ \phi $ into projections
$$ \AA^{m + n} \to \dots \to \AA^n, $$
we may reduce to the case $ m = 1 $. Since $ \phi $ is a dominant rational map, it induces an injection of fields $ \phi^* : k\br{W} \to k\br{V} $. We have to prove that the resulting field extension $ k\br{V} / \phi^*k\br{W} $ is algebraic, and hence that the transcendence degrees are the same. Look at the coordinate function $ X_1 $ on $ V $. This is the coordinate which is discarded by $ \pi $. Because $ \phi $ is a projection, $ X_2, \dots, X_{1 + n} $ on $ V $ are all in $ \phi^*k\br{W} $ and so the field $ k\br{V} $ is generated by $ \phi^*k\br{W} $ and $ X_1 $. Since $ \phi $ is generically finite, $ V $ is strictly contained in $ W \times \AA^1 $. Hence there is a non-zero polynomial $ f \in k\sbr{W}\sbr{X_{1 + n}} $ which vanishes on $ V $. This gives a $ k\br{W} $-algebraic relation satisfied by $ \eval{X_1}_V $ in $ k\br{V} $. Now $ k\br{V} $ is generated by $ k\br{W} $ and $ \eval{X_1}_V $, so $ k\br{V} $ is algebraic over $ k\br{W} $ as required.
\end{proof}

This allows us to restate the definition by saying, $ \dim V = d $ if and only if there exists a generically finite dominant rational map $ V \dashrightarrow \PP^d $.

\lecture{24}{Friday}{06/03/20}

Lecture 24 is a problems class.

\subsubsection{Facts about dimension}

\lecture{25}{Monday}{09/03/20}

We begin with some simple facts. Let $ V $ and $ W $ be irreducible quasi-projective algebraic varieties.

\begin{fact*}
If $ \phi : V \dashrightarrow W $ is a dominant rational map, then $ \dim W \le \dim V $. This follows from the fact that $ \phi^* $ is an injection $ k\br{W} \to k\br{V} $.
\end{fact*}

\begin{fact*}
$ \dim V \times W = \dim V + \dim W $. This holds because if $ \phi : V \dashrightarrow \AA^d $ and $ \psi : W \dashrightarrow \AA^e $ are generically finite dominant rational maps, then $ \br{\phi, \psi} : V \times W \dashrightarrow \AA^{d + e} $ is a generically finite dominant rational map.
\end{fact*}

\subsubsection{Dimension of closed subsets}

\begin{lemma}
\label{lem:subsetdimension}
Let $ V $ be an irreducible quasi-projective variety and let $ W $ be an irreducible closed subset of $ V $. Then $ \dim W \le \dim V $.
\end{lemma}

\begin{proof}
It suffices to prove Lemma \ref{lem:subsetdimension} for irreducible $ V $ and $ W $. Using Lemma \ref{lem:quasiprojectiveaffine}, we may assume that $ V $ and $ W $ are affine algebraic sets in some affine space $ \AA^n $. Let $ d = \dim V $. Then any $ d + 1 $ of the coordinate functions are algebraically dependent in $ k\br{V} $. In other words, there exists a polynomial $ f \in k\sbr{T_1, \dots, T_{d + 1}} $ such that $ f\br{\eval{X_{i_1}}_V, \dots, \eval{X_{i_{d + 1}}}_V} = 0 $ in $ k\br{V} $. Since $ W \subseteq V $, this relation still holds after restricting to $ W $, so $ f\br{\eval{X_{i_1}}_W, \dots, \eval{X_{i_{d + 1}}}_W} = 0 $ in $ k\br{W} $. But the field of functions $ k\br{W} $ is generated, as a $ k $-field, by $ \eval{X_1}_W, \dots, \eval{X_n}_W $, so this establishes that $ \trdeg\br{k\br{W} / k} \le d $.
\end{proof}

We will later show that equality can only happen in Lemma \ref{lem:subsetdimension} if $ W = V $. We could prove this algebraically now, but instead we will end the algebraic proofs using transcendence degree here and prove everything else geometrically. This means that we will need several steps before improving Lemma \ref{lem:subsetdimension} to a strict inequality.

\pagebreak

\subsubsection{Dimension of a reducible variety}

So far we have defined the dimension of an irreducible quasi-projective variety. The \textbf{dimension} of a reducible variety is defined to be the maximum of the dimensions of the irreducible components. To explain why this is a sensible definition, and why not minimum for example, note that if $ V = V_1 \cup \dots \cup V_r $ are the irreducible components of $ V $, then $ V_i \subseteq V $ so we should have $ \dim V_i \le \dim V $ for each $ i $. Meanwhile, we could find $ W_i $ for each $ i $ such that $ V_i \subseteq W_i $ and $ \dim W_i = \max\br{\dim V_1, \dots, \dim V_r} $. Then every irreducible component of $ W_1 \cup \dots \cup W_r $ has the same dimension, so it makes sense to declare that $ \dim\br{W_1 \cup \dots \cup W_r} $ is equal to $ \dim W_i $ for all $ i $. But then $ V \subseteq W_1 \cup \dots \cup W_r $ so $ \dim V \le \dim W_i = \max\br{\dim V_1, \dots, \dim V_r} $.

\subsubsection{Intersection with a hyperplane}

We begin by studying intersections between a projective algebraic set and hypersurfaces. For today, just hyperplanes. This is much simpler for projective varieties than for quasi-projective varieties, because then we know that there can be no intersections hiding at infinity. The expectation is that, if $ V $ is an algebraic set and $ H $ is a hypersurface, then $ \dim V \cap H $ should usually be $ \dim V - 1 $, because it is just adding one more equation to the equations defining $ V $. Before proving this, we need a couple of lemmas. Firstly, there is no room between a hypersurface and $ \PP^n $ to squeeze in another irreducible algebraic set.

\begin{lemma}
\label{lem:hypersurfaceirreducible}
Let $ H \subseteq \PP^n $ be a hyperplane, or more generally a hypersurface. Let $ V \subseteq \PP^n $ be an irreducible projective algebraic set. If $ V \ne \PP^n $ and $ V \ne H $, then $ H \not\subseteq V $.
\end{lemma}

\begin{proof}
Look at ideals of polynomials which vanish on $ H $ and $ V $.
\end{proof}

Secondly, we need to know how projection interacts with dimension.

\begin{lemma}
\label{lem:projectiondimension}
Let $ V \subseteq \PP^n $ be an irreducible projective algebraic set. Let $ p \in \PP^n $ and let $ Z \subseteq \PP^n $ be a hyperplane such that $ p \notin Z $. Let $ \pi : \PP^n \dashrightarrow Z $ be the projection from $ p $ onto $ Z $. If $ p \notin V $, then $ \pi\br{V} $ is a Zariski closed subset of $ Z $ and $ \eval{\pi}_V : V \to \pi\br{V} $ is generically finite, so $ \dim \pi\br{V} = \dim V $.
\end{lemma}

\begin{proof}
The projection $ \pi $ is regular on $ \PP^n \setminus \cbr{p} $, and in particular it is regular on $ V $. Since $ V $ is complete, $ \pi\br{V} $ is a closed subset of $ Z $. Now $ \eval{\pi}_V : V \to \pi\br{V} $ is certainly dominant. Indeed it is surjective. In order to show that $ \dim \pi\br{V} = \dim V $, it suffices to show that $ \eval{\pi}_V $ is generically finite. Consider a point $ y \in \pi\br{V} $. The preimage of $ y $ under $ \eval{\pi}_V $ is the intersection $ V \cap \L_{py} $, where $ \L_{py} $ is the line through $ p $ and $ y $. Now $ V \cap \L_{py} $ is a closed subset of $ \L_{py} $. Furthermore $ V \cap \L_{py} \ne \L_{py} $ because $ p \notin V $. Because $ \L_{py} \cong \PP^1 $, we conclude that $ V \cap \L_{py} $ must be finite. In other words $ \eval{\pi}_V^{-1}\br{y} $ is finite for all $ y \in \pi\br{V} $, and so $ \eval{\pi}_V $ is generically finite.
\end{proof}

Now we are ready to prove the result on the dimension of intersection with a hyperplane. Note the exceptional cases. If $ H $ contains a component of $ V $ of maximum dimension, then $ \dim V \cap H = \dim V $, while if $ \dim V = 0 $ then $ V \cap H $ might be empty. If $ \dim V > 0 $, then $ V \cap H \ne \emptyset $ by Lemma \ref{lem:hyperplaneintersection}.

\begin{proposition}
\label{prop:hyperplanedimension}
Let $ V \subseteq \PP^n $ be a projective algebraic set. Let $ H \subseteq \PP^n $ be a hyperplane which does not contain any irreducible component of $ V $. If $ \dim V > 0 $, then $ V \cap H $ is non-empty and $ \dim V \cap H = \dim V - 1 $.
\end{proposition}

\begin{proof}
First replace $ V $ by an irreducible component $ V_1 $ such that $ \dim V_1 = \dim V $. Thus we may assume that $ V $ is irreducible. The proof is by induction on $ n $, the dimension of the ambient space. The base case of the induction is when $ V = \PP^n $. Remember we are inducting on $ n $, not $ \dim V $. This is trivial, since $ V \cap H = H \cong \PP^{n - 1} $ certainly has dimension $ n - 1 $. Otherwise, $ V \ne \PP^n $. We will project into $ \PP^{n - 1} $. In order to use Lemma \ref{lem:projectiondimension}, we need to project from a point $ p \notin V $. In order for the projection to interact nicely with $ H $, we need $ p \in H $. Fortunately, we can use Lemma \ref{lem:hypersurfaceirreducible} to show that a suitable $ p $ exists. We are assuming $ V \ne \PP^n $ while the hypothesis of Proposition \ref{prop:hyperplanedimension} tells us that $ V \not\subseteq H $, so $ V \ne H $. Therefore by Lemma \ref{lem:hypersurfaceirreducible}, $ H \not\subseteq V $, the opposite way round to our hypothesis, so we can select a point $ p \in H $ such that $ p \notin V $. Choose a hyperplane $ Z \subseteq \PP^n $ such that $ p \notin Z $. It does not matter which we choose. Let $ \pi : \PP^n \to Z $ be the projection from $ p $ onto $ Z $. Because $ p \in H $, all lines through $ p $ and a point of $ H $ lie entirely in $ H $. Therefore $ x \in H \setminus \cbr{p} $ if and only if $ \pi\br{x} \in H \cap Z $, and consequently $ \pi\br{V \cap H} = \pi\br{V} \cap \br{H \cap Z} $. This implies that $ \pi\br{V} \not\subseteq H \cap Z $, because $ V \not\subseteq H $. By completeness, $ \pi\br{V} $ is a closed subset of $ Z \cong \PP^{n - 1} $, while $ H \cap Z $ is a hyperplane in $ Z $. Furthermore, $ \pi\br{V} $ is irreducible and we have shown that $ \pi\br{V} \not\subseteq H \cap Z $. Therefore, by induction, we have $ \dim \pi\br{V} \cap \br{H \cap Z} = \dim \pi\br{V} - 1 $. We conclude by using Lemma \ref{lem:projectiondimension}, which tells us that $ \dim \pi\br{V} = \dim V $ and $ \dim \pi\br{V \cap H} = \dim \pi\br{V} \cap \br{H \cap Z} $.
\end{proof}

\pagebreak

\subsubsection{The Veronese embedding}

\lecture{26}{Thursday}{12/03/20}

In order to generalise Proposition \ref{prop:hyperplanedimension} from intersections between $ V $ and hyperplanes to intersections with hypersurfaces, we use the Veronese embedding to reduce this to the case of an intersection with a hyperplane. This is defined as follows. Let $ d, n \in \ZZ_{\ge 0} $ and let $ N = \binom{n + d}{d} - 1 $. There are $ N + 1 $ monomials of degree $ d $ in variables $ X_0, \dots, X_n $, expressions of the form
$$ X_0^{a_0} \dots X_n^{a_n}, \qquad a_0, \dots, a_n \in \ZZ_{\ge 0} \qquad a_0 + \dots + a_n = d. $$
We define a regular map $ \nu_{n, d} : \PP^n \to \PP^N $ by writing down all these monomials of degree $ d $, in some order.

\begin{example*}
For $ n = d = 2 $ we get $ N = 5 $ and
$$ \nu_{2, 2}\br{\sbr{X_0 : X_1 : X_2}} = \sbr{X_0^2 : X_1^2 : X_2^2 : X_0X_1 : X_1X_2 : X_0X_2}. $$
\end{example*}

This is called the \textbf{degree $ d $ Veronese embedding} of $ \PP^n $. By completeness, the image of $ \nu_{n, d} $ is a projective algebraic set $ \V_{n, d} \subseteq \PP^N $. One can write down explicit polynomials defining this algebraic set, since they are determinants of $ 2 \times 2 $ matrices. Importantly, $ \nu_{n, d} $ is an isomorphism $ \PP^n \to \V_{n, d} $, and proving this is elementary but the notation gets pretty complicated. The benefit of doing all this is that, if $ H \subseteq \PP^n $ is a hypersurface defined by some homogeneous polynomial $ f = \sum_I a_I\underline{X}^I $ of degree $ d $, then because the monomials of degree $ d $ become individual homogeneous coordinates via the Veronese embedding, the equation for $ \nu_{n, d}\br{H} $ is a linear equation $ \sum_I a_IZ_I = 0 $. Thus $ \nu_{n, d}\br{H} = \V_{n, d} \cap Z $ for some hyperplane $ Z \subseteq \PP^N $. Therefore, instead of studying the intersection between $ V \subseteq \PP^n $ and a hypersurface $ H \subseteq \PP^n $, we can instead study the intersection between $ \nu_{n, d}\br{V} \subseteq \V_{n, d} \subseteq \PP^N $ and a hyperplane $ Z \subseteq \PP^N $. Because $ \nu_{n, d} $ is an isomorphism, we can use Proposition \ref{prop:hyperplanedimension} to deduce the same result for intersections with hypersurfaces.

\begin{theorem}
\label{thm:projectivedimension}
Let $ V \subseteq \PP^n $ be a projective algebraic set. Let $ H \subseteq \PP^n $ be a hypersurface which does not contain any irreducible component of $ V $. If $ \dim V > 0 $, then $ V \cap H $ is non-empty and $ \dim V \cap H = \dim V - 1 $.
\end{theorem}

On the other hand, it is much harder to tell what the dimension will be for the intersection between $ V $ and two or more hyperplanes, since the problem is that $ H_2 $ must satisfy the condition that it does not contain any irreducible component of $ V \cap H_1 $, and it may be hard to tell whether this happens or not.

\subsubsection{Dimension of proper closed subsets}

I mentioned last time that we can strengthen Lemma \ref{lem:subsetdimension} to a strict inequality, as long as $ W \ne V $. In this lemma, it is essential that $ V $ is irreducible, whereas in Lemma \ref{lem:subsetdimension}, that condition is not necessary.

\begin{lemma}
\label{lem:properdimension}
Let $ V $ be an irreducible quasi-projective variety and let $ W $ be a closed subset of $ V $. If $ W \ne V $, then $ \dim V < \dim W $.
\end{lemma}

\begin{proof}
Suppose that $ V $ is a quasi-projective algebraic set in $ \PP^n $. Let $ \overline{V} $ and $ \overline{W} $ denote the closures of $ V $ and $ W $ respectively in $ \PP^n $. Because $ W $ is closed in $ V $ and not equal to $ V $, $ \overline{V} \ne \overline{W} $. So we can pick a homogeneous polynomial $ f \in k\sbr{X_0, \dots, X_n} $ which vanishes on $ \overline{W} $ but not on $ \overline{V} $. Let $ H $ be the hypersurface defined by $ f $. Then $ \overline{W} \subseteq \overline{V} \cap H $ so Theorem \ref{thm:projectivedimension} implies that $ \dim \overline{W} \le \dim \overline{V} \cap H = \dim \overline{V} - 1 $. Since $ V $ is open in $ \overline{V} $, $ \dim V = \dim \overline{V} $ and similarly $ \dim W = \dim \overline{W} $ which completes the proof.
\end{proof}

\subsubsection{Dimension and equations}

What is the dimension of a subset of $ \PP^n $ defined by $ r $ homogeneous polynomial equations? We can try to work this out by applying Theorem \ref{thm:projectivedimension} repeatedly. The zero set of a single homogeneous polynomial $ f_1 $ is a hypersurface $ H_1 $, which we know has dimension $ n - 1 $. The zero set of two homogeneous polynomials $ f_1 $ and $ f_2 $ is an intersection $ H_1 \cap H_2 $ of two hypersurfaces. If $ f_1 $ and $ f_2 $ have no common factor, then $ H_2 $ does not contain any irreducible component of $ H_1 $ and so Theorem \ref{thm:projectivedimension} tells us that $ \dim H_1 \cap H_2 = n - 2 $. But once we look at three homogeneous polynomials $ f_1, f_2, f_3 $, we try to apply Theorem \ref{thm:projectivedimension} to $ V = H_1 \cap H_2 $ so we have to ask whether $ H_3 $ contains any irreducible component of $ H_1 \cap H_2 $. There is no easy condition to tell whether this is true. Consider the examples from problem sheets $ 1 $ and $ 2 $. There were algebraic sets defined by two polynomials with no common factors. Working out the irreducible components of the intersection was hard work. The best we can say is $ \dim H_1 \cap H_2 \cap H_3 = n - 2 $ or $ \dim H_1 \cap H_2 \cap H_3 = n - 3 $. As we repeat the process, controlling the irreducible components only gets harder. All we can say is that for each extra equation, the dimension goes down by either zero or one. By induction, all we get is the following inequality.

\pagebreak

\begin{proposition}
\label{prop:equationsdimension}
Let $ f_1, \dots, f_r \in k\sbr{X_0, \dots, X_n} $ be homogeneous polynomials and let $ V \subseteq \PP^n $ be the zero set of these polynomials. If $ r \le n $, then $ V \ne \emptyset $ and $ \dim V \ge n - r $.
\end{proposition}

\begin{proof}
Let $ H_i $ be the hypersurface defined by the equation $ f_i = 0 $. By Theorem \ref{thm:projectivedimension}, if $ H_i $ does not contain any irreducible component of $ H_1 \cap \dots \cap H_{i - 1} $, then $ \dim H_1 \cap \dots \cap H_i = \dim H_1 \cap \dots \cap H_{i - 1} - 1 $. On the other hand, if $ H_i $ does contain an irreducible component of $ H_1 \cap \dots \cap H_{i - 1} $, then the dimension might not go down at all. In any case, $ \dim H_1 \cap \dots \cap H_i \ge \dim H_1 \cap \dots \cap H_{i - 1} - 1 $. Iterating this proves Proposition \ref{prop:equationsdimension}.
\end{proof}

\subsubsection{Complete intersections}

We saw that if you take $ r $ homogeneous polynomials, their zero set in $ \PP^n $ has dimension at least $ n - r $. We cannot insist that the dimension be equal to $ n - r $, because the zero set of one of the polynomials might contain the zero set of the others. In reverse, we can ask the following. If $ V \subseteq \PP^n $ is a projective algebraic set of dimension $ n - r $, do there exist $ r $ homogeneous polynomials which define $ V $? The answer is not always. There are two relevant definitions. The first one is more in the style of this course, but the second one turns out to be more natural because it gives more algebraic information.

\begin{definition*}
Let $ V \subseteq \PP^n $ be an algebraic set of dimension $ n - r $. Then $ V $ is a \textbf{set-theoretic complete intersection} if there exist $ r $ homogeneous polynomials such that $ V $ is the zero set of these polynomials, and $ V $ is a \textbf{complete intersection} if there exist $ r $ homogeneous polynomials which generate the ideal of $ V $.
\end{definition*}

Being a complete intersection is a stronger property than being a set-theoretic complete intersection.

\begin{example*}
\hfill
\begin{itemize}
\item A set of three non-collinear points in $ \PP^2 $ is a set-theoretic complete intersection but not a complete intersection, since there exist two polynomials defining this set, but you need three polynomials to generate its ideal.
\item An irreducible example is the twisted cubic which we saw earlier. It is the one-dimensional algebraic set $ C \subseteq \PP^3 $ defined by the three equations
$$ WY - X^2 = 0, \qquad WZ - XY = 0, \qquad XZ - Y^2 = 0. $$
Any two of these equations define a one-dimensional algebraic set which has $ C $ as an irreducible component, but also has another irreducible component. It is possible to find two polynomials which define the set $ C $, for example
$$ WY - X^2 = 0, \qquad WZ^2 - 2XYZ + Y^3 = 0. $$
But two polynomials cannot generate the ideal of $ C $. The earlier three polynomials do generate the ideal of $ C $.
\item Take the two planes in $ \PP^4 $,
$$ P_1 = \cbr{x \in \PP^4 \st x_1 = x_2 = 0}, \qquad P_2 = \cbr{x \in \PP^4 \st x_3 = x_4 = 0}. $$
These intersect in only one point, namely $ \sbr{1 : 0 : 0 : 0 : 0} $. The union $ P_1 \cup P_2 $ has dimension two but it needs four equations to define it.
\item One can also find examples of irreducible two-dimensional algebraic sets of $ \PP^4 $ which are not set-theoretic complete intersections, with a singularity which looks like the intersection point of the two planes in $ P_1 \cup P_2 $.
\end{itemize}
\end{example*}

We had to go to $ \PP^4 $ to give explicit examples of non-set-theoretic complete intersections. It is an open question whether every irreducible algebraic set in $ \PP^3 $ is a set-theoretic complete intersection.

\subsubsection{Generalising to quasi-projective varieties}

Theorem \ref{thm:projectivedimension} applies to irreducible quasi-projective algebraic sets $ V \subseteq \PP^n $ as well as projective algebraic sets, except that for a quasi-projective algebraic set it can happen that $ V \cap H = \emptyset $, since Lemma \ref{lem:hyperplaneintersection} applies only to projective algebraic sets. The precise statement is as follows.

\pagebreak

\begin{theorem}
\label{thm:quasiprojectivedimension}
Let $ V \subseteq \PP^n $ be an irreducible quasi-projective algebraic set. Let $ H \subseteq \PP^n $ be a hypersurface which does not contain $ V $. If $ V \cap H \ne \emptyset $, then $ \dim V \cap H = \dim V - 1 $.
\end{theorem}

This is much harder to prove than Theorem \ref{thm:projectivedimension}, so we will omit the proof. One might attempt to prove Theorem \ref{thm:quasiprojectivedimension} by writing $ V $ as $ \overline{V} \cap U $, where $ \overline{V} $ is the closure of $ V $ in $ \PP^n $ and $ U $ is an open set and then applying Theorem \ref{thm:projectivedimension} to $ \overline{V} $. A priori, the problem with this is that the maximum-dimension components of $ \overline{V} \cap H $ might be contained in the closed set which is the complement of $ U $, and then $ V \cap H $ would have dimension less than $ \dim \overline{V} \cap H = \dim V - 1 $. Actually this cannot happen, since with harder work we can show that every irreducible component of $ \overline{V} \cap H $ has dimension equal to $ \dim V - 1 $. You can do this either geometrically or using an algebraic result called Krull's Hauptidealsatz. Of course the non-emptiness part of Proposition \ref{prop:equationsdimension} does not generalise to affine sets, but the dimension inequality does provided we assume that the set is non-empty.

\subsubsection{Topological definition of dimension}

\lecture{27}{Friday}{13/03/20}

Our previous definition of dimension was algebraic. We can also describe the dimension of a projective variety in terms of its topology.

\begin{theorem}
\label{thm:topologicaldimension}
Let $ V $ be a projective variety. The dimension of $ V $ is the maximum $ d \in \ZZ $ such that there exists a chain of irreducible closed subsets
$$ V \supseteq V_d \supsetneq \dots \supsetneq V_0 \supsetneq \emptyset. $$
\end{theorem}

Some care is required in the statement of Theorem \ref{thm:topologicaldimension} to get the numbering right. The point is that $ \dim V_i = i $, so $ V_0 $ is still non-empty.

\begin{note*}
$ V = V_d $ if and only if $ V $ is irreducible. All the other inclusions must be strict.
\end{note*}

In Theorem \ref{thm:topologicaldimension}, it is essential to require all the $ V_i $ to be irreducible. Otherwise we could make the chain arbitrarily long by inserting reducible sets with more and more components, all of dimension $ i $, in between $ V_i $ and $ V_{i + 1} $.

\begin{proof}
First we prove that such a sequence with $ d = \dim V $ exists. Choose $ V_d $ to be an irreducible component of $ V $ whose dimension is equal to $ \dim V $. Choose $ H $ as in Proposition \ref{prop:hyperplanedimension} applied to $ V_d $. Let $ V_{d - 1} $ be an irreducible component in $ V_d \cap H $ such that $ \dim V_{d - 1} = \dim V_d \cap H = \dim V - 1 $. We can repeat this procedure, getting $ V_i \subsetneq V_{i + 1} $ with $ \dim V_i = i $ until we get to $ V_0 $ with $ \dim V_0 = 0 $. In the other direction, to show that there is no such sequence with $ d > \dim V $, this follows immediately from the fact that $ \dim V_i < \dim V_{i + 1} $, by Lemma \ref{lem:properdimension}.
\end{proof}

\subsubsection{Generalising to quasi-projective varieties}

Just like Theorem \ref{thm:projectivedimension}, Theorem \ref{thm:topologicaldimension} generalises to quasi-projective varieties as well as projective varieties. We will omit the proof, but it is not much harder. The idea is to apply the same argument to the projective closure $ \overline{V_d} $. Almost all hyperplanes give $ \dim \overline{V_d} \cap H = \dim V - 1 $, but only a few hyperplanes cause trouble by having a component of $ \overline{V_d} \cap H $ which does not intersect $ V_d $. So it is possible to find some hyperplane which gives $ \dim V_d \cap H = \dim V - 1 $ and then repeat. However, Theorem \ref{thm:topologicaldimension} is not really strong enough to be useful.

\begin{example*}
In $ \PP^n $, we can write down a chain of closed subsets
$$ \PP^n \supsetneq \dots \supsetneq \PP^1 \supsetneq \cbr{\text{point}} \supsetneq \emptyset. $$
This chain is maximal, so we cannot insert another irreducible closed subset anywhere in the middle of it. But just exhibiting this chain, together with Theorem \ref{thm:topologicaldimension}, is not enough to prove that $ \dim \PP^n = n $. Maybe there is a completely different chain which is longer.
\end{example*}

It turns out that that cannot happen. One can prove that every maximal chain of irreducible closed subsets in an irreducible quasi-projective variety $ V $ has length equal to $ \dim V $. This is another hard theorem, requiring the same work as proving Theorem \ref{thm:quasiprojectivedimension}, about the intersection of a quasi-projective algebraic set with a hypersurface.

\pagebreak

\subsection{Counting dimensions of parameter spaces}

\subsubsection{Fibre dimension theorem}

We have now seen several definitions of dimension, via transcendence degree, via rational maps to hypersurfaces or to affine space, and via chains of closed subsets. None of these is easy to compute for specific examples, except in simple cases, since knowing that the chain of closed subsets definition works for any maximal chain means that it is sometimes usable. When we want to calculate the dimension of a particular variety, we often use the following powerful theorem.

\begin{theorem}
\label{thm:fibredimension}
Let $ V $ and $ W $ be irreducible quasi-projective varieties and let $ \phi : V \to W $ be a surjective regular map. Then
\begin{enumerate}
\item for every $ w \in W $, $ \dim \phi^{-1}\br{w} \ge \dim V - \dim W $, and
\item there exists a non-empty open subset $ U \subseteq W $ such that $ \dim \phi^{-1}\br{w} = \dim V - \dim W $ for all $ w \in U $.
\end{enumerate}
\end{theorem}

The sets $ \phi^{-1}\br{w} $ for $ w \in W $ are called the \textbf{fibres} of $ \phi $. Consequently,
$$ \dim V - \dim W = \min_{w \in W} \dim \phi^{-1}\br{w}. $$

\begin{example*}
Consider the projection from $ \AA^{n + m} $ to $ \AA^n $. All the fibres are copies of $ \AA^m $, which has dimension equal to $ \dim \AA^{n + m} - \dim \AA^n $.
\end{example*}

Part $ 2 $ of Theorem \ref{thm:fibredimension} tells us that most fibres have the expected dimension, as in this example, but there might be a proper closed subset of exceptions. Part $ 1 $ of Theorem \ref{thm:fibredimension} tells us that for the exceptional fibres, the dimension is always bigger than expected. It is complicated to write down examples of surjective maps where there is a non-empty exceptional set using equations. So I shall cheat and give an example which is not surjective, only dominant, so Theorem \ref{thm:fibredimension} does not actually apply to this example, but it still illustrates the idea that fibre dimension gets bigger over a closed subset.

\begin{example*}
Consider
$$ \function[\phi]{\AA^2}{\AA^2}{\br{x, y}}{\br{x, xy}}. $$
Consider the vertical line
$$ L_x = \cbr{\br{x, y} \st y \in k}. $$
When $ x \ne 0 $, $ \phi $ restricts to an isomorphism $ L_x \to L_x $. But when $ x = 0 $, $ \phi $ maps all of $ L_0 $ down to $ \br{0, 0} $. Hence the image of $ \phi $ is $ \br{\AA^2 \setminus \cbr{\br{0, y}}} \cup \cbr{\br{0, 0}} $. We see that, above the open set $ \cbr{\br{x, y} \st x \ne 0} $, the fibres of $ \phi $ are single points, that is with dimension $ 2 - 2 = 0 $. On the other hand, above the point $ \br{0, 0} $, the fibre $ \phi^{-1}\br{\br{0, 0}} $ is a line, so has dimension $ 1 \ge 2 - 2 $.
\end{example*}

We will not prove Theorem \ref{thm:fibredimension}. The proof uses similar methods to Theorem \ref{thm:quasiprojectivedimension}, plus an induction. We generally use Theorem \ref{thm:fibredimension} in situations where we know the dimension of either $ V $ or $ W $ and want to work out the other. If we can work out $ \dim \phi^{-1}\br{w} $ for just a single $ w \in W $, then we get an inequality. If we can work out $ \dim \phi^{-1}\br{w} $ for $ w $ in some open set then we can work out the desired dimension exactly. An importantly special case is if there exists $ w $ such that $ \dim \phi^{-1}\br{w} = 0 $, then $ \dim V = \dim W $.

\lecture{28}{Monday}{16/03/20}

Lecture 28 is a class test.

\subsubsection{Universal family of hypersurfaces}

\lecture{29}{Thursday}{19/03/20}

The fibre dimension theorem is particularly useful when applied to families of algebraic varieties and parameter spaces. These are a powerful feature of algebraic geometry, since often we can consider some collection of algebraic varieties, and construct another algebraic variety which has one point for each variety in the collection. We may also be able to fit all the varieties of the collection together into a single big algebraic variety. This is different form other forms of geometry, where a family of objects rarely forms an object of the same type.

\pagebreak

\begin{definition*}
Let $ B $ be a quasi-projective variety. A \textbf{family of projective algebraic sets} over $ B $ is a Zariski closed subset $ \VVV \subseteq B \times \PP^n $. For each $ b \in B $, we write
$$ \VVV_b = \cbr{x \in \PP^n \st \br{b, x} \in \VVV}, $$
and call this a \textbf{fibre} of $ \VVV $. The set $ B $ is called the \textbf{base} or \textbf{parameter space} of the family.
\end{definition*}

This definition might seem rather abstract. To give some idea of what is going on, we will look at a simple example, since we will see some more complex examples later.

\begin{example*}
A hypersurface of degree $ d $ in $ \PP^n $ means the zero set of a non-zero homogeneous polynomial in $ k\sbr{X_0, \dots, X_n} $ of degree $ d $. Let $ \V_{n, d} $ denote the space of homogeneous polynomials in $ k\sbr{X_0, \dots, X_n} $ of degree $ d $, and these polynomials form a vector space of dimension $ \dim \V_{n, d} = \binom{n + d}{d} $. If one homogeneous polynomial is a scalar multiple of another, then they define the same hypersurface. Let $ \P_{n, d} $ denote the projective space associated with $ \V_{n, d} $, that is
$$ \P_{n, d} = \br{\V_{n, d} \setminus \cbr{0}} / \text{scalars} \cong \PP^N, \qquad N = \binom{n + d}{d} - 1. $$
For a polynomial $ f \in \V_{n, d} $, let us write $ \sbr{f} $ for the corresponding point in $ \P_{n, d} $. Using the basis for $ \V_{n, d} $ which consists of the monomials
$$ X_0^{i_0} \dots X_n^{i_n}, \qquad i_0 + \dots + i_n = d, $$
we see that the homogeneous coordinates of $ \sbr{f} \in \P_{n, d} $ are given by the coefficients of $ f $. Each non-zero polynomial $ f \in \V_{n, d} $ defines a hypersurface $ \HHH_f \subseteq \PP^n $. If $ f $ is a scalar multiple of $ g $, then they define the same hypersurface, $ \HHH_f = \HHH_g $. This is not quite an if and only if, because things can go wrong with polynomials that do not generate a radical ideal. Try to come up with an example. Thus, instead of labelling hypersurfaces by polynomials $ f \in \V_{n, d} $ we can label them instead by points in $ \P_{n, d} $. Hence we get a hypersurface $ \HHH_{\sbr{f}} $ associated with each point $ \sbr{f} \in \P_{n, d} $. The homogeneous coordinates of $ f $ form the coefficients of the polynomial defining $ \HHH_{\sbr{f}} $. This has two benefits.
\begin{itemize}
\item The association of hypersurfaces with points in $ \P_{n, d} $ is almost injective. It is injective for polynomials $ f $ which generate radical ideals, and these form a dense open subset of $ \P_{n, d} $.
\item By using the projective base $ \P_{n, d} $ instead of the affine base $ \V_{n, d} $, we can take advantage of properties like completeness.
\end{itemize}
We can fit these hypersurfaces together into a family over the base $ \P_{n, d} $. In other words, there is a single closed set $ \HHH \subseteq \P_{n, d} \times \PP^n $ such that the fibre
$$ \HHH_{\sbr{f}} = \cbr{x \in \PP^n \st \br{\sbr{f}, x} \in \HHH} $$
is the hypersurface defined by the polynomial $ f $. To see that $ \HHH $ is closed, we observe that it is defined by a polynomial equation which is bihomogeneous of degree $ \br{1, d} $,
$$ \HHH = \cbr{\br{\sbr{f}, x} \in \P_{n, d} \times \PP^n \st \sum_{0 \le i_0, \dots, i_n \le d, \ i_0 + \dots + i_n = d} f_{i_0 \dots i_n}X_0^{i_0} \dots X_n^{i_n} = 0}, $$
where $ f_{i_0 \dots i_n} $ denote the coefficients of the polynomial $ f \in \V_{n, d} $. We call $ \HHH $ the \textbf{universal family of hypersurfaces of degree $ d $ in $ \PP^n $}. We think of $ \P_{n, d} \cong \PP^N $ as the \textbf{parameter space for hypersurfaces of degree $ d $ in $ \PP^n $}.
\end{example*}

\begin{remark*}
The word universal here is related to the fact that every hypersurface of degree $ d $ appears as a fibre in this family, and most of them only appear once. If we work with schemes instead of varieties, then each hypersurface will really appear exactly once. However a rigorous definition of what it means for a family to be universal is more subtle than this, and too complicated to define in this course, since it involves the notion of a flat family of schemes.
\end{remark*}

\pagebreak

\subsubsection{Subsets of parameter spaces}

One of the benefits of parameter spaces and families of varieties is that they give us a way of talking about all varieties with some particular property at once. If we take a family $ \VVV \subseteq B \times \PP^n $ and consider the subset of fibres which satisfy an interesting geometric condition, then very often the corresponding set of points in the parameter space
$$ \cbr{b \in B \st \VVV_b \ \text{satisfies a given condition}} $$
is an open or closed subset of $ B $.

\begin{example*}
As a simple example, if we fix a point $ x \in \PP^n $, then the set
$$ \cbr{b \in B \st x \in \VVV_b} $$
is a closed subset. This is the image of the closed set $ \br{B \times \cbr{x}} \cap \VVV \subseteq B \times \PP^n $ under the projection $ \pi_1 : B \times \PP^n \to B $, so it is closed because $ \PP^n $ is complete, by Theorem \ref{thm:projectionclosed}.
\end{example*}

\begin{example*}
The set
$$ \cbr{\sbr{f} \in \P_{n, d} \st f \ \text{is irreducible}} $$
is an open set, and so is the set
$$ \cbr{\sbr{f} \in \P_{n, d} \st f \ \text{generates a radical ideal}}. $$
This will be on problem sheet $ 5 $.
\end{example*}

\subsubsection{Dimension counting}

\lecture{30}{Friday}{20/03/20}

An important use of families of varieties, and the fact that the family is itself a variety, is that we can calculate the dimension of the parameter space, or of interesting subsets of it, using the fibre dimension theorem. By doing this, we can show that certain sets are empty or non-empty or finite or infinite or equal or not equal to the entire parameter space.

\begin{example*}
Consider the intersection of $ n + 1 $ hypersurfaces in $ \PP^n $. From our earlier discussions of dimension, we expect that usually such an intersection should be empty, because $ n + 1 > n $, but of course sometimes it will be non-empty. By counting dimensions of parameter spaces, we can be more specific about how often sometimes non-empty occurs, since we will prove that the subset of the parameter space where this intersection is non-empty is a closed subset, and then we will compare its dimension with the dimension of the entire parameter space. What is the appropriate parameter space? In order to get parameter spaces for hypersurfaces, we have to fix the degree of the defining polynomial, since the dimension of $ \P_{n, d} $ increases as $ d $ grows, so if there was a single parameter space for all hypersurfaces in degree $ d $ it would have to be infinite-dimensional, which does not fit within our notion of varieties. For simplicity, we will assume that all of the $ n + 1 $ hypersurfaces we are intersecting have the same degree $ d $. We are looking at sequences of $ n + 1 $ hypersurfaces, so the parameter space we need is $ \P_{n, d}^{n + 1} $. We could more generally pick a sequence of $ d_0, \dots, d_n \in \ZZ_{> 0} $ and look at intersections of the form $ \HHH_0 \cap \dots \cap \HHH_n $ where $ \HHH_0 $ has degree $ d_0 $, $ \HHH_1 $ has degree $ d_1 $, etc. Because we have fixed the degree of each $ \HHH_i $, we can still form a parameter space for such sequences, since it would be the product $ \P_{n, d_0} \times \dots \times \P_{n, d_n} $. The example below would still work, but would sometimes get a little more complicated. The subset of the parameter space which we want to study is
$$ S = \cbr{\br{a_0, \dots, a_n} \in \P_{n, d}^{n + 1} \st \bigcap_{i = 0}^n \HHH_{a_i} \ne \emptyset}. $$
The algebraic varieties we are interested in, intersections of $ n + 1 $ hypersurfaces, should form a family over $ \P_{n, d}^{n + 1} $. More precisely, we want a family of algebraic varieties over $ \P_{n, d}^{n + 1} $ such that the fibre above $ \br{a_0, \dots, a_n} $ is $ \bigcap_{i = 0}^n \HHH_{a_i} $. We can define this family by
$$ \Sigma = \cbr{\br{a_0, \dots, a_n, x} \in \P_{n, d}^{n + 1} \times \PP^n \st \forall i, \ x \in \HHH_{a_i}}. $$
Then $ \Sigma $ is a closed subset of $ \P_{n, d}^{n + 1} \times \PP^n $ because for each $ i $, the condition $ x \in \HHH_{a_i} $ is given by a polynomial condition in the homogeneous coordinates of $ a_i \in \P_{n, d} $, which is equal to the coefficients of a polynomial $ f_i $ such that $ a_i = \sbr{f_i} $, and of $ x \in \PP^n $. Thus it is a family of algebraic varieties in the sense we defined in the previous lecture.

\pagebreak

Let $ \pi_1 $ denote the projection $ \Sigma \subseteq \P_{n, d}^{n + 1} \times \PP^n \to \P_{n, d}^{n + 1} $. By definition, $ \pi_1^{-1}\br{a_0, \dots, a_n} \cap \Sigma \ne \emptyset $ if and only if $ \br{a_0, \dots, a_n} \in S $. In other words, $ S = \pi_1\br{\Sigma} $. Therefore, because $ \PP^n $ is complete, $ S $ is a closed subset of $ \P_{n, d}^{n + 1} $. Why are we focussing on the set where $ \bigcap_{i = 0}^n \HHH_{a_i} $ is non-empty rather than the set where it is empty? Because closed sets are usually more interesting than open sets, for example it makes sense to ask what is the dimension of a closed subset, while the dimension of an open set is always the same as the dimension of the space it is contained in. What is $ \dim S $? We can work this out by two applications of the fibre dimension theorem. First we apply it to the projection $ \Sigma \to \PP^n $ to find $ \dim \Sigma $, then we apply it to the projection $ \Sigma \to S $ to find $ \dim S $. The reason we can do this is that we know the dimension of $ \PP^n $ and we can work out the dimensions of the fibres of both projections from $ \Sigma $. In order to apply the fibre dimension theorem to $ \Sigma $, we need to know that $ \Sigma $ is irreducible. This is true, and could be proved using tools from this course, but is a little more complicated than we want to do now, so we shall take it for granted. To compute $ \dim \Sigma $, we will apply the fibre dimension theorem to the projection $ p : \Sigma \to \PP^n $. This map is surjective, since for any $ x \in \PP^n $, we can pick $ a \in \P_{n, d} $ such that $ x \in \HHH_a $ and then $ \br{a, \dots, a, x} \in p^{-1}\br{x} \subseteq \Sigma $. The fibres are
$$ p^{-1}\br{x} = \cbr{\br{a_0, \dots, a_n} \in \P_{n, d}^{n + 1} \st \forall i, \ x \in \HHH_{a_i}} = \cbr{a \in \P_{n, d} \st x \in \HHH_a}^{n + 1}. $$
Thus
$$ \dim p^{-1}\br{x} = \br{n + 1}\dim \cbr{a \in \P_{n, d} \st x \in \HHH_a}. $$
In order to calculate $ \dim \cbr{a \in \P_{n, d} \st x \in \HHH_a} $, make a linear change of coordinates so that $ x = \sbr{0 : \dots : 0 : 1} $. This change of coordinates will not change the dimension of $ \cbr{a \in \P_{n, d} \st x \in \HHH_a} $, so it suffices to work out the dimension for the special case of $ \sbr{0 : \dots : 0 : 1} $. Now $ \sbr{0 : \dots : 0 : 1} \in \HHH_a $ if and only if the homogeneous polynomial $ f $ vanishes at $ \sbr{0 : \dots : 0 : 1} $, where $ a = \sbr{f} $. The value of $ f $ at $ \sbr{0 : \dots : 0 : 1} $ is just the $ X_n^d $ coefficient of $ f $. Thus $ \sbr{0 : \dots : 0 : 1} \in \HHH_{\sbr{f}} $ if and only if the $ X_n^d $ coefficient of $ f $ is zero. In other words, $ \cbr{a \in \P_{n, d} \st x \in \HHH_a} $ is a subspace of $ \P_{n, d} $ defined by one linear equation, so
$$ \dim \cbr{a \in \P_{n, d} \st x \in \HHH_a} = \dim \P_{n, d} - 1 = N - 1, \qquad N = \binom{n + d}{d} - 1. $$
Alternatively, we could have seen this without reducing to the case $ x = \sbr{0 : \dots : 0 : 1} $ by observing that the condition $ x \in \HHH_{\sbr{f}} $ is a single linear condition on the coefficients of $ f $, as you see just by expanding out $ f\br{x_0, \dots, x_n} = 0 $. Therefore,
$$ \dim p^{-1}\br{x} = \br{n + 1}\br{N - 1}, \qquad x \in \PP^n. $$
We can apply the fibre dimension theorem, in Theorem \ref{thm:fibredimension}, to get
$$ \dim \Sigma = \dim \PP^n + \dim p^{-1}\br{x} = n + \br{n + 1}\br{N - 1} = N\br{n + 1} - 1. $$
By part $ 2 $ of the fibre dimension theorem, this holds for all $ x $ in some non-empty open subset of $ \PP^n $. It does not matter which $ x $ we choose because we showed that all the fibres have the same dimension. Now to compute $ \dim S $, we will apply the fibre dimension theorem to the projection $ q : \Sigma \to S $. This map is surjective by construction. This time, the fibres do not all have the same dimension, but the minimum dimension of the fibres is zero. To see that there are fibres of dimension zero, observe that for suitable choices of $ n + 1 $ homogeneous polynomials of degree $ d $, the intersection of the corresponding hypersurfaces is finite and non-empty, for example $ f_i = X_i^d $ for $ 0 \le i \le n - 1 $ and $ f_n = X_0^d $, repeating $ f_0 $, have the unique common solution $ \sbr{0 : \dots : 0 : 1} $. Therefore the fibre dimension theorem implies that
$$ \dim S = \dim \Sigma - 0 = N\br{n + 1} - 1. $$
We recall how this follows from the fibre dimension theorem. By part $ 1 $, the fact that there is just a single fibre of dimension zero implies that $ 0 \ge \dim \Sigma - \dim S $. By part $ 2 $ of the fibre dimension theorem, there exists an open subset $ U \subseteq S $ on which $ \dim q^{-1}\br{s} = \dim \Sigma - \dim S $. But since $ q^{-1}\br{s} $ can never be negative, this forces $ 0 \le \dim q^{-1}\br{s} = \dim \Sigma - \dim S $. Combining these gives $ \dim S = \dim \Sigma $ as we claimed. In particular, we have $ \dim S = \dim \P_{n, d}^{n + 1} - 1 $. This means that it is only slightly unusual for $ n + 1 $ hypersurfaces to have non-empty intersection, since this subset of the parameter space has dimension only one less than the entire parameter space. As an application of this calculation, we see that $ S $ is a hypersurface in $ \P_{n, d}^{n + 1} $, and therefore it is defined by a single polynomial $ F \in k\sbr{X_{iJ} \st 0 \le i \le n, \ 0 \le J \le N} $. In other words, there exists some polynomial $ F $ such that, when we evaluate it at the coefficients of $ n + 1 $ homogeneous polynomials $ f_0, \dots, f_n $ of degree $ d $, we get zero if and only if the intersection $ \bigcap_{i = 0}^n \HHH_{\sbr{f_i}} $ is non-empty.
\end{example*}

\end{document}