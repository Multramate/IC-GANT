\def\module{M3P20 Geometry I: Algebraic Curves}
\def\lecturer{Dr Mattia Talpo}
\def\term{Autumn 2018}
\def\cover{
$$
\begin{tikzpicture}[scale=0.5]
\draw (-3, 0) circle (2);
\draw [dotted] (-1, 0) arc (0:180:2 and 0.5);
\draw [dotted, thick] (-1, 0) arc (0:-180:2 and 0.5);
\fill (-4, 1) circle (0.1) node[above]{\tiny $ 0 $};
\fill (-2, 1) circle (0.1) node[above]{\tiny $ 1 $};
\draw [dashed] (-4, 1) to (-2, 1);
\fill (-4, -1) circle (0.1) node[below]{\tiny $ \infty $};
\fill (-2, -1) circle (0.1) node[below]{\tiny $ \lambda $};
\draw [dashed] (-4, -1) to (-2, -1);
\draw (3, 0) circle (2);
\draw [dotted] (1, 0) arc (180:0:2 and 0.5);
\draw [dotted, thick] (1, 0) arc (-180:0:2 and 0.5);
\fill (2, 1) circle (0.1) node[above]{\tiny $ 1 $};
\fill (4, 1) circle (0.1) node[above]{\tiny $ 0 $};
\draw [dashed] (2, 1) to (4, 1);
\fill (2, -1) circle (0.1) node[below]{\tiny $ \lambda $};
\fill (4, -1) circle (0.1) node[below]{\tiny $ \infty $};
\draw [dashed] (2, -1) to (4, -1);
\end{tikzpicture}
$$
$$ \Downarrow $$
$$
\begin{tikzpicture}[scale=0.5]
\draw (-3, 0) circle (2);
\draw [dotted] (-1, 0) arc (0:180:2 and 0.5);
\draw [dotted, thick] (-1, 0) arc (0:-180:2 and 0.5);
\fill (-4, 1) circle (0.1) node[above]{\tiny $ 0 $};
\fill (-2, 1) circle (0.1) node[above]{\tiny $ 1 $};
\draw [fill=lightgray, thick] (-3, 1) ellipse (1 and 0.25);
\fill (-4, -1) circle (0.1) node[below]{\tiny $ \infty $};
\fill (-2, -1) circle (0.1) node[below]{\tiny $ \lambda $};
\draw [fill=lightgray, thick] (-3, -1) ellipse (1 and 0.25);
\draw (3, 0) circle (2);
\draw [dotted] (1, 0) arc (180:0:2 and 0.5);
\draw [dotted, thick] (1, 0) arc (-180:0:2 and 0.5);
\fill (2, 1) circle (0.1) node[above]{\tiny $ 1 $};
\fill (4, 1) circle (0.1) node[above]{\tiny $ 0 $};
\draw [fill=lightgray, thick] (3, 1) ellipse (1 and 0.25);
\fill (2, -1) circle (0.1) node[below]{\tiny $ \lambda $};
\fill (4, -1) circle (0.1) node[below]{\tiny $ \infty $};
\draw [fill=lightgray, thick] (3, -1) ellipse (1 and 0.25);
\end{tikzpicture}
$$
$$ \Downarrow $$
$$
\begin{tikzpicture}[scale=0.5]
\draw [fill=lightgray, thick] (-3, 2) ellipse (1 and 0.25);
\fill (-4, 2) circle (0.1) node[left]{\tiny $ 0 $};
\fill (-2, 2) circle (0.1) node[right]{\tiny $ 1 $};
\draw [dashed] (-2, -2) arc (0:180:1 and 0.25);
\draw [thick] (-2, -2) arc (0:-180:1 and 0.25);
\fill [lightgray, opacity=0.5] (-3, -2) ellipse (1 and 0.25);
\fill (-4, -2) circle (0.1) node[left]{\tiny $ \infty $};
\fill (-2, -2) circle (0.1) node[right]{\tiny $ \lambda $};
\draw (-4, -2) to (-4, 2);
\draw (-2, -2) to (-2, 2);
\draw [dotted] (-2, 0) arc (0:180:1 and 0.25);
\draw [dotted, thick] (-2, 0) arc (0:-180:1 and 0.25);
\draw [fill=lightgray, thick] (3, 2) ellipse (1 and 0.25);
\fill (2, 2) circle (0.1) node[left]{\tiny $ 1 $};
\fill (4, 2) circle (0.1) node[right]{\tiny $ 0 $};
\draw [dashed] (2, -2) arc (180:0:1 and 0.25);
\draw [thick] (2, -2) arc (-180:0:1 and 0.25);
\fill [lightgray, opacity=0.5] (3, -2) ellipse (1 and 0.25);
\fill (2, -2) circle (0.1) node[left]{\tiny $ \lambda $};
\fill (4, -2) circle (0.1) node[right]{\tiny $ \infty $};
\draw (2, -2) to (2, 2);
\draw (4, -2) to (4, 2);
\draw [dotted] (2, 0) arc (180:0:1 and 0.25);
\draw [dotted, thick] (2, 0) arc (-180:0:1 and 0.25);
\end{tikzpicture}
$$
$$ \Downarrow $$
$$
\begin{tikzpicture}[scale=0.5]
\draw [fill=lightgray, thick] (-2, 1.5) ellipse (0.25 and 0.5);
\fill (-2, 2) circle (0.1) node[right]{\tiny $ 0 $};
\fill (-2, 1) circle (0.1) node[right]{\tiny $ 1 $};
\draw [fill=lightgray, thick] (-2, -1.5) ellipse (0.25 and 0.5);
\fill (-2, -1) circle (0.1) node[right]{\tiny $ \lambda $};
\fill (-2, -2) circle (0.1) node[right]{\tiny $ \infty $};
\draw (-2, 2) arc (90:270:2 and 2);
\draw (-2, 1) arc (90:270:1 and 1);
\draw [dotted] (-3, 0) arc (0:180:0.5 and 0.25);
\draw [dotted, thick] (-3, 0) arc (0:-180:0.5 and 0.25);
\draw [dashed] (2, 2) arc (90:-90:0.25 and 0.5);
\draw [thick] (2, 2) arc (90:270:0.25 and 0.5);
\fill [lightgray, opacity=0.5] (2, 1.5) ellipse (0.25 and 0.5);
\fill (2, 2) circle (0.1) node[left]{\tiny $ 0 $};
\fill (2, 1) circle (0.1) node[left]{\tiny $ 1 $};
\draw [dashed] (2, -2) arc (-90:90:0.25 and 0.5);
\draw [thick] (2, -2) arc (270:90:0.25 and 0.5);
\fill [lightgray, opacity=0.5] (2, -1.5) ellipse (0.25 and 0.5);
\fill (2, -1) circle (0.1) node[left]{\tiny $ \lambda $};
\fill (2, -2) circle (0.1) node[left]{\tiny $ \infty $};
\draw (2, 2) arc (90:-90:2 and 2);
\draw (2, 1) arc (90:-90:1 and 1);
\draw [dotted] (3, 0) arc (180:0:0.5 and 0.25);
\draw [dotted, thick] (3, 0) arc (-180:0:0.5 and 0.25);
\end{tikzpicture}
$$
$$ \Downarrow $$
$$
\begin{tikzpicture}[scale=0.5]
\draw (0, 0) circle (2);
\draw (0, 0) circle (1);
\draw [dashed] (0, 2) arc (90:-90:0.25 and 0.5);
\draw [dashed, thick] (0, 2) arc (90:270:0.25 and 0.5);
\fill (0, 2) circle (0.1) node[above]{\tiny $ 0 $};
\fill (0, 1) circle (0.1) node[below]{\tiny $ 1 $};
\draw [dashed] (0, -2) arc (-90:90:0.25 and 0.5);
\draw [dashed, thick] (0, -2) arc (270:90:0.25 and 0.5);
\fill (0, -1) circle (0.1) node[above]{\tiny $ \lambda $};
\fill (0, -2) circle (0.1) node[below]{\tiny $ \infty $};
\draw [dotted] (-1, 0) arc (0:180:0.5 and 0.25);
\draw [dotted, thick] (-1, 0) arc (0:-180:0.5 and 0.25);
\draw [dotted] (1, 0) arc (180:0:0.5 and 0.25);
\draw [dotted, thick] (1, 0) arc (-180:0:0.5 and 0.25);
\end{tikzpicture}
$$
}
\def\syllabus{Affine plane algebraic curves. Projective space. Plane projective curves. Projectivisation. Points at infinity. Singularities. Smoothness. Intersections of plane curves. Resultants. Multiplicities. B\'ezout's theorem. Conics. Cubic curves. Riemann surfaces. Genus. Ramification. The Riemann-Hurwitz formula. The degree-genus formula.}
\def\thm{section}

\input{../style/header}

\begin{document}

\input{../style/cover}

\setcounter{section}{0}

\section{Introduction}

\lecture{1}{Monday}{08/10/18}

This course is intended as a first course in algebraic geometry. It will focus on one-dimensional algebraic varieties. The following are the reference books for the course.
\begin{itemize}
\item F Kirwan, Complex algebraic curves, 1992
\item W Fulton, Algebraic curves, an introduction to algebraic geometry, 1969
\end{itemize}

\begin{note*}
The official notes are integrated in these unofficial notes.
\end{note*}

Geometry is the study of shapes in suitable spaces, such as sets of points on the real line $ \RR $, lines and circles in $ \RR^2 $, spheres in higher dimensional Euclidean spaces $ \RR^n $, etc. One way to think about shapes is to see them as the locus of zeroes defined by
$$ \cbr{\br{x_1, \dots, x_n} \in \RR^n \st f\br{x_1, \dots, x_n} = 0} \subseteq \RR^n, $$
for some suitable function $ f $.

\begin{example}
\label{eg:1.1}
\hfill
\begin{itemize}
\item Circles with centre at $ \br{0, 0} $ in $ \RR^2 $ are
$$ \cbr{f_1\br{x, y} = x^2 + y^2 - R^2 = 0}, \qquad R \in \RR. $$
\item The unit square with vertices at $ \cbr{\br{\pm 1, 0}, \br{0, \pm 1}} $ in $ \RR^2 $ is
$$ \cbr{f_2\br{x, y} = \abs{x} + \abs{y} - 1 = 0}. $$
\item Spheres in $ \RR^n $ are
$$ \cbr{f_3\br{x_1, \dots, x_n} = x_1^2 + \dots + x_n^2 - R^2 = 0}, \qquad R \in \RR. $$
\end{itemize}
\end{example}

\begin{remark}
Note that every subset $ S \subseteq \RR^n $ is the zero set of some function, by just defining
$$ \function[\chi_S]{\RR^n}{\RR}{x}{
\begin{cases}
0 & x \in S \\
1 & x \notin S
\end{cases}
}. $$
\end{remark}

The class of functions used to define our shapes has great consequences on their geometry. In Example \ref{eg:1.1}, $ f_1 $ is a polynomial so that it is differentiable and also $ \C^\infty $, while $ f_2 $ is continuous but not differentiable at $ \cbr{\br{0, \pm 1}, \br{\pm 1, 0}} $, the vertices of the square. The function $ \chi_S $ is not even continuous, unless $ S $ is empty, or the whole $ \RR^n $. As these examples illustrate, an underlying principle is the equivalence between the regularity properties of $ f $ and the regularity properties of $ \cbr{f = 0} $. \textbf{Algebraic geometry} is the area of mathematics that studies the shapes in spaces defined by polynomial equations using algebra. Such shapes are called \textbf{algebraic varieties}. Their geometric properties are intimately related to the algebraic properties of the defining polynomial equations.

\begin{example}
\hfill
\begin{itemize}
\item Let $ f\br{x} $ be a polynomial. Then the zero set $ \cbr{f\br{x} = 0} \subseteq \RR $ is a finite set of points in $ \RR $, and every finite set of points arises in this manner.
\item The circle $ \cbr{x^2 + y^2 - 1 = 0} \subseteq \RR^2 $ is an algebraic variety.
\item Spheres in higher dimensions are algebraic varieties, defined by the equation $ \cbr{x_1^2 + \dots + x_n^2 = r^2} \subseteq \RR^n $, where $ r \in \RR_{\ge 0} $ is the radius.
\end{itemize}
\end{example}

\begin{exercise**}
\hfill
\begin{itemize}
\item Is $ \ZZ \subseteq \RR $ an algebraic variety?
\item Is the unit square an algebraic variety?
\end{itemize}
\end{exercise**}

\pagebreak

\begin{definition}
Let $ K $ be a field, such as $ K = \QQ, \RR, \CC $. For $ \alpha = \br{\alpha_1, \dots, \alpha_n} \in \NN^n $ a multi-index, denote a \textbf{monomial} by
$$ x^\alpha = x_1^{\alpha_1} \dots x_n^{\alpha_n}, \qquad \abs{\alpha} = \sum_{i = 1}^n \alpha_i. $$
A \textbf{polynomial} of degree $ d $ in $ n $ variables with coefficients in $ K $ is a finite sum
$$ P\br{x_1, \dots, x_n} = \sum_{\alpha \in \NN^n} a_\alpha x^\alpha, \qquad a_\alpha \in K, $$
where $ a_\alpha = 0 $ for all $ \abs{\alpha} > d $ and $ a_\alpha \ne 0 $ for some $ \alpha $ with $ \abs{\alpha} = d $. The set of polynomials of arbitrary degree in $ n $ variables with coefficients in $ K $ is denoted $ K\sbr{x_1, \dots, x_n} $.
\end{definition}

\begin{example*}
Let $ n = 3 $. Then
$$ P\br{x_1, x_2, x_3} = 3 + x_1^2x_2 + x_3^{10}, \qquad \alpha = \br{0, 0, 0}, \br{2, 1, 0}, \br{0, 0, 10} $$
has degree ten.
\end{example*}

\begin{exercise**}
\hfill
\begin{itemize}
\item Show that $ K\sbr{x_1, \dots, x_n} $ is a ring, and that if $ P $ and $ Q $ are polynomials of degrees $ p $ and $ q $ respectively, then the degree of $ \lambda P + \mu Q $ for $ \lambda, \mu \in K $ is at most $ \max\cbr{p, q} $. Give an example of polynomials $ P, Q \in K\sbr{x} $ such that
$$ \deg \br{P + Q} < \max\cbr{\deg P, \deg Q}. $$
\item Show that $ \br{P \cdot Q}\br{x_1, \dots, x_n} = P\br{x_1, \dots, x_n}Q\br{x_1, \dots, x_n} $ is a polynomial $ P \cdot Q \in K\sbr{x_1, \dots, x_n} $ with $ \deg PQ = \deg P + \deg Q $. What if $ P = 0 $? What is $ \deg 0 $?
\end{itemize}
\end{exercise**}

\begin{definition}
An \textbf{affine plane curve} defined over $ K $ is
$$ C = \cbr{\br{x, y} \in K^2 \st P\br{x, y} = 0} \subseteq K^2, $$
where $ P \in K\sbr{x, y} $ is non-constant. More generally, an \textbf{algebraic variety} $ V \subseteq K^n $ is a subset of $ K^n $ defined as the locus
$$ \cbr{f_1 = \dots = f_k = 0} \subseteq K^n, $$
where $ f_1, \dots, f_k \in K\sbr{x_1, \dots, x_n} $ are polynomials in $ n $ variables with coefficients in $ K $.
\end{definition}

\begin{example}
\hfill
\begin{itemize}
\item If we allow constant polynomials, then for $ P = 0 $ we get $ C = K^2 $, and if $ P $ is a non-zero constant, then $ C $ is the empty set. Neither of those really look like curves.
\item Let $ a, b, c \in \RR $ with $ \br{a, b} \ne \br{0, 0} $. The curve
$$ \cbr{\br{x, y} \in \RR^2 \st ax + by + c = 0} $$
is a line.
\item Let $ a, b \in \RR^* = \RR \setminus \cbr{0} $. The curve
$$ \cbr{\br{x, y} \in \RR^2 \st \dfrac{x^2}{a^2} + \dfrac{y^2}{b^2} - 1 = 0} $$
is an ellipse.
\item Let $ a, b \in \RR^* = \RR \setminus \cbr{0} $. The curve
$$ \cbr{\br{x, y} \in \RR^2 \st \dfrac{x^2}{a^2} - \dfrac{y^2}{b^2} - 1 = 0} $$
is a hyperbola.
\item Spheres, and quadrics such as ellipsoids, paraboloids, and hyperboloids in $ \RR^3 $ are all defined via a single polynomial equation of degree two. A line in $ \RR^3 $ can be defined by two equations in degree one.
\end{itemize}
\end{example}

\pagebreak

The following is the first property of algebraic curves.

\begin{lemma}
\label{lem:1.7}
The union of two affine plane curves is again an affine plane curve.
\end{lemma}

\begin{proof}
Let $ f_1, f_2 \in K\sbr{x, y} $ and let
$$ C_1 = \cbr{\br{x, y} \in K^2 \st f_1\br{x, y} = 0}, \qquad C_2 = \cbr{\br{x, y} \in K^2 \st f_2\br{x, y} = 0}. $$
Then $ f_1 \cdot f_2 \in K\sbr{x, y} $ is a polynomial and
$$ C_1 \cup C_2 = \cbr{\br{x, y} \in K^2 \st \br{f_1 \cdot f_2}\br{x, y} = 0}, $$
so that $ C_1 \cup C_2 $ is an affine plane curve.
\end{proof}

\begin{exercise**}
Write down an equation for the plane curve that is the union of the lines through any two vertices of the unit square.
\end{exercise**}

Recall the following.

\begin{definition}
A polynomial $ P \in K\sbr{x_1, \dots, x_n} $ is \textbf{reducible} over $ K $ if there are non-constant polynomials $ Q, R \in K\sbr{x_1, \dots, x_n} $ such that $ P = Q \cdot R $. A polynomial $ P $ is \textbf{irreducible} if it is not reducible. Recall that a polynomial $ P $ is called non-constant if $ \deg P > 0 $.
\end{definition}

\begin{example*}
$ x_1x_2 $ is reducible, and $ x_1 + x_2 $ is irreducible.
\end{example*}

\begin{remark}
Recall also that every polynomial $ P \in K\sbr{x_1, \dots, x_n} $ can be written as a product of irreducible factors
$$ P = f_1 \dots f_k, $$
in an essentially unique way up to multiplication by constants. We have
$$ \cbr{P = 0} = \cbr{f_1 = 0} \cup \dots \cup \cbr{f_k = 0} \subseteq K^n, $$
so in particular, for $ n = 2 $, every algebraic curve is a union of algebraic curves defined by irreducible polynomials.
\end{remark}

In the course, we will consider questions such as the following.
\begin{itemize}
\item When do polynomials $ f, g \in K\sbr{x, y} $ define the same affine plane curve?
\item What can be said about the intersection $ \cbr{f = 0} \cap \cbr{g = 0} \subseteq K^2 $?
\end{itemize}
Very different questions can be approached through algebraic curves. For example, we can study integer solutions to some Diophantine equations.

\begin{example}
The unit circle is the curve
$$ C = \cbr{x^2 + y^2 = 1} \subseteq \RR^2. $$
Several parametrisations are known, such as
$$ \function{\intco{0, 2\pi}}{\RR^2}{t}{\br{\cos t, \sin t}}. $$
We can write down another parametrisation of $ C $ by considering lines through the point $ P = \br{-1, 0} $, using a stereographic projection. A line through $ P $ with slope $ t \in \RR $ has equation
$$ L_t = \cbr{y = t\br{x + 1}} \subseteq \RR^2 $$
and meets $ C $ in two points, $ P $ and $ P_t = \br{x\br{t}, y\br{t}} $. We can determine the coordinate of $ P_t $ by solving the system
$$ L_t \cap C =
\begin{cases}
y = t\br{x + 1} \\
x^2 + y^2 = 1
\end{cases}.
$$

\pagebreak

Replacing the value of $ y $ given by the first equation into the second yields two solutions for $ x\br{t} $. The first one is $ x = -1 $ and corresponds to the point $ P = \br{-1, 0} $. The second is $ \br{x\br{t}, y\br{t}} $, where
\begin{equation}
\label{eq:1}
x\br{t} = \dfrac{1 - t^2}{1 + t^2}, \qquad y\br{t} = \dfrac{2t}{1 + t^2}.
\end{equation}
Note that when $ t \to \infty $, $ \br{x\br{t}, y\br{t}} \to \br{-1, 0} $, so that $ t \mapsto \br{x\br{t}, y\br{t}} $ is a parametrisation of $ C $ that identifies it with $ \RR \cup \cbr{\infty} $. The advantage of this parametrisation is that it is given by rational functions, that is $ x\br{t} $ and $ y\br{t} $ are of the form $ t \mapsto p\br{t} / q\br{t} $, where $ p $ and $ q $ are polynomials. One can use this parametrisation to get the general solution of the equation
\begin{equation}
\label{eq:2}
x^2 + y^2 = z^2
\end{equation}
for $ x, y, z \in \ZZ $ coprime. If $ t = p / q \in \QQ $, where $ p, q \in \ZZ $ are coprime, then $ x\br{t}, y\br{t} \in \QQ $ in $ \br{\ref{eq:1}} $ becomes
$$ x\br{t} = \dfrac{p^2 - q^2}{p^2 + q^2}, \qquad y\br{t} = \dfrac{2pq}{p + q^2}. $$
If
$$ x = p^2 - q^2, \qquad y = 2pq, \qquad z = p^2 + q^2, $$
$ x, y, z \in \ZZ $ satisfy $ \br{\ref{eq:2}} $. They are coprime precisely when $ p $ and $ q $ are coprime and not both odd. When $ p $ and $ q $ are coprime and both odd, then
$$ x = \dfrac{p^2 - q^2}{2}, \qquad y = pq, \qquad \dfrac{p^2 + q^2}{2} $$
satisfy $ \br{\ref{eq:2}} $. Conversely, this is the general form of solutions in $ \br{\ref{eq:2}} $. Indeed, given $ x, y, z \in \ZZ $ coprime that satisfy $ \br{\ref{eq:2}} $, $ z \ne 0 $ and
$$ \dfrac{x^2}{z^2} + \dfrac{y^2}{z^2} = 1, $$
so that $ \br{x / z, y / z} \in \CC $ and if $ \br{x, y, z} \ne \br{-1, 0, 1} $, there is $ t \in \RR $ such that
$$ \br{\dfrac{x}{z}, \dfrac{y}{z}} = \br{x\br{t}, y\br{t}}. $$
But then since $ x / z, y / z \in \QQ $, we can take $ t \in \QQ $ and $ x, y, z $ have the form above.
\end{example}

\lecture{2}{Thursday}{11/10/18}

\begin{definition}
Let $ f \in \RR\sbr{x, y} $ and let $ C = \cbr{f = 0} $. A \textbf{rational point} of $ C $ is a point $ \br{x, y} \in C $, that is $ f\br{x, y} = 0 $, such that $ x, y \in \QQ $.
\end{definition}

\begin{example}
There are infinitely many rational points on the circle
$$ \cbr{x^2 + y^2 = 1} \subseteq \RR^2, $$
which can be described explicitly, and can be used to solve
$$ a^2 + b^2 = c^2, \qquad a, b, c \in \ZZ, $$
a problem in number theory. Take $ n \ge 3 $ and consider
$$ C = \cbr{x^n + y^n - 1 = 0}. $$
What are the rational points of $ C $? Write
$$ x = \dfrac{a}{c}, \qquad y = \dfrac{b}{c}, \qquad a, b, c \in \ZZ, \qquad c \ne 0. $$
Then
$$ \br{x, y} \in C \qquad \iff \qquad a^n + b^n = c^n. $$
Fermat's last theorem by Wiles then states that there exists no solution with $ a, b \ne 0 $.
\end{example}

\pagebreak

\section{Complex plane curves}

Let $ P \in \RR\sbr{x, y} $ be a polynomial with coefficients in $ \RR $. A priori, it is natural to study the real plane curve
$$ C_\RR = \cbr{\br{x, y} \in \RR^2 \st P\br{x, y} = 0}. $$
However, $ P $ can also been seen as a polynomial with coefficients in $ \CC $, and it will often be simpler to study the complex plane curve
$$ C_\CC = \cbr{\br{x, y} \in \CC^2 \st P\br{x, y} = 0}. $$
We first explain some of the properties of algebraic curves that we would like to hold and explain why these properties do not necessarily hold for real plane curves, and some unpleasant things happen.

\begin{fact**}
Many real curves are so degenerate that they do not even have points, that is $ C_\RR = \emptyset $. If $ C_\RR \ne \emptyset $, the dimension of $ C_\RR $, that is whether it is a union of points or a genuine curve, is difficult to determine.
\end{fact**}

\begin{example}
\label{eg:2.1}
Let $ t \in \RR $ and consider
$$ f_t\br{x, y} = x^2 + y^2 - t, $$
and the real plane curve
$$ C_t = \cbr{f_t\br{x, y} = 0} \subseteq \RR^2. $$
\begin{itemize}
\item If $ t > 0 $, $ C_t $ is a circle with radius $ \sqrt{t} $.
\item If $ t = 0 $, $ C_0 = \cbr{\br{0, 0}} $.
\item If $ t < 0 $, $ C_t = \emptyset $.
\end{itemize}

\end{example}

\begin{fact**}
In general, it is not clear when two polynomials $ f, g \in \RR\sbr{x, y} $ define the same real plane curve, that is when
$$ \cbr{\br{x, y} \in \RR^2 \st f\br{x, y} = 0} = \cbr{\br{x, y} \in \RR^2 \st g\br{x, y} = 0}. $$
\end{fact**}

\begin{example}
\label{eg:2.2}
Let $ f $ and $ g $ denote the polynomials
$$ f\br{x, y} = x^2y + y^2 + x^3 + x, \qquad g\br{x, y} = x^2 + 2xy + y^2. $$
Then, since $ f\br{x, y} = \br{x + y} \cdot \br{x^2 + 1} $ and $ g\br{x, y} = \br{x + y}^2 $,
$$ \cbr{\br{x, y} \in \RR^2 \st f\br{x, y} = 0} = \cbr{\br{x, y} \in \RR^2 \st g\br{x, y} = 0}. $$
\end{example}

\begin{fact**}
In general, it is hard to predict when a curve intersects a fixed line, or more generally when two real curves intersect.
\end{fact**}

\begin{example}
In the notation of Example \ref{eg:2.1}, let
$$ C = C_1 = \cbr{\br{x, y} \in \RR^2 \st x^2 + y^2 - 1} \subseteq \RR^2 $$
be the unit circle. Consider the line
$$ L = \cbr{ax + by + c = 0}, \qquad \br{a, b} \ne \br{0, 0}. $$
Then, depending on $ \br{a, b, c} \in \RR^3 $, $ L \cap C $ consists of two points, one point, or is empty.
\end{example}

Most of these difficulties disappear when working with curves $ C_\CC \subseteq \CC^2 $, essentially because $ \CC $ is algebraically closed, in other words the following theorem holds.

\begin{theorem}[Fundamental theorem of algebra]
\label{thm:2.4}
Let $ P \in \CC\sbr{x} $ be a non-constant polynomial. Then $ P $ has at least one complex root, that is there exists $ \alpha \in \CC $ such that $ P\br{\alpha} = 0 $.
\end{theorem}

\pagebreak

This, first of all, has the following consequence.

\begin{proposition}
Let $ P \in \CC\sbr{x, y} $ be a non-constant polynomial. Then the algebraic curve
$$ C = \cbr{\br{x, y} \in \CC^2 \st P\br{x, y} = 0} $$
contains infinitely many points.
\end{proposition}

\begin{proof}
Because $ P $ is not constant, one of $ x $ and $ y $ will show up in a monomial of $ P $. Assume that it is $ x $. Otherwise, the same argument swapping $ x $ and $ y $. By grouping together monomials with the same degree in $ x $, we can write $ P\br{x, y} $ as
$$ P\br{x, y} = f_0\br{y} + \dots + x^d \cdot f_d\br{y}, \qquad d \ge 1, $$
thanks to the assumption above, and $ f_0\br{y}, \dots, f_d\br{y} $ are polynomials in $ y $ alone, with $ f_d\br{y} \ne 0 $. Now note that since $ P\br{x, y} \ne 0 $, there will be infinitely many values $ y_0 \in \CC $ of $ y $ for which $ P\br{x, y_0} \ne 0 $. Indeed, the equation $ P\br{x, y} = 0 $ has finitely many solutions, and $ \CC $ has infinitely many elements. For any one of those values $ y_0 \in C $, the polynomial of $ x $ alone given by $ P\br{x, y_0} \in \CC\sbr{x} $ is non-constant and has at least a root, by the fundamental theorem of algebra. Call this root $ x_0 = \alpha\br{y_0} \in \CC $. Then the points $ \br{x_0, y_0} $ are infinitely many points, all belonging to the curve $ C = \cbr{P = 0} $. They are all distinct, because the second coordinate is always different.
\end{proof}

\begin{example}
Let $ a, b, c \in \CC $ with $ \br{a, b} \ne \br{0, 0} $, and let
$$ f\br{x, y} = ax + by + c. $$
If $ a \ne 0 $, for each $ y \in \CC $, there is precisely one solution of $ f\br{x, y} = 0 $, namely
$$ x = -\dfrac{b}{a}y - \dfrac{c}{a}. $$
Thus there is a one-to-one correspondence
$$ C = \cbr{f = 0} \subseteq \CC^2 \qquad \leftrightsquigarrow \qquad \CC, $$
that is a plane when seen as an $ \RR $-vector space $ \CC \cong \RR^2 $. We will call $ C $ a \textbf{complex line}.
\end{example}

\begin{remark}
It is difficult to draw complex curves. Our intuition is for real vector spaces, and this makes complex curves hard to visualise. They are objects of real dimension two in $ \CC^2 \cong \RR^4 $, a four-dimensional real vector space.
\end{remark}

\begin{example}
Let
$$ f\br{x, y} = x^2 + y^2 = \br{x + iy} \cdot \br{x - iy}. $$
Then, as in Lemma \ref{lem:1.7}, $ C = \cbr{f = 0} \subseteq \CC^2 $ is the union of the two complex lines
$$ \cbr{x + iy = 0}, \qquad \cbr{x - iy = 0}. $$
When seen as $ \RR $-vector spaces, these two planes meet at exactly one point corresponding to $ \br{0, 0} \in \RR^2 \subseteq \CC^2 $, the only real point of $ C $. It is difficult to imagine two planes meeting in one point, because our intuition relies on the three-dimensional space $ \RR^3 $, while $ \CC^2 \cong \RR^4 $.
\end{example}

Describing intersections is also easier.

\begin{example}
Consider
$$ C = \cbr{x^2 + y^2 - 1 = 0} \subseteq \CC^2, \qquad L = \cbr{ax + by + c = 0} \subseteq \CC^2. $$
If $ b \ne 0 $, we determine the intersection $ C \cap L $ by solving the linear system
$$
\begin{cases}
x^2 + y^2 = 1, \\
y = -\dfrac{a}{b}x - \dfrac{c}{b}
\end{cases}.
$$
Unless $ a^2 = -b^2 $ and $ c = 0 $, there are one or two solutions. Again, it is hard to imagine a two-dimensional real surface which meets a real plane in two points.
\end{example}

\pagebreak

We now turn to the question of recognising when two polynomials define the same plane curve. Here again, working in $ \CC $ is a simplification.

\begin{theorem}[Consequence of Hilbert's Nullstellensatz]
\label{thm:2.10}
Let $ f, g \in \CC\sbr{x, y} $ be two polynomials. Then
$$ \cbr{\br{x, y} \in \CC^2 \st f\br{x, y} = 0} = \cbr{\br{x, y} \in \CC^2 \st g\br{x, y} = 0} $$
if and only if there exist
$$ P_1, \dots, P_k \in \CC\sbr{x, y}, \qquad a_1, \dots, a_k, b_1, \dots, b_k \in \ZZ_{> 0}, \qquad \lambda_1, \lambda_2 \in \CC^*, $$
such that
\begin{equation}
\label{eq:3}
\begin{cases}
f\br{x, y} = \lambda_1 P_1^{a_1} \dots P_k^{a_k} \\
g\br{x, y} = \lambda_2 P_1^{b_1} \dots P_k^{b_k}
\end{cases}.
\end{equation}
\end{theorem}

\lecture{3}{Friday}{12/10/18}

\begin{proof}
Assume that $ \br{\ref{eq:3}} $ holds. Then by the proof of Lemma \ref{lem:1.7},
$$ \cbr{f = 0} = \cbr{P_1^{a_1} = 0} \cup \dots \cup \cbr{P_k^{a_k} = 0} = \cbr{P_1 = 0} \cup \dots \cup \cbr{P_k = 0}, $$
because if $ \alpha \in \CC $ is such that $ \alpha^n = 0 $, then $ \alpha = 0 $. The same holds for $ \cbr{g = 0} $. Therefore $ \cbr{f = 0} = \cbr{g = 0} $. The second half of the proof needs tools of commutative algebra, and is omitted.
\end{proof}

Thus, the relation between the geometric shape $ C = \cbr{f = 0} $ in $ \CC^2 $ and the polynomial $ f \in \CC\sbr{x, y} $ is more transparent than in $ \RR^2 $.

\begin{remark}
In fact, the statement of Theorem \ref{thm:2.10} is not true over $ \RR $, as Example \ref{eg:2.2} shows. Even better, we can just take
$$ f\br{x, y} = x^2 + 1, \qquad g\br{x, y} = 1 $$
as polynomials in $ \RR\sbr{x, y} $. Their zero locus is
$$ \cbr{f = 0} = \cbr{g = 0} = \emptyset $$
in both cases, but $ f $ and $ g $ cannot be written in the form guaranteed by $ \br{\ref{eq:3}} $.
\end{remark}

We will always work in $ \CC $. Let us introduce some important notions for the study of polynomials.

\begin{definition}
A polynomial $ f \in K\sbr{x, y} $ has \textbf{no repeated factors} over $ K $ if it cannot be written as a product of the form
$$ f\br{x, y} = g\br{x, y}^2 \cdot h\br{x, y}, \qquad g, h \in K\sbr{x, y} $$
where $ g $ is non-constant. Equivalently,
$$ f = P_1 \cdot \dots \cdot P_k, $$
where $ P_1, \dots, P_k $ are distinct irreducible polynomials.
\end{definition}

\begin{exercise**}
Prove the equivalence of the two different definitions.
\end{exercise**}

\begin{corollary}
Let $ f, g \in \CC\sbr{x, y} $ be polynomials with non-repeated factors. Then $ f $ and $ g $ define the same complex plane curve $ \cbr{f = 0} = \cbr{g = 0} $ if and only if there is a non-zero constant $ \lambda \in \CC^* $ such that $ f = \lambda g $.
\end{corollary}

\begin{proof}
Easy consequence of Theorem \ref{thm:2.10}.
\end{proof}

\begin{remark}
Note that we do not lose anything by only working with polynomials with no repeated factors. Indeed, if
$$ f = P_1^{a_1} \dots P_k^{a_k}, \qquad a_i \in \NN $$
is a factorisation of $ f $ in distinct irreducible polynomials $ P_i $ for all $ i $, and we set
$$ g = P_1 \cdot \dots \cdot P_k, $$
then we have $ \cbr{f = 0} = \cbr{g = 0} $, and $ g $ has no repeated factors.
\end{remark}

\pagebreak

Let $ C \subseteq \CC^2 $ be a complex plane curve. We have proved that, up to multiplication by $ \lambda \in \CC^* $, there is a unique non-constant polynomial $ f \in \CC\sbr{x, y} $ with no repeated factors such that $ C = \cbr{f = 0} $. It makes sense to define the following.

\begin{definition}
The \textbf{degree} of an affine curve $ C \subseteq \CC^2 $ is the degree of any polynomial with no repeated factors $ f $ which defines $ C $, such that $ C = \cbr{f = 0} $, that is $ \deg C = \deg f $.
\end{definition}

\begin{example}
\hfill
\begin{itemize}
\item A complex line has always degree one, since they are defined by a linear polynomial.
\item A conic, a curve defined by a polynomial $ f\br{x, y} $ of degree two, has degree two, unless it is a double line, that is
$$ f\br{x, y} = L\br{x, y}^2, $$
for some linear polynomial $ L\br{x, y} $. In that case, it has degree equal to $ \deg L = 1 $.
\item If $ P \in \CC\sbr{x, y} $ is an irreducible polynomial of degree two and $ L \in \CC\sbr{x, y} $ is a polynomial of degree one, then the curve $ \cbr{P \cdot L = 0} $ has degree three. For example,
$$ \cbr{x^2y + y^2 + x + 1 = 0} $$
has degree three, assuming it has no repeated factors.
\end{itemize}
\end{example}

Unless mentioned otherwise, in the first few weeks, we will assume that polynomials have no repeated factors.

\begin{definition}
Let $ f_1, f_2 \in \CC\sbr{x, y} $ be polynomials with no repeated factors and let
$$ C_1 = \cbr{f = 0}, \qquad C_2 = \cbr{g = 0} $$
be the associated complex curves. The curves $ C_1 $ and $ C_2 $ have \textbf{no common component} if there is no non-constant polynomial $ P $ that divides both $ f $ and $ g $.
\end{definition}

We can read off whether $ C_1 $ and $ C_2 $ have common components from the factorisation of $ f_1 $ and $ f_2 $ in irreducible polynomials. If
$$ f = P_1^{a_1} \dots P_k^{a_k}, \qquad g = Q_1^{b_1} \dots Q_k^{b_k}, $$
where all $ P_i $ and $ Q_i $ are irreducible, and $ P_i \ne P_j $ and $ Q_i \ne Q_j $ for $ i \ne j $, then $ C_1 $ and $ C_2 $ have no common component if and only if $ \lambda P_i \ne Q_j $ for all $ i $ and $ j $ and $ \lambda \in \CC^* $.

\begin{remark}
The terminology comes from the fact that if $ f = P_1 \dots P_k $ as above, the algebraic curve $ \cbr{P_i = 0} $ is said to be \textbf{irreducible}, and it is called an \textbf{irreducible component} of the algebraic curve $ \cbr{f = 0} $, which is the union of all its components.
\end{remark}

\begin{exercise**}
Show that if $ C_1 $ and $ C_2 $ have no common component, then
$$ \deg C_1 \cup C_2 = \deg C_1 + \deg C_2. $$
\end{exercise**}

\begin{exercise**}
Let $ L $ and $ L' $ be the lines
$$ L = \cbr{ax + by + c = 0} \subseteq \CC^2, \qquad L' = \cbr{a'x + b'y + c' = 0} \subseteq \CC^2. $$
\begin{itemize}
\item Show that $ L $ and $ L' $ meet at exactly one point if and only if $ ab' - a'b \ne 0 $.
\item Show that $ L = L' $ if and only if there exists $ \lambda \in \CC $ such that $ \lambda \ne 0 $ and
$$ a' = \lambda a, \qquad b' = \lambda b, \qquad c' = \lambda c. $$
\end{itemize}
\end{exercise**}

\pagebreak

\begin{remark}[First aid topology]
\label{rem:2.19}
\hfill
\begin{itemize}
\item A \textbf{topological space} $ X $ is a set, equipped with a collection of \textbf{open subsets} $ \cbr{U_i \subseteq X} $, such that
\begin{itemize}
\item $ \emptyset $ and $ X $ are open,
\item any union $ \bigcup_{i \in I} U_i $ of open sets $ U_i $ is open, and
\item any finite intersection $ \bigcap_{i = 1}^k U_i $ of open sets $ U_i $ is open.
\end{itemize}
\item A \textbf{metric space} $ X $, such as $ \br{\CC^n, \norm{.}} $, is a topological space. The open sets are given by arbitrary unions and finite intersections of the familiar \textbf{open balls}
$$ \B\br{x, \epsilon} = \cbr{z \in X \st \norm{z - x}} < \epsilon. $$
\item A subset $ X \subseteq Y $ of a topological space $ Y $ inherits a topology from $ Y $. The open sets of $ X $ are the sets $ X \cap U $, where $ U \subseteq Y $ is an open set of $ Y $.
\item $ X $ is \textbf{compact} if for all open covering
$$ X = \bigcup_{i \in I} U_i, $$
where $ U_i $ are open, there exists a finite subcovering
$$ X = \bigcup_{i_1, \dots, i_k} U_{i_j}, \qquad \cbr{i_1, \dots, i_k} \subseteq I. $$
\item The \textbf{Heine-Borel theorem} states that a subset $ X $ of $ \RR^n $ or of $ \CC^m $ is compact if and only if $ X $ is \textbf{closed}, that is its complement is open, and \textbf{bounded}, for the usual norm.
\item A closed subset of a compact space is compact.
\item A map $ f : X \to Y $ between topological spaces is \textbf{continuous} if and only if $ f^{-1}\br{U} $ is open, in $ X $, whenever $ U \subseteq Y $ is open. It follows that $ f^{-1}\br{F} $ is closed whenever $ F \subseteq Y $ is closed. In particular, if $ f \in \CC\sbr{x_1, \dots, x_n} $ is a polynomial, $ f $ defines a map $ f : \CC^n \to \CC $ that is continuous, and
$$ f^{-1}\br{\cbr{0}} = \cbr{f = 0} \subseteq \CC^n $$
is closed because $ \cbr{0} $ is a closed subset of $ \CC $.
\end{itemize}
\end{remark}

In particular, $ \CC^2 $ is a topological space with the Euclidean distance in $ \RR^4 $, and if
$$ C = \cbr{f = 0} \subseteq \CC^2 $$
is an affine plane curve, then $ C $ is a topological space that inherits a topology as a subset of $ \CC^2 \cong \RR^4 $. The open sets of $ C $ are $ U \cap C $ where $ U \subseteq \CC^2 $ is open. So algebraic curves have a natural topology.

\begin{lemma}
Let $ C \subseteq \CC^2 $ be an affine plane curve, then $ C $ is not compact.
\end{lemma}

\begin{proof}
Since $ f $ is a continuous function $ \CC^2 \to \CC $, $ C = \cbr{f = 0} = f^{-1}\br{\cbr{0}} $, and $ \cbr{0} $ is closed in $ \CC $, $ C $ is closed in $ \CC^2 $. We show that $ C \subseteq \CC^2 $ is not bounded. Assume that it is, then there is a constant $ M > 0 $ such that $ C \subseteq \B\br{0, M} $, where the open ball is
$$ \B\br{0, M} = \cbr{\br{x, y} \in \CC^2 \st \abs{x}^2 + \abs{y}^2 < M}. $$
Want to show that some points in $ \CC $ are outside this open ball. Let $ x_0 \in \CC $ be such that $ \abs{x_0} > M $ and assume we can arrange for $ g = f\br{x_0, y} $ to be a non-constant polynomial of $ y $. What if $ f\br{x, y} $ happens to be a polynomial of $ x $ alone, so that this cannot be arranged? \footnote{Exercise} By the fundamental theorem of algebra, $ g $ has a root $ y_0 \in \CC $ and the point $ \br{x_0, y_0} \in C $. This is a contradiction, as $ \br{x_0, y_0} \notin \B\br{0, M} $.
\end{proof}

\pagebreak

\section{Projective space}

\lecture{4}{Monday}{15/10/18}

Recall that it is difficult to determine when two affine plane curves $ C, C' \in \CC^2 $ intersect, and some curves do not in fact intersect, even over $ \CC $. We want to fix that, and the key is adding points at infinity.

\begin{example}
\hfill
\begin{itemize}
\item Consider two distinct lines
$$ L_1 = \cbr{ax + by + c = 0}, \qquad L_2 = \cbr{a'x + b'y + c' = 0}. $$
Then $ L_1 $ and $ L_2 $ meet at exactly one point if and only if
$$ \det \twobytwo{a}{b}{a'}{b'} \ne 0. $$
But we can pretend that parallel lines meet at a point at infinity corresponding to the direction vector.
\item Consider the asymptotic curve and line
$$ C = \cbr{xy - 1 = 0}, \qquad L = \cbr{x = 0}. $$
Then $ C $ and $ L $ do not meet, but again we can pretend that they meet at a point at infinity.
\end{itemize}
\end{example}

Informally, a heuristic trick is to introduce a variable $ z $.
\begin{enumerate}
\item Replace $ \br{x, y} \mapsto \br{x / z, y / z} $.
\item Solve $ z = 0 $.
\end{enumerate}

\begin{example}
\hfill
\begin{itemize}
\item Consider the lines
$$ L_1 = \cbr{ax + by + c = 0}, \qquad L_2 = \cbr{a'x + b'y + c' = 0}. $$
Clearly $ L_1 $ and $ L_2 $ do not meet. Let us apply the trick. By $ 1 $ and $ 2 $ we get
$$
\begin{cases}
\dfrac{x}{z} + \dfrac{y}{z} + 1 = 0 \\
\dfrac{x}{z} + \dfrac{y}{z} - 1 = 0
\end{cases}
\qquad \implies \qquad
\begin{cases}
x + y + z = 0 \\
x + y - z = 0
\end{cases}
\qquad \implies \qquad
\begin{cases}
x + y = 0 \\
x + y = 0
\end{cases}.
$$
We get that the point $ \br{1, -1, 0} $ is a common solution. This will be called the point at infinity.
\item Consider the asymptotic curve and line
$$ C = \cbr{xy - 1 = 0}, \qquad L = \cbr{x = 0}. $$
Apply $ 1 $ and $ 2 $ to get
$$
\begin{cases}
xy - z^2 = 0 \\
\dfrac{x}{z} = 0
\end{cases}
\qquad \implies \qquad
\begin{cases}
xy = 0 \\
x = 0
\end{cases}.
$$
We get that $ \br{0, 1, 0} $ is a common solution. Again, this will be called the point at infinity.
\end{itemize}
\end{example}

To make this formal, we introduce the projective plane $ \PP^2 $. We will add points at infinity to $ \CC^2 $, in such a way that asymptotic curves meet at infinity. We will then compactify an affine plane curve $ C $ so that the two compactifications are compatible, that is
$$ \br{C \subseteq \CC^2} \hookrightarrow \br{\overline{C} \subseteq \PP^2}. $$

\pagebreak

\begin{notation}
Fix $ n \ge 0 $ and $ \CC^{n + 1} $. Let $ \underline{0} = \br{0, \dots, 0} \in \CC^{n + 1} $ be the origin of the $ \br{n + 1} $-dimensional complex Euclidean space. We will denote
$$ W = \CC^{n + 1} \setminus \cbr{\underline{0}}, $$
that is a point $ x \in W $ is given by $ x = \br{x_0, \dots, x_n} $ where $ x_0, \dots, x_n \in \CC $ are not all zero. We define the equivalence relation on $ W $, for any $ x, y \in W $ by
$$ x \sim y \qquad \iff \qquad \exists \lambda \in \CC^* = \CC \setminus \cbr{0}, \ x = \lambda y. $$
\end{notation}

\begin{exercise**}
Show that $ \sim $ is an equivalence relation on $ W $.
\end{exercise**}

\begin{notation}
Given $ x \in W $, we denote
$$ \sbr{x} = \cbr{y \in W \st x \sim y}. $$
For simplicity, if $ x = \br{x_0, \dots, x_n} $ we will denote
$$ \sbr{x} = \sbr{x_0, \dots, x_n}, $$
instead of $ x = \sbr{\br{x_0, \dots, x_n}} $.
\end{notation}

\begin{exercise**}
Show that $ \sbr{x} = \sbr{y} $ if and only if $ x \sim y $. Show that if $ y \notin \sbr{x} $ then $ \sbr{x} \cap \sbr{y} = \emptyset $.
\end{exercise**}

\begin{definition}
The \textbf{$ n $-dimensional complex projective space} $ \PP_\CC^n $, or $ \PP^n\br{\CC} $, or simply $ \PP^n $, is defined as the quotient of $ W $ by $ \sim $, that is
$$ \PP_\CC^n = W / \sim = \cbr{\sbr{x} \st x \in W = \CC^{n + 1} \setminus \cbr{\underline{0}}}. $$
The coordinates of $ \PP^n $ are $ \sbr{x} \in \PP^n $ except $ \sbr{0, \dots, 0} $, and
$$ \sbr{\lambda x_0, \dots, \lambda x_n} = \sbr{x_0, \dots, x_n}. $$
In other words, in $ \PP^n $, two points $ \sbr{x_0, \dots, x_n} $ and $ \sbr{y_0, \dots, y_n} $ are the same point if and only if there exists a non-zero constant $ \lambda $ such that
$$ x_0 = \lambda y_0, \qquad \dots, \qquad x_n = \lambda y_n. $$
\end{definition}

\begin{example}
The point $ \sbr{1, 2, i} $ is the same as the point $ \sbr{i, 2i, -1} $.
\end{example}

\begin{exercise**}
Show that there exists a bijection
$$ \PP^n \qquad \leftrightsquigarrow \qquad \cbr{\text{one-dimensional subspaces of} \ \CC^{n + 1}}. $$
In fact, if $ V $ is a finite-dimensional vector space over $ \CC $ without the choice of a basis, we can define the associated projective space $ \PP\br{V} $ as the set of one-dimensional linear subspaces of $ V $.
\end{exercise**}

\begin{example}
For any non-zero $ x \in \CC $ we have $ \sbr{x} = \sbr{1} $. So
$$ \PP^0 = \CC^1 \setminus \cbr{0} / \sim = \cbr{\sbr{1}} $$
is a point.
\end{example}

\begin{notation}
For any $ i = 0, \dots, n $, denote the \textbf{affine chart}
$$ U_i = \cbr{\sbr{x} = \sbr{x_1, \dots, x_n} \in \PP^n \st x_i \ne 0} \subseteq \PP^n. $$
\end{notation}

\begin{lemma}
\label{lem:3.9}
$$ \PP^n = U_0 \cup \dots \cup U_n. $$
\end{lemma}

\begin{proof}
Take $ \sbr{x} = \sbr{x_0, \dots, x_n} \in \PP^n $ then $ x \in W $ and in particular $ x = \br{x_0, \dots, x_n} $ where at least one of the coefficients is non-zero, say $ x_i \ne 0 $. Then $ \sbr{x} \in U_i $. Thus any $ \sbr{x} \in \PP^n $ is contained in the union of $ U_0, \dots, U_n $.
\end{proof}

\pagebreak

\begin{lemma}
\label{lem:3.10}
Pick $ i = 0, \dots, n $. Define
$$ \function[\phi_i]{\CC^n}{U_i}{\br{y_1, \dots, y_n}}{\sbr{y_1, \dots, y_i, 1, y_{i + 1}, \dots, y_n}}. $$
Then $ \phi_i $ is a bijection and its inverse is given by
$$ \function[\psi_i]{U_i}{\CC^n}{\sbr{x_0, \dots, x_n}}{\br{\dfrac{x_0}{x_i}, \dots, \dfrac{x_{i - 1}}{x_i}, \dfrac{x_{i + 1}}{x_i}, \dots, \dfrac{x_n}{x_i}}}. $$
\end{lemma}

\begin{proof}
First note that both $ \phi_i $ and $ \psi_i $ is well-defined, indeed, if $ \br{y_1, \dots, y_n} \in \CC^n $ then
$$ \br{y_1, \dots, y_i, 1, y_{i + 1}, \dots, y_n} \in W $$
and therefore
$$ \sbr{y_1, \dots, y_i, 1, y_{i + 1}, \dots, y_n} \in \PP^n. $$
Similarly, if $ \sbr{x_0, \dots, x_n} = \sbr{x_0', \dots, x_n'} $ then it follows that
$$ \psi_i\sbr{x_0, \dots, x_n} = \psi_i\sbr{x_0', \dots, x_n'}. $$
Thus, it is enough to show that both $ \phi_i \circ \psi_i $ and $ \psi_i \circ \phi_i $ coincide with the identity. We have
$$ \psi_i\br{\phi_i\br{y_1, \dots, y_n}} = \psi_i\sbr{y_1, \dots, y_i, 1, y_{i + 1}, \dots, y_n} = \br{\dfrac{y_1}{1}, \dots, \dfrac{y_i}{1}, \dfrac{y_{i + 1}}{1}, \dots, \dfrac{y_n}{1}} = \br{y_1, \dots, y_n}. $$
Similarly,
$$ \phi_i\br{\psi_i\sbr{x_0, \dots, x_n}} = \phi_i\br{\dfrac{x_0}{x_i}, \dots, \dfrac{x_{i - 1}}{x_i}, \dfrac{x_{i + 1}}{x_i}, \dots, \dfrac{x_n}{x_i}} = \sbr{\dfrac{x_0}{x_i}, \dots, \dfrac{x_{i - 1}}{x_i}, 1, \dfrac{x_{i + 1}}{x_i}, \dots, \dfrac{x_n}{x_i}} = \sbr{x_0, \dots, x_n}. $$
Thus they are inverses.
\end{proof}

\begin{example*}
Let $ n = 2 $ and $ \sbr{x_0, x_1, x_2} \in \PP^2 $. Then
$$ \function[\phi_1]{\CC^2}{U_1}{\br{0, 0}}{\sbr{0, 1, 0}}, \qquad \function[\phi_2]{\CC^2}{U_2}{\br{0, 0}}{\sbr{0, 0, 1}}. $$
\end{example*}

Lemma \ref{lem:3.9} and Lemma \ref{lem:3.10} can be used to define a topology on $ \PP^n $. Let $ U \subseteq \PP^n $, then $ U $ is open if and only if $ \phi_i^{-1}\br{U \cap U_i} \subseteq \CC^n $ is open, in $ U_i \cong \CC^n $, for any $ i = 0, \dots, n $.

\begin{exercise**}
Show that $ U_i \subseteq \PP^n $ is open in $ \PP^n $ for all $ i = 0, \dots, n $.
\end{exercise**}

\begin{exercise**}
\label{ex:11}
We can define another topology on $ \PP^n $ as the quotient topology induced by the map
$$ \function[\pi]{W}{\PP^n}{\br{x_0, \dots, x_n}}{\sbr{x_0, \dots, x_n}}, $$
so a subset $ U \subseteq \PP^n $ is open if and only if its preimage $ \pi^{-1}\br{U} \subseteq W $ is open in $ W $. Show that this indeed defines a topology, and that this topology coincides with the one defined above using the maps $ \phi_i $. Check that with this topology on $ \PP^n $, $ \pi $ is continuous.
\end{exercise**}

\begin{exercise**}
\label{ex:12}
Prove that $ \PP^n $ is compact. A hint is to restrict the projection $ \pi $ of Exercise \ref{ex:11} to the $ \br{n + 1} $-dimensional sphere $ \S^{n + 1} \subseteq W $, and check that this restriction is surjective and continuous. Since $ \S^{n + 1} $ is compact, it follows that $ \PP^n $ is compact as well.
\end{exercise**}

\begin{example}
\hfill
\begin{itemize}
\item $ \PP^1 = \cbr{\sbr{x_0, x_1} \st \br{x_0, x_1} \in \CC^2 \setminus \cbr{\underline{0}}} $ is the union of $ U_0 $ and $ U_1 $. The intersection of $ U_0 $ and $ U_1 $ is
$$ U_0 \cap U_1 = \cbr{\sbr{x_0, x_1} \st x_0 \ne 0, \ x_1 \ne 0}, $$
which can be identified with $ \CC^* = \CC \setminus \cbr{0} $ via the map
$$ \function{U_0 \cap U_1}{\CC^*}{\sbr{x_0, x_1}}{\dfrac{x_1}{x_0}}. $$

\pagebreak

Using this identification and the maps $ \psi_i $, the inclusions $ U_0 \cap U_1 \subseteq U_0 $ and $ U_0 \cap U_1 \subseteq U_1 $ are the maps
$$ \function{\CC^*}{\CC^1}{z}{z}, \qquad \function{\CC^*}{\CC^1}{z}{\dfrac{1}{z}}. $$
Then $ \PP^1 $ is glued together from two copies of $ \CC $ along $ U_0 \cap U_1 $ by these inclusions, so $ \PP^1 = \CC^1 \cup \cbr{\infty} $. Over the real numbers, $ \PP^1\br{\RR} $ is built up in the same way from two copies of $ \RR^1 $, and can be identified with the circle $ \S^1 $.
\item $ \PP^2 = \cbr{\sbr{x_0, x_1, x_2} \st \br{x_0, x_1, x_2} \in \CC^3 \setminus \cbr{\underline{0}}} $ is the union of $ U_0 \cong U_1 \cong U_2 \cong \CC^2 $, and the intersection can be described similarly. At infinity we will have a line.
\item More generally, $ \PP^n $ can be described similarly.
\end{itemize}
\end{example}

In practice, we will view the affine complex plane $ \CC^2 $ as being embedded in $ \PP^2 $ as one of the open sets $ U_i $.

\begin{example*}
We identify $ \br{x, y} \in \CC^2 $ and $ \sbr{x, y, 1} \in \PP^2 $.
\end{example*}

What is the complement of this embedding, that is the points at infinity?

\begin{notation}
For any $ i = 0, \dots, n $, denote
$$ \PPP_i = \cbr{\sbr{x_0, \dots, x_n} \in \PP^n \st x_i = 0} \subseteq \PP^n. $$
\end{notation}

\begin{lemma}
\label{lem:3.13}
For any $ i = 0, \dots, n $, we have $ \PP^n = U_i \sqcup \PPP_i $. Moreover if we define
$$ \function[f_i]{\PP^{n - 1}}{\PPP_i}{\sbr{z_0, \dots, z_{n - 1}}}{\sbr{z_0, \dots, z_{i - 1}, 0, z_i, \dots, z_{n - 1}}}, $$
then $ f_i $ is a bijection.
\end{lemma}

\begin{proof}
Both statements are easy to check. \footnote{Exercise}
\end{proof}

In conclusion, we have that
$$ \PP^n = U_i \sqcup \PPP_i, \qquad U_i \cong \CC^n, \qquad \PPP_i \cong \PP^{n - 1}, $$
so $ \PP^n \cong \CC^n \sqcup \dots \sqcup \CC^0 $. Then $ \PPP_i $ is called the \textbf{hyperplane at infinity}.

\begin{example}
\hfill
\begin{itemize}
\item We have already seen that $ \PP^0 $ is a point.
\item $ \PP^1 \cong \CC^1 \cup \PP^0 $. In other words, $ \PP^1 $ is obtained by adding a point at infinity to the complex line $ \CC $. It is a way to compactify the real plane. If the $ \CC^1 $ above is $ U_0 $, this point at infinity is the origin of the other open subset $ U_1 \cong \CC^1 $. One can show that there is an bijection, which is also a homeomorphism
$$ \function{\PP^1}{\S^2 \subseteq \RR^3}{r}{\dfrac{1}{r}}. $$
$ \PP^1 $ is called the \textbf{projective line}, by problem sheet $ 1 $.
\item $ \PP^2 \cong \CC^2 \cup \PP^1 $. Thus $ \PP^2 $ is obtained by adding a projective \textbf{line at infinity} to the complex plane $ \CC^2 $. Then $ \PP^2 $ is called the \textbf{projective plane}.
\end{itemize}
\end{example}

\begin{note*}
The point at infinity or the line at infinity is not unique. It depends on the choice of the coordinate, and in our settings, it depends on $ i $. In the future, we will often fix $ i $, and this will give us a unique choice of the point or line at infinity.
\end{note*}

\pagebreak

\section{Projective curves}

\lecture{5}{Thursday}{18/10/18}

Recall that an algebraic curve is given by
$$ C = \cbr{f\br{x, y} = 0} \subseteq \CC^2, \qquad f \in \CC\sbr{x, y}. $$
In this section, we want to define projective curves similarly in $ \PP^2 $ and then compactify these affine curves. If we try to define a plane projective curve in the same way as an affine curve, that is as
$$ \cbr{f = 0} \subseteq \PP^2, \qquad f \in \CC\sbr{x_0, x_1, x_2}, $$
the first hurdle we encounter is that $ f $ does not define a function on $ \PP^2 $.

\begin{example}
\hfill
\begin{itemize}
\item Let
$$ f\br{x, y, z} = x^2 + y^2 - z^2. $$
Then $ f\br{1, 1, 1} \ne f\br{2, 2, 2} $, so that $ f $ does not define a function on $ \PP^2 $. It makes no sense to talk about $ f\br{1, 1, 1} $, because in $ \PP^2 $, $ \sbr{1, 1, 1} = \sbr{2, 2, 2} $, so the value would not be well-defined. However, the locus where $ f $ vanishes in this case is well-defined. If $ f\br{x, y, z} = 0 $, then $ f\br{\lambda x, \lambda y, \lambda z} = 0 $ for all $ \lambda \in \CC^* $, so that the subset
$$ \cbr{\sbr{x, y, z} \in \PP^2 \st f\br{x, y, z} = 0} $$
is well-defined.
\item Let
$$ g\br{x_0, x_1, x_2} = x_0^2 + x_1, $$
then $ g\br{i, 1, 0} = 0 $, but $ g\br{2i, 2, 0} \ne 0 $, so that in this case, the vanishing locus
$$ \cbr{\sbr{x_0, x_1, x_2} \in \PP^2 \st g\br{x_0, x_1, x_2} = 0} $$
is not even well-defined.
\end{itemize}
\end{example}

The example shows that if we want to define projective curves as
$$ \cbr{\sbr{x_0, x_1, x_2} \in \PP^2 \st f\br{x_0, x_1, x_2} = 0}, $$
then $ f \in \CC\sbr{x_0, x_1, x_2} $ has to satisfy some additional properties.

\begin{definition}
A polynomial $ f \in K\sbr{x_0, \dots, x_n} $ is \textbf{homogeneous} if all its monomials have the same degree $ d \in \NN $, that is
$$ f\br{x_0, \dots, x_n} = \sum_{\alpha, \ \abs{\alpha} = d} a_\alpha x^\alpha, \qquad \alpha \in \NN^{n + 1}. $$
\end{definition}

\begin{example}
\hfill
\begin{itemize}
\item The polynomial
$$ f\br{x, y, z} = x^2 + y^2 - z^2 $$
is homogeneous of degree two.
\item The polynomial
$$ g\br{x_0, x_1, x_2} = x_0^2 + x_1 $$
is not homogeneous.
\item The polynomial
$$ f\br{x, y} = Ax^3 + Bx^2y + Cxy^2 + Dy^3 $$
is homogeneous of degree three, and all the homogeneous polynomials of degree three in $ x $ and $ y $ can be written in this form.
\item The polynomial
$$ g\br{x, y, z} = x^4 - 2x^2yz + yz^3 $$
is homogeneous of degree four.
\end{itemize}
\end{example}

\pagebreak

\begin{lemma}
\label{lem:4.4}
Let $ P \in \CC\sbr{x_0, \dots, x_n} $ be a polynomial. If $ P $ is homogeneous of degree $ d $, then
$$ P\br{\lambda x_0, \dots, \lambda x_n} = \lambda^dP\br{x_0, \dots, x_n}, \qquad \lambda \in \CC, \qquad \br{x_0, \dots, x_n} \in \CC^{n + 1}. $$
\end{lemma}

\begin{proof}
Let $ P $ be a homogeneous polynomial of degree $ d $. Then
$$ P = M_1 + \dots + M_k, $$
where each $ M_i $ is a monomial of degree $ d $. For each monomial
$$ M = a_\alpha x^\alpha = a_\alpha x_0^{\alpha_0} \dots x_n^{\alpha_n}, \qquad \alpha \in \NN^{n + 1}, \qquad a_\alpha \in \CC $$
of degree $ d $, we have
$$ M\br{\lambda x_0, \dots, \lambda x_n} = a_\alpha\br{\lambda^{\alpha_0}x_0^{\alpha_0}} \dots \br{\lambda^{\alpha_n}x_n^{\alpha_n}} = \lambda^{\sum_{i = 0}^n \alpha_i}a_\alpha x^\alpha = \lambda^da_\alpha x^\alpha = \lambda^dM\br{x_0, \dots, x_n}, $$
because $ \sum_{i = 0}^n \alpha_i = \abs{\alpha} = d $. For the arbitrary homogeneous polynomial $ P $, write $ P = \sum_{i = 1}^k M_i $. Thus
$$ P\br{\lambda x_0, \dots, \lambda x_n} = \sum_{i = 1}^k M_i\br{\lambda x_0, \dots, \lambda x_n} = \lambda^d\sum_{i = 1}^k M_i\br{x_0, \dots, x_n} = \lambda^dP\br{x_0, \dots, x_n}. $$
\end{proof}

\begin{exercise**}
Prove the converse implication of Lemma \ref{lem:4.4}, that is if $ P \in \CC\sbr{x_0, \dots, x_n} $ and
$$ P\br{\lambda x_0, \dots, \lambda x_n} = \lambda^dP\br{x_0, \dots, x_n}, \qquad \lambda \in \CC, \qquad \br{x_0, \dots, x_n} \in \CC^{n + 1}, $$
then $ P $ is homogeneous of degree $ d $.
\end{exercise**}

\begin{proposition}
Let $ P $ be a homogeneous polynomial. Then
$$ \cbr{\sbr{x_0, \dots, x_n} \in \PP^n \st P\br{x_0, \dots, x_n} = 0} $$
is well-defined.
\end{proposition}

\begin{proof}
We have to check that if $ \br{x_0, \dots, x_n} \sim \br{y_0, \dots, y_n} $, $ P\br{x_0, \dots, x_n} = 0 $ if and only if $ P\br{y_0, \dots, y_n} = 0 $. This follows immediately from Lemma \ref{lem:4.4}, because by definition of $ \sim $,
$$ \br{y_0, \dots, y_n} = \br{\lambda x_0, \dots, \lambda x_n}, \qquad \lambda \in \CC^*, $$
so $ P\br{x_0, \dots, x_n} = 0 $ if and only if $ P\br{\lambda x_0, \dots, \lambda x_n} = \lambda^dP\br{x_0, \dots, x_n} = 0 $.
\end{proof}

\begin{notation}
Unless mentioned otherwise, arbitrary polynomials will be denoted $ f, g, h, \dots $, while homogeneous polynomials will be denoted $ P, Q, R, \dots $.
\end{notation}

Let $ P_1, \dots, P_k \in \CC\sbr{x_0, \dots, x_n} $ be homogeneous polynomials. Then the vanishing locus
$$ \cbr{P_1 = \dots = P_k = 0} \subseteq \PP^n $$
is a \textbf{projective variety}. These are the main object of study of algebraic geometry. In this class, we will focus on plane projective curves.

\begin{definition}
A \textbf{complex plane projective algebraic curve} is
$$ C = \cbr{\sbr{x_0, x_1, x_2} \in \PP^2 \st P\br{x_0, x_1, x_2} = 0} \subseteq \PP^2, $$
where $ P $ is a non-constant homogeneous polynomial $ P \in \CC\sbr{x_0, x_1, x_2} $.
\end{definition}

\begin{example}
The hyperplanes at infinity
$$ \PPP_i = \cbr{x_i = 0} \subseteq \PP^2, \qquad i = 0, 1, 2 $$
are projective curves, of degree one.
\end{example}

\begin{definition}
A \textbf{projective line} is a projective curve defined by a homogeneous polynomial $ ax_0 + bx_1 + cx_2 = 0 $ of degree one.
\end{definition}

\pagebreak

We have seen that in the case of affine plane curves $ \cbr{f = 0} \subseteq \CC^2 $, the irreducible factors of the polynomial $ f $ were important when studying curves. The next lemma ensures that the same type of results hold for projective curves.

\begin{lemma}
\label{lem:4.10}
Let $ P \in K\sbr{x_0, \dots, x_n} $ be a non-zero homogeneous polynomial. Assume that
$$ P = Q \cdot R, \qquad Q, R \in K\sbr{x_0, \dots, x_n}. $$
Then the polynomials $ Q $ and $ R $ are homogeneous.
\end{lemma}

\begin{proof}
Exercise. \footnote{Exercise}
\end{proof}

\begin{remark}
As in the case of affine plane curves, we can therefore make sense of \textbf{irreducible} projective plane curves, $ C = \cbr{P = 0} \subseteq \PP^2 $ with $ P $ irreducible. When $ P $ is reducible as
$$ P = P_1^{a_1} \dots P_k^{a_k}, \qquad a_i \in \NN^*, $$
with $ P_i $ distinct irreducible polynomials, the projective curves $ C_i = \cbr{P_i = 0} $ are called the \textbf{irreducible components} of $ C = \cbr{P = 0} $.
\end{remark}

\begin{remark}
\label{rem:4.12}
Hilbert's Nullstellensatz, and Theorem \ref{thm:2.10}, still holds. In particular, if $ P, Q \in \CC\sbr{x, y, z} $ are homogeneous polynomials with no repeated factors,
$$ \cbr{P = 0} = \cbr{Q = 0} \subseteq \PP^2 $$
if and only if $ P = \lambda Q $ for $ \lambda \in \CC^* $.
\end{remark}

\begin{definition}
Let $ C \subseteq \PP^2 $ be a projective plane curve and $ P $ any homogeneous polynomial with no repeated factor such that $ C = \cbr{P = 0} \subseteq \PP^2 $. The \textbf{degree} of $ C $ is the degree of $ P $.
\end{definition}

\begin{exercise**}
Show that the union of two projective curves $ C_1, C_2 \subseteq \PP^2 $ is a projective curve. More generally, show that if $ X_1, X_2 \subseteq \PP^2 $ are projective varieties, then $ X_1 \cup X_2 \subseteq \PP^n $ is again a projective variety.
\end{exercise**}

\begin{exercise**}
Show that if $ X = \cbr{P = 0} \subseteq \PP^n $ for a non-zero homogeneous polynomial $ P \in \CC\sbr{x_0, \dots, x_n} $, then
$$ X = \cbr{x_0P = \dots = x_nP = 0}. $$
\end{exercise**}

\begin{lemma}
Let $ C \subseteq \PP^2 $ be a projective curve. Then $ C $ is compact.
\end{lemma}

Recall that affine curves are never compact.

\begin{proof}
Recall that a closed subset of a compact set is compact itself. Since $ \PP^2 $ is compact, by Exercise \ref{ex:12}, we only need to prove that $ C $ is closed, or equivalently, that $ \pi^{-1}\br{C} \subseteq W = \CC^3 \setminus \cbr{\underline{0}} $ is closed, where
$$ \function[\pi]{W}{W / \sim = \PP^2}{\br{x_0, x_1, x_2}}{\sbr{x_0, x_1, x_2}}, $$
by Remark \ref{rem:2.19}. Assume that $ C = \cbr{P = 0} $ for a homogeneous polynomial $ P $. Then, $ P : W \to \CC $ is a continuous map, so that
$$ \pi^{-1}\br{C} = P^{-1}\br{\cbr{0}} \cap W = \cbr{P\br{x_0, x_1, x_2} = 0} \cap W $$
is a closed subset of $ W $.
\end{proof}

\begin{remark}
You may have heard of the \textbf{Zariski topology} for algebraic varieties. The Zariski topology is defined on affine spaces $ \CC^n $ or on projective spaces $ \PP^n $ as the topology whose closed sets are of the form
$$ \V\br{S} = \cbr{\underline{x} \in \CC^n \st f\br{\underline{x}} = 0}, $$
where $ S $ is a set of polynomials, or homogeneous polynomials, $ f \in \CC\sbr{x_0, \dots, x_n} $. In this course, we do not work in the Zariski topology, but in the classical topology, metric or Euclidean, on $ \CC^{n + 1} $ and in the topology this induces on $ \PP^n $ as outlined above. One reason for that is that the Zariski topology is not Hausdorff, or separated.
\end{remark}

\lecture{6}{Friday}{19/10/18}

Lecture 6 is a problems class.

\pagebreak

\section{Affine vs projective plane curves}

We now show how to projectivise affine curves, and study the relationship between affine and projective curves.

\begin{notation}
We will typically use coordinates $ x $ and $ y $ on $ \CC^2 $ and $ x_0, x_1, x_2 $ on $ \PP^2 $.
\end{notation}

Let $ C = \cbr{f = 0} \subseteq \CC^2 $ for $ f \in \CC\sbr{x, y} \setminus \cbr{0} $ be an affine curve, and want to construct a projective curve $ \overline{C} \subseteq \PP^2 $, a projectivisation of $ C $. Recall that we have identified $ \CC^2 $ with the open subset $ U_2 = \cbr{x_2 \ne 0} \subseteq \PP^2 $, via the inverse functions
$$ \function[\phi_2]{U_2}{\CC^2}{\sbr{x_0, x_1, x_2}}{\br{\dfrac{x_0}{x_2}, \dfrac{x_1}{x_2}}}, \qquad \function[\psi_2]{\CC^2}{U_2}{\br{x, y}}{\sbr{x, y, 1}}. $$
We now want to identify $ U_2 \cap \overline{C} \subseteq \CC^2 $ with the original curve $ C $ for a suitable projective plane curve $ \overline{C} = \cbr{P = 0} \subseteq \PP^2 $ for $ P $ homogeneous, picking $ \CC^2 \cong U_2 \subseteq \PP^2 $ to be the points not at infinity.

\begin{example*}
The idea is to let $ x = x_0 / x_2 $ and $ y = x_1 / x_2 $. For example,
$$ f\br{x, y} = x^3 + y + 1 = \br{\dfrac{x_0}{x_2}}^3 + \br{\dfrac{x_1}{x_2}} + 1. $$
Clear denominators to get
$$ P\br{x_0, x_1, x_2} = x_0^3 + x_1x_2^2 + x_2^3, $$
homogeneous of degree three. Restricting $ P $ to $ U_2 \cong \CC^2 $ I get back
$$ P\br{x, y, 1} = x^3 + y + 1 = f\br{x, y}. $$
Thus $ \cbr{P = 0} = \overline{C} $ is the projectivisation of $ \cbr{f = 0} = C $.
\end{example*}

\begin{theorem}
There is a one-to-one correspondence
$$ \correspondence{\text{projective plane curves} \ \overline{C} = \cbr{P = 0} \subseteq \PP^2 \ \text{that} \\ \text{do not contain the line at infinity} \ \PPP_2 = \cbr{x_2 = 0}}{\text{affine curves} \ C = \cbr{f = 0} \subseteq \CC^2}. $$
The bijection is obtained by
$$ \bijection{C}{\overline{C}}{f}{\sbr{P : \br{x_0, x_1, x_2} \mapsto x_2^d \cdot f\br{\tfrac{x_0}{x_2}, \tfrac{x_1}{x_2}}}}{\sbr{f : \br{x, y} \mapsto P\br{x, y, 1}}}{P}, $$
where $ d = \deg f $. The affine curve $ \cbr{f = 0} \subseteq \CC^2 $ is $ \phi_2\br{U_2 \cap \overline{C}} $, where $ \overline{C} = \cbr{P = 0} $.
\end{theorem}

\begin{notation}
In general, $ P $ is called the \textbf{homogenisation} of the polynomial $ f $, and $ \overline{C} $ is the \textbf{projectivisation} of $ C $.
\end{notation}

\begin{proof}
Let $ \overline{C} = \cbr{P = 0} \subseteq \PP^2 $ be a projective curve that does not contain $ \cbr{x_2 = 0} $, as in the statement. Then $ P $ contains at least one monomial without $ x_2 $, so that $ f : \br{x, y} \mapsto P\br{x, y, 1} $ is a polynomial in $ x $ and $ y $. If not,
$$ P = x_2 \cdot Q, \qquad \cbr{P = 0} = \cbr{x_2 = 0} \cup \cbr{Q = 0}. $$
So $ f\br{x, y} $ has degree equal to $ d = \deg P $. Under the identification $ \phi_2 : U_2 \to \CC^2 $ defined in the previous section,
$$ \phi_2\br{U_2 \cap \overline{C}} = \cbr{\br{x, y} \in \CC^2 \st f\br{x, y} = 0}. $$
Conversely, if $ C = \cbr{f = 0} $, then $ C $ is the image by $ \phi_2 $ of the intersection of $ U_2 $ and $ \overline{C} $, where $ \overline{C} = \cbr{P = 0} $, where the polynomial $ P $ is defined by
$$ P\br{x_0, x_1, x_2} = x_2^d \cdot f\br{\dfrac{x_0}{x_2}, \dfrac{x_1}{x_2}}. $$
Check that $ P $ is a well-defined homogeneous polynomial of degree $ d $, and that the two constructions are the inverses of each other. \footnote{Exercise}
\end{proof}

\pagebreak

\begin{example*}
Look at an example where $ \overline{C} $ does contain $ \cbr{x_2 = 0} $. Let
$$ P\br{x_1, x_1, x_2} = x_0x_2^2 + x_1^2x_2 = x_2\br{x_0x_2 + x_1^2}. $$
Then
$$ f\br{x, y} = P\br{x, y, 1} = x + y^2, $$
so
$$ P\br{x_0, x_1, x_2} = \br{\dfrac{x_0}{x_2} + \br{\dfrac{x_1}{x_2}}^2}x_2^2 = x_0x_2 + x_1^2. $$
\end{example*}

\begin{remark*}
To intersect $ \cbr{P = 0} $ and $ \cbr{Q = 0} $ in $ \PP^2 $, solve $ P = 0 $ and $ Q = 0 $ in $ x_0, x_1, x_2 $ to get homogeneous coordinates of points of intersection, where $ \underline{0} $ is not a valid solution and $ \br{\lambda x_0, \lambda x_1, \lambda x_2} = \br{x_0, x_1, x_2} $.
\end{remark*}

\begin{example}
\hfill
\begin{itemize}
\item Let $ \overline{C} $ be the projective curve
$$ \overline{C} = \cbr{P\br{x_0, x_1, x_2} = x_0^2 + x_1^2 + x_2^2 = 0}. $$
Then $ C = \phi_2\br{\overline{C} \cap U_2} $ is $ \cbr{f = 0} \subseteq \CC^2 $, where
$$ f\br{x, y} = x^2 + y^2 + 1. $$
\item Let $ C $ be the affine curve
$$ C = \cbr{x^2y + y - 1 = 0}. $$
Then $ \overline{C} $ is defined by
$$ x_2^3\br{\br{\dfrac{x_0}{x_2}}^2\br{\dfrac{x_1}{x_2}} + \br{\dfrac{x_1}{x_2}} - 1} = x_0^2x_1 + x_1x_2^2 - x_2^3. $$
\end{itemize}
\end{example}

\begin{exercise**}
Let $ i = 0 $ or $ i = 1 $. Recall that $ \phi_i $ denotes the homeomorphism $ \phi_i : U_i \to \CC^2 $. Show that if $ \overline{C} \subseteq \PP^2 $ is a projective curve that does not contain $ \PPP_i = \cbr{x_i = 0} $, then $ C_i = \phi_i\br{\overline{C} \cap U_i} \subseteq \CC^2 $ is an affine curve.
\end{exercise**}

\lecture{7}{Monday}{22/10/18}

\begin{example}
Intersect projectivisations to find the points of intersection at infinity.
\begin{itemize}
\item Consider the parallel lines
$$ L_1 = \cbr{x + y + 1 = 0}, \qquad L_2 = \cbr{x + y - 1 = 0}. $$
The corresponding projective lines are given by
$$ \overline{L_1} = \cbr{x_0 + x_1 + x_2 = 0}, \qquad \overline{L_2} = \cbr{x_0 + x_1 - x_2 = 0}, $$
then solve to give
$$
\begin{cases}
x_0 + x_1 = -x_2 \\
x_0 + x_1 = x_2
\end{cases}
\qquad \implies \qquad
\begin{cases}
x_0 + x_1 = 0 \\
x_2 = 0
\end{cases}.
$$
Inside $ \PP^2 $, the intersection $ L_1 \cap L_2 $ consists of exactly one point $ p = \sbr{1, -1, 0} $. Thus, the two projective lines meet at one point $ p \in \PPP_0 $, that is $ p $ is a point at infinity.
\item Similarly, let
$$ C = \cbr{xy - 1 = 0}, \qquad L = \cbr{x = 0}, $$
then the projectivisations are
$$ \overline{C} = \cbr{x_0 \cdot x_1 - x_2^2 = 0}, \qquad \overline{L} = \cbr{x_0 = 0}, $$
then intersect to give
$$
\begin{cases}
x_0 = 0 \\
x_0x_1 - x_2^2 = 0
\end{cases}
\qquad \implies \qquad
\begin{cases}
x_0 = 0 \\
x_2 = 0
\end{cases}.
$$
As above, in $ \PP^2 $, $ \overline{C} \cap \overline{L} $ consists of a single point $ \cbr{\sbr{0, 1, 0}} $ lying on $ \PPP_2 = \cbr{x_2 = 0} $, the hyperplane at infinity.
\end{itemize}
\end{example}

\pagebreak

\begin{example}
Projective conics over $ \RR $ are defined by degree two equations. In $ \RR^2 $, smooth conics are three kinds, ellipses, hyperbolas, and parabolas. Passing to $ \PP^2\br{\RR} $, these three kinds of curves become the same. Ellipses have no new points at infinity, hyperbolas have two new points at infinity, and parabolas have one new point at infinity.
\begin{itemize}
\item Consider the hyperbola $ C $ with equation
$$ f\br{x, y} = x^2 - y^2 + 1. $$
Projectivising, we obtain the curve $ \overline{C} $ with equation
$$ P\br{x_0, x_1, x_2} = x_0^2 - x_1^2 + x_2^2. $$
Restrict to $ U_1 = \cbr{x_1 \ne 0} \cong \RR^2 $. In $ \overline{C} \cap U_1 $, the equation of the unit circle
$$ g\br{x, y} = x^2 - 1 + y^2 = x^2 + y^2 - 1 $$
is obtained by setting $ x_1 = 1 $.
\item Consider the parabola
$$ C = \cbr{y = x^2} \subseteq \RR^2 $$
Projectivising, this becomes the curve
$$ \overline{C} = \cbr{x_1x_2 = x_0^2} \subseteq \PP^2\br{\RR} $$
The intersection with the line at infinity $ x_2 = 0 $ gives $ x_0^2 = 0 $, so the only point is $ \sbr{0, 1, 0} $. The square suggests some kind of tangency, and indeed $ \overline{C} $ is tangent to $ x_2 = 0 $. In the chart $ x_0 \ne 0 $, the equation becomes
$$ xy = 1, $$
and we see a hyperbola. In the chart $ x_1 \ne 0 $ we have again a parabola,
$$ y = x^2. $$
\item Consider the unit circle
$$ C = \cbr{x^2 + y^2 - 1 = 0} \subseteq \RR^2. $$
Projectivising we obtain
$$ \overline{C} = \cbr{x_0^2 + x_1^2 = x_2^2} \subseteq \PP^2\br{\RR}. $$
The intersection with the line at infinity $ x_2 = 0 $ is empty, as we could expect. In the chart $ x_0 \ne 0 $ we obtain the curve
$$ 1 + x^2 - y^2 = 0, $$
which is a hyperbola, and similarly in $ x_1 \ne 0 $.
\end{itemize}
\end{example}

\begin{exercise**}
Let $ a, b, c, d, e, f \in \CC $, with $ \br{a, b, c} \ne \br{0, 0, 0} $, and define
$$ C = \cbr{ax^2 + bxy + cy^2 + dx + ey + f = 0}. $$
Define the projectivisation $ \overline{C} $ of $ C $ and determine its points on the line at infinity.
\end{exercise**}

\begin{exercise**}
\label{ex:18}
\hfill
\begin{itemize}
\item Show that there exists a unique projective line $ L \subseteq \PP^2 $ through two distinct points $ P, Q \in \PP^2 $.
\item Show that two distinct projective lines in $ \PP^2 $ meet in exactly one point.
\end{itemize}
\end{exercise**}

\begin{exercise**}
\label{ex:19}
Let $ P_1, P_2, P_3 $ be three points of $ \PP^2 $, and denote
$$ P_i = \sbr{b_{i1}, b_{i2}, b_{i3}}, \qquad i = 1, 2, 3, $$
their coordinates. Let $ B = \br{b_{ij}} $ be the associated $ 3 \times 3 $ matrix. Show that $ P_1, P_2, P_3 $ lie in the same projective line if and only if $ \det B = 0 $.
\end{exercise**}

\pagebreak

\section{Points at infinity}

Given an affine curve $ C \subseteq \CC^2 $ and its projectivisation $ \overline{C} \subseteq \PP^2 $, we study the points at infinity of $ C $, that is the points of $ \overline{C} $ that do not lie on $ C $. Let us first recall the notation in use. Denote by $ U_2 $ the open set of $ \PP^2 $ defined by $ \CC^2 \cong U_2 = \cbr{x_2 \ne 0} \subseteq \PP^2 $, and let $ \PPP_2 = \PP^2 \setminus U_2 = \cbr{x_2 = 0} $ be the corresponding hyperplane or line at infinity. The homeomorphism is defined by inverses
$$ \function[\phi]{\CC^2}{U_2}{\br{x, y}}{\sbr{x, y, 1}}, \qquad \function[\psi]{U_2}{\CC^2}{\sbr{x_0, x_1, x_2}}{\sbr{\dfrac{x_0}{x_2}, \dfrac{x_1}{x_2}}}. $$
Let $ C $ be the affine curve
$$ C = \cbr{\br{x, y} \in \CC^2 \st f\br{x, y} = 0}, $$
where $ f \in \CC\sbr{x, y} $ is a polynomial of degree $ d $ with no repeated factors. The projectivisation of $ C $ is then the curve $ \overline{C} $ such that $ \overline{C} \cap U_2 = \phi\br{C} $, or equivalently such that $ \psi\br{\overline{C} \cap U_2} = C $. The curve $ \overline{C} $ is
$$ \overline{C} = \cbr{\sbr{x_0, x_1, x_2} \in \PP^2 \st P\br{x_0, x_1, x_2} = 0}, \qquad P\br{x_0, x_1, x_2} = x_2^df\br{\dfrac{x_0}{x_2}, \dfrac{x_1}{x_2}}. $$
where $ P $ is a homogeneous polynomial. Let $ f_i \in \CC\sbr{x, y} $ be the homogeneous polynomials of degree $ 0 \le i \le d $ with
$$ f\br{x, y} = f_0\br{x, y} + \dots + f_d\br{x, y}, $$
and note that
\begin{equation}
\label{eq:4}
P\br{x_0, x_1, x_2} = f_0\br{x_0, x_1}x_2^d + \dots + f_d\br{x_0, x_1}.
\end{equation}

\begin{definition}
The \textbf{points at infinity} of $ C $ are the points on $ \overline{C} \setminus \phi\br{C} $. We will often just write $ \overline{C} \setminus C $.
\end{definition}

How many points at infinity can there be? If $ \cbr{x_2 = 0} \subseteq \overline{C} $, if and only if $ x_2 $ divides $ P\br{x_0, x_1, x_2} $, then there are infinitely many. Assume $ \cbr{x_2 = 0} \not\subseteq \overline{C} $. Look at $ P\br{x_0, x_1, 0} $, and find solutions of $ P\br{x_0, x_1, 0} = 0 $ in $ \PP^1 \cong \PPP_2 $. The points at infinity of $ C $ are thus
$$ \overline{C} \setminus C = \overline{C} \cap \PPP_2 = \cbr{\sbr{x_0, x_1, 0} \in \PP^2 \st P\br{x_0, x_1, 0} = 0} = \cbr{\sbr{x_0, x_1} \in \PP^1 \st f_d\br{x_0, x_1} = 0}, $$
from $ \br{\ref{eq:4}} $, and under the identification $ \PPP_2 \cong \PP^1 $, that is a projective variety in $ \PPP_2 \cong \PP^1 $. It is natural to expect that such a projective variety consists of a finite number of points. This is what we will prove next.

\begin{lemma}
\label{lem:6.2}
Let $ Q \in \CC\sbr{x_0, x_1} $ be a non-zero homogeneous polynomial of degree $ d \ge 1 $. Then there are $ \alpha_i, \beta_i \in \CC $ with $ \br{\alpha_i, \beta_i} \ne \br{0, 0} $ for $ i = 1, \dots, d $ such that
$$ Q\br{x_0, x_1} = \prod_{i = 1}^d \br{\alpha_ix_0 + \beta_ix_1}. $$
Therefore,
$$ \cbr{\sbr{x_0, x_1} \in \PP^1 \st Q\br{x_0, x_1} = 0} = \cbr{P_i = \sbr{-\beta_i, \alpha_i}} \subseteq \PP^1. $$
\end{lemma}

\begin{note*}
The $ P_i $ need not be distinct.
\end{note*}

\begin{proof}
Let us pass to $ U_1 \cong \CC^1 \subseteq \PP^1 $, one of the two affine charts. Write
$$ Q\br{x_0, x_1} = \sum_{r = 0}^d a_rx_0^rx_1^{d - r} = x_1^d \cdot \sum_{r = 0}^e a_r\br{\dfrac{x_0}{x_1}}^r, \qquad e = \max\cbr{r \st a_r \ne 0}. $$
Define $ f \in \CC\sbr{x} $ as $ f\br{x} = \sum_{r = 0}^e a_rx^r $. By the fundamental theorem of algebra, in Theorem \ref{thm:2.4}, there are $ \lambda_1, \dots, \lambda_e \in \CC $ such that
$$ f\br{x} = a_e \cdot \prod_{i = 1}^e \br{x - \lambda_i}, $$

\pagebreak

where $ \lambda_i $ are the roots of $ f $, and hence
$$ Q\br{x_0, x_1} = x_1^d \cdot a_e \cdot \prod_{i = 1}^e \br{\dfrac{x_0}{x_1} - \lambda_i} = a_e \cdot x_1^{d - e} \cdot \prod_{i = 1}^e \br{x_0 - \lambda_ix_1}. $$
This proves Lemma \ref{lem:6.2}, if we set
$$ \br{\alpha_i, \beta_i} =
\begin{cases}
\br{1, -\lambda_i} & i < e \\
\br{a_e, -a_e\lambda_e} & i = e \\
\br{0, 1} & i > e
\end{cases}.
$$
The description that $ \cbr{Q = 0} \subseteq \PP^1 $ is clear, once we note that $ \br{\alpha_i, \beta_i} \ne \br{0, 0} $.
\end{proof}

We have proved the following.

\begin{theorem}
Let $ \overline{C} \subseteq \PP^2 $ be a projective curve defined by a polynomial of degree $ d $ that does not contain $ \PPP_2 $. Then $ \overline{C} \cap \PPP_2 $ is a non-empty set of at most $ d = \deg Q $ points.
\end{theorem}

\begin{definition}
Let $ C = \cbr{f = 0} \subseteq \CC^2 $ for $ f \in \CC\sbr{x, y} $ be an affine curve of degree $ d $ and let $ \overline{C} $ be its projectivisation, where, as usual, $ C = \psi\br{\overline{C} \cap U_2} $. Denote
$$ f = f_d + \dots + f_0, \qquad \deg f_i = i, \qquad f_d \not\equiv 0, $$
the decomposition of $ f $ into its homogeneous polynomial parts, so that
$$ P\br{x_0, x_1, x_2} = \sum_{i = 0}^d x_2^{d - i}f_i\br{x_0, x_1} = f_d\br{x_0, x_1} + \dots + f_0\br{x_0, x_1}x_2^d. $$
Then, if $ \br{\alpha_i, \beta_i} \in \CC^2 \setminus \cbr{\underline{0}} $ for $ i = 1, \dots, d $ are such that
$$ f_d\br{x_0, x_1} = \prod_{i = 1}^d \br{\alpha_ix_0 + \beta_ix_1}, $$
the affine lines
$$ \cbr{\alpha_ix + \beta_iy = 0} \subseteq \CC^2 $$
are the \textbf{asymptotes} of $ C $. The \textbf{points at infinity} at $ x_2 = 0 $ of $ C $ depend on the equation $ f_d\br{x_0, x_1} = 0 $, and are
$$ \overline{C} \setminus C = \cbr{\sbr{-\beta_i, \alpha_i}} \subseteq \PPP_2. $$
Each asymptote meets $ \overline{C} $ at the point $ \sbr{-\beta_i, \alpha_i} \in \PP^1 $, the line at infinity. \footnote{Exercise}
\end{definition}

\begin{remark}
It is clear from Lemma \ref{lem:6.2} that asymptotes are well-defined. Note that the asymptotes are lines in $ \CC^2 $ because $ \br{\alpha_i, \beta_i} \ne \br{0, 0} $.
\end{remark}

\begin{example}
Consider the affine curve
$$ C = \cbr{\br{x, y} \in \CC^2 \st x^2 + y^2 - 1 = 0}. $$
The projectivisation of $ C $ is
$$ \overline{C} = \cbr{\sbr{x_0, x_1, x_2} \in \PP^2 \st x_0^2 + x_1^2 - x_2^2 = 0}, $$
so that the points at infinity of $ C $ are given by
$$ \overline{C} \setminus C = \cbr{\sbr{x_0, x_1, 0} \in \PP^2 \st x_0^2 + x_1^2 = 0}. $$
This shows that $ C $ has two asymptotes, namely $ L_\pm = \cbr{x \pm iy = 0} $, and two points at infinity $ \cbr{\sbr{\pm i, 1, 0}} $.
\end{example}

\begin{exercise**}
Find the asymptotes of the affine curve given by the equation
$$ x^2y + y^3 + xy + x + 1 = 0. $$
\end{exercise**}

\begin{exercise**}
Write an example of an affine curve whose asymptotes include the lines
$$ x + 2y = 0, \qquad 4x - 3y = 0, \qquad 7x + 9y = 0. $$
\end{exercise**}

\pagebreak

\section{Smoothness and singularities}

\lecture{8}{Thursday}{25/10/18}

Smoothness is a very important notion in algebraic geometry, and in geometry in general. The idea is that an algebraic, affine or projective, curve $ C \subseteq \CC^2, \PP^2 $ will be called smooth at a point $ p $ if $ C $ does not have an angle, a corner, or a pinched point, etc. at $ p $. We are going to formalise this by requiring that we can make sense of the tangent line of $ C $ at $ p $, and this will involve derivatives of a defining equation, without repeated factors, of $ C $. When $ C $ is smooth at a point $ p $, topologically around $ p $ it will look like a two-dimensional small disc in the complex plane $ \CC $. In the following, we always assume that polynomials defining curves do not have repeated factors.

\begin{notation}
Given a function $ f\br{x_1, \dots, x_n} $, we will denote by $ f_{x_i} $ or $ \partial_{x_i}f $ the partial derivative of $ f $ with respect to $ x_i $.
\end{notation}

Let $ C = \cbr{f = 0} \subseteq \CC^2 $ for $ f \in \CC\sbr{x, y} $ and let $ \br{a, b} \in C $. Then the \textbf{tangent line} of $ C $ at the point $ \br{a, b} \in C $ is the line defined by the equation
$$ f_x\br{a, b}\br{x - a} + f_y\br{a, b}\br{y - b} = 0. $$

\begin{note*}
This equation defines a complex line if and only if either $ f_x\br{a, b} $ or $ f_y\br{a, b} $, or both, is not zero.
\end{note*}

\begin{definition}
The affine curve $ C $ is \textbf{smooth} at a point $ \br{a, b} \in C $ if at least one of $ f_x\br{a, b} $ and $ f_y\br{a, b} $ is not zero, so that the above equation defines a line in $ \CC^2 $. On the other hand if
$$ f_x\br{a, b} = f_y\br{a, b} = 0, $$
then $ \br{a, b} $ is called a \textbf{singular} point of $ C $. We will simply say that $ C $ is \textbf{smooth} if $ C $ is smooth at every point.
\end{definition}

\begin{example}
\hfill
\begin{itemize}
\item Any line $ C \subseteq \CC^2 $ is smooth.
\item The curve
$$ \cbr{x^2 + y^2 - 1 = 0} $$
is smooth.
\item The curve
$$ \cbr{y^2 - x^2\br{x + 1} = 0} $$
is singular in one point $ \br{0, 0} $. This kind of singularity is called a \textbf{node}.
\item The curve
$$ \cbr{y^2 - x^3 = 0} $$
is singular in one point $ \br{0, 0} $. This kind of singularity is called a \textbf{cusp}.
\end{itemize}
\end{example}

How about projective curves? We give a similar definition, but this time we will have three variables and three partial derivatives.

\begin{definition}
If a point $ p = \sbr{z_0, z_1, z_2} $ of a projective curve $ C = \cbr{P = 0} \subseteq \PP^2 $ for $ P \in \CC\sbr{x_0, x_1, x_2} $ homogeneous satisfies
$$ P_{x_i}\br{z_0, z_1, z_2} = 0, \qquad i = 0, 1, 2, $$
then we will say that $ C $ is \textbf{singular} at $ p $. Then $ C $ is \textbf{smooth} at $ p $ if it is not singular, and $ C $ is said to be \textbf{smooth} if it does not admit any singular point, so it is smooth at every point.
\end{definition}

\begin{lemma}
\label{lem:7.5}
Let $ C = \cbr{P = 0} \subseteq \PP^2 $ be a projective curve which does not contain the line $ \cbr{x_2 = 0} $, and let $ C_0 = \cbr{f = 0} \subseteq \CC^2 $ be the associated affine curve, where $ f\br{x, y} = P\br{x, y, 1} $. Then $ \br{a, b} $ is a singular point of $ C_0 $ if and only if $ \sbr{a, b, 1} $ is a singular point of $ C $.
\end{lemma}

\pagebreak

For the proof we need the following.

\begin{theorem}[Euler relation]
\label{thm:7.6}
Let $ P \in \CC\sbr{x_0, x_1, x_2} $ be a homogeneous polynomial of degree $ d $. Then the following relation holds at each point $ \sbr{x_0, x_1, x_2} \in \PP^2 $.
$$ x_0 \cdot P_{x_0} + x_1 \cdot P_{x_1} + x_2 \cdot P_{x_2} = d \cdot P. $$
\end{theorem}

\begin{example*}
Let
$$ P\br{x_0, x_1, x_2} = x_0^2 + x_1^2 + x_2^2. $$
Then $ P_{x_0} = 2x_0 $, $ P_{x_1} = 2x_1 $, and $ P_{x_2} = 2x_2 $. Thus
$$ x_0 \cdot P_{x_0} + x_1 \cdot P_{x_1} + x_2 \cdot P_{x_2} = 2\br{x_0^2 + x_1^2 + x_2^2} = d \cdot P. $$
\end{example*}

\begin{proof}
By Lemma \ref{lem:4.4}, for any $ \lambda \in \CC $ we have
$$ P\br{\lambda x_0, \lambda x_1, \lambda x_2} = \lambda^d \cdot P\br{x_0, x_1, x_2}. $$
We now compute the derivative with respect to $ \lambda $ of both sides of this equation. By the equality above we have
$$ \sum_{i = 0}^2 x_iP_{x_i}\br{\lambda x_0, \lambda x_1, \lambda x_2} = d\lambda^{d - 1}P\br{x_0, x_1, x_2}, \qquad \lambda \in \CC. $$
Thus, if we plug in $ \lambda = 1 $, we get the claim.
\end{proof}

\begin{proof}[Proof of Lemma \ref{lem:7.5}]
Let $ \br{a, b} \in C_0 $ be a singular point of $ C_0 $. Note that $ P\br{x, y, 1} = f\br{x, y} $ by construction, so $ P_{x_0}\br{x, y, 1} = f_x\br{x, y} $ and $ P_{x_1}\br{x, y, 1} = f_y\br{x, y} $. Then, since $ f\br{a, b} = 0 $ we have $ P\br{a, b, 1} = 0 $. Since $ f_x\br{a, b} = f_y\br{a, b} = 0 $, we have $ P_{x_0}\br{a, b, 1} = P_{x_1}\br{a, b, 1} = 0 $. Finally by Theorem \ref{thm:7.6}, we have
$$ P_{x_2}\br{a, b, 1} = x_0 \cdot P_{x_0}\br{a, b, 1} + x_1 \cdot P_{x_1}\br{a, b, 1} + x_2 \cdot P_{x_2}\br{a, b, 1} = dP\br{a, b, 1} = 0, $$
since everything is zero except $ P_{x_2}\br{a, b, 1} $. Thus, we have
$$ P_{x_i}\br{a, b, 1} = 0, \qquad i = 0, 1, 2. $$
The converse implication is proved similarly.
\end{proof}

\begin{exercise**}
Show that
\begin{itemize}
\item $ C = \cbr{x_0^2 + x_1^2 + x_2^2 = 0} $ is smooth,
\item $ C = \cbr{x_1^2x_0 - x_2^3 = 0} $ is singular at the point $ \sbr{1, 0, 0} $, and
\item any projective line is smooth.
\end{itemize}
\end{exercise**}

\begin{definition}
Let $ p = \sbr{z_0, z_1, z_2} $ be a smooth point of the projective curve $ C = \cbr{P = 0} $. The \textbf{projective tangent line} of the curve $ C = \cbr{P = 0} $ at the point $ p $ is given by the equation
\begin{equation}
\label{eq:5}
\sum_{i = 0}^2 P_{x_i}\br{z_1, z_2, z_3} \cdot x_i = 0.
\end{equation}
\end{definition}

\begin{note*}
The line is well-defined since the curve $ C $ is smooth at the point $ p $.
\end{note*}

\begin{proposition}
Let $ C \subseteq \PP^2 $ be a projective algebraic curve not containing the line $ \cbr{x_2 = 0} $. Then the affine line in $ U_2 $ associated to the projective tangent line at $ \sbr{a, b, 1} \in C $ is the tangent line at a smooth point $ \br{a, b} $ of the affine curve $ C_0 $ associated to $ C $ in $ U_2 $.
\end{proposition}

Equivalently, the projectivisation of the tangent line to $ C_0 \subseteq \CC^2 $ at $ \br{a, b} \in C_0 $ is the projective tangent line to the projectivisation $ C $ of $ C_0 $ at $ \sbr{a, b, 1} $.

\pagebreak

\begin{proof}
Assume $ C = \cbr{P = 0} \subseteq \PP^2 $ does not contain the line $ \cbr{x_2 = 0} $. Let $ f\br{x, y} = P\br{x, y, 1} $ and let $ C_0 = \cbr{f = 0} $. The affine line associated to $ \br{\ref{eq:5}} $ at the point $ \br{a, b} \in C_0 $ is given by the equation
$$ P_{x_0}\br{a, b, 1} \cdot x_0 + P_{x_1}\br{a, b, 1} \cdot x_1 + P_{x_2}\br{a, b, 1} \cdot x_2 = 0. $$
Since $ P\br{a, b, 1} = 0 $, by Theorem \ref{thm:7.6} we have
$$ P_{x_2}\br{a, b, 1} = -a \cdot P_{x_0}\br{a, b, 1} - b \cdot P_{x_1}\br{a, b, 1}. $$
Moreover, as above we have $ f_x\br{a, b} = P_{x_0}\br{a, b, 1} $ and $ f_y\br{a, b} = P_{x_1}\br{a, b, 1} $. Combining everything together we get
$$ f_x\br{a, b}\br{x - a} + f_y\br{a, b}\br{y - b} = 0, $$
which is the equation of the tangent line of $ C_0 $ at $ \br{a, b} $.
\end{proof}

\begin{theorem}
\label{thm:7.9}
Let $ C $ be a smooth projective curve. Then $ C $ is irreducible.
\end{theorem}

Assume that any two projective curves in $ \PP^2 $ intersect in at least one point, so there exists $ p \in C_1 \cap C_2 $. Later on we will prove this.

\begin{proof}
Suppose not. Then in particular,
$$ \cbr{P = 0} = C = C_1 \cup C_2 = \cbr{Q = 0} \cup \cbr{R = 0} = \cbr{Q \cdot R = 0}, $$
where $ C_1 = \cbr{Q = 0} $ and $ C_2 = \cbr{R = 0} $ are projective curves. We want to show that $ A = \sbr{a, b, c} \in C_1 \cap C_2 \ne \emptyset $ is a singular point for $ C $, which contradicts the assumption on $ C $. We have
$$ P_{x_i}\br{A} = \br{Q \cdot R}_{x_i}\br{A} = Q\br{A} \cdot R_{x_i}\br{A} + R\br{A} \cdot Q_{x_i}\br{A} = 0, \qquad i = 1, 2. $$
The last equality follows from the fact that $ Q\br{A} = R\br{A} = 0 $. Thus $ C $ is singular at $ A $ as claimed, a contradiction.
\end{proof}

\lecture{9}{Friday}{26/10/18}

\begin{example*}
An example of a reducible curve, where the two pieces have the same tangent line where they intersect. $ C_1 = \cbr{y - x^2 = 0} $ and $ C_2 = \cbr{y + x^2 = 0} $ has $ \br{0, 0} $ as the only point of intersection. The tangent line at $ \br{0, 0} $ to both $ C_1 $ and $ C_2 $ is $ y = 0 $. The definition implies that
$$ C = C_1 \cup C_2 = \cbr{\br{y - x^2}\br{y + x^2} = 0} = \cbr{y^2 - x^4 = 0} $$
is not smooth at $ \br{0, 0} $. Note that the tangent line at $ \br{0, 0} \in C $ for some affine curve $ C $ is given by the linear part of $ f = 0 $ where $ \cbr{f = 0} = C $. The equation
$$ f_x\br{0, 0}\br{x - 0} + f_y\br{0, 0}\br{y - 0} = 0 $$
is a linear approximation of $ C $ around $ \br{0, 0} $. Now $ y^2 - x^4 = 0 $ does not have a linear part. The best possible approximation is a double line $ y^2 = 0 $, the term of lowest degree of $ f $. Thus $ \br{0, 0} \in \cbr{y^2 - x^4 = 0} $ should not be a smooth point.
\end{example*}

\begin{remark}
The same reasoning shows that the curve $ C = \cbr{f = 0} $ defined by a polynomial $ f $ with a repeated factor, say $ f = g^2 \cdot h $ for $ g $ non-constant, is singular at all points of the curve $ \cbr{g = 0} $. This is why it is important that we assume that polynomials defining curves have no repeated factors in this section.
\end{remark}

\begin{theorem}
\label{thm:7.11}
Let $ C $ be an irreducible projective curve of degree $ d $. Then the number of singular points of $ C $ is at most $ d \cdot \br{d - 1} $. In particular it is finite.
\end{theorem}

We will prove this later on, after seeing some results on intersections of curves.

\begin{exercise**}
For which values of $ \lambda \in \CC $ does the algebraic curve
$$ y^2 - x\br{x - 1}\br{x - \lambda} = 0 $$
admit at least one singular point? For each of those values of $ \lambda $, what are the singular points?
\end{exercise**}

\pagebreak

\section{Projective transformations}

How do we move around points, or change coordinates, in $ \PP^n $? In linear algebra, that is in $ \CC^n $, we do that with linear maps $ L : \CC^n \to \CC^n $, that is functions such that
$$ L\br{\lambda v + \mu w} = \lambda L\br{v} + \mu L\br{w}, \qquad v, w \in \CC^n, \qquad \lambda, \mu \in \CC. $$
These correspond to $ n \times n $ matrices $ A = \br{a_{ij}} $ with coefficients in $ \CC $. Given such a matrix, we can define a linear function by
$$ \function[L]{\CC^n}{\CC^n}{\br{x_1, \dots, x_n}}{A \cdot \threebyone{x_1}{\vdots}{x_n} = \threebyone{\sum_{j = 1}^n a_{ij}x_j}{\vdots}{\sum_{j = 1}^n a_{nj}x_j}}, $$
and a linear function $ L $ gives a matrix by setting $ a_{ij} $ as the $ i $-th coefficient of the vector $ L\br{e_j} \in \CC^n $. How about in $ \PP^n = W / \sim $? Use matrices or linear transformations in $ \CC^{n + 1} $.

\begin{lemma}
\label{lem:8.1}
Assume that $ A $ is an $ \br{n + 1} \times \br{n + 1} $ matrix with coefficients in $ \CC $ such that $ \det A \ne 0 $, if and only if it is invertible. Then the function defined by
$$ \function[\Phi]{\PP^n}{\PP^n}{\sbr{x_0, \dots, x_n}}{\sbr{A \cdot \threebyone{x_0}{\vdots}{x_n}}} $$
is well-defined, and a bijection.
\end{lemma}

\begin{proof}
Since $ \det A \ne 0 $, we know from linear algebra that if
$$ A \cdot \threebyone{x_0}{\vdots}{x_n} = \underline{0}, $$
then
$$ \threebyone{x_0}{\vdots}{x_n} = \underline{0}. $$
If $ A $ is not invertible there is no associated $ \Phi $. Thus if $ x \in W = \CC^{n + 1} \setminus \cbr{\underline{0}} $, then $ A \cdot x \in W $. Moreover, if $ x, y \in W $ are such that $ \sbr{x} = \sbr{y} $, then there exists a non-zero $ \lambda \in \CC $ such that $ x = \lambda y $ and $ A \cdot x = \lambda A \cdot y $, which implies that $ \sbr{A \cdot x} = \sbr{A \cdot y} $. It follows that $ \Phi $ is well-defined. It is a bijection, with inverse given by the same kind of transformation obtained from the inverse matrix $ A^{-1} $.
\end{proof}

\begin{definition}
Any such function like $ \Phi $ in Lemma \ref{lem:8.1} is called a \textbf{projective transformation}.
\end{definition}

\begin{remark}
Note that an arbitrary $ \br{n + 1} \times \br{n + 1} $ matrix $ A $ does not define a well-defined function as above, because there might be non-zero vectors $ v \in \CC^{n + 1} $ such that $ A \cdot v = \underline{0} $, and thus $ \sbr{A \cdot v} $ would not define a point of projective space.
\end{remark}

\begin{example}
\label{eg:8.4}
You probably have encountered M\"obius transformations in complex analysis. They are rational functions $ f : \PP^1 \to \PP^1 $ of one complex variable $ z $
$$ f : z \mapsto \dfrac{az + b}{cz + d}, \qquad a, b, c, d \in \CC, \qquad ad - bc \ne 0. $$

\pagebreak

In terms of geometry, these are the projective transformations of $ \PP^1 $ to itself. Indeed, if $ \sbr{x_0, x_1} $ are the homogeneous coordinates on $ \PP^1 $, a projective transformation $ \Phi $ associated to a $ 2 \times 2 $ invertible matrix $ T $ is given by
$$ \function[\Phi]{\PP^2}{\PP^2}{\sbr{x_0, x_1}}{\sbr{A \cdot \br{x_0, x_1}} = \sbr{ax_0 + bx_1, cx_0 + dx_1}}, \qquad T = \twobytwo{a}{b}{c}{d}, $$
where $ T $ is invertible. If, as in Lemma \ref{lem:3.13}, we write
$$ \PP^1 = \CC \cup \cbr{\infty}, \qquad \cbr{\infty} = \cbr{x_1 = 0} = \cbr{\sbr{1, 0}}, $$
then if $ x_1 \ne 0 $,
$$ \sbr{x_0, x_1} = \sbr{\dfrac{x_0}{x_1}, 1} = \sbr{z, 1}, \qquad z = \dfrac{x_0}{x_1}, $$
and
$$ \Phi\sbr{z, 1} = \sbr{ax_0 + bx_1, cx_0 + dx_1} = \sbr{az + b, cz + d}, $$
and if $ cz + d \ne 0 $, that is $ \sbr{z, 1} \ne \sbr{-d, c} $, this is
$$ \Phi\sbr{z, 1} = \sbr{\dfrac{az + b}{cz + d}, 1} = \sbr{f\br{z}, 1}. $$
Here, unlike in complex analysis, the point $ \cbr{\infty} = \cbr{\sbr{1, 0}} $ plays no special role, and we see right away that
$$ \Phi\sbr{1, 0} = \sbr{a, c}, \qquad \Phi\sbr{-d, c} = \sbr{1, 0}. $$
\end{example}

\begin{theorem}
\label{thm:8.5}
Assume that $ P_1, P_2, P_3 $ are three non-collinear points in $ \PP^2 $, that is not on the same line. Then there exists a projective transformation $ \Phi : \PP^2 \to \PP^2 $ such that
$$ \Phi\br{P_1} = \sbr{1, 0, 0}, \qquad \Phi\br{P_2} = \sbr{0, 1, 0}, \qquad \Phi\br{P_3} = \sbr{0, 0, 1}. $$
\end{theorem}

\begin{remark*}
Every projective transformation $ \Phi = \sbr{A} $ is invertible. Just take $ \Phi^{-1} = \sbr{A^{-1}} $.
\end{remark*}

\begin{proof}
Let $ A $ be the transpose of the matrix defined in Exercise \ref{ex:19}, so
$$ P_i = \br{a_{1i}, a_{2i}, a_{3i}} \in \CC^3, \qquad A = \br{a_{ij}}. $$
Then, since $ P_1, P_2, P_3 $ are not collinear, it follows that $ \det A \ne 0 $ and $ A $ is invertible. Let $ B $ be the inverse matrix of $ A $ and let $ \Phi = \sbr{B} : \PP^2 \to \PP^2 $ be the projective transformation associated to the matrix $ B $. Then $ BP_i = e_i $, so
$$ \Phi\br{P_1} = \sbr{1, 0, 0}, \qquad \Phi\br{P_2} = \sbr{0, 1, 0}, \qquad \Phi\br{P_3} = \sbr{0, 0, 1}, $$
as desired.
\end{proof}

\begin{exercise**}
When do two linear transformations $ L, L' : \CC^{n + 1} \to \CC^{n + 1} $ give rise to the same projective transformation $ \PP^n \to \PP^n $?
\end{exercise**}

\begin{exercise**}
Show that if $ P_1, P_2, P_3 \in \PP^1_\CC $ are distinct points, there exists a unique projective transformation $ \Psi : \PP_1 \to \PP_1 $ such that
$$ \Psi\br{P_1} = \sbr{1, 0}, \qquad \Psi\br{P_2} = \sbr{0, 1}, \qquad \Psi\br{P_3} = \sbr{1, 1}. $$
\end{exercise**}

\begin{exercise**}
\label{ex:26}
Assume that $ P_1, P_2, P_3, P_4 \in \PP^2_\CC $ are four points such that no three of them lie in the same line. Show that there exists a unique projective transformation $ \Psi : \PP^2 \to \PP^2 $ such that
$$ \Psi\br{P_1} = \sbr{1, 0, 0}, \qquad \Psi\br{P_2} = \sbr{0, 1, 0}, \qquad \Psi\br{P_3} = \sbr{0, 0, 1}, \qquad \Psi\br{P_4} = \sbr{1, 1, 1}. $$
\end{exercise**}

\pagebreak

\begin{proof}[Proof of Exercise \ref{ex:26}]
Take a $ \Phi $ as in Theorem \ref{thm:8.5}. I can scale the representatives of the $ P_i $, so $ \sbr{v_i} = P_i $. Choose $ v_4 $ such that
$$ P_4 = \sbr{v_4}, \qquad v_4 = \sum_{i = 1}^3 \lambda_i v_i = \lambda_1 \cdot v_1 + \lambda_2 \cdot v_2 + \lambda_3 \cdot v_3, \qquad \lambda_i \in \CC, \qquad \lambda_i^*. $$
We are in $ \CC^3 $, and the $ v_1, v_2, v_3 $ are linearly independent, so they are a basis. If $ \lambda_i = 0 $ for some $ i $, the remaining vectors are in the same two-dimensional subspace of $ \CC $, contradicting non-collinearity in $ \PP^2 $. Take $ \lambda_i \cdot v_i $ as representatives for $ P_i $ for $ i = 1, 2, 3 $ and $ v_4 $ for $ P_4 $, so get a matrix $ A $ as before, so $ A \cdot e_i = P_i $ and
$$ A \cdot \threebyone{1}{1}{1} = \sum_{i = 1}^3 \lambda_iv_i = v_4, $$
so $ B = A^{-1} $, $ \Psi = \sbr{B} $, and
$$ \Psi\br{P_1} = \sbr{1, 0, 0}, \qquad \Psi\br{P_2} = \sbr{0, 1, 0}, \qquad \Psi\br{P_3} = \sbr{0, 0, 1}, \qquad \Psi\br{P_4} = \sbr{1, 1, 1}. $$
\end{proof}

There is a version of the previous statement in higher dimensions.

\begin{definition}
A \textbf{hyperplane} in $ \PP^n $ is the image of a subspace of dimension $ n $ in $ \CC^{n + 1} $ via the map $ \pi : W \to \PP^n $. Equivalently, it is the locus of points $ \sbr{x_0, \dots, x_n} $ of $ \PP^n $ satisfying some linear equation
$$ \sum_{i = 1}^n a_ix_i = 0, \qquad \br{a_0, \dots, a_n} \ne \underline{0}. $$
\end{definition}

\begin{example}
Projective lines are precisely the hyperplanes of $ \PP^2 $.
\end{example}

\begin{exercise**}
Let $ \SSS = \cbr{p_0, \dots, p_n, q} \subseteq \PP^n $ be a collection of $ n + 2 $ distinct points such that no $ n + 1 $ points of $ \SSS $ lie in a hyperplane. Denote by $ e_i $ for $ i = 0, \dots, n $ the vectors of the standard basis of $ \CC^{n + 1} $. Then there is a unique projective transformation $ f : \PP^n \to \PP^n $ such that
$$ f\br{p_i} = \sbr{e_i} = \sbr{0, \dots, 0, 1, 0, \dots, 0}, $$
for all $ i $ and $ f\br{q} = \sbr{1, \dots, 1} $. Sometimes such a set of points is called a \textbf{projective basis}, in analogy with bases of vector spaces.
\end{exercise**}

\begin{exercise**}
Let $ L $ be a line in $ \PP^2 $. Then given $ i = 0, 1, 2 $, there exists a projective transformation $ f : \PP^2 \to \PP^2 $ such that $ f\br{L} = \PPP_i = \cbr{x_i = 0} $.
\end{exercise**}

\begin{exercise**}
\label{ex:29}
Let $ C = \cbr{P = 0} \subseteq \PP^2 $ be a projective curve and let $ \Phi = \sbr{A} : \PP^2 \to \PP^2 $ be a projective transformation, a $ 3 \times 3 $ matrix $ A $. Show that
\begin{itemize}
\item $ \Phi\br{C} $ is again a projective curve of degree $ \deg \Phi\br{C} = \deg C $, in particular $ C $ is a line if and only if $ \Phi\br{C} $ is a line,
\item $ \Phi\br{C} $ is irreducible if and only if $ C $ is, and there is a natural bijection between the sets of components of the two curves,
\item $ C $ is smooth if and only if $ \Phi\br{C} $ is smooth,
\item if $ p \in C $ is a smooth point and $ l $ is the tangent line of $ C $ at $ p $ then $ \Phi\br{C} $ is smooth at the point $ \Phi\br{p} $ and $ \Phi\br{l} $ is the tangent line of $ \Phi\br{C} $ at $ \Phi\br{p} $, and
\item if $ D \subseteq \PP^2 $ is another projective curve, then $ \Phi $ induces a bijection between $ C \cap D $ and $ \Phi\br{C} \cap \Phi\br{D} $.
\end{itemize}
What is the equation of $ \Phi\br{C} $?
\end{exercise**}

\begin{remark}
As Exercise \ref{ex:29} suggests, one should think of curves only differing from each other via a projective transformation to be the same curve, since projective transformations preserve their properties. These transformations should be thought of as a change of a projective coordinate system.
\end{remark}

\pagebreak

\section{Resultants and weak B\'ezout}

\lecture{10}{Monday}{29/10/18}

Now we start studying how projective curves intersect in the projective plane, heading towards B\'ezout's theorem. Let $ C = \cbr{P = 0} $ and $ D = \cbr{Q = 0} $ be two projective curves of degree $ n $ and $ m $ defined by homogeneous polynomials $ P, Q \in \CC\sbr{x_0, x_1, x_2} $. We want to study
$$ C \cap D = \cbr{P = 0} \cap \cbr{Q = 0}, $$
where $ P $ and $ Q $ have no repeated factors, that is points $ \sbr{x_0, x_1, x_2} $ that are solutions up to scaling of the equations for $ C $ and $ D $,
$$ P\br{x_0, x_1, x_2} = 0, \qquad Q\br{x_0, x_1, x_2} = 0, \qquad \br{x_0, x_1, x_2} \ne \br{0, 0, 0}. $$
B\'ezout's theorem states that $ C \cap D $ has $ n \cdot m $ points, unless $ C $ and $ D $ have a common component, and count points with multiplicity.

\begin{example*}
If you do not use multiplicity, there might be less than $ n \cdot m $ points.
\begin{itemize}
\item Tangencies. Let $ C = \cbr{y = x^2} $ and $ D = \cbr{y = 0} $. In $ \PP^2 $, they intersect in $ 1 \ne \br{2}\br{1} = \deg C\deg D $ point in this case.
\item Singularities of $ C $ and $ D $. Let $ C $ be two lines and $ D $ be a line passing through the intersection of $ C $. Then there is $ 1 \ne \br{2}\br{1} = \deg C\deg D $ point of intersection.
\end{itemize}
Think of perturbing the equations.
\end{example*}

We first have to develop some algebraic tools, the resultant. We first take a step back to the case of polynomials in one variable and study solutions of $ p\br{x} = q\br{x} = 0 $ for polynomials $ p, q \in \CC\sbr{x} $. Let $ p $ and $ q $ be
$$ p\br{x} = a_0 + \dots + a_nx^n = \sum_{i = 0}^n a_ix^i, \qquad a_n \ne 0, \qquad a_i \in \CC, \qquad \deg p = n, $$
$$ q\br{x} = b_0 + \dots + b_mx^m = \sum_{i = 0}^m b_ix^i, \qquad b_m \ne 0, \qquad b_i \in \CC, \qquad \deg q = m. $$
When does $ p\br{x} = q\br{x} = 0 $ have solutions? Transform this question into linear algebra. The polynomials $ p $ and $ q $ have a common root, that is there is $ \lambda \in \CC $ such that $ p\br{\lambda} = q\br{\lambda} = 0 $, precisely if there is a non-constant polynomial $ l \in \CC\sbr{x} $ such that $ p\br{x} = l\br{x}r\br{x} $ and $ q\br{x} = l\br{x}s\br{x} $, where $ r $ and $ s $ are non-zero polynomials, which thus have $ \deg r \le n - 1 $ and $ \deg s \le m - 1 $.

\begin{lemma}
\label{lem:9.1}
The polynomials $ p $ and $ q $ have a common root if and only if there are non-zero polynomials $ r $ and $ s $ with $ \deg r \le n - 1 $ and $ \deg s \le m - 1 $ with
\begin{equation}
\label{eq:6}
p\br{x} \cdot s\br{x} - q\br{x} \cdot r\br{x} = 0,
\end{equation}
the zero polynomial.
\end{lemma}

\begin{proof}
By taking $ r $ and $ s $ in the previous discussion, it is clear that if $ p $ and $ q $ have a common root, then $ \br{\ref{eq:6}} $ holds. Conversely assume that $ \br{\ref{eq:6}} $ holds. There is a unique decomposition
$$ p\br{x} = cp_1\br{x}^{a_1} \dots p_k\br{x}^{a_k}, \qquad c \in \CC^*, \qquad a_i \in \NN^*, $$
where $ p_1, \dots, p_k $ are monic non-constant irreducible polynomials. Since
$$ p_1\br{x}^{a_1} \dots p_k\br{x}^{a_k} \mid q\br{x}r\br{x}, \qquad \deg r \le n - 1 < \sum_{i = 1}^k a_i \deg p_i, $$
at least one of the irreducible polynomials $ p_i\br{x} $ divides $ q\br{x} $, by irreducibility. It follows that $ p $ and $ q $ have a common factor and, by the fundamental theorem of algebra, that $ p $ and $ q $ have a common root.
\end{proof}

\pagebreak

We now show that $ \br{\ref{eq:6}} $ is a system of $ m + n $ equations in $ m + n $ variables. Now write $ r\br{x} $ and $ s\br{x} $ in terms of unknown coefficients. Let $ \underline{v} = \br{v_0, \dots, v_{n + m - 1}} \in \CC^{n + m} $ be defined by
$$ s\br{x} = v_0 + \dots + v_{m - 1}x^{m - 1} = \sum_{i = 0}^{m - 1} v_ix^i, \qquad -r\br{x} = v_m + \dots + v_{n + m - 1}x^{n - 1} = \sum_{i = 0}^{n - 1} v_{m + i}x^i. $$
Substitute these into $ p\br{x}s\br{x} - q\br{x}r\br{x} = 0 $, and get a big system of equations. Then $ \br{\ref{eq:6}} $ is
$$ \br{v_0a_0 + v_mb_0} + \dots + \br{\sum_{k = 0}^i \br{v_ka_{i - k} + v_{m + k}b_{i - k}}}x^i + \dots + \br{v_{m - 1}a_n + v_{n + m - 1}b_m}x^{n + m - 1} = 0. $$
Since this is a polynomial of degree $ n + m - 1 $, we thus have a system of $ n + m $ equations in $ n + m $ variables of the form
\begin{equation}
\label{eq:7}
A \cdot v = 0,
\end{equation}
where $ A $ is an $ \br{n + m} \times \br{n + m} $ matrix
$$ A =
\begin{pmatrix}
a_0 & & 0 & b_0 & & 0 \\
\vdots & \ddots & & \vdots & \ddots & \\
a_n & & a_0 & b_m & & b_0 \\
& \ddots & \vdots & & \ddots & \vdots \\
0 & & a_n & 0 & & b_m
\end{pmatrix},
$$
where there are $ m $ columns of $ a_i $ and $ n $ columns of $ b_i $. From linear algebra, we know that $ \br{\ref{eq:7}} $ has a non-trivial solution if and only if $ \det A = 0 $. This motivates the following definition.

\begin{definition}
Let $ p, q \in \CC\sbr{x} $ be as above. Then the \textbf{resultant} of $ p $ and $ q $ is the determinant of the $ \br{n + m} \times \br{n + m} $ matrix $ A^\intercal $,
$$ \R_{p, q} = \det A^\intercal = \det
\begin{pmatrix}
a_0 & \dots & a_n & & 0 \\
& \ddots & & \ddots & \\
0 & & a_0 & \dots & a_n \\
b_0 & \dots & b_m & & 0 \\
& \ddots & & \ddots & \\
0 & & b_0 & \dots & b_m
\end{pmatrix}.
$$
\end{definition}

Thus, Lemma \ref{lem:9.1} can be reformulated as the following.

\begin{theorem}
\label{thm:9.3}
Let $ p, q \in \CC\sbr{x} $ be two non-zero polynomials. Then, $ p $ and $ q $ have a common root if and only if $ \R_{p, q} = 0 $.
\end{theorem}

\begin{example}
\hfill
\begin{itemize}
\item Let
$$ p\br{x} = x^2 - 1, \qquad q\br{x} = x^2 + 2x + 1, $$
so
$$ a_0 = 1, \qquad a_1 = 0, \qquad a_2 = -1, \qquad b_0 = 1, \qquad b_1 = 2, \qquad b_2 = 1. $$
Then the resultant of $ p $ and $ q $ is the determinant of a $ 4 \times 4 $ matrix,
$$ \R_{p, q} = \det
\begin{pmatrix}
-1 & 0 & 1 & 0 \\
0 & -1 & 0 & 1 \\
1 & 2 & 1 & 0 \\
0 & 1 & 2 & 1
\end{pmatrix}.
$$
Check that the determinant is $ \R_{p, q} = 0 $. \footnote{Exercise} Thus, $ p $ and $ q $ have a common solution, $ x = -1 $.

\pagebreak

\item Let $ n = 1 $ and $ m = 4 $, so
$$ p\br{x} = a_0 + a_1x, \qquad q\br{x} = b_0 + b_1x + b_2x^2 + b_3x^3 + b_4x^4. $$
Then $ A $ is a $ 5 \times 5 $ matrix
$$ A =
\begin{pmatrix}
a_0 & 0 & 0 & 0 & b_0 \\
a_1 & a_0 & 0 & 0 & b_1 \\
0 & a_1 & a_0 & 0 & b_2 \\
0 & 0 & a_1 & a_0 & b_3 \\
0 & 0 & 0 & a_1 & b_4
\end{pmatrix}.
$$
\item Recall that $ p \in \CC\sbr{x} $ has a repeated root if and only if $ p $ and $ p' $ have a common root, that is by what precedes if and only if $ \R_{p, p'} = 0 $. If
$$ p\br{x} = ax^2 + bx + c, \qquad a \ne 0, $$
then
$$ \R_{p, p'} = \det \threebythree{c}{b}{a}{b}{2a}{0}{0}{b}{2a} = a\br{4ac - b^2}. $$
We see that $ -\R_{p, p'} = a \cdot \Delta $, where $ \Delta $ is the discriminant of the quadratic equation $ p\br{x} = 0 $.
\item Let $ n = 2 $ and $ m = 3 $, so
$$ p\br{x} = a_0 + a_1x + a_2x^2, \qquad q\br{x} = b_0 + b_1x + b_2x^2 + b_3x^3. $$
Then $ A $ is a $ 5 \times 5 $ matrix
$$ A =
\begin{pmatrix}
a_0 & 0 & 0 & b_0 & 0 \\
a_1 & a_0 & 0 & b_1 & b_0 \\
a_2 & a_1 & a_0 & b_2 & b_1 \\
0 & a_2 & a_1 & b_3 & b_2 \\
0 & 0 & a_2 & 0 & b_3
\end{pmatrix}.
$$
\end{itemize}
\end{example}

\lecture{11}{Thursday}{01/11/18}

In general, the resultant is useful because it tends to be easier to compute the determinant of a matrix than to factorise polynomials in order to determine whether they have a common root. Assume now that $ P, Q \in \CC\sbr{x_0, x_1, x_2} $ are homogeneous polynomials of degrees $ n $ and $ m $ respectively. We write $ P $ and $ Q $ as polynomials in $ x_0 $, with coefficients in $ \CC\sbr{x_1, x_2} $. Then
$$ P\br{x_0, x_1, x_2} = \sum_{i = 0}^n a_i\br{x_1, x_2}x_0^i, \qquad Q\br{x_0, x_1, x_2} = \sum_{j = 0}^m b_j\br{x_1, x_2}x_0^j, $$
where $ a_i \in \CC\sbr{x_1, x_2} $ is a homogeneous polynomial of degree $ n - i $, and $ b_j \in \CC\sbr{x_1, x_2} $ is homogeneous of degree $ m - j $. In particular, $ a_n = P\br{1, 0, 0} $ and $ b_m = Q\br{1, 0, 0} $ are constants.

\begin{definition}
\label{def:9.5}
Assume that $ P\br{1, 0, 0} \ne 0 $ and $ Q\br{1, 0, 0} \ne 0 $. The \textbf{resultant} of $ P $ and $ Q $ is the determinant of an $ \br{n + m} \times \br{n + m} $ matrix,
$$ \R_{P, Q}\br{x_1, x_2} = \det
\begin{pmatrix}
a_0\br{x_1, x_2} & \dots & a_n\br{x_1, x_2} & & 0 \\
& \ddots & & \ddots & \\
0 & & a_0\br{x_1, x_2} & \dots & a_n\br{x_1, x_2} \\
b_0\br{x_1, x_2} & \dots & b_m\br{x_1, x_2} & & 0 \\
& \ddots & & \ddots & \\
0 & & b_0\br{x_1, x_2} & \dots & b_m\br{x_1, x_2}
\end{pmatrix}.
$$
\end{definition}

The entries of the matrix above are homogeneous polynomials in $ \CC\sbr{x_1, x_2} $. If you specify $ x_1 = a $ and $ x_2 = b $ for $ a, b \in \CC $, then $ \R_{P, Q} $ is the resultant of $ P\br{x_0, a, b} $ and $ Q\br{x_0, a, b} $. We admit the following theorem, which can be proven using tools from commutative algebra.

\begin{theorem}
\label{thm:9.6}
Let $ P, Q \in \CC\sbr{x_0, x_1, x_2} $ be homogeneous polynomials of degrees $ n $ and $ m $, and assume that $ a_n, b_m \ne 0 $. Then $ P $ and $ Q $ have a common factor if and only if $ \R_{P, Q} \equiv 0 $, that is if $ \R_{P, Q}\br{x_1, x_2} = 0 $ for all $ x_1, x_2 \in \CC $.
\end{theorem}

\pagebreak

In fact, slightly more is true.

\begin{theorem}
\label{thm:9.7}
Let $ P, Q \in \CC\sbr{x_0, x_1, x_2} $ be homogeneous polynomials such that $ P\br{1, 0, 0}, Q\br{1, 0, 0} \ne 0 $. Then $ \R_{P, Q} \in \CC\sbr{x_1, x_2} $ is a homogeneous polynomial of degree $ nm $.
\end{theorem}

\begin{proof}
Let $ A $ be the $ \br{n + m} \times \br{n + m} $ matrix above, that is such that $ \R_{P, Q} = \det A $. Recall from linear algebra that
$$ \det A = \sum_{\sigma \in \SSS_{n + m}} \sgn \sigma\prod_{k = 1}^{n + m}A_{k, \sigma\br{k}}. $$
The entries of $ A $ are either zero or are homogeneous polynomials. We thus only need to check that for each $ \sigma \in \SSS_{n + m} $ such that $ A_{k, \sigma\br{k}} \ne 0 $ for all $ k $, $ \prod_{k = 1}^{n + m} A_{k, \sigma\br{k}} $ is of degree $ nm $. By definition of $ A $, the non-zero entries of $ A $ are
$$ A_{k, l} =
\begin{cases}
a_{l - k}\br{x_1, x_2} & k \le m, \ 0 \le l - k \le n \\
b_{l - k + m}\br{x_1, x_2} & k \ge m + 1, \ 0 \le l - k + m \le m
\end{cases}.
$$
Then
$$ \deg a_{l - k} = n - \br{l - k}, \qquad \deg b_{l - k + m} = m - \br{l - k + m} = k - l, $$
so that when non-zero, $ \prod_{k = 1}^{n + m} A_{k, \sigma\br{k}} $ has degree
$$ \deg \prod_{k = 1}^{n + m} A_{k, \sigma\br{k}} = \sum_{k = 1}^m \br{n - \br{\sigma\br{k} - k}} + \sum_{k = m + 1}^{m + n} \br{k - \sigma\br{k}} = nm + \sum_{k = 1}^{m + n} k - \sum_{k = 1}^{m + n} \sigma\br{k}. $$
The last two terms are equal because $ \sigma $ is a permutation, so this is equal to $ nm $ for all permutations $ \sigma \in \SSS_{m + n} $, and this proves that $ \R_{P, Q} $ is a homogeneous polynomial of degree $ nm $.
\end{proof}

Recall that homogeneous polynomials in two variables always factor as a product of linear homogeneous polynomials. We can now prove a weak form of B\'ezout's theorem. We will refine the statement later on.

\begin{theorem}[Weak B\'ezout theorem]
\label{thm:9.8}
Let $ C, D \subseteq \PP^2 $ be projective curves of degrees $ \deg C = n $ and $ \deg D = m $ respectively. Then
\begin{enumerate}
\item $ C $ and $ D $ intersect in at least one point, that is $ C \cap D $ is not empty, and
\item $ C $ and $ D $ have at most $ \#\cbr{C \cap D} \le nm $ distinct points of intersection, unless they have a common component.
\end{enumerate}
\end{theorem}

\begin{proof}
Given finitely many projective curves $ C_1, \dots, C_k \subseteq \PP^2 $, one can always find a point $ p \in \PP^2 $ in the complement $ \PP^2 \setminus \bigcup_{i = 1}^k C_i $. \footnote{Exercise}
\begin{enumerate}
\item We first prove $ 1 $. Let $ p \in \PP^2 $ be a point that lies neither on $ C $ nor on $ D $, so not on $ C \cup D $. There is a projective transformation
$$ \function[\Phi]{\PP^2}{\PP^2}{p}{\sbr{1, 0, 0}}. $$
Transform $ C $ and $ D $ using $ \Phi $, so replace them with $ \Phi\br{C} $ and $ \Phi\br{D} $. Note that $ \Phi\br{C} $ and $ \Phi\br{D} $ are projective curves of degrees $ \deg \Phi\br{C} = \deg C $ and $ \deg \Phi\br{D} = \deg D $, and that $ \#\cbr{C \cap D} = \#\cbr{\Phi\br{C} \cap \Phi\br{D}} $, by Exercise \ref{ex:29}. Thus, after replacing $ C $ with $ \Phi\br{C} $ and $ D $ with $ \Phi\br{D} $ we may assume that $ \sbr{1, 0, 0} \notin C \cup D $. Let $ P, Q \in \CC\sbr{x_0, x_1, x_2} $ be homogeneous polynomials of degrees $ n $ and $ m $ with no repeated factors that define $ C $ and $ D $, that is $ C = \cbr{P = 0} $ and $ D = \cbr{Q = 0} $. So $ P\br{1, 0, 0} \ne 0 $ and $ Q\br{1, 0, 0} \ne 0 $ if and only if $ \sbr{1, 0, 0} \notin C \cup D $. Using the projective transformation to ensure this, $ P\br{1, 0, 0} \ne 0 $ and $ Q\br{1, 0, 0} \ne 0 $. We assume that $ C $ and $ D $ have no common component, as the result is trivial if they do. Denote by $ R $ the resultant polynomial of $ P $ and $ Q $, $ R\br{x_1, x_2} = \R_{P, Q}\br{x_1, x_2} $ for $ x_1, x_2 \in \CC $, and factor it. By Theorem \ref{thm:9.6} and Theorem \ref{thm:9.7}, $ R $ is a homogeneous polynomial of degree $ nm $ that is not identically zero. By Lemma \ref{lem:6.2}, there are $ \br{\alpha_i, \beta_i} \in \CC^2 \setminus \cbr{\br{0, 0}} $ for $ i = 1, \dots, nm $ such that
$$ R\br{x_1, x_2} = \prod_{i = 1}^{nm} \br{\alpha_ix_1 + \beta_ix_2}. $$

\pagebreak

Fix $ \br{a, b} \in \CC^2 \setminus \cbr{\br{0, 0}} $, and let $ f, g \in \CC\sbr{x} $ be the polynomials defined by $ f\br{x} = P\br{x, a, b} $ and $ g\br{x} = Q\br{x, a, b} $. Then, $ R\br{a, b} = \R_{f, g} $. In particular, if $ \br{a, b} = \br{-\beta_1, \alpha_1} $, $ R\br{-\beta_1, \alpha_1} = 0 $, and by Theorem \ref{thm:9.3}, there is $ \lambda \in \CC $ such that $ P\br{\lambda, -\beta_1, \alpha_1} = f\br{\lambda} = g\br{\lambda} = Q\br{\lambda, -\beta_1, \alpha_1} = 0 $, so $ f\br{x_0} $ and $ g\br{x_0} $ have a common root $ \lambda $. Since $ \br{-\beta_1, \alpha_1} \ne \br{0, 0} $, $ \br{\lambda, \beta_1, \alpha_1} \ne \br{0, 0, 0} $, so that $ p = \sbr{\lambda, -\beta_1, \alpha_1} $ is a well-defined point of $ \PP^2 $ and is on both $ C $ and $ D $, so $ p \in C \cap D $.

\lecture{12}{Friday}{02/11/18}

\item We will show that if $ C \cap D $ contains at least $ nm + 1 $ distinct points, $ C $ and $ D $ have a common factor. Let $ \SSS = \cbr{p_1, \dots, p_{nm + 1}} $ be any set of $ nm + 1 $ distinct points and denote by $ L_{i, j} $ the unique line containing $ p_i $ and $ p_j $ for $ 1 \le i, j \le nm + 1 $. For each $ i $, denote by $ \sbr{x_0^i, x_1^i, x_2^i} $ the coordinates of $ p_i $. The point $ x = \sbr{x_0, x_1, x_2} \in \PP^2 $ belongs to $ L_{i, j} $ if and only if $ \det A = 0 $, where
\begin{equation}
\label{eq:8}
A_{i, j} = \threebythree{x_0}{x_0^i}{x_0^j}{x_1}{x_1^i}{x_1^j}{x_2}{x_2^i}{x_2^j}.
\end{equation}
Let $ p \in \PP^2 $ be any point that lies neither on $ C $ nor $ D $ nor on any $ L_{i, j} $, that is $ p \notin C \cup D \cup \bigcup_{i, j} L_{i, j} $. Can apply a projective transformation
$$ \function[\Phi]{\PP^2}{\PP^2}{p}{\sbr{1, 0, 0}}. $$
Taking images along $ \Phi $, the image of $ \SSS $ is a set of $ nm + 1 $ distinct points and the image of $ L_{i, j} $ by $ \Phi $ is the unique line through $ \Phi\br{p_i} $ and $ \Phi\br{p_j} $. As in the proof of $ 1 $, after replacing $ C, D, \SSS $ by their images by $ \Phi $, we may assume that $ \sbr{1, 0, 0} \notin C \cup D $ and that $ \sbr{1, 0, 0} $ lies on no line through two points $ p_i, p_j \in \SSS $. In particular, by $ \br{\ref{eq:8}} $,
$$ \det \threebythree{1}{x_0^i}{x_0^j}{0}{x_1^i}{x_2^j}{0}{x_2^i}{x_2^j} \ne 0, $$
that is $ \br{x_1^i, x_2^i} \ne \br{0, 0} $ for all $ i $, otherwise determinant is zero, so that $ \sbr{x_1^i, x_2^i} $ is a well-defined point of $ \PP^1 $, and $ \sbr{x_1^i, x_2^i} \ne \sbr{x_1^j, x_2^j} $ for all $ i \ne j $. Let $ P, Q \in \CC\sbr{x_0, x_1, x_2} $ be homogeneous polynomials of degrees $ n $ and $ m $ that define $ C $ and $ D $, that is $ C = \cbr{P = 0} $ and $ D = \cbr{Q = 0} $. Since $ \sbr{1, 0, 0} \notin C \cup D $, $ P\br{1, 0, 0} \ne 0 $ and $ Q\br{1, 0, 0} \ne 0 $. Denote by $ R $ the resultant $ \R_{P, Q} $ of $ P $ and $ Q $. This is homogeneous of degree $ nm $ and factors into linear factors
$$ R\br{x_1, x_2} = \prod_{i = 1}^{nm}\br{\alpha_ix_1 + \beta_ix_2}, \qquad \br{\alpha_i, \beta_i} \ne \br{0, 0}, $$
so $ \cbr{R = 0} \subseteq \PP^1 $ has at most $ nm $ distinct elements. Now assume $ C \cap D $ contains at least $ nm + 1 $ points and let $ \SSS \subseteq C \cap D $ be a set of $ nm + 1 $ distinct points. Set $ \br{\alpha_i, \beta_i} = \br{-x_2^i, x_1^i} $ for $ i = 1, \dots, nm + 1 $. By construction, for all $ i $, $ f_i\br{x} = P\br{x_0, x_1^i, x_2^i} $ and $ g_i\br{x} = Q\br{x_0, x_1^i, x_2^i} $ have a common root so that $ \R_{f_i, g_i} = 0 $. But we have $ \R_{f_i, g_i} = R\br{x_1^i, x_2^i} $, so that $ \br{\alpha_ix_1 + \beta_ix_2} $ is a factor of the polynomial $ R\br{x_1, x_2} $. Since $ \sbr{x_1^i, x_2^i} \ne \sbr{x_1^j, x_2^j} $ these factors are distinct, so $ \cbr{\sbr{x_1^i, x_2^i}} \subseteq \PP^1 $ has at least $ nm + 1 $ distinct points and
\begin{equation}
\label{eq:9}
R\br{x_1, x_2} = \prod_{i = 1}^{nm + 1} \br{\alpha_ix_1 + \beta_ix_2}S\br{x_1, x_2},
\end{equation}
for some, possibly constant, homogeneous polynomial $ S $. If $ R\br{x_1, x_2} $ is not identically zero, by Theorem \ref{thm:9.7}, it has degree $ nm $. Thus, $ \br{\ref{eq:9}} $ shows that $ R $ is identically zero, because the degree of the polynomial on the right hand side of $ \br{\ref{eq:9}} $ is at least $ nm + 1 $ if this polynomial is not identically zero. Thus, by Theorem \ref{thm:9.6}, $ P $ and $ Q $ have a common factor and $ C $ and $ D $ have a common component.
\end{enumerate}
\end{proof}

This finishes the proof of Theorem \ref{thm:7.9}, and now we can also prove Theorem \ref{thm:7.11}, stated before.

\pagebreak

\begin{proof}[Proof of Theorem \ref{thm:7.11}]
Use B\'ezout's theorem. Let $ C = \cbr{P = 0} $ for $ P $ a polynomial of degree $ d $ defining $ C $. The singular points are solutions $ \sbr{x_1, x_2, x_3} $ at
$$ P = 0, \qquad P_{x_0} = 0, \qquad P_{x_1} = 0, \qquad P_{x_2} = 0. $$
Without loss of generality we may assume that there exists $ i = 0, 1, 2 $ such that $ Q = P_{x_i} $ is not zero, otherwise $ P $ is constant. Thus $ Q $ is a homogeneous polynomial of degree $ d - 1 $. If $ p $ is a singular point of $ C $ then $ P\br{p} = Q\br{p} = 0 $. Clearly the opposite is not true. Let $ D = \cbr{Q = 0} $. Then $ D $ is another projective curve of degree at most $ d - 1 $ and the intersection $ C \cap D $ contains all the singular points of $ C $. Moreover, since $ C $ is irreducible, it follows that $ C $ and $ D $ do not have any common component. By Theorem \ref{thm:9.8}, it follows that the number of intersection points of $ C $ and $ D $ is at most $ \deg C\deg D = d \cdot \br{d - 1} $ and the claim follows.
\end{proof}

\begin{proposition}[Pascal's mystic hexagon]
Let $ C \subseteq \PP^2 $ be an irreducible conic and let $ p_1, \dots, p_6 \in C $ be six distinct points that form a hexagon, that is no three of the points $ p_1, \dots, p_6 $ lie on a projective line. Then the points of intersection of lines passing through opposite sides are collinear.
\end{proposition}

\begin{proof}
Assume that $ p_1, \dots, p_6 $ are ordered such that the lines $ L_1, \dots, L_6 $, with $ L_i $ the unique line through $ p_i $ and $ p_{i + 1} $, form the sides of a hexagon. Denote by $ D_1 $ and $ D_2 $ the cubic curves
$$ D_1 = L_1 \cup L_3 \cup L_5, \qquad D_2 = L_2 \cup L_4 \cup L_6. $$
Both cubic curves are reducible by definition, and both contain the points $ p_1, \dots, p_6 $. Let
$$ q_1 = L_1 \cap L_4, \qquad q_2 = L_3 \cap L_6, \qquad q_3 = L_5 \cap L_2 $$
be the not necessarily distinct points of intersection of opposite sides. We want to prove that there is a projective line $ L $ through $ q_1, q_2, q_3 $. First note that if $ q_1, q_2, q_3 $ are not distinct, there is a projective line through $ q_1, q_2, q_3 $ by Exercise \ref{ex:18}. We therefore assume that $ q_1, q_2, q_3 $ are three distinct points. The points $ q_1, q_2, q_3 $ are not in the set $ \cbr{p_1, \dots, p_6} $ because otherwise, one of the lines $ L_1, \dots, L_6 $ would have to contain at least three of the points $ p_1, \dots, p_6 $. Since $ C $ is irreducible, it contains none of the lines $ L_1, \dots, L_6 $. In particular, $ C $ has no common component with $ D_1 $ or with $ D_2 $. Since
$$ C \cap D_1 \supseteq \cbr{p_1, \dots, p_6}, \qquad C \cap D_2 \supseteq \cbr{p_1, \dots, p_6}, $$
and since $ C $ and $ D_1 $ and $ C $ and $ D_2 $ have no common component, their intersections consist of at most $ \br{2}\br{3} = 6 $ points and therefore
$$ C \cap D_1 = C \cap D_2 = \cbr{p_1, \dots, p_6}. $$
This shows that the points $ q_1, q_2, q_3 $ do not lie on $ C $. I will construct another cubic, having seven points of intersection with $ C $. Let $ p_0 \in C $ be a point that does not belong to the set $ \cbr{p_1, \dots, p_6} $. In particular, the point $ p_0 $ does not lie on $ D_1 $ or on $ D_2 $. Let $ P $ and $ Q $ be homogeneous polynomials that define the cubic curves $ D_1 $ and $ D_2 $, products of the equations of the lines, that is
$$ D_1 = \cbr{P = 0}, \qquad D_2 = \cbr{Q = 0}. $$
Since $ p_0 \notin D_1 \cup D_2 $, $ P\br{p_0} \ne 0 $ and $ Q\br{p_0} \ne 0 $, so that there exists $ \sbr{\lambda, \mu} \in \PP^1 $ such that $ \lambda P\br{p_0} + \mu Q\br{p_0} = 0 $, such as $ \sbr{-Q\br{p_0}, P\br{p_0}} $. Consider the cubic curve
$$ D = \cbr{\lambda P + \mu Q = 0} \subseteq \PP^2, $$
where $ \lambda P + \mu Q $ is a homogeneous polynomial of degree three. The points $ p_1, \dots, p_6 $ lie on $ D_1 \cap D_2 $, hence they satisfy $ P\br{p_i} = Q\br{p_i} = 0 $ for all $ i $, so $ \br{\lambda P + \mu Q}\br{p_i} = 0 $, and $ p_1, \dots, p_6 \in D $. Since $ p_0 \in D $, the intersection $ C \cap D $ thus contains at least seven distinct points $ p_0, \dots, p_6 $. By B\'ezout's theorem, this implies that $ C $ and $ D $ have a common component, and since $ C $ is irreducible, that has to be $ C $ and $ C \subseteq D $. If $ Q $ is a homogeneous polynomial of degree two that defines $ C $, there is a homogeneous polynomial $ S $ of degree one such that
$$ D = \cbr{Q \cdot S = 0} = C \cup \cbr{S = 0}, $$
of which $ \cbr{S = 0} $ has to be a line. Let $ L $ be the projective line $ L = \cbr{S = 0} $ that I was looking for. Since the points $ q_1, q_2, q_3 \in D_1 \cap D_2 $, they also lie on $ D $. We have seen that $ q_1, q_2, q_3 \notin C $, thus, they lie on $ L $.
\end{proof}

\lecture{13}{Monday}{05/11/18}

Lecture 13 is a problems class.

\pagebreak

\section{Conics}

\lecture{14}{Thursday}{08/11/18}

In $ \RR^2 $ there are three types of conics, which are projective curves of degree two,
\begin{enumerate}
\item ellipse, which is compact and therefore it does not admit any point at infinity,
\item parabola, which admits a unique point at infinity, and
\item hyperbola, which admits two points at infinity.
\end{enumerate}
We have seen how looking at them in projective space eliminates the difference, but we still have examples with only one point, or without any points, such as
$$ x^2 + y^2 = 0, \qquad x^2 + y^2 = -1. $$
In $ \CC^2 $, case $ 1 $ cannot happen because no affine curve is compact or, in other words, any affine curve has a point at infinity, and we know that in any case there are infinitely many points. Let $ C = \cbr{P = 0} $, where $ P $ has degree two for $ P \in \CC\sbr{x_0, x_1, x_2} $. By Theorem \ref{thm:9.8}, the number of points at infinity in the line at infinity $ \cbr{x_2 = 0} $ of any conic $ C $ is either one or two.

\begin{example}
\hfill
\begin{itemize}
\item $ \sbr{0, 1, 0} $ is the only point at infinity of
$$ \cbr{x_2x_1 - x_0^2 = 0}, $$
since $ x_2 = 0 $, so $ x_0^2 = 0 $.
\item $ \sbr{1, \pm i, 0} $ are the two points at infinity of
$$ \cbr{x_0^2 + x_1^2 + x_2^2 = 0}. $$
\end{itemize}
\end{example}

We now prove that all irreducible conics are the same up to projective equivalence.

\begin{theorem}
\label{thm:10.2}
Let $ C $ be an irreducible conic, if and only if $ P $ is irreducible. Then there exists a projective transformation $ \Psi : \PP^2 \to \PP^2 $ such that
$$ \Psi\br{C} = \cbr{x_2^2 + x_1x_0 = 0}. $$
\end{theorem}

\begin{remark}
Note that this equation is the same as
$$ x_0^2 + x_1^2 + x_2^2 = 0 $$
up to projective transformation, via
$$ x_0 \mapsto x_0 + ix_1, \qquad x_1 \mapsto x_0 - ix_1, \qquad x_2 \mapsto x_2. $$
\end{remark}

\begin{proof}
By Theorem \ref{thm:7.11} there exists a smooth point $ p \in C $. After taking a projective transformation we may assume that $ p = \sbr{0, 1, 0} $ and that the tangent line of $ C $ at the point $ p $ has equation
$$ x_0 = 0, $$
by Exercise \ref{ex:29}. Let $ C = \cbr{P = 0} $, where $ P \in \CC\sbr{x_0, x_1, x_2} $ is a homogeneous polynomial of degree two. We may write
$$ P\br{x_0, x_1, x_2} = ax_0^2 + bx_1^2 + cx_2^2 + dx_0x_1 + ex_0x_2 + fx_1x_2, \qquad a, b, c, d, e, f \in \CC. $$
The tangent line of $ C $ at $ \sbr{0, 1, 0} $ is given by
$$ \sum_{i = 0}^2 x_i \cdot P_{x_i}\br{0, 1, 0} = x_0 \cdot P_{x_0}\br{0, 1, 0} + x_1 \cdot P_{x_1}\br{0, 1, 0} + x_2 \cdot P_{x_2}\br{0, 1, 0} = 0. $$

\pagebreak

But we know that this line is $ x_0 = 0 $ and therefore
$$ P_{x_1}\br{0, 1, 0} = P_{x_2}\br{0, 1, 0} = 0. $$
Compute these, and see that they are $ b $ and $ f $, so it follows that $ b = f = 0 $ and
$$ P\br{x_0, x_1, x_2} = ax_0^2 + cx_2^2 + dx_0x_1 + ex_0x_2 = cx_2^2 + x_0\br{ax_0 + dx_1 + ex_2}. $$
Want to change coordinates to get $ x_2^2 + x_1x_0 = 0 $. Let
$$ A = \threebythree{1}{0}{0}{a}{d}{e}{0}{0}{\sqrt{c}}, $$
where $ \sqrt{c} $ denotes any one of the complex square roots of $ c $. Check that $ A $ is invertible. Assume that $ \det A = d \cdot \sqrt{c} = 0 $. Then either $ c = 0 $ or $ d = 0 $. If $ c = 0 $ then
$$ P = x_0\br{ax_0 + dx_1 + ex_2}, $$
which is not irreducible. If $ d = 0 $ then
$$ P = cx_2^2 + ax_0^2 + ex_0x_2, $$
which can be factored, being a homogeneous polynomial in two variables. In both cases, $ P $ is not irreducible, which contradicts the assumption. Then $ \det A \ne 0 $. Let $ \Psi : \PP^2 \to \PP^2 $ be the projective transformation associated to $ A $, by $ \Psi = \sbr{A} $. Then if $ \sbr{z_0, z_1, z_2} = \Psi\br{\sbr{x_0, x_1, x_2}} $, we have
$$ z_0 = x_0, \qquad z_1 = ax_0 + dx_1 + ex_2, \qquad z_2 = \sqrt{c}x_2, $$
and the equation of $ \Psi\br{C} $ becomes
$$ z_2^2 + z_1z_0 = 0, $$
as claimed. Convince yourself that this is the same that you get by doing $ P\br{A^{-1}\br{z_0, z_1, z_2}} $. \footnote{Exercise}
\end{proof}

\begin{corollary}
\label{cor:10.4}
Let $ C $ be a conic. Then $ C $ is smooth if and only if it is irreducible.
\end{corollary}

\begin{proof}
By Theorem \ref{thm:7.9}, if $ C $ is reducible then it is not smooth, so if $ C $ is smooth then it is irreducible. Assume now that $ C $ is irreducible. Then by Theorem \ref{thm:10.2}, after taking a projective transformation we may assume that $ C $ is given by the equation
$$ x_2^2 + x_0x_1 = 0, $$
which defines a smooth conic, by Exercise \ref{ex:29}.
\end{proof}

\begin{remark}
In general it is not true that if $ C $ is irreducible then $ C $ is smooth, for higher degree curves.
\end{remark}

\begin{example}
Let
$$ C = \cbr{x_2^3 - x_0x_1^2 = 0} \subseteq \PP^2. $$
Then $ C $ is singular at the point $ \sbr{1, 0, 0} $ but $ C $ is irreducible otherwise $ C $ would contain a line. Check that $ C $ does not contain any line. \footnote{Exercise}
\end{example}

\begin{exercise**}
\label{ex:30}
\hfill
\begin{itemize}
\item Show that for every reducible conic $ C $ there exists a projective transformation $ \Psi : \PP^2 \to \PP^2 $ such that
$$ \Psi\br{C} = \cbr{x_0^2 + x_1^2 = 0}. $$
\item Show that for any linear homogeneous polynomial $ L\br{x_0, x_1, x_2} $, there exists a projective transformation $ \Psi : \PP^2 \to \PP^2 $ such that
$$ \Psi\br{C} = \cbr{x_0^2 = 0}, $$
where $ C = \cbr{L^2 = 0} $.
\end{itemize}
\end{exercise**}

\pagebreak

In conclusion, if $ C = \cbr{f = 0} $ is a projective curve defined by a homogeneous polynomial $ f $ of degree two, which could be reducible or the square of a linear form, then after a change of coordinates, by a projective transformation, $ C $ is of one of the following three forms.
\begin{itemize}
\item A double line
$$ x_0^2 = 0. $$
This according to our definitions is not actually a curve of degree two, but of degree one.
\item Two distinct lines intersecting at a point
$$ x_0^2 + x_1^2 = 0. $$
\item An irreducible and smooth conic
$$ x_0^2 + x_1^2 + x_2^2 = 0. $$
\end{itemize}
These three forms are clearly distinct, that is they cannot be brought into one another via a projective transformation.

\begin{remark}
There exists a natural bijection between $ \PP^1 $ and the conic
$$ C = \cbr{x_2^2 + x_1x_0 = 0} \subseteq \PP^2, $$
defined by
$$ \function[f]{\PP^1}{C \subseteq \PP^2}{\sbr{z_0, z_1}}{\sbr{z_0^2, -z_1^2, z_0z_1}}, $$
which satisfies the equation of $ C $. Check that this is a bijection. \footnote{Exercise} Thus, it follows by Theorem \ref{thm:10.2} that any irreducible conic admits a natural bijection with $ \PP^1 $ and therefore with the sphere
$$ \cbr{\br{x, y, z} \in \RR^3 \st x^2 + y^2 + z^2 = 1} \subseteq \RR^3. $$
Thus, the affine curve defined by the equation $ x^2 + y^2 = 1 $ admits a bijection with the sphere minus two distinct points.
\end{remark}

\begin{remark}
The bijection between a smooth conic and $ \PP^1 $, of which there are actually many, can be seen geometrically as follows. Fix a point $ p \in C $, and look at the set $ S $ of lines through $ p $. On the one hand, $ S $ is in bijection with $ C $ itself, via the map that sends a line $ L $ through $ p $ to the other point of $ L \cap C $, which we take to be $ p $ itself if $ L $ is the tangent line to $ C $ in $ p $. On the other hand, $ S $ is also naturally in bijection with $ \PP^1 $, in the following way. The space of lines in $ \PP^2 $ can be identified itself with $ \PP^2 $. Every line has an equation $ ax_0 + bx_1 + cx_2 = 0 $ with $ \br{a, b, c} \ne \br{0, 0, 0} $, and this represents the same line as another equation $ a'x_0 + b'x_1 + c'x_2 = 0 $ if and only if $ \sbr{a, b, c} = \sbr{a', b', c'} $ as points of $ \PP^2 $. Moreover, the space of lines passing through $ p = \sbr{z_0, z_1, z_2} $ is given by the equation $ az_0 + bz_1 + cz_2 = 0 $ inside this $ \PP^2 $ with coordinates $ \sbr{a, b, c} $. Here, $ a, b, c $ play the role usually played by $ x_0, x_1, x_2 $, and $ z_0, z_1, z_2 $ are numbers. This identifies the space of lines through $ p $ with a copy of $ \PP^1 $. The following is another way. Fix equations $ L_1\br{x_0, x_1, x_2} $ and $ L_2\br{x_0, x_1, x_2} $ passing through $ p $. Then every other line passing through $ p $ has equation $ \lambda L_1 + \mu L_2 = 0 $ for a uniquely determined point $ \sbr{\lambda, \mu} \in \PP^1 $. \footnote{Exercise} This also identifies the space of lines through $ p $ with a $ \PP^1 $.
\end{remark}

\begin{exercise**}
\label{ex:31}
Let $ C \subseteq \PP^2 $ be a conic. Show that there exists a symmetric $ 3 \times 3 $ matrix $ A = \br{a_{ij}} $ such that
$$ P\br{z_0, z_1, z_2} = \sum_{i, j = 0}^2 a_{ij}z_iz_j $$
is the homogeneous polynomial which defines $ C $. Show that $ C $ is irreducible if and only if $ \det A \ne 0 $.
\end{exercise**}

More generally, the rank of this matrix determines if the conic is a double line, a pair of distinct lines, or a smooth conic.

\pagebreak

\section{Multiplicities and strong B\'ezout}

In order to refine the statement of B\'ezout's theorem, we need to introduce the intersection multiplicity of curves $ C, D \subseteq \PP^2 $ at a point $ p \in \PP^2 $. This will encode both how singular $ p $ is as a point of $ C $ and $ D $ and the relative position, or tangency, of $ C $ and $ D $ at $ p $. We start by defining a number that measures just the singularity of one of the two curves at $ p $. If $ f\br{x} \in \CC\sbr{x} $ is a polynomial of one variable, the multiplicity of $ f $ in some $ \alpha \in \CC $ is the number of times that the factor $ \br{x - \alpha} $ appears in the factorisation of $ f $ in linear factors, so $ \max\cbr{d \st \br{x - \alpha}^d \mid f\br{x}} $. Let
$$ f\br{x} = a \cdot \br{x - \lambda_1}^{a_1} \dots \br{x - \lambda_k}^{a_k}. $$
If $ \alpha = \lambda_i $, the multiplicity is $ a_i $. The multiplicity is zero if $ \alpha $ is not a root, that is $ f\br{\alpha} \ne 0 $. In order to generalise the definition to polynomials in more variables, we can observe that this multiplicity is $ k $ if and only if we have
$$ f^{\br{0}}\br{\alpha} = \dots = f^{\br{k - 1}}\br{\alpha} = 0, \qquad f^{\br{k}}\br{\alpha} \ne 0. $$
By convention, $ f^{\br{0}} = f $.

\begin{example*}
If multiplicity is one, then $ f\br{\alpha} = 0 $ and $ f'\br{\alpha} \ne 0 $.
\end{example*}

\begin{notation}
Let $ f \in \CC\sbr{x_0, \dots, x_n} $ and let $ \alpha \in \NN^{n + 1} $ be a multi-index. Recall that $ \abs{\alpha} = \alpha_0 + \dots + \alpha_n $. Denote
$$ \partial^\alpha f = f_{x_0^{\alpha_0} \dots x_n^{\alpha_n}} = \dfrac{\partial^{\abs{\alpha}} f}{\partial x_0^{\alpha_0} \dots \partial x_n^{\alpha_n}}, $$
and recall that for all $ \alpha $, $ \partial^\alpha f $ is a polynomial, and that $ \partial^\alpha f \equiv 0 $ whenever all its coefficients are zero. Set $ \partial^{\br{0, \dots, 0}} f = f $.
\end{notation}

\begin{example*}
Let $ n = 1 $. Then $ \partial^{\br{1, 1}} f = f_{x_1x_0} = f_{x_0x_1} $.
\end{example*}

\begin{definition}
Let $ f \in \CC\sbr{x_0, \dots, x_n} $ be a polynomial and $ p = \br{a_0, \dots, a_n} \in \CC^{n + 1} $ be a point. The \textbf{multiplicity} of $ f $ at $ p $ is
$$ \mult_p f = \min\cbr{\abs{\alpha} \st \partial^\alpha f\br{a_0, \dots, a_n} \ne 0} = \max\cbr{k \in \NN \st \forall \abs{\alpha} < k, \ \partial^\alpha f\br{a_0, \dots, a_n} = 0}. $$
Let $ C = \cbr{P = 0} \subseteq \PP^2 $ be a projective curve defined by a homogeneous polynomial $ P \in \CC\sbr{x_0, x_1, x_2} $ with no repeated factors. The multiplicity of $ C $ at $ p = \sbr{a, b, c} \in \PP^2 $ is
$$ \mult_p C = \mult_{\br{a, b, c}} P. $$
\end{definition}

Want to check
$$ \mult_{\br{\lambda a, \lambda b, \lambda c}} P = \mult_{\br{a, b, c}} P. $$
This is true as $ \partial^\alpha P\br{\lambda a, \lambda b, \lambda c} = \lambda^{\deg P - \abs{\alpha}}\partial^\alpha P\br{a, b, c} $, and the left hand side is zero if and only if $ \partial^\alpha P\br{a, b, c} $ is zero. In other words, this is the order of vanishing of $ f $ at $ p $.

\lecture{15}{Friday}{09/11/18}

Let $ C = \cbr{P = 0} $ be a projective curve and $ p \in \PP^2 $. Then the following holds.
\begin{itemize}
\item $ \mult_p C = 0 $ if and only if $ P\br{p} = \partial^{\br{0, 0, 0}} P\br{p} \ne 0 $, that is if and only if $ p \notin C $.
\item $ \mult_p C = 1 $ if and only if $ P\br{p} = \partial^{\br{0, 0, 0}} P\br{p} = 0 $ and there is $ \alpha $ with $ \abs{\alpha} = 1 $ such that $ \partial^{\alpha} P\br{p} \ne 0 $. Since the only indices $ \alpha $ with $ \abs{\alpha} = 1 $ are $ \br{1, 0, 0}, \br{0, 1, 0}, \br{0, 0, 1} $, this happens if and only if at least one of $ P_{x_0}\br{p}, P_{x_1}\br{p}, P_{x_2}\br{p} $ is non-zero, if and only if $ p $ is not a singular point of $ C $. Thus, $ \mult_p C = 1 $ if and only if $ p $ is a smooth point of $ C $.
\item Similarly $ \mult_p C \ge 2 $ if and only if $ p $ is a singular point of $ C $.
\end{itemize}

\pagebreak

\begin{example}
\hfill
\begin{itemize}
\item The curve with equation
$$ f\br{x_0, x_1, x_2} = x_0^2x_1 + x_0x_1x_2 $$
has multiplicity three at $ p = \br{0, 0, 0} $.
\begin{itemize}
\item $ \abs{\alpha} = 0 $ gives $ \partial^{\br{0, 0, 0}} f\br{p} = f\br{p} = 0 $.
\item $ \abs{\alpha} = 1 $ gives
\begin{itemize}
\item $ \partial^{\br{1, 0, 0}} f\br{p} = f_{x_0}\br{p} = \br{2x_0x_1 + x_1x_2}\br{0, 0, 0} = 0 $,
\item $ \partial^{\br{0, 1, 0}} f\br{p} = f_{x_1}\br{p} = \br{x_0^2 + x_0x_2}\br{0, 0, 0} = 0 $, and
\item $ \partial^{\br{0, 0, 1}} f\br{p} = f_{x_2}\br{p} = \br{x_0x_1}\br{0, 0, 0} = 0 $.
\end{itemize}
\item $ \abs{\alpha} = 2 $ gives $ \partial^\alpha f\br{p} = 0 $ for all $ \alpha $ with $ \abs{\alpha} = 2 $.
\item But $ \partial^{\br{2, 1, 0}} f\br{p} = f_{x_0^2x_1}\br{p} = 2 $.
\end{itemize}
\item The curve with equation
$$ P\br{x_0, x_1, x_2} = x_0^2x_2 - x_1^2\br{x_1 + x_2} $$
has multiplicity two at $ p = \sbr{0, 0, 1} $. Indeed,
\begin{itemize}
\item $ P_{x_0} = 2x_0x_2 $ vanishes at $ p $,
\item $ P_{x_1} = -3x_1^2 - 2x_1x_2 $ vanishes at $ p $,
\item $ P_{x_2} = x_0^2 - x_1^2 $ vanishes at $ p $, and
\item $ P_{x_0x_0} = 2x_2 $ does not vanish at $ p $.
\end{itemize}
\end{itemize}
\end{example}

\begin{exercise**}
\label{ex:32}
Multiplicity behaves well under projective transformations. Assume that $ C = \cbr{P = 0} $ is a projective curve and that $ \chi $ is a projective transformation. Show that
$$ \mult_p C = \mult_{\chi\br{p}} \chi\br{C}. $$
A hint is that partial derivatives are linear maps.
\end{exercise**}

\begin{exercise**}
\label{ex:33}
Let $ \overline{C} = \cbr{P = 0} $ be a projective curve that does not contain the line $ \cbr{x_2 = 0} $. Denote by $ f\br{x, y} = P\br{x, y, 1} $ and let $ C = \cbr{f = 0} $ be the associated affine curve. Let $ \br{a, b} \in C $. Then
$$ \mult_{\sbr{a, b, 1}} \overline{C} = \mult_{\br{a, b}} f. $$
\end{exercise**}

\begin{note*}
Another way to think about multiplicity $ \mult_p f $ of $ f \in \CC\sbr{x_0, \dots, x_n} $ at $ p \in \CC^{n + 1} $ is exactly the lowest degree of terms with non-zero coefficients in the Taylor expansion of $ f $ around the point $ p $, given by
$$ \mult_p f = \sum_{\alpha \in \NN^{n + 1}} \dfrac{\partial^\alpha f}{\prod_{i = 0}^n \alpha_i!}\br{p}\prod_{i = 0}^n \br{x_i - p_i}^{\alpha_i}. $$
If $ p = \br{0, \dots, 0} $, then this coincides with $ f $.
\end{note*}

\begin{remark}
\label{rem:11.4}
A consequence of Exercise \ref{ex:32} and Exercise \ref{ex:33} is that $ \mult_p C \le \deg C $ for all $ p \in C $. Indeed, if $ f \in \CC\sbr{x, y} $ is a polynomial of degree $ d $, it is clear that $ \mult_{\br{0, 0}} f \le d $, so that $ \mult_{\sbr{0, 0, 1}} C \le d $. For any $ p \in \PP^2 $, let
$$ \function[\Phi]{\PP^2}{\PP^2}{p}{\sbr{0, 0, 1}}. $$
Then $ \mult_p C = \mult_{\sbr{0, 0, 1}} \Phi\br{C} $, and the result follows because $ \Phi\br{C} $ is a curve of degree $ \deg C $. Why? Suppose $ \deg C = n $. Pick a monomial $ x_{i_1} \dots x_{i_n} $ that appears with non-zero coefficient in $ P $. Then $ P_{x_{i_1} \dots x_{i_n}}\br{p} \ne 0 $ for $ p \in \PP^2 $.
\end{remark}

\begin{lemma}
\label{lem:11.5}
Let $ P \in \CC\sbr{x_0, x_1} $ be a homogeneous polynomial of degree $ d > 0 $, and denote $ \cbr{P = 0} = \cbr{p_1, \dots, p_k} \subseteq \PP^1 $. Then,
$$ \sum_{i = 1}^k \mult_{p_i} P = d, $$
and, in particular, $ k \le d $.
\end{lemma}

\begin{example*}
Let $ P = x_0^2 $ then $ \cbr{P = 0} = \cbr{\sbr{0, 1}} $ then $ \mult_{\sbr{0, 1}} x_0^2 = 2 $. If $ a \ne 0 $ then $ \mult_{\sbr{a, b}} x_0^2 = 0 $.
\end{example*}

\pagebreak

This is essentially the statement that a degree $ d $ polynomial in one variable has $ d $ roots when counted with multiplicity.

\begin{proof}
As in the proof of Lemma \ref{lem:6.2}, we may write
$$ P\br{x_0, x_1} = \lambda x_0^{d - e} \cdot \prod_{i \in I} \br{x_1 - a_ix_0}^{d_i}, \qquad \lambda \ne 0, \qquad d_i, e \in \NN, \qquad \sum_{i \in I} d_i = e, $$
where $ a_i \in \CC $ are such that $ a_i \ne a_j $ and $ a_i \ne 0 $ for all $ i \ne j \in I $. Note that in the expression of $ P $, $ e $ is not necessarily distinct from zero, in which case $ I = \emptyset $ and the product is empty, or from $ d $. Let us denote
$$ \cbr{p_1, \dots, p_k} =
\begin{cases}
\cbr{\sbr{1, a_i}}_{i \in I} \cup \cbr{\sbr{0, 1}} & 0 < d < e \\
\cbr{\sbr{0, 1}} & e = 0 \\
\cbr{\sbr{1, a_i}}_{i \in I} & e = d
\end{cases}.
$$
It is easy to check from the definition of multiplicity that, for each $ i $, $ \mult_{\sbr{1, a_i}} P = d_i $ and $ \mult_{\sbr{0, 1}} P = d - e $, and the claim follows from $ \sum_{i \in I} d_i = e $.
\end{proof}

\lecture{16}{Monday}{12/11/18}

Multiplicity is the measure of the singularity of $ C $ at $ p $. Using multiplicities of curves, one can already improve Theorem \ref{thm:9.8}. We will not prove the following, but rather prove directly the strong version of B\'ezout's theorem, which will have the following as a corollary.

\begin{theorem}
\label{thm:11.6}
Let $ C_1 $ and $ C_2 $ be two plane projective curves with no common components of degree $ n $ and $ m $ respectively. Let $ C_1 \cap C_2 = \cbr{p_1, \dots, p_k} $. Then
$$ k \le \sum_{i = 1}^k \mult_{p_i} C_1 \cdot \mult_{p_i} C_2 \le n \cdot m. $$
\end{theorem}

In particular, it follows that $ k \le n \cdot m $, as in Theorem \ref{thm:9.8}. Using multiplicities like this is still not enough to attain equality. For example, for a line tangent to a conic at a point, the multiplicity of both curves at the intersection point is one, but the product of the degrees is two. We have to define a multiplicity of intersection of the two curves, that on top of their singularities also keeps track of how they interact. To also detect tangencies, have to look at the multiplicity of the resultant. Let us start by proving the following.

\begin{lemma}
\label{lem:11.7}
Let $ P, Q \in \CC\sbr{x_0, x_1, x_2} $ be homogeneous polynomials such that $ P\br{1, 0, 0} \ne 0 $, $ Q\br{1, 0, 0} \ne 0 $, $ \deg P = n $, and $ \deg Q = m $. Let $ p = \sbr{z_0, z_1, z_2} \in \PP^2 $ be such that $ p \ne \sbr{1, 0, 0} $ and let $ r = \mult_p P $ and $ s = \mult_p Q $. Then if $ \R_{P, Q}\br{x_1, x_2} = \det R\br{x_1, x_2} $ is the resultant of $ P $ and $ Q $, we have
$$ \mult_{\sbr{z_1, z_2}} \R_{P, Q} \ge r \cdot s. $$
\end{lemma}

\begin{proof}
After applying a projective transformation we may assume that $ p = \sbr{0, 0, 1} $, by Exercise \ref{ex:32}. Note that $ \mult_{\sbr{0, 1}} R\br{x_1, x_2} = \mult_0 R\br{y, 1} $, since $ R $ is homogeneous. We may write
$$ P = \sum_{i = 0}^n a_i\br{x_1, x_2}x_0^i, \qquad Q = \sum_{i = 0}^m b_i\br{x_1, x_2}x_0^i, $$
where $ a_i $ and $ b_i $ are homogeneous polynomials. Let
$$ f\br{x, y} = P\br{x, y, 1} = \sum_{i = 0}^n a_i\br{y, 1}x^i = \sum_{i = 0}^n \widetilde{a_i}\br{y}x^i, \qquad \widetilde{a_i}\br{y} = a_i\br{y, 1}, $$
and similarly let
$$ g\br{x, y} = Q\br{x, y, 1} = \sum_{i = 0}^m b_i\br{y, 1}x^i = \sum_{i = 0}^m \widetilde{b_i}\br{y}x^i, \qquad \widetilde{b_i}\br{y} = b_i\br{y, 1}. $$

\pagebreak

Then $ \mult_{\br{0, 0}} f = r $ and $ \mult_{\br{0, 0}} g = s $. In particular, since the minimum degree of any monomial that appears on $ f $ with non-zero coefficient is $ r $, it follows that $ \mult_0 \widetilde{a_i}\br{y} \ge r - i $ if $ i < r $, that is $ \widetilde{a_i}\br{y} = y^{r - i} \cdot A_i\br{y} $ if $ i < r $, and similarly $ \widetilde{b_i}\br{y} = y^{s - i} \cdot B_i\br{y} $ if $ i < s $, for some polynomials $ A_i $ and $ B_i $ in $ y $. Note that by Remark \ref{rem:11.4}, we have $ r \le n $ and $ s \le m $. By Definition \ref{def:9.5}, it follows that
$$ R\br{y, 1} =
\begin{pmatrix}
y^r \cdot A_0\br{y} & \dots & y^0 \cdot A_r\br{y} & \dots & A_n\br{y} & & 0 \\
& \ddots & & \ddots & & \ddots & \\
0 & & y^r \cdot A_0\br{y} & \dots & y^0 \cdot A_r\br{y} & \dots & A_n\br{y} \\
y^s \cdot B_0\br{y} & \dots & y^0 \cdot B_s\br{y} & \dots & B_m\br{y} & & 0 \\
& \ddots & & \ddots & & \ddots & \\
0 & & y^s \cdot B_0\br{y} & \dots & y^0 \cdot B_s\br{y} & \dots & B_m\br{y}
\end{pmatrix}.
$$
Want to show $ \mult_0 \det R\br{y, 1} \ge r \cdot s $. Let $ R_1\br{y} $ be the matrix obtained by multiplying the $ i $-th row of $ R\br{y, 1} $ by $ y^{s - i + 1} $ for any $ i \le s $, and multiplying its $ \br{m + j} $-th row by $ y^{r - j + 1} $ for any $ j \le r $. Then we obtain
$$ R_1\br{y} =
\begin{pmatrix}
y^{r + s} \cdot A_0\br{y} & \dots & y^s \cdot A_r\br{y} & \dots & y^s \cdot A_n\br{y} & & 0 \\
& \ddots & & \ddots & & \ddots & \\
0 & & y^{r + 1} \cdot A_0\br{y} & \dots & y^1 \cdot A_r\br{y} & \dots & y^1 \cdot A_n\br{y} \\
y^{r + s} \cdot B_0\br{y} & \dots & y^r \cdot B_s\br{y} & \dots & y^r \cdot B_m\br{y} & & 0 \\
& \ddots & & \ddots & & \ddots & \\
0 & & y^{s + 1} \cdot B_0\br{y} & \dots & y^1 \cdot B_s\br{y} & \dots & y^1 \cdot B_m\br{y}
\end{pmatrix}.
$$
Now let $ R_2\br{y} $ be the matrix obtained by dividing the $ i $-th column of $ R_1\br{y} $ by $ y^{r + s + 1 - i} $ for any $ i \le r + s $. Then we obtain
$$ R_2\br{y} =
\begin{pmatrix}
A_0\br{y} & \dots & A_r\br{y} & \dots & y^s \cdot A_n\br{y} & & 0 \\
& \ddots & & \ddots & & \ddots & \\
0 & & A_0\br{y} & \dots & A_r\br{y} & \dots & y \cdot A_n\br{y} \\
B_0\br{y} & \dots & B_s\br{y} & \dots & y^r \cdot B_m\br{y} & & 0 \\
& \ddots & & \ddots & & \ddots & \\
0 & & B_0\br{y} & \dots & B_s\br{y} & \dots & y \cdot B_m\br{y}
\end{pmatrix}.
$$
In particular $ \det R_2 $ is a polynomial in $ y $ and it follows from linear algebra that
\begin{align*}
\det R\br{y, 1}
& = \det R_1\br{y} \cdot y^{-s} \cdot \dots \cdot y^{-1} \cdot y^{-r} \cdot \dots \cdot y^{-1}
= \det R_1\br{y} \cdot y^{-\tfrac{s\br{s + 1}+r\br{r + 1}}{2}} \\
& = \det R_2\br{y} \cdot y^{r + s} \cdot \dots \cdot y^1 \cdot y^{-\tfrac{s\br{s + 1} + r\br{r + 1}}{2}}
= \det R_2\br{y} \cdot y^{\tfrac{\br{r + s + 1}\br{r + s}}{2} - \tfrac{s\br{s + 1}+r\br{r + 1}}{2}} \\
& = \det R_2\br{y} \cdot y^{rs}.
\end{align*}
Since $ \det R_2\br{y} $ is a polynomial, it follows that $ \mult_{\sbr{0, 1}} \R_{P, Q} = \mult_0 \det R\br{y, 1} \ge r \cdot s $, where for the first equality it is essential that $ R $ is homogeneous, and the claim follows.
\end{proof}

Inspired by Lemma \ref{lem:11.7} above, we can now define the intersection number of two curves at a given point.

\begin{definition}
\label{def:11.8}
Let $ C = \cbr{P = 0} \subseteq \PP^2 $ and $ D = \cbr{Q = 0} \subseteq \PP^2 $ be projective curves defined by homogeneous polynomials $ P, Q \in \CC\sbr{x_0, x_1, x_2} $ with no repeated factor, and assume that $ \sbr{1, 0, 0} \notin C \cup D $.
\begin{itemize}
\item Assume that $ C $ and $ D $ have no common component, and let $ \cbr{p_1, \dots, p_k} = C \cap D $, with $ \sbr{a_i, b_i, c_i} = p_i $. Assume that $ \sbr{1, 0, 0} $ lies on none of the lines through $ p_i $ and $ p_j $, where $ 1 \le i, j \le k $. The \textbf{intersection multiplicity}, or \textbf{intersection number}, of $ C $ and $ D $ at $ p = \sbr{a, b, c} \in \PP^2 $ is
$$ \I\br{p, C, D} = \I\br{p, P, Q} =
\begin{cases}
\mult_{\sbr{b, c}} \R_{P, Q}\br{x_1, x_2} & p \in C \cap D \\
0 & p \notin C \cap D
\end{cases}.
$$
\item If $ E $ is a common component of $ C $ and $ D $, set $ \I\br{p, C, D} = \infty $ for all $ p \in E $.
\end{itemize}
\end{definition}

\pagebreak

\begin{remark}
As in the proof of Theorem \ref{thm:9.8}, the assumption on $ \sbr{1, 0, 0} $ guarantees that if $ p_i = \sbr{a_i, b_i, c_i} \in C \cap D $, then $ \br{b_i, c_i} \ne \br{0, 0} $, so that $ \sbr{b_i, c_i} \in \PP^1 $, and that $ p_i $ is the only point of $ C \cap D $ with coordinates $ \sbr{\lambda, b_i, c_i} $ for some $ \lambda \in \CC $. In other words, it guarantees that $ \cbr{\sbr{b_i, c_i} \st 1 \le i \le k} $ is a set of $ k $ distinct points of $ \PP^1 $.
\end{remark}

Recall that given $ p, C, D $, we may assume that the hypotheses of Definition \ref{def:11.8} are satisfied after a projective transformation $ \Psi : \PP^2 \to \PP^2 $. The following exercise shows that intersection numbers can be computed in any coordinate system for which the assumptions on the point $ \sbr{1, 0, 0} $ are satisfied.

\begin{exercise**}
Let $ \Psi : \PP^2 \to \PP^2 $ be a projective transformation, and let $ C, D \subseteq \PP^2 $ be projective curves and $ p \in \PP^2 $. Assume that $ p \ne \sbr{1, 0, 0} $ and $ \Psi\br{p} \ne \sbr{1, 0, 0} $, and that $ \sbr{1, 0, 0} \notin C \cup D \cup \Psi\br{C} \cup \Psi\br{D} $, and also that $ \sbr{1, 0, 0} $ does not lie on any line through two points of $ C \cap D $ and of $ \Psi\br{C} \cap \Psi\br{D} $. Show that
$$ \I\br{p, C, D} = \I\br{\Psi\br{p}, \Psi\br{C}, \Psi\br{D}}. $$
\end{exercise**}

\begin{note*}
These numbers are well-defined because of the assumptions on the two curves. This seems hard to do by hand. See Remark \ref{rem:12.9}.
\end{note*}

\begin{remark}
\label{rem:11.10}
Assume that $ C $ and $ D $ have no common component, and let $ \cbr{p_i = \sbr{a_i, b_i, c_i} \st 1 \le i \le k} = C \cap D $. Then, by Theorem \ref{thm:9.3}, $ \R_{P, Q}\br{b_i, c_i} = 0 $ for all $ i = 1, \dots, k $, so that $ \I\br{p_i, C, D} > 0 $. This shows that $ \I\br{p, C, D} \ne 0 $ if and only if $ p \in C \cap D $.
\end{remark}

\begin{theorem}[Strong B\'ezout theorem]
\label{thm:11.11}
Let $ C, D \subseteq \PP^2 $ be projective curves of degrees $ n $ and $ m $ that have no common component. Let $ C \cap D = \cbr{p_i = \sbr{a_i, b_i, c_i} \st 1 \le i \le k} $. Then
$$ \sum_{i = 1}^k \I\br{p_i, C, D} = n \cdot m. $$
\end{theorem}

\begin{proof}
After projective transformation, we may assume that $ \sbr{1, 0, 0} $ is contained in none of the lines $ L_{i, j} $ through $ p_i $ and $ p_j $ where $ 1 \le i < j \le k $. Let $ R\br{x_1, x_2} $ be the resultant of $ P $ and $ Q $. As is recalled in Remark \ref{rem:11.10}, the $ k $ points $ \sbr{b_i, c_i} \in \PP^1 $ are distinct and by definition, $ \I\br{p_i, C, D} = \mult_{\sbr{b_i, c_i}} R\br{x_1, x_2} $. By Theorem \ref{thm:9.6}, $ R\br{x_1, x_2} $ is a homogeneous polynomial of degree $ n \cdot m $, so that the claim follows from Lemma \ref{lem:11.5}.
\end{proof}

\lecture{17}{Thursday}{15/11/18}

\begin{example}
Consider the curves $ C_1 $ and $ C_2 $ defined by
$$ C_1 = \cbr{x_0x_2 - x_1^2 = 0}, \qquad C_2 = \cbr{x_0x_2 + x_1^2 = 0}. $$
We want to compute $ \I\br{p, C_1, C_2} $ for $ p = \sbr{0, 0, 1} $. As $ \sbr{1, 0, 0} \in C_1 \cap C_2 $, we first need to change variables. We consider the projective transformation $ \Psi\br{\sbr{x_0, x_1, x_2}} = \sbr{x_1, x_0, x_2} $, so that
$$ \Psi\br{C_1} = \cbr{x_1x_2 - x_0^2 = 0}, \qquad \Psi\br{C_2} = \cbr{x_1x_2 + x_0^2 = 0}, \qquad \Psi\br{C_1} \cap \Psi\br{C_2} = \cbr{\sbr{0, 1, 0}, \sbr{0, 0, 1}}. $$
Note that $ \Psi\br{\sbr{0, 0, 1}} = \sbr{0, 0, 1} $. The resultant of $ \Psi\br{C_1} $ and $ \Psi\br{C_2} $ is
$$ R\br{x_1, x_2} = \det
\begin{pmatrix}
x_1x_2 & 0 & -1 & 0 \\
0 & x_1x_2 & 0 & -1 \\
x_1x_2 & 0 & 1 & 0 \\
0 & x_1x_2 & 0 & 1
\end{pmatrix}
= 4x_1^2x_2^2. $$
Thus
$$ \I\br{\sbr{0, 0, 1}, C_1, C_2} = \I\br{\sbr{0, 0, 1}, \Psi\br{C_1}, \Psi\br{C_2}} = \mult_{\sbr{0, 1}} R\br{x_1, x_2} = 2, $$
and similarly, $ \I\br{\sbr{1, 0, 0}, C_1, C_2} = 2 $. B\'ezout's theorem is satisfied in this case.
\end{example}

Now we can note that Theorem \ref{thm:11.6} is a corollary of the strong theorem.

\begin{proof}[Proof of Theorem \ref{thm:11.6}]
Follows directly from Theorem \ref{thm:11.11} and Lemma \ref{lem:11.7}.
\end{proof}

\begin{exercise**}
Show that an irreducible projective curve $ C $ of degree $ d $ has at most $ d\br{d - 1} / 2 $ singular points.
\end{exercise**}

\begin{exercise**}
Let $ C $ be an irreducible projective curve of degree $ d $ with a point $ p \in C $ with multiplicity $ q = \mult_p C $. Show that there exists a line $ L \subseteq \PP_\CC^2 $ such that $ p \in L $ and which meets $ C $ in exactly $ d - q + 1 $ points. In particular, for any projective curve $ C $ of degree $ d $ there exists a line which meets $ C $ in $ d $ points.
\end{exercise**}

\pagebreak

\section{More about intersection multiplicities}

We now look at a few more properties of intersection multiplicities. We start by giving an alternative description of the resultant of two polynomials in one variable.

\begin{lemma}
\label{lem:12.1}
Let $ p, q \in \CC\sbr{x} $ be monic polynomials of degrees $ n $ and $ m $, so that there are $ \lambda_1, \dots, \lambda_n \in \CC $ and $ \mu_1, \dots, \mu_m \in \CC $ such that $ p\br{x} = \prod_{i = 1}^n \br{x - \lambda_i} $ and $ q\br{x} = \prod_{j = 1}^m \br{x - \mu_j} $. Then, $ \R_{p, q} $, the resultant of $ p $ and $ q $, is a homogeneous polynomial of degree $ nm $ in the variables $ \lambda_1, \dots, \lambda_n $ and $ \mu_1, \dots, \mu_m $. More precisely,
$$ \R_{p, q} = \prod_{i, j}\br{\lambda_i - \mu_j} = \br{-1}^{nm}\prod_{j = 1}^m p\br{\mu_j} = \prod_{i = 1}^n q\br{\lambda_i}. $$
\end{lemma}

\begin{proof}
Write
$$ p\br{x} = \sum_{i = 1}^n a_i\br{\lambda_1, \dots, \lambda_n} \cdot x^i, \qquad q\br{x} = \sum_{j = 1}^m b_j\br{\mu_1, \dots, \mu_m} \cdot x^j, $$
where $ a_i $ is a homogeneous polynomial of degree $ n - i $ in the variables $ \lambda_1, \dots, \lambda_n $ and $ b_j $ is a homogeneous polynomial of degree $ m - j $ in the variables $ \mu_1, \dots, \mu_m $. The proof that $ \R_{p, q} $ is a homogeneous polynomial of degree $ nm $ in $ \lambda_1, \dots, \lambda_n, \mu_1, \dots, \mu_m $ is identical to the proof of Theorem \ref{thm:9.7}. We now see the expression for $ p $ as a homogeneous polynomial of degree $ n $ in $ \CC\sbr{x, \lambda_1, \dots, \lambda_n} $ and $ q $ as a homogeneous polynomial of degree $ m $ in $ \CC\sbr{x, \mu_1, \dots, \mu_m} $. By Theorem \ref{thm:9.3}, for each $ i $ and $ j $, if some $ \lambda_i = \mu_j $, $ \R_{p, q} = 0 $, so that, as polynomials in $ \lambda_1, \dots, \lambda_n, \mu_1, \dots, \mu_m $, we have $ \lambda_i - \mu_j \mid \R_{p, q} $, so
$$ \R_{p, q} = \prod_{i, j} \br{\lambda_i - \mu_j}S, $$
where $ S $ is a homogeneous polynomial in $ \lambda_1, \dots, \lambda_n, \mu_1, \dots, \mu_m $, by Lemma \ref{lem:4.10}. Since $ \deg \R_{p, q} = nm $, the degree of $ S $ is zero and $ S $ is a constant in $ \CC^* $ with $ \R_{p, q} = S\prod_{i, j} \br{\lambda_i - \mu_j} $. The constant $ S = 1 $, as can be checked by computing the resultant of $ p\br{x} = \br{x - 1}^n $ and $ q\br{x} = x^m $.
\end{proof}

\begin{remark}
More generally, if the leading coefficients of $ p $ and $ q $ are $ a_n \ne 0 $ and $ b_m \ne 0 $ then
$$ \R_{p, q} = a_n^mb_m^n\prod_{i, j} \br{\lambda_i - \mu_j}. $$
\end{remark}

\begin{remark}
\label{rem:12.3}
Let $ f_1, f_2, g \in \CC\sbr{x} $ be monic polynomials. An immediate consequence of Lemma \ref{lem:12.1} is that $ \R_{f_1f_2, g} = \R_{f_1, g} \cdot \R_{f_2, g} $.
\end{remark}

\begin{lemma}
\label{lem:12.4}
Let $ P_1, P_2, Q \in \CC\sbr{x_0, x_1, x_2} $ be homogeneous polynomials with $ P_i\br{1, 0, 0}, Q\br{1, 0, 0} \ne 0 $, and let $ P = P_1 \cdot P_2 $. Let $ R\br{x_1, x_2} $ be the resultant of $ P $ and $ Q $ and $ R_i\br{x_1, x_2} $ be the resultant of $ P_i $ and $ Q $ for $ i = 1, 2 $. For all $ \sbr{b, c} \in \PP^1 $, we have
$$ \mult_{\sbr{b, c}} R = \mult_{\sbr{b, c}} R_1 + \mult_{\sbr{b, c}} R_2. $$
\end{lemma}

\begin{proof}
$ P_i\br{1, 0, 0} \ne 0 $, so $ a \cdot x_0^{\deg P_i} $ is a monomial of $ P_i $ for $ a \ne 0 $. Let $ a_1, a_2, b \in \CC^* $ be constants such that $ P_1 = a_1P'_1 $, $ P_2 = a_2P'_2 $, and $ Q = bQ' $, where $ P'_1, P'_2, Q' $ are homogeneous polynomials that are monic in $ x_0 $. Then, if $ m = \deg Q $, $ P' = P'_1P'_2 $, and $ a = a_1a_2 \in \CC^* $, the resultants are scalar multiples that satisfy $ \R_{P_1, Q} = a_1^mb^{\deg P_1}\R_{P'_1, Q'} $, $ \R_{P_2, Q} = a_2^mb^{\deg P_2}\R_{P'_2, Q'} $, and $ \R_{P, Q} = a^mb^{\deg P}\R_{P', Q'} $. In particular, for any $ \sbr{b, c} \in \PP^1 $, the multiplicities of $ \R_{P_1, Q}, \R_{P_2, Q}, \R_{P, Q} $ and of $ \R_{P'_1, Q'}, \R_{P'_2, Q'}, \R_{P', Q'} $ coincide. We may therefore assume that $ P_1, P_2, Q $ are monic with respect to $ x_0 $. Fix $ \sbr{b, c} \in \PP^1 $ and let $ f_i\br{x} = P_i\br{x, b, c} $, $ f\br{x} = f_1\br{x} \cdot f_2\br{x} $, and $ g\br{x} = Q\br{x, b, c} $. The polynomials $ f_1, f_2, f, g $ are monic. \footnote{Exercise} By Lemma \ref{lem:12.1} and the consequence in Remark \ref{rem:12.3}, $ \R_{f, g} = \R_{f_1, g} \cdot \R_{f_2, g} $, that is we have $ \R_{P, Q}\sbr{b, c} = \R_{P_1, Q}\sbr{b, c} \cdot \R_{P_2, Q}\sbr{b, c} $. As this holds for every $ \sbr{b, c} \in \PP^1 $, $ \R_{P, Q} = \R_{P_1, Q} \cdot \R_{P_2, Q} $ in $ \CC\sbr{x_1, x_2} $, and
$$ \mult_{\sbr{b, c}} R = \mult_{\sbr{b, c}} R_1 + \mult_{\sbr{b, c}} R_2, \qquad \sbr{b, c} \in \PP^1. $$
\end{proof}

\pagebreak

The following proposition gathers a few important properties of intersection multiplicities.

\begin{proposition}
\label{prop:12.5}
Let $ C \subseteq \PP^2 $ and $ D \subseteq \PP^2 $ be projective curves defined by homogeneous polynomials $ P, Q \in \CC\sbr{x_0, x_1, x_2} $. Let $ p \in \PP^2 $ be a point. The intersection numbers $ \I\br{p, P, Q} $ satisfy the following.
\begin{enumerate}
\item Intersection numbers are symmetric, so $ \I\br{p, C, D} = \I\br{p, D, C} $.
\item $ \I\br{p, C, D} = \infty $ if $ p $ lies on a common component of $ C $ and $ D $ and $ \I\br{p, C, D} \in \ZZ $ otherwise.
\item $ \I\br{p, C, D} \ne 0 $ if and only if $ p \in C \cap D $.
\item If $ C $ and $ D $ are distinct lines and if $ \cbr{p} = C \cap D $ then $ \I\br{p, C, D} = 1 $.
\item If $ P = P_1 \cdot P_2 $, for homogeneous polynomials $ P_1 $ and $ P_2 $, then $ \I\br{p, P_1 \cdot P_2, Q} = \I\br{p, P_1, Q} + \I\br{p, P_2, Q} $.
\item If $ P = P_1 \cdot Q + P_2 $, for homogeneous polynomials $ P_1 $ and $ P_2 $, then $ \I\br{p, P, Q} = \I\br{p, P_2, Q} $.
\end{enumerate}
\end{proposition}

\begin{proof}
\hfill
\begin{enumerate}
\item Since the effect of exchanging the rows of a matrix on its determinant is to multiply it by $ \br{-1} $, $ \R_{P, Q} = \pm\R_{Q, P} $, and since multiplication by a constant does not affect the multiplicity of a polynomial, $ 1 $ follows.
\item $ 2 $ is by definition and is part of Definition \ref{def:11.8}.
\item $ 3 $ is by construction and was noted in Remark \ref{rem:11.10}.
\item For $ 4 $, after projective transformation, we may assume that $ C = \cbr{x_0 = 0} $ and $ D = \cbr{x_0 + x_1 = 0} $, so that $ \sbr{1, 0, 0} \notin C \cup D $ and $ \cbr{p} = C \cap D = \cbr{\sbr{0, 0, 1}} $. Then, $ \I\br{p, C, D} = 1 $ by an easy computation. \footnote{Exercise}
\item $ 5 $ is an application of the statement about multiplicities of resultants in Lemma \ref{lem:12.4}.
\item We now prove $ 6 $. Let $ R\br{x_1, x_2} $ be the resultant of $ P_1 \cdot Q + P_2 $ and $ Q $ and let $ R'\br{x_1, x_2} $ be the resultant of $ P_2 $ and $ Q $. Then, denote by
$$ P_2 = \sum_{i = 1}^n a_i\br{x_1, x_2} \cdot x_0^i, \qquad P_1 = \sum_{i = 1}^n c_i\br{x_1, x_2} \cdot x_0^i, \qquad Q = \sum_{i = 1}^n b_i\br{x_1, x_2} \cdot x_0^i. $$
Then
$$ P_1 \cdot Q + P_2 = \sum_{i = 1}^n \br{a_i + \sum_{j = 0}^i c_j \cdot b_{i - j}} \cdot x_0^i, $$
so
$$ R\br{x_1, x_2} = \det
\begin{pmatrix}
a_0 + b_0c_0 & \dots & a_n + \sum_{j = 0}^n c_jb_{i - j} & & 0 \\
& \ddots & & \ddots & \\
0 & & a_0 + b_0c_0 & \dots & a_n + \sum_{j = 0}^n c_jb_{i - j} \\
b_0 & \dots & b_n & & 0 \\
& \ddots & & \ddots & \\
0 & & b_0 & \dots & b_n
\end{pmatrix},
$$
so that the resultant matrix of $ R $ is obtained from the resultant matrix of $ R' $ by performing the following row operations.
\begin{itemize}
\item Add $ c_{j - 1} $ times the $ m + j $ row to the $ 1 $-st row, for each $ j = 1, \dots, n $.
\item $ \dots $.
\item Add $ c_{j - 1} $ times the $ m + j + n - 1 $ row to the $ n $-th row, for each $ j = 1, \dots, n $.
\end{itemize}
Since performing these row operations do not affect the determinant, $ R = R' $ and $ 6 $ follows.
\end{enumerate}
This finishes the proof of Proposition \ref{prop:12.5}.
\end{proof}

\pagebreak

\begin{example}
Consider the curves
$$ C_1 = \cbr{x_0x_2 - x_1^2 = 0}, \qquad C_2 = \cbr{x_0x_2 + x_1^2 = 0}, $$
and let $ p = \sbr{0, 0, 1} \in C_1 \cap C_2 $. Then
\begin{align*}
\I\br{p, C_1, C_2}
& = \I\br{p, x_0x_2 - x_1^2, x_0x_2 + x_1^2} & \text{by definition}, \\
& = \I\br{p, 2x_0x_2, x_0x_2 + x_1^2} & \text{by} \ 6, \\
& = \I\br{p, x_0, x_0x_2 + x_1^2} + \I\br{p, x_2, x_0x_2 + x_1^2} & \text{by} \ 5, \\
& = \I\br{p, x_0, x_0x_2 + x_1^2} & \text{by} \ 3, \\
& = \I\br{p, x_0, x_1^2} & \text{by} \ 6, \\
& = 2 \cdot \I\br{p, x_0, x_1} & \text{by} \ 5, \\
& = 2 & \text{by} \ 4.
\end{align*}
\end{example}

\lecture{18}{Friday}{16/11/18}

\begin{exercise**}
Let
$$ C = \cbr{x_0x_2^2 - x_1\br{x_1 - x_0}\br{x_1 + x_0} = 0} \subseteq \PP^2, \qquad L = \cbr{ax_0 + bx_1 = 0} \subseteq \PP^2, $$
for some $ a, b \in \CC $ not both zero, and let $ p = \sbr{0, 0, 1} $. Compute $ \I\br{p, C, L} $.
\end{exercise**}

\begin{proposition}
Let $ C \subseteq \PP^2 $ be a projective curve and $ p \in C $ a smooth point. If $ L = \T_p C $ is the tangent line to $ C $ at $ p $, $ \I\br{p, C, \T_p C} > 1 $.
\end{proposition}

\begin{proof}
Let $ C = \cbr{P = 0} $ and $ p = \sbr{a, b, c} $. We may assume that $ \sbr{1, 0, 0} \notin C \cup \T_p C $ so that $ P_{x_0}\br{a, b, c} \ne 0 $. The tangent to $ C $ at $ p $ is
$$ \T_p C = \cbr{P_{x_0}\br{a, b, c} \cdot x_0 + P_{x_1}\br{a, b, c} \cdot x_1 + P_{x_2}\br{a, b, c} \cdot x_2 = 0}, $$
so
$$ x_0 = -\dfrac{P_{x_1}\br{a, b, c}x_1 + P_{x_2}\br{a, b, c}x_2}{P_{x_0}\br{a, b, c}}, $$
and from applying Lemma \ref{lem:12.1} to
$$ p\br{x} = P\br{x, x_1, x_2}, \qquad q\br{x} = x + \dfrac{P_{x_1}\br{a, b, c}x_1 + P_{x_2}\br{a, b, c}x_2}{P_{x_0}\br{a, b, c}}, $$
it follows that the resultant $ \R_{C, L} $ is equal to a scalar multiple of the polynomial in $ x_1 $ and $ x_2 $,
$$ Q\br{x_1, x_2} = P\br{-\dfrac{P_{x_1}\br{a, b, c}x_1 + P_{x_2}\br{a, b, c}x_2}{P_{x_0}\br{a, b, c}}, x_1, x_2}. $$
If $ P $ is not monic in $ x_0 $, there will be a non-zero constant factor, irrelevant when taking multiplicity. The multiplicity $ \I\br{p, C, \T_p C} > 1 $ if and only if $ Q $ has a repeated factor $ \br{cx_1 - bx_2} $ at $ p $. This holds because
$$ Q\br{b, c} = P\br{a, b, c} = 0, \quad Q_{x_1}\br{b, c} = P_{x_0}\br{a, b, c}\br{-\dfrac{P_{x_1}\br{a, b, c}}{P_{x_0}\br{a, b, c}}} + P_{x_1}\br{a, b, c} + 0 = 0, \quad Q_{x_2}\br{b, c} = 0, $$
by the chain rule, so that $ \sbr{b, c} $ is a common root of $ Q $ and $ Q_{x_i} $. Claim that this implies that $ Q\br{x_1, x_2} = \br{cx_1 - bx_2}^2 \cdot R\br{x_1, x_2} $, for some polynomial $ R $. This concludes the proof.
\end{proof}

\begin{exercise**}
Show that the claim holds, so $ \br{cx_1 - bx_2}^2 \mid Q\br{x_1, x_2} $.
\end{exercise**}

\begin{exercise**}
Show that the converse of the above is also true. If $ p \in C $ is a smooth point, and $ L $ is a line with $ \I\br{p, C, L} > 1 $, then $ L $ is the tangent line to $ C $ at $ p $.
\end{exercise**}

\pagebreak

One can actually define intersection multiplicities of projective curves $ C, D \subseteq \PP^2 $ by the properties listed in Proposition \ref{prop:12.5}. We will not prove this, see Theorem 3.18 in Kirwan's book if you are interested.

\begin{proposition}
\label{prop:12.8}
Properties $ 1 $ to $ 6 $ in Proposition \ref{prop:12.5} determine uniquely and characterise completely $ \I\br{p, C, D} $ for any point $ p \in \PP^2 $ and any projective curves $ C, D \subseteq \PP^2 $.
\end{proposition}

\begin{remark}
\label{rem:12.9}
Proposition \ref{prop:12.8} is another proof that the intersection multiplicity is defined independent of the choice of coordinates on $ \PP^2 $, that is that
$$ \I\br{p, C, D} = \I\br{\Psi\br{p}, \Psi\br{C}, \Psi\br{D}}, $$
for any projective transformation $ \Psi : \PP^2 \to \PP^2 $.
\end{remark}

\begin{remark}
Another consequence is that the intersection multiplicity $ \I\br{p, C, D} $ depends only on the components of $ C $ and $ D $ that contain the point $ p $.
\end{remark}

The intersection of two distinct lines at their point of intersection is one. The next question we could ask is, when do curves $ C $ and $ D $ intersect at a point $ p \in C \cap D $ with multiplicity one? The following proposition, that we state without proving, gives the answer.

\begin{proposition}
\label{prop:12.11}
Let $ C, D \subseteq \PP^2 $ be projective curves and $ p $ a point of $ \PP^2 $. Then $ \I\br{p, C, D} = 1 $ if and only if $ p \in C \cap D $ is a smooth point of $ C $ and of $ D $, and the tangent lines to $ C $ and $ D $ at $ p $ are distinct. Then $ C $ and $ D $ meet \textbf{transversely} at $ p $.
\end{proposition}

\begin{remark}
By Proposition \ref{prop:12.5}.$ 2 $ and Proposition \ref{prop:12.5}.$ 3 $, $ \I\br{p, C, D} $ is a non-zero finite number if and only if $ p \in C \cap D $ and $ p $ does not lie on a common component of $ C $ and $ D $, and by Lemma \ref{lem:11.7},
$$ 1 \le \mult_p C \cdot \mult_p D \le \I\br{p, C, D} = 1 $$
implies that $ \mult_p C = \mult_p D = 1 $, so that $ p $ is a smooth point of $ C $ and of $ D $. We would therefore have to show that if $ p \in C \cap D $ is a smooth point of $ C $ and of $ D $, $ \I\br{p, C, D} = 1 $ if and only if the tangent lines $ L_C $ and $ L_D $ of $ C $ and $ D $ at $ p $ are distinct.
\end{remark}

Proposition \ref{prop:12.11} implies immediately the following corollary.

\begin{corollary}
Let $ C, D \subseteq \PP^2 $ be two projective curves with no common component, $ n = \deg C $, and $ m = \deg D $. Then for any $ p \in C \cap D $, $ C $ and $ D $ are smooth at $ p $ and have distinct tangent lines at $ p $ if and only if
$$ \#\cbr{C \cap D} = n \cdot m. $$
\end{corollary}

\begin{proposition}
\label{prop:12.14}
Let $ L $ be a projective line and $ C \subseteq \PP^2 $ a curve of degree $ d $. If $ p \in C \cap L $, $ \I\br{p, C, L} > 1 $ if and only if either $ C $ is singular at $ p $ or $ L $ is the tangent line to $ C $ at $ p $. Moreover, more generally, if $ C $ is singular at $ p $, then $ \I\br{p, C, L} > \mult_p C $ if and only if $ L $ is one of the higher tangent lines to $ C $ at $ p $.
\end{proposition}

\begin{proof}
See Exercise $ 6 $ of problem sheet $ 2 $.
\end{proof}

\begin{example*}
\hfill
\begin{itemize}
\item Let
$$ y^2 = x^2\br{x + 1} = x^3 + x^2. $$
The lowest degree form is $ y^2 = x^2 $, so the higher tangent lines at the origin are $ y = \pm x $.
\item Let
$$ y^2 = x^3. $$
The lowest degree form is $ y^2 = 0 $, so the higher tangent lines at the origin are $ y^2 = 0 $.
\end{itemize}
\end{example*}

\pagebreak

\section{Cubic curves}

In this section, we investigate the geometry of cubic curves. Up to projective transformation,
\begin{itemize}
\item a projective line is $ L = \cbr{x_0 = 0} $,
\item a smooth irreducible conic is $ C = \cbr{x_0^2 + x_1^2 + x_2^2 = 0} \subseteq \PP^2 $.
\end{itemize}
The equation of a smooth line or conic can be brought in a uniquely determined \textbf{standard form}. What about cubics? By contrast, we will see that the equation of a smooth cubic curve can be brought in standard form, but that standard form depends on a parameter. We prove the following.

\begin{theorem}
\label{thm:13.1}
Let $ C \subseteq \PP^2 $ be a smooth projective cubic curve of degree three. Then, there exists a projective transformation $ \Psi : \PP^2 \to \PP^2 $ and $ \lambda \in \CC \setminus \cbr{0, 1} $ such that
$$ \Psi\br{C} = \cbr{x_1^2x_2 = x_0\br{x_0 - x_2}\br{x_0 - \lambda x_2}} \subseteq \PP^2. $$
\end{theorem}

Dehomogenising with respect to $ x_2 $, $ y^2 = x\br{x - 1}\br{x - \lambda} $ is the \textbf{Legendre form} for \textbf{elliptic curves}. In order to prove Theorem \ref{thm:13.1}, we need to define inflection points of projective curves. These will generalise the points of inflection on graphs of functions.

\begin{definition}
\label{def:13.2}
Let $ P \in \CC\sbr{x_0, x_1, x_2} $ be a homogeneous polynomial. The \textbf{Hessian matrix} of $ P $ is the symmetric matrix whose entries are the second order differentials of $ P $,
$$ \H_P = \br{\dmd{P}{2}{x_i}{}{x_j}{}}_{0 \le i, j \le 2} = \threebythree{P_{x_0, x_0}}{P_{x_0, x_1}}{P_{x_0, x_2}}{P_{x_1, x_0}}{P_{x_1, x_1}}{P_{x_1, x_2}}{P_{x_2, x_0}}{P_{x_2, x_1}}{P_{x_2, x_2}}. $$
The \textbf{Hessian} of $ P $ is $ \HHH_P\br{x_0, x_1, x_2} = \det \H_P $. An \textbf{inflection point}, or \textbf{flex point}, of $ C $ is a smooth point $ p = \sbr{a, b, c} $ of $ C $ such that $ \HHH_P\br{a, b, c} = 0 $.
\end{definition}

$ \HHH_P $ is a homogeneous polynomial of degree $ 3\br{d - 2} $ when $ d \ge 3 $. The only thing there is to check is that $ \HHH_P $ is a homogeneous polynomial of the specified degree. When $ d \ge 3 $, all non-zero entries of $ \H_P $ are homogeneous polynomials of degree $ d - 2 $, and $ \H_P $ is a $ 3 \times 3 $ matrix, so $ \HHH_P $ is indeed a homogeneous polynomial of degree $ 3\br{d - 2} $. An inflection point $ p $ is a smooth point $ p \in C $ whose intersection multiplicity with the tangent line to $ C $ at $ p $ is at least three. \footnote{Exercise}

\begin{lemma}
\label{lem:13.3}
Let $ P \in \CC\sbr{x_0, x_1, x_2} $ be a homogeneous polynomial of degree $ d > 1 $. Then
\begin{equation}
\label{eq:10}
x_2^2 \cdot \HHH_P = \br{d - 1}^2 \cdot \det \threebythree{P_{x_0, x_0}}{P_{x_0, x_1}}{P_{x_0}}{P_{x_1, x_0}}{P_{x_1, x_1}}{P_{x_1}}{P_{x_0}}{P_{x_1}}{\tfrac{d}{d - 1} \cdot P}.
\end{equation}
\end{lemma}

\begin{remark}
Analogous formulae to $ \br{\ref{eq:10}} $ can be stated for $ x_0 $ and $ x_1 $.
\end{remark}

\lecture{19}{Monday}{19/11/18}

\begin{proof}
For ease of notation, let us label the rows and columns of the Hessian matrix as follows.
$$ \H_P = \onebythree{C_0}{C_1}{C_2} = \threebyone{R_0}{R_1}{R_2}.
$$
Each $ P_{x_i} $ is a homogeneous polynomial of degree $ d - 1 $, so that by the Euler relation, in Theorem \ref{thm:7.6}, we have
$$ \br{d - 1}P_{x_i} = x_0P_{x_0, x_i} + x_1P_{x_1, x_i} + x_2P_{x_2, x_i}, $$
and
\begin{align*}
x_2 \cdot \HHH_P
& = \det \onebythree{C_0}{C_1}{x_2C_2}
= \det \onebythree{C_0}{C_1}{x_0C_0 + x_1C_1 + x_2C_2} \\
& = \det \threebythree{P_{x_0, x_0}}{P_{x_0, x_1}}{\br{d - 1}P_{x_0}}{P_{x_1, x_0}}{P_{x_1, x_1}}{\br{d - 1}P_{x_1}}{P_{x_2, x_0}}{P_{x_2, x_1}}{\br{d - 1}P_{x_2}}
= \br{d - 1}\det \threebythree{P_{x_0, x_0}}{P_{x_0, x_1}}{P_{x_0}}{P_{x_1, x_0}}{P_{x_1, x_1}}{P_{x_1}}{P_{x_2, x_0}}{P_{x_2, x_1}}{P_{x_2}}
= \br{d - 1}\det \threebyone{R_0'}{R_1'}{R_2'}.
\end{align*}

\pagebreak

Similarly,
$$ x_2^2 \cdot \HHH_P = \br{d - 1}\det \threebyone{R_0'}{R_1'}{x_2R_2'} = \br{d - 1}\det \threebyone{R_0'}{R_1'}{x_0R_0' + x_1R_1' + x_2R_2'}. $$
Using the Euler relation for $ P_{x_0} $ and $ P_{x_1} $ and the Euler relation for $ P $
$$ dP = x_0P_{x_0} + x_1P_{x_1} + x_2P_{x_2}, $$
we find that this last matrix has the desired form.
\end{proof}

\begin{note*}
For a line every point is an inflection point, because the Hessian matrix is zero.
\end{note*}

\begin{lemma}
\label{lem:13.5}
Let $ C $ be a smooth projective curve of degree $ d $. If $ d \ge 3 $, $ C $ has at least one point of inflection.
\end{lemma}

\begin{proof}
Let $ C $ be a projective curve of degree $ d \ge 2 $. If $ d = 2 $, $ \HHH_P $ is a constant polynomial, and it is non-zero, as one can check directly, using the standard form for a conic that we have seen before. Therefore, $ C $ has no point of inflection, which agrees with Lemma \ref{lem:13.5}. We now assume that $ d > 2 $, so that $ \HHH_P $ is a homogeneous polynomial of degree $ \deg \HHH_P = 3\br{d - 2} \ge 3 $ by Definition \ref{def:13.2}. Then it follows from the weak version of B\'ezout's Theorem \ref{thm:9.8} that there is at least a point in $ C \cap \cbr{\HHH_P = 0} $, which is then an inflection point, since $ C $ is smooth.
\end{proof}

\begin{remark}
\label{rem:13.6}
It also true that if $ d \ge 2 $, then $ \deg C \cdot \deg \HHH_P = 3d\br{d - 2} $, so $ C $ has at most $ 3d\br{d - 2} $ points of inflection. Note that this follows from the strong form of B\'ezout's theorem, once we know that $ C $ and $ \cbr{\HHH_P = 0} $ have no common component. Unfortunately this does not immediately follow from irreducibility of $ C $, because $ 3\br{d - 2} > d $ as soon as $ d \ge 4 $, and $ \cbr{\HHH_P = 0} $ could well be reducible, or have multiple components, for that matter. The way around this is to prove that if every smooth point of an irreducible curve is an inflection point, which would happen if $ C $ were a component of $ \cbr{\HHH_P = 0} $, then $ C $ has to be a line, by Lemma 3.32 in Kirwan's book. \footnote{Exercise}
\end{remark}

We now see that the presence of inflection points guarantees that the equation of every smooth cubic curve can be put in a very simple form.

\begin{proof}[Proof of Theorem \ref{thm:13.1}]
Let $ P $ be the irreducible homogeneous polynomial of degree three such that $ C = \cbr{P = 0} $. By Lemma \ref{lem:13.5}, $ C $ has at least one inflection point. Up to projective transformation, we may thus assume that $ q = \sbr{0, 1, 0} $ is an inflection point of $ C $, and that the tangent line to $ C $ at $ q $ is $ \T_q C = \cbr{x_2 = 0} $. This implies that
$$ P\br{0, 1, 0} = 0, \qquad P_{x_0}\br{0, 1, 0} = 0, \qquad P_{x_1}\br{0, 1, 0} = 0, \qquad P_{x_2}\br{0, 1, 0} \ne 0, \qquad \HHH_P\br{0, 1, 0} = 0. $$
We may write the equation of $ P $ as
$$ P\br{x_0, x_1, x_2} = Ax_1^3 + Bx_0x_1^2 + Cx_2x_1^2 + Dx_0^2x_1 + Ex_0x_2x_1 + Fx_2^2x_1 + \Phi\br{x_0, x_2}, \qquad A, B, C, D, E, F \in \CC, $$
where $ \Phi $ is a homogeneous polynomial of degree three in the variables $ x_0 $ and $ x_2 $. Since $ P\br{0, 1, 0} = 0 $, $ A = 0 $. Since $ P_{x_0}\br{0, 1, 0} = 0 $, $ B = 0 $. Since $ P_{x_2}\br{0, 1, 0} \ne 0 $, $ C \ne 0 $. Now we would like to say something about the other coefficients. This will involve some manipulation of $ \HHH_P $. By the analogous result of Lemma \ref{lem:13.3}, we have
$$ x_1^2 \cdot \HHH_P = \br{d - 1}^2 \cdot \det \threebythree{P_{x_0, x_0}}{P_{x_0}}{P_{x_0, x_2}}{P_{x_0}}{\tfrac{d}{d - 1} \cdot P}{P_{x_2}}{P_{x_0, x_2}}{P_{x_2}}{P_{x_2, x_2}} = 4\det \threebythree{P_{x_0, x_0}}{P_{x_0}}{P_{x_0, x_2}}{P_{x_0}}{\tfrac{3}{2} \cdot P}{P_{x_2}}{P_{x_0, x_2}}{P_{x_2}}{P_{x_2, x_2}}, $$
so that
$$ 0 = \HHH_P\br{0, 1, 0} = 4\det \threebythree{P_{x_0, x_0}}{0}{P_{x_0, x_2}}{0}{0}{P_{x_2}}{P_{x_0, x_2}}{P_{x_2}}{P_{x_2, x_2}} = -4P_{x_2}\br{0, 1, 0}^2P_{x_0, x_0}\br{0, 1, 0}, $$

\pagebreak

so that $ P_{x_0, x_0}\br{0, 1, 0} = 0 $, since $ P_{x_2}\br{0, 1, 0} $ is non-zero. Since $ P_{x_0, x_0}\br{0, 1, 0} = 0 $, $ D = 0 $. We may thus write
$$ P\br{x_0, x_1, x_2} = x_1x_2\br{Ex_0 + Cx_1 + Fx_2} + \Phi\br{x_0, x_2} = C\br{x_1 + \dfrac{Ex_0 + Fx_2}{2C}}^2x_2 + \Phi'\br{x_0, x_2}, $$
where $ \Phi' \in \CC\sbr{x_0, x_2} $ is a homogeneous polynomial of degree three. Consider the projective transformation
$$ \function[\Psi_1]{\PP^2}{\PP^2}{\sbr{x_0, x_1, x_2}}{\sbr{x_0, x_1 + \tfrac{Ex_0 + Fx_2}{2C}, x_2}}. $$
Note that $ \Psi_1 $ is well-defined because $ C \ne 0 $. Then I get that the equation of $ \Psi_1\br{C} $ is
$$ \Psi_1\br{C} = \cbr{x_1^2x_2 = \Phi''\br{x_0, x_2}} \subseteq \PP^2, $$
where $ \Phi'' \in \CC\sbr{x_0, x_2} $ is a homogeneous polynomial of degree three. By Lemma \ref{lem:6.2}, $ \Phi'' $ is a product of linear factors. Since $ C $ and hence $ \Psi_1\br{C} $ are irreducible, $ x_2 $ does not divide $ \Phi'' $. Thus
$$ \Phi''\br{x_0, x_2} = K\br{x_0 - ax_2}\br{x_0 - bx_2}\br{x_0 - cx_2}, \qquad K \in \CC^*, \qquad a, b, c \in \CC. $$
After a suitable diagonal projective transformation $ \Psi_2 $, $ K = 1 $, and the equation of $ \Psi_2 \circ \Psi_1\br{C} $ is
$$ \Psi_2 \circ \Psi_1\br{C} = \cbr{x_1^2x_2 = \br{x_0 - ax_2}\br{x_0 - bx_2}\br{x_0 - cx_2}} \subseteq \PP^2. $$
Since $ C $ is non-singular, $ a, b, c $ are distinct. \footnote{Exercise} The map
$$ \function[\Psi_3]{\PP^2}{\PP^2}{\sbr{x_0, x_1, x_2}}{\sbr{\tfrac{x_0 - ax_2}{b - a}, \eta x_1, x_2}}, \qquad \dfrac{1}{\eta^2} = \br{b - a}^3 $$
is thus a well-defined projective transformation and
$$ \Psi_3 \circ \Psi_2 \circ \Psi_1\br{C} = \cbr{x_1^2x_2 = x_0\br{x_0 - x_2}\br{x_0 - \lambda x_2}} \subseteq \PP^2, \qquad \lambda \in \CC. $$
Note that $ \lambda \ne 0, 1 $ because $ C $ is non-singular. This is exactly the form we wanted.
\end{proof}

\lecture{20}{Thursday}{22/11/18}

Lecture 20 is a problems class.

\lecture{21}{Friday}{23/11/18}

\begin{corollary}
Let $ C \subseteq \PP^2 $ be a smooth cubic curve. Then $ C $ has precisely nine points of inflection.
\end{corollary}

\begin{proof}
Let $ C = \cbr{P = 0} $, where $ P $ is a homogeneous polynomial of degree three. Define $ D = \cbr{\HHH_P = 0} $ to be the curve defined by the Hessian of $ P $. Recall that $ \HHH_P $ may have repeated factors. Note that $ C $ and $ D $ do not have common components. Since $ C $ is irreducible, they would have to coincide. By Theorem \ref{thm:13.1} we can assume that $ C $ has equation
$$ x_1^2x_2 = x_0\br{x_0 - x_2}\br{x_0 - \lambda x_2}, $$
and it is easy to check that $ \sbr{0, 0, 1} $ is not an inflection point of this particular cubic. \footnote{Exercise} By B\'ezout's Theorem \ref{thm:11.11}, we then have
$$ 9 = \deg C \cdot \deg D = \sum_{p \in C \cap D} \I\br{p, C, D}. $$
It is thus enough to prove that for each inflection point $ p \in C \cap D $, $ \I\br{p, C, D} = 1 $. By Proposition \ref{prop:12.11}, this is equivalent to proving that $ p $ is a smooth point of $ C $ and $ D $ and that $ \T_p C \ne \T_p D $. Let $ p \in C \cap D $, then by Theorem \ref{thm:13.1}, up to projective transformation, we may assume that $ p = \sbr{0, 1, 0} $, and that the equation of $ C $ is
$$ \cbr{x_1^2x_2 = x_0\br{x_0 - x_2}\br{x_0 - \lambda x_2}}, \qquad \lambda \in \CC \setminus \cbr{0, 1}. $$
Then $ \T_p C = \cbr{x_2 = 0} $, while
$$ \partial_{x_0}\HHH_P\br{0, 1, 0} = 24, \qquad \partial_{x_1}\HHH_P\br{0, 1, 0} = 0, \qquad \partial_{x_2}\HHH_P\br{0, 1, 0} = 8\br{\lambda - 1}, $$
so that $ p $ is a smooth point of $ D $ and $ \T_p D \ne \T_p C $. This finishes the proof.
\end{proof}

\pagebreak

\section{Linear systems}

Before moving on to Riemann surfaces, we briefly turn our attention to the way curves behave in families. Here are two basic questions.
\begin{itemize}
\item Given two irreducible curves $ C = \cbr{P = 0} $ and $ D = \cbr{Q = 0} $ of the same degree, we can consider a family of curves $ C_{\sbr{\lambda, \mu}} = \cbr{\lambda P + \mu Q = 0} $ parametrised by $ \sbr{\lambda, \mu} \in \PP^1 $. The curves $ C $ and $ D $ are special members of the family. How do properties of $ C_{\sbr{\lambda, \mu}} $ relate to properties of $ C $ and $ D $?
\item Let $ p_1, \dots, p_k $ be points in $ \PP^2 $. When can we find a curve of degree $ d $ that passes through $ p_1, \dots, p_k $? When can we find a curve $ C $ of degree $ d $ with $ \mult_{p_i} C = q_i $, for a collection $ q_1, \dots, q_k \in \NN $?
\end{itemize}

\begin{example*}
\hfill
\begin{itemize}
\item Let $ d = 1 $, $ k = 2 $, and $ q_1 = q_2 = 1 $. Then there is only one projective line.
\item Let $ d = 1 $, $ k = 3 $, and $ q_1 = q_2 = q_3 = 1 $. Then it depends on whether $ p_1, p_2, p_3 $ are collinear or not.
\end{itemize}
\end{example*}

\begin{example}
Let us consider projective lines in $ \PP^2 $. Recall that the equation of every line $ L $ is given by
$$ L = \cbr{ax_0 + bx_1 + cx_2 = 0} \subseteq \PP^2, \qquad \br{a, b, c} \in \CC^3, \qquad \br{a, b, c} \ne \br{0, 0, 0}. $$
Then $ \br{a, b, c} $ and $ \br{a', b', c'} $ define the same line if and only if there exists $ \lambda \in \CC^* $ such that $ \br{a, b, c} = \br{\lambda a', \lambda b', \lambda c'} $, that is when $ \sbr{a, b, c} = \sbr{a', b', c'} $ as points of $ \PP^2 $. This shows that
$$ \cbr{\text{projective lines} \ L \subseteq \PP^2} \cong \PP^2. $$
Let $ p \in \PP^2 $ be a point. Then the space of lines passing through $ p = \sbr{z_0, z_1, z_2} $ for $ z_i \in \CC $ is given by the points $ \sbr{a, b, c} $ with $ a \cdot z_0 + b \cdot z_1 + c \cdot z_2 = 0 $, which are lines $ \PP^1 $ defined by equations $ \cbr{ax_0 + bx_1 + cx_2 = 0} \subseteq \PP^2 $ in $ \PP^2 $. We may assume that $ p = \sbr{0, 0, 1} $, after projective transformation. Then the set of lines $ L \subseteq \PP^2 $ that contain $ p $ is the set of lines such that $ a \cdot 0 + b \cdot 0 + c \cdot 1 = c = 0 $. In other words,
$$ \cbr{\text{projective lines} \ L \subseteq \PP^2 \st p \in L} \cong \cbr{\sbr{a, b, 0} \in \PP^2} \cong \PP^1. $$
We have seen that given two points $ p \ne q \in \PP^2 $ there is a unique line $ L_{p, q} $ through $ p $ and $ q $. This shows that passage through $ q $ gives a single line
$$ \cbr{\text{projective lines} \ L \subseteq \PP^2 \st p, q \in L} = \cbr{L_{p, q}} \cong \PP^0. $$
\end{example}

We can parametrise projective curves of degree $ d $ in a similar way. More precisely, we have seen that any curve of degree $ d $, $ C = \cbr{P = 0} $ is defined by a homogeneous polynomial $ P \in \CC\sbr{x_0, x_1, x_2} $ of degree $ d $ with no repeated factors. Write
$$ P\br{x_0, x_1, x_2} = \sum_{\br{i, j, k} \in \NN^3} a_{i, j, k}x_0^ix_1^jx_2^k, $$
where the only non-zero coefficients $ a_{i, j, k} $ correspond to multi-indices $ \br{i, j, k} $ with $ i + j + k = d $. The set
$$ I_d = \cbr{\br{i, j, k} \in \NN^3 \st i + j + k = d} $$
has precisely $ \br{d + 1}\br{d + 2} / 2 $ elements, since the number of $ \br{i, j} $ such that $ i + j \le e \le d $ is $ e + 1 $, and the number of $ \br{i, j} $ such that $ i + j \le d $ is $ 1 + \dots + \br{d + 1} = \br{d + 1}\br{d + 2} / 2 $. We may order the triples $ \br{i, j, k} \in I $ by lexicographic order. Recall from Remark \ref{rem:4.12} that if $ P $ and $ Q $ are two homogeneous polynomials with no repeated factors, $ C = \cbr{P = 0} = \cbr{Q = 0} $ precisely when $ P = \lambda Q $ for some $ \lambda \in \CC^* $. This shows that there is a well-defined map
$$ \function[\Psi_d]{\cbr{C = \cbr{P = 0} \st \deg C = d}}{\PP^{N_d}}{C = \cbr{\sum_{\br{i, j, k} \in \NN^3} a_{i, j, k}x_0^ix_1^jx_2^k = 0}}{\sbr{a_{i, j, k}} = \sbr{a_{0, 0, d}, \dots, a_{d, 0, 0}}}, $$
where $ N_d = \br{d + 1}\br{d + 2} / 2 - 1 = d\br{d + 3} / 2 $.

\pagebreak

\begin{example*}
\hfill
\begin{itemize}
\item $ d = 1 $ gives $ N_1 = \br{1}\br{4} / 2 = 2 $.
\item $ d = 2 $ gives $ N_2 = \br{2}\br{5} / 2 = 5 $.
\item $ d = 3 $ gives $ N_3 = \br{3}\br{6} / 2 = 9 $.
\end{itemize}
\end{example*}

\begin{remark}
The map $ \Psi_d $ is not surjective when $ d > 1 $. In $ \PP^{N_d} $, there are points that correspond to $ P $ with repeated factors. Indeed, for instance, the point $ \sbr{1, 0, \dots, 0} \in \PP^{N_d} $ corresponds to $ P\br{x_0, x_1, x_2} = x_0^d $, so that it defines a line $ L = \cbr{x_0 = 0} $ with multiplicity $ d $. We will include this case in our description by counting that curve component with multiplicity $ d $. Also, we will set $ \mult_p C = d \cdot \mult_p L = d $ for $ p \in C $, and analogously for curves with more than one repeated component, and not necessarily of degree one, and for intersection numbers of two curves with repeated components, so that for example for the curves $ C = \cbr{x_0^d = 0} $ and $ D = \cbr{x_1^e = 0} $, we have $ \I\br{p, C, D} = de $ in the only point of intersection $ p = \sbr{0, 0, 1} $. B\'ezout's theorem continues to hold with these more general definitions.
\end{remark}

\begin{definition}
Let $ \LLL_d $ denote the set of curves $ C \subseteq \PP^2 $ defined by a homogeneous polynomial of degree $ d $, possibly with repeated factors. Then $ \Psi_d $ defines a bijection
$$ \function[\Psi_d]{\LLL_d}{\PP^{N_d}}{C = \cbr{\sum_{\br{i, j, k} \in I} a_{i, j, k}x_0^ix_1^jx_2^k = 0}}{\sbr{a_{i, j, k}}}, \qquad N_d = \dfrac{d\br{d + 3}}{2}. $$
\end{definition}

\begin{example}
\hfill
\begin{itemize}
\item We have seen that $ \LLL_1 \cong \PP^2 $.
\item Similarly, $ \LLL_2 \cong \PP^5 $, and $ \LLL_2 $ contains smooth conics, reducible conics with no repeated factors, and a subspace $ F \subseteq \LLL_2 $ of fake conics that are defined by polynomials with repeated factors, so double lines in $ \PP^2 $. The subset $ F $ parametrises lines counted with multiplicity two, $ F \cong \LLL_1 \cong \PP^2 $.
\item Last, $ \LLL_3 \cong \PP^9 $, and $ \LLL_3 $ contains a subspace $ F_1 \cong \PP^2 $ parametrising lines counted with multiplicity three and a subspace $ F_2 \cong \PP^2 \times \PP^2 $ parametrising the union of a line counted with multiplicity two and a line counted with multiplicity one.
\end{itemize}
\end{example}

\begin{remark}
\hfill
\begin{itemize}
\item We have proved in previous lectures that up to a projective transformation, there are only three kinds of conics. Here the space of conics $ \LLL_2 $ on the other hand has infinitely many elements, but in this space we are also remembering the way that the conic sits inside $ \PP^2 $, via its equation. What relates the two different points of view, is that the group of projective transformations $ \Psi : \PP^2 \to \PP^2 $, that is usually denoted by $ \PGL_3\br{\CC} $, acts on the space $ \LLL_2 $, and there are exactly three orbits for the action, described by the three conics
$$ x_0^2 = 0, \qquad x_0^2 + x_1^2 = 0, \qquad x_0^2 + x_1^2 + x_2^2 = 0, $$
mentioned after Exercise \ref{ex:30}.
\item For cubics something similar happens. $ \PGL_3\br{\CC} $ acts on the space $ \LLL_3 $, but this time there are infinitely many orbits. The equation of Theorem \ref{thm:13.1} gives one such cubic for every $ \lambda \in \CC \setminus \cbr{1, 0} $, and although it is not true that these are all non-isomorphic, for every $ \lambda $ there is a finite number of $ \lambda' $, at most six, for which the two curves are isomorphic, that is one equation can be brought to the other via a projective transformation, so there is still an infinite number of non-isomorphic smooth cubics.
\end{itemize}
\end{remark}

\begin{lemma}
\label{lem:14.6}
Let $ d, q \in \NN $. Let $ p \in \PP^2 $, then
$$ \SSS = \cbr{C \in \LLL_d \st \mult_p C \ge q} \cong \PP^{N_{d, q}}, \qquad N_{d, q} = \dfrac{d\br{d + 3}}{2} - \dfrac{q\br{q + 1}}{2}. $$
\end{lemma}

\pagebreak

\begin{proof}
We will show that $ \Psi_d\br{\SSS} \cong \PP^{N_{d, q}} $, where as above, $ \Psi_d $ is the map
$$ \function[\Psi_d]{\LLL_d}{\PP^{N_d}}{C = \cbr{\sum_{\br{i, j, k} \in I} a_{i, j, k}x_0^ix_1^jx_2^k = 0}}{\sbr{a_{i, j, k}}}. $$
We denote by $ \sbr{C} = \Psi_d\br{C} $ for each $ C \in \LLL_d $. We show that $ C \in \SSS $ if and only if $ \sbr{C} \in \PP^{N_d} $ is in the subspace of solutions of a linear system of $ q\br{q + 1} / 2 $ independent equations, that is a linear system defined by a matrix of size $ q\br{q + 1} / 2 \times N_d $ of rank $ q\br{q + 1} / 2 $. After projective transformation, we may assume that $ p = \sbr{0, 0, 1} $. Let $ C \in \LLL_d $, and denote by $ P $ a homogeneous polynomial of degree $ d $ with $ C = \cbr{P = 0} $. Let
$$ f\br{x, y} = P\br{x, y, 1} = \sum_{\br{i, j, k} \in I} a_{i, j, k}x^iy^j. $$
Then $ \mult_p P = \mult_{\br{0, 0}} f \ge q $ if and only if $ a_{i, j, k} = 0 $ for all $ \br{i, j, k} \in I $ with $ i + j < q $. Denote by $ J \subseteq \cbr{0, \dots, N_d} $ the set of indices in lexicographic order that correspond to the subset
$$ \cbr{\br{i, j, k} \in I \st i + j < q} $$
of $ I $. In $ \sbr{a_{i, j, k}} $, a bunch of these are zero. As there are $ q\br{q + 1} / 2 $ triples $ \br{i, j, k} $ with $ i + j + k = d $ and $ i + j < q $, \footnote{Exercise} the ones that are left are the coordinates of the $ \PP^{N_{d, q}} $,
$$ \Psi_d\br{\SSS} \cong \PP^{N_{d, q}} = \cbr{\sbr{C} = \sbr{C_0, \dots, C_{N_d}} \in \PP^{N_d} \st \forall j \in J, \ C_j = 0}. $$
\end{proof}

\begin{example*}
Let $ \sbr{x_1, x_2, x_3, x_4} \in \PP^3 $. Then $ x_0 = 0 $ and $ x_1 = 0 $ implies that
$$ \function[\Psi_d]{\LLL_d}{\PP^1}{\sbr{0, 0, x_2, x_3}}{\sbr{x_2, x_3}}. $$
\end{example*}

\begin{example}
Let $ p \in \PP^2 $, and consider the space
$$ \SSS = \cbr{C \in \LLL_2 \st \mult_p C \ge 2}. $$
Then, by Lemma \ref{lem:14.6}, $ \SSS \cong \PP^2 $. Recall that an irreducible conic is always smooth, by Corollary \ref{cor:10.4}. Therefore, the curves $ C \in \SSS $ parametrise \textbf{degenerate conics} of the form $ C = L \cup L' $, where $ L $ and $ L' $ are projective lines containing $ p $. The lines $ L $ and $ L' $ need not be distinct, as the points of $ \LLL_2 $ also parametrise double lines. It is easy to check by direct methods \footnote{Exercise} that
$$ \cbr{\br{L, L'} \in \LLL_1 \st p \in L \cap L'} \cong \PP^2. $$
\end{example}

\lecture{22}{Monday}{26/11/18}

\begin{definition}
\label{def:14.8}
Let $ p_1, \dots, p_k $ be distinct points of $ \PP^2 $, and fix $ d, q_1, \dots, q_k \in \ZZ_{> 0} $. Then
$$ \SSS = \cbr{C \in \LLL_d \st \forall i = 1, \dots, k, \ \mult_{p_i} C \ge q_i} $$
is the \textbf{linear system of curves} of degree $ d $ going through the points $ p_i $ with multiplicity at least $ q_i $ for $ i = 1, \dots, k $.
\end{definition}

This is a copy of $ \PP^N $ inside $ \LLL_d $. Every condition on $ p_i $ gives some linear equations in the coefficients of a polynomial defining $ C $, but these equations might not be independent.

\begin{theorem}
\label{thm:14.9}
With the notation of Definition \ref{def:14.8},
$$ \SSS \cong \PP^N, \qquad N \ge N' = \dfrac{d\br{d + 3}}{2} - \sum_{i = 1}^k \dfrac{q_i\br{q_i + 1}}{2}. $$
\end{theorem}

The number $ N' $ is the expected dimension of $ \SSS $, which is what you get if the equations are independent, while $ N $ is its actual dimension.

\begin{proof}
Prove this precisely. \footnote{Exercise}
\end{proof}

\pagebreak

\begin{corollary}
Let $ p_1, \dots, p_k $ be distinct points of $ \PP^2 $ and $ d, q_1, \dots, q_k \in \br{\NN^*}^{k + 1} $. If $ N' \ge 0 $, there exists a curve $ C \in \LLL_d $ that passes through $ p_1, \dots, p_k $ with the assigned multiplicities $ q_1, \dots, q_k $.
\end{corollary}

\begin{proof}
This is an immediate consequence of Theorem \ref{thm:14.9}.
\end{proof}

\begin{example*}
Let $ k = 1 $ and $ q_1 = 2 $. Then $ d\br{d + 3} / 2 \ge 2 \cdot \tfrac{3}{2} $, so $ d\br{d + 3} \ge 6 $. Thus $ d \ge 2 $.
\end{example*}

Linear systems of dimension one have a special name.

\begin{definition}
A \textbf{pencil of curves} of degree $ d $ is a family of plane curves
$$ C_{\sbr{\lambda_0, \lambda_1}} = \cbr{\lambda_0 \cdot P_1 + \lambda_1 \cdot P_2 = 0} \subseteq \PP^2, $$
where $ P_1 $ and $ P_2 $ are homogeneous polynomials of degree $ d $ with no common factor of $ C_1 = \cbr{P_1 = 0} $ and $ C_2 = \cbr{P_2 = 0} $ in $ \SSS $, and $ \sbr{\lambda_0, \lambda_1} \in \PP^1 $. In other words $ \cbr{C_{\sbr{\lambda_0, \lambda_1}}}_{\sbr{\lambda_0, \lambda_1} \in \PP^1} $ is a family of curves of degree $ d $ of dimension one, that is parametrised by $ \PP^1 $. If $ \SSS \cong \PP^1 $ is a linear system of curves of degree $ d $, it defines naturally a pencil of curves of degree $ d $.
\end{definition}

\begin{exercise**}
\label{ex:40}
Let $ p_1, \dots, p_4 \in \PP^2 $ be four non-collinear points. Prove that
$$ \SSS = \cbr{C \in \LLL_2 \st p_1, \dots, p_4 \in C} \cong \PP^1. $$
\end{exercise**}

\begin{example}
By Exercise \ref{ex:40} above, $ \SSS $ defines a pencil of conics, the pencil of conics through $ p_1, \dots, p_4 $. Let $ C_1, C_2 \in \SSS $ be distinct conics in $ \SSS $ and assume that $ C_1 = \cbr{P_1 = 0} $ and $ C_2 = \cbr{P_2 = 0} $ for homogeneous polynomials $ P_1 $ and $ P_2 $ of degree two. Then every other conic is $ \lambda \cdot P_1 + \mu \cdot P_2 = 0 $. How many reducible conics are there in $ \SSS $? Since $ p_1, \dots, p_4 $ are non-collinear, neither $ C_1 $ nor $ C_2 $ is a line with multiplicity two, and $ P_1 $ and $ P_2 $ are polynomials with no repeated factor. Further $ P_1 $ and $ P_2 $ have no common factor. The pencil of conics through $ p_1, \dots, p_4 $ parametrises the family of curves
$$ C_{\sbr{\lambda, \mu}} = \cbr{\lambda \cdot P_1 + \mu \cdot P_2 = 0} \subseteq \PP^2. $$
Recall that $ C_{\sbr{\lambda, \mu}} $ is smooth if and only if it is irreducible, that is if and only if
$$ F\br{\lambda, \mu} = \det M_{\sbr{\lambda, \mu}} = \det \br{\lambda \cdot M_{P_1} + \mu \cdot M_{P_2}} \ne 0, $$
where $ M_{\sbr{\lambda, \mu}}, M_{P_1}, M_{P_2} $ are the matrices associated to $ C_{\sbr{\lambda, \mu}}, C_1, C_2 $ as in Exercise \ref{ex:31}. The polynomial $ F \in \CC\sbr{\lambda, \mu} $ is homogeneous of degree three in $ \lambda $ and $ \mu $, so that it is either identically zero, and one can prove that this does not happen, or it has at least one and at most three roots by Lemma \ref{lem:6.2}. Geometrically, if three among the $ p_i $ are contained in a line $ L $, all conics through $ p_1, \dots, p_4 $ have to have $ L $ as a component, by B\'ezout's theorem, and the other line has to pass through the fourth point, but is arbitrary otherwise. In this case the determinant is identically zero, and every conic of the linear system is reducible. Otherwise, there are exactly three reducible conics in the family, given by the three possible pairs of lines passing through $ p_1, \dots, p_4 $. So the pencil of conics through $ p_1, \dots, p_4 $ has at least one and at most three reducible elements.
\end{example}

\begin{proposition}
Let $ p_1, \dots, p_8 \in \PP^2 $ be eight distinct points and suppose that no four of the points lie on a line and no seven on a conic. Then
$$ \SSS = \cbr{C \in \LLL_3 \st p_1, \dots, p_8 \in C} \cong \PP^1. $$
\end{proposition}

\begin{corollary}
Let $ C_1 $ and $ C_2 $ be two cubic curves whose intersection consists of nine distinct points $ C_1 \cap C_2 = \cbr{p_1, \dots, p_9} $. Then any cubic curve $ D \subseteq \PP^3 $ that contains $ p_1, \dots, p_8 $ passes through $ p_9 $.
\end{corollary}

\begin{proof}
One proves that $ p_1, \dots, p_8 $ satisfy the assumptions of Theorem \ref{thm:14.9}, so that cubics through these points form a pencil. Then if $ P_1 $ and $ P_2 $ are homogeneous polynomials of degree three with $ C_1 = \cbr{P_1 = 0} $ and $ C_2 = \cbr{P_2 = 0} $, $ P_1 $ and $ P_2 $ form a basis of the two-dimensional vector space of homogeneous polynomials defining a curve in $ \SSS $. In other words,
$$ \SSS = \cbr{P_{\sbr{\lambda, \mu}} = \cbr{\lambda \cdot P_1 + \mu \cdot P_2 = 0} \st \sbr{\lambda, \mu} \in \PP^1}. $$
It follows that if $ p_9 \in C_1 \cap C_2 $, $ P_1\br{p_9} = P_2\br{p_9} = 0 $, then $ P_{\sbr{\lambda, \mu}}\br{p_9} = 0 $ and $ p_9 \in P $ for every $ P \in \SSS $.
\end{proof}

\pagebreak

\section{Riemann surfaces}

In this part of the course, we will see that a smooth projective curve has a single topological invariant that characterises its topology, its genus, and we will introduce the formalism of Riemann surfaces to study this genus. We have seen that a projective line $ \PP^1 $ is homeomorphic to the sphere $ \S^2 \subseteq \RR^3 $. We also saw that stereographic projection defined a homeomorphism, in fact a diffeomorphism, \footnote{Exercise} between any smooth conic $ C $ and $ \PP^1 $, by a bijection between $ C $ and lines through $ p_0 $, or a bijection to any line $ L_0 $ not containing $ p_0 $, so that a smooth conic is also homeomorphic to a sphere $ \S^2 \subseteq \RR^3 $. If $ C \subseteq \PP^2 $ is a smooth projective plane curve of degree $ d \ge 3 $, can do a similar projection. We will see that $ C $ is a homeomorphic to a sphere with $ g $ handles, where $ g $ is the genus of $ C $ and can be determined in terms of $ d $. In these cases, stereographic projection turns out to be a bit more complicated than for smooth conics. We now look at the case $ d = 3 $, where the study of stereographic projection gives us a good grasp of the topology of a smooth cubic. Stereographic projection of $ C $ with respect to $ p_0 \in C $ is defined as follows. Fix a smooth point $ p_0 \in C $, recall that $ \SSS = \cbr{L \in \LLL_1 \st p_0 \in L} \cong \PP^1 $ and we can identify $ \SSS $ with any line $ L_0 \subseteq \PP^2 $ that does not contain $ p_0 $ by the bijection $ L_0 \in \SSS \mapsto L \cap L_0 \in L $. Then, the stereographic projection is the surjective map
$$ \function[\pi]{C}{L_0}{p}{L_{p, p_0} \cap L_0}, $$
where $ L_{p, p_0} $ is the unique line through $ p $ and $ p_0 $ if $ p \ne p_0 $ or $ \T_{p_0} C $ if $ p = p_0 $, which is not one-to-one anymore. Equivalently, $ L_{p, p_0} $ is the line through $ p_0 $ and $ \pi\br{p} $. By Proposition \ref{prop:12.14} and B\'ezout's Theorem \ref{thm:11.11}, $ \pi^{-1}\br{\pi\br{p}} \subseteq C $ consists of $ d - 1 $ points unless $ L_{p, p_0} $ is tangent to $ C $ at some point in $ \pi^{-1}\br{p} $. Then $ \pi $ is a $ \br{d - 1} $-to-one covering space of $ \PP^1 $.

\lecture{23}{Thursday}{29/11/18}

\begin{example*}
\hfill
\begin{itemize}
\item The covering space
$$ \function[f]{\S^1 \subseteq \CC}{\S^1 \subseteq \CC}{z}{z^2} $$
is two-to-one everywhere. Pretend I do not know the source $ \S^1 $. Could have a disjoint union of two copies of $ \S^1 $ with the identity map on each copy, which is a trivial covering space. Glue back with a cross to give the $ \S^1 $ from before, which is a non-trivial covering space.
\item Assume $ d = 3 $. Recall that up to projective transformation, a smooth cubic is defined by an equation of the form
$$ C = \cbr{P\br{x_0, x_1, x_2} = x_1^2x_2 - x_0\br{x_0 - x_2}\br{x_0 - \lambda x_2} = 0}, \qquad \lambda \ne 0, 1. $$
The affine equation is $ C_0 = \cbr{y^2 = x\br{x - 1}\br{x - \lambda}} $. If $ \pi : C \to \PP^1 $ is the stereographic projection from the inflection point $ p_0 = \sbr{0, 1, 0} $, we see by direct calculation that $ \pi $ is two-to-one and the fibre $ \pi^{-1}\br{\pi\br{p}} $ consists of precisely two points unless $ p = p_0 = \sbr{0, 1, 0} $, or $ p_0 \in \T_p C $, that is $ P_{x_1}\br{p} = 0 $, which occurs when $ p $ is one of the points $ p_0 = \sbr{0, 1, 0} $, $ p_1 = \sbr{0, 0, 1} $, $ p_2 = \sbr{1, 0, 1} $, or $ p_3 = \sbr{\lambda, 0, 1} $. The projection $ \pi $ presents $ C $ as a two sheeted cover of $ \PP^1 $ ramified at the points $ p_0, \dots, p_3 $. Informally, in the neighbourhood of a ramification point, the stereographic projection $ \pi $ behaves like
$$ \function{C_0}{\CC = \cbr{y = 0}}{\br{x, y}}{x}. $$
Projectively, $ \sbr{x_0, x_1, x_2} \mapsto \sbr{x_0, x_1} \in \PP^1 $. From this, we construct a topological model of $ C $ as follows. Take two spheres $ \PP^1 \cong \S^2 $ and slit each sphere twice in identical ways along paths from $ \pi\br{p_0} $ to $ \pi\br{p_1} $ and from $ \pi\br{p_2} $ to $ \pi\br{p_3} $. Open up the slits to make two holes, then turn one of the spheres over and glue it to the other respecting the markings. In this way, you obtain a torus. For any value of $ \lambda $, we obtain a fixed topological object, the torus $ \T \cong \S^1 \times \S^1 $. So $ C $ is homeomorphic to a torus. Where did $ \lambda $ go? It is in the structure of the Riemann surface. The parameter $ \lambda $ that distinguishes different, non-isomorphic, cubics will influence the complex structure that we obtain on $ \T $, that is the structure of complex-analytic manifold.

\pagebreak

\item Similarly, if
$$ C = \cbr{y^2 = \prod_{i = 1}^{2g + 1} \br{x - a_i}} \subseteq \CC^2, $$
for distinct $ a_i \in \CC $, the projectivisation of $ C $ is a hyper elliptic curve $ \overline{C} \subseteq \PP^2 $. Just like the cubic above, the stereographic projection from $ p_0 = \sbr{0, 1, 0} $ is a two-sheeted cover ramified at $ 2g + 2 $ points $ p_0, \dots, p_{2g + 1} $, where $ p_i = \sbr{a_i, 0, 1} $. The topological model of $ \overline{C} $ is then a sphere with $ g $ holes.
\end{itemize}
\end{example*}

We will now adopt a more analytic viewpoint on the study of smooth projective plane curves, and see how this complements the algebraic approach. The end goal for this section is to prove the degree-genus formula. We will see that a smooth projective curve $ C \subseteq \PP^2 $ is topologically a compact orientable surface. These are classified by a single number, their Euler characteristic, or equivalently their genus $ g \in \NN $. An orientable surface of genus $ g $ is homeomorphic to a sphere with $ g $ holes or handles attached in the surface. The degree-genus formula says that a smooth projective curve $ C \subseteq \PP^2 $ of degree $ d $ has genus $ g = \br{d - 1}\br{d - 2} / 2 $. Let us start by defining and studying the basic properties of Riemann surfaces.

\begin{definition}
\label{def:15.1}
A \textbf{Riemann surface} is a topological space $ S $, endowed with an \textbf{atlas} $ \cbr{\br{U_i, \phi_i}}_{i \in I} $, where
\begin{itemize}
\item $ S $ is Hausdorff,
\item for each $ i \in I $, $ U_i \subseteq S $ is an open subset,
\item for each $ i \in I $, $ \phi_i : U_i \to V_i $ is a homeomorphism, where $ V_i \subseteq \CC $ is an open subset,
\item for each $ i \in I $, $ U_i $ form an \textbf{open cover} of $ S $, that is $ S = \bigcup_{i \in I} U_i $, and
\item if $ U_i \cap U_j \ne \emptyset $, the \textbf{transition function}
$$ \phi_j \circ \phi_i^{-1} : \phi_i\br{U_i \cap U_j} \to \phi_j\br{U_i \cap U_j}, $$
where $ \phi_i\br{U_i \cap U_j} $ and $ \phi_i\br{U_i \cap U_j} $ are open subsets of $ \CC $, is \textbf{biholomorphic}, so holomorphic and invertible with holomorphic inverse. This is to talk about holomorphicity of functions defined on $ S $.
\end{itemize}
For each $ i \in I $, $ U_i $ is a \textbf{coordinate neighbourhood} and $ \phi_i : U_i \to \CC $ is a \textbf{holomorphic coordinate} on $ U_i $.
\end{definition}

\begin{remark}
Being locally homeomorphic to an open subset of $ \CC \cong \RR^2 $, a Riemann surface is really a surface in the sense of differential geometry, that is a space with two real dimensions.
\end{remark}

\begin{remark}
Keeping the notation of Definition \ref{def:15.1} above, let $ f_i : V_i \to f_i\br{V_i} \subseteq \CC $ be a biholomorphic function, with $ f_i\br{V_i} $ open in $ \CC $. If $ S $ is a Riemann surface, and $ \cbr{\br{U_i, \phi_i}}_{i \in I} $ is an atlas, then for each $ i \in I $, $ f_i \circ \phi_i $ is also a holomorphic coordinate on $ U_i \subseteq S $, so that $ \cbr{\br{U_i, f_i \circ \phi_i}}_{i \in I} $ is another atlas for $ S $.
\end{remark}

We are interested in properties of Riemann surfaces that are independent of the choice of holomorphic coordinates. In some cases, we will use holomorphic functions to change the atlas to more suitable holomorphic coordinates.

\begin{example}
\hfill
\begin{itemize}
\item Let $ S = \PP^1 $, and consider $ \cbr{\br{U_0, \phi_0}, \br{U_1, \phi_1}} $, where
$$ U_0 = \cbr{\sbr{x_0, x_1} \in \PP^1 \st x_0 \ne 0}, \qquad \function[\phi_0]{U_0}{\CC}{\sbr{x_0, x_1}}{\dfrac{x_1}{x_0}}, $$
$$ U_1 = \cbr{\sbr{x_0, x_1} \in \PP^1 \st x_1 \ne 0}, \qquad \function[\phi_1]{U_1}{\CC}{\sbr{x_0, x_1}}{\dfrac{x_0}{x_1}}. $$
Then $ S = U_0 \cup U_1 $, and $ \phi_0 $ and $ \phi_1 $ are homeomorphic, and on $ U_0 \cap U_1 = \cbr{x_0 \ne 0, \ x_1 \ne 0} $,
$$
\begin{array}{crcccl}
\phi_0 \circ \phi_1^{-1} : & \CC \setminus \cbr{0} & \to & U_1 \cap U_0 & \to & \CC \\
& z & \mapsto & \sbr{z, 1} & \mapsto & \dfrac{1}{z}
\end{array},
$$
which is biholomorphic because $ z \ne 0 $ on $ \CC^* = \phi_1\br{U_0 \cap U_1} $. So this is an atlas, and $ \PP^1 $ acquires the structure of a Riemann surface.

\pagebreak

\lecture{24}{Friday}{30/11/18}

\item Let $ \omega_1, \omega_2 \in \CC^* $ be linearly independent over $ \RR $, that is $ \omega_1 / \omega_2 \notin \RR $, and let
$$ \Lambda = \ZZ\omega_1 + \ZZ\omega_2 = \cbr{n\omega_1 + m\omega_2 \st \br{n, m} \in \ZZ^2} \subseteq \CC $$
be a subgroup of $ \CC $ with respect to $ + $. Define an equivalence relation $ \sim $ on $ \CC $ by
$$ z_1 \sim z_2 \qquad \iff \qquad z_1 - z_2 \in \Lambda, $$
and we are going to consider the quotient $ X = \CC / \Lambda = \CC / \sim $. There is a natural quotient map $ \pi : \CC \to X = \CC / \Lambda $ and we endow $ X $ with the quotient topology, that is $ U \subseteq X $ is open if and only if $ \pi^{-1}\br{U} \subseteq \CC $ is open. Note that for all $ z \in \CC $, $ z $ has a unique representative in the \textbf{fundamental parallelogram} $ \PPP $ with vertices at $ 0, \omega_1, \omega_2, \omega_1 + \omega_2 $, where opposite sides of $ \PPP $ are identified. Topologically, $ X \cong \T $, where $ \T $ is a complex torus. From this description, is not very hard to see that $ X $ is compact. If $ z \in \CC $, then for $ \epsilon > 0 $ small enough, the open disc $ \D\br{z, \epsilon} = \cbr{\omega \in \CC \st \abs{z - \omega} < \epsilon} $ is homeomorphic to $ \pi\br{\D\br{z, \epsilon}} $. Denote $ \phi_z $ the resulting homeomorphism $ \phi_z : \pi\br{\D\br{z, \epsilon}} \to \D\br{z, \epsilon} $. If $ \epsilon $ is as above, since $ \CC = \bigcup_{z \in \CC} \D\br{z, \epsilon} $ and $ X $ is compact, I can choose a finite subcover, so we may choose $ z_1, \dots, z_N \in X $ such that
$$ X = \bigcup_{1 \le i \le N} \pi\br{\D\br{z_i, \epsilon}}, $$
and use these as coordinate neighbourhoods. Then, $ \cbr{\br{U_i = \pi\br{\D\br{z_i, \epsilon}} \subseteq \CC, \phi_{z_i}}} $ is an atlas for $ X $. Indeed, the only thing left to check is that transition functions are biholomorphic, but this is clear, indeed note that $ \phi_j \circ \phi_i^{-1} : z \mapsto z + \lambda $ are all translations by an element $ \lambda \in \Lambda $ for all $ z \in U_i \cap U_j $. A hint is to pick $ x \in U_i \cap U_j $ then its preimages are $ x_i \in \D\br{z_i, \epsilon} $ and $ x_j \in \D\br{z_j, \epsilon} $, so we have $ x_i = \lambda + x_j $ for some $ \lambda \in \Lambda $, and $ \lambda $ cannot vary as you move around in $ U_i \cap U_j $. These things are exactly the smooth cubics in $ \PP^2 $. Note that $ \CC / \Lambda $ is a group. Every cubic in $ \PP^2 $ also has a group structure.
\end{itemize}
\end{example}

Next, we consider what will be for us the fundamental example of Riemann surfaces, smooth plane projective curves.

\begin{lemma}
\label{lem:15.5}
Let $ C = \cbr{P\br{x_0, x_1, x_2} = 0} \subseteq \PP^2 $ be a smooth plane projective curve. Then $ C $ has a natural structure of a Riemann surface.
\end{lemma}

To prove this, we need a version of the implicit function theorem for holomorphic functions, and polynomials in particular.

\begin{theorem}[Implicit function theorem for complex polynomials]
Let $ f\br{x, y} \in \CC\sbr{x, y} $ be a polynomial and assume that $ \br{a, b} \in \CC^2 $ satisfies $ f\br{a, b} = 0 $ and $ \tpd{f}{x}\br{a, b} \ne 0 $. Let $ C = \cbr{f\br{x, y} = 0} $. Then locally around $ \br{a, b} $, $ C $ is the graph of a holomorphic function. There are open neighbourhoods $ a \in U \subseteq \CC $ and $ b \in V \subseteq \CC $ and a holomorphic function $ \lambda : V \to U $ such that $ \lambda\br{b} = a $ and $ f\br{\lambda\br{y}, y} = 0 $ for $ y \in V $, such that $ C \cap \br{U \times V} = \cbr{\br{\lambda\br{y}, y} \st y \in V} $ is the graph of $ \lambda $.
\end{theorem}

\begin{note*}
In particular,
\begin{itemize}
\item around $ \br{a, b} $, the function $ \lambda $ is uniquely determined, because two functions having the same graph are equal, and
\item the functions
$$ \function{V}{C \cap \br{U \times V}}{y}{\br{\lambda\br{y}, y}}, \qquad \function{C \cap \br{U \times V}}{V}{\br{x, y}}{y} $$
are inverse homeomorphisms.
\end{itemize}
\end{note*}

\begin{example*}
\hfill
\begin{itemize}
\item Let
$$ x^2 + y^2 - 1 = 0. $$
Use $ y = \sqrt{x^2 + 1} $ around $ \br{0, 1} $ and use $ x = \sqrt{y^2 + 1} $ around $ \br{1, 0} $.
\item If
$$ f\br{x, y} = x - p\br{y}, $$
then $ \tpd{f}{x} \equiv 1 $, so $ f\br{x, y} = 0 $, so $ x = p\br{y} $.
\end{itemize}
\end{example*}

\pagebreak

\begin{proof}[Proof of Lemma \ref{lem:15.5}]
We define an atlas that gives $ C $ the structure of a Riemann surface. Recall that $ U_i \subseteq \PP^2 $ were the open covers $ U_i = \cbr{x_i \ne 0} $, we denote by $ U_i \cap C $ the affine curve that is the restriction of $ C $ to the open set $ U_i \cong \CC^2 $. We show that each $ p \in C $ lies in an open coordinate neighbourhood $ p \in U_p \subseteq C $ and construct homeomorphisms $ \phi_p : U_p \to \phi_p\br{U_p} \subseteq \CC $ such that $ \cbr{\br{U_p, \phi_p}}_{p \in C} $ form an atlas. Let us first assume that $ p = \sbr{a, b, 1} \in U_2 $, and write
$$ C_2 = C \cap U_2 = \cbr{f\br{x, y} = P\br{x, y, 1} = 0}, \qquad x = \dfrac{x_0}{x_2}, \qquad y = \dfrac{x_1}{x_2}. $$
Since $ C $ is smooth, $ p \in C $ is a smooth point, so $ \br{f_x\br{a, b}, f_y\br{a, b}} \ne \br{0, 0} $. If $ f_y\br{a, b} \ne 0 $, then, by the implicit function theorem, there are neighbourhoods $ a \in V \subseteq \CC $ and $ b \in W \subseteq \CC $ and a holomorphic function $ g : V \to W $ such that $ C_2 \cap \br{V \times W} = \cbr{\br{x, g\br{x}} \st x \in V} $. We may further assume, since $ f_y $ is continuous that $ f_y\br{x, y} \ne 0 $ for all $ \br{x, y} \in C_2 \cap \br{V \times W} $. Define
$$ U_p^{2, y} = C_2 \cap \br{V \times W}, \qquad \function[\phi_p]{U_p^{2, y}}{\CC}{\sbr{x, y, 1}}{x}. $$
This is a homeomorphism onto its image with inverse $ x \mapsto \sbr{x, g\br{x}, 1} $. If on the other hand $ f_y\br{a, b} = 0 $, then we have $ f_x\br{a, b} \ne 0 $, and we define in the same way using $ x $ as a function of $ y $ to get
$$ U_p^{2, x} = \cbr{\br{h\br{y}, y} \st y \in W}, \qquad \function[\phi_p]{U_p^{2, x}}{\CC}{\sbr{x, y, 1}}{y}. $$
Moreover, if $ p \in U_1 \setminus U_2 $ or $ p \in U_0 \setminus \br{U_1 \cup U_2} $, we also define $ U_p^{1, y}, U_p^{1, x}, U_p^{0, y}, U_p^{0, x} $ in the exact same manner. Note that $ x $ and $ y $ mean different things in different affine charts. We have to check that transition functions between these open sets are biholomorphic. There are three cases.
\begin{itemize}
\item If $ U_p^{2, y} \cap U_{p'}^{2, y} \ne \emptyset $, then $ \phi_p = \phi_{p'} $, so that the transition function is the identity, which is holomorphic.
\item If $ \sbr{a, b, 1} \in U_p^{2, y} \cap U_{p'}^{2, x} $, then $ f_x\br{a, b} \ne 0 $ and $ f_y\br{a, b} \ne 0 $ and on $ U_p^{2, y} \cap U_{p'}^{2, x} $, there are holomorphic functions $ g : V \to W $ and $ h : W \to V $ such that $ y = g\br{x} $ and $ x = h\br{y} $. By construction, $ g $ and $ h $ are the transition functions between the holomorphic coordinates $ \sbr{x, y, 1} \mapsto x $ and $ \sbr{x, y, 1} \mapsto y $.
\item Now we have to look at open subsets that we get from points that live in different affine charts $ U_i $. Assume for example that $ U_p^{2, y} \cap U_{p'}^{1, \widetilde{z}} \ne \emptyset $. The other cases are analogous. Write
$$ C \cap U_1 = \cbr{P\br{\widetilde{x}, 1, \widetilde{z}} = 0}, \qquad \tilde{x} = \dfrac{x_0}{x_1}, \qquad \tilde{z} = \dfrac{x_2}{x_1}, $$
and $ C \cap U_2 = \cbr{P\br{x, y, 1} = 0} $, where $ x $ and $ y $ are as above. Then in points of $ U_p^{2, y} \cap U_{p'}^{1, \widetilde{z}} $ the two charts are given by
$$ \function[\phi_p]{U_p^{2, y}}{\CC}{\sbr{x, y, 1}}{x}, \qquad \function[\phi_{p'}]{U_{p'}^{1, \widetilde{z}}}{\CC}{\sbr{\widetilde{x}, 1, \widetilde{z}}}{\widetilde{x}} $$
respectively. If $ y = g\br{x} $ on $ U_p^{2, y} $ and $ \widetilde{z} = h\br{\widetilde{x}} $ on $ U_{p'}^{1, \widetilde{z}} $ are the two holomorphic functions coming from the implicit function theorem, then the transition function is given by
$$
\begin{array}{crcccl}
\phi_{p'} \circ \phi_p^{-1} : & \phi_p\br{U_p^{2, y} \cap U_{p'}^{1, \widetilde{z}}} & \to & U_p^{2, y} \cap U_{p'}^{1, \widetilde{z}} & \to & \phi_{p'}\br{U_p^{2, y} \cap U_{p'}^{1, \widetilde{z}}} \\
& x & \mapsto & \sbr{x, g\br{x}, 1} = \sbr{\dfrac{x}{g\br{x}}, 1, \dfrac{1}{g\br{x}}} & \mapsto & \dfrac{x}{g\br{x}} = \widetilde{x}
\end{array},
$$
since $ g\br{x} \ne 0 $, which is biholomorphic where defined. Note that we already know that this function is a homeomorphism, the new bit is the fact that it is holomorphic.
\end{itemize}
This shows that we may cover $ C $ with open sets $ U_p $ endowed with homeomorphisms $ \phi_p $ such that the transition functions are biholomorphic. This atlas $ \cbr{\br{U_p, \phi_p}}_{p \in C} $ gives $ C $ the structure of a Riemann surface.
\end{proof}

\lecture{25}{Monday}{03/12/18}

\begin{remark}
The proof gives actually something more. For every projective curve $ C $, if $ \Sing C $ denotes the set of singular points of $ C $, then $ C \setminus \Sing C \subseteq C $ is naturally a Riemann surface.
\end{remark}

\pagebreak

Using atlases, we can define holomorphic functions on a Riemann surface.

\begin{definition}
\label{def:15.8}
Let $ S $ be a Riemann surface, and $ f : S \to \CC $ be a continuous function. Then $ f $ is \textbf{holomorphic} at $ x \in S $ if for some coordinate neighbourhood with a chart $ \br{U_i, \phi_i} $ around $ x \in U $, the function
$$ f \circ \phi_i^{-1} : \phi_i\br{U_i} \to \CC $$
is holomorphic at $ \phi_i\br{x} $. The function $ f $ is \textbf{holomorphic} if it is holomorphic at every $ x \in S $.
\end{definition}

\begin{exercise**}
Check that Definition \ref{def:15.8} above is independent of the chosen coordinate chart around $ x $. In particular, a function $ f : X \to \CC $ is holomorphic if and only if the function $ f \circ \phi_i^{-1} : \phi_i\br{U_i} \to \CC $ is holomorphic for every $ i $.
\end{exercise**}

\begin{definition}
Let $ f : X \to Y $ be a continuous function between Riemann surfaces. Then $ f $ is \textbf{holomorphic} if, for the atlases $ \cbr{\br{U_i, \phi_i}}_{i \in I} $ of $ X $ and $ \cbr{\br{V_j, \psi_j}}_{j \in J} $ of $ Y $, the function
$$ \psi_j \circ f \circ \phi_i^{-1} : \phi_i\br{U_i} \to \psi_j\br{V_j} $$
is holomorphic for all $ i $ and $ j $.
\end{definition}

\begin{definition}
A holomorphic function $ f : X \to Y $ is an \textbf{isomorphism}, or \textbf{biholomorphism}, of Riemann surfaces if it is bijective, and its inverse $ f^{-1} $ is holomorphic.
\end{definition}

\begin{remark}
\label{rem:15.11}
Two different atlases $ \UUU = \cbr{\br{U_p, \phi_p}}_{p \in S} $ and $ \UUU' = \cbr{\br{U'_p, \phi'_p}}_{p \in S} $, in the sense of Definition \ref{def:15.1}, on the same topological space $ S $ are said to be \textbf{compatible} if the transition functions from $ \UUU $ to $ \UUU' $ are holomorphic, or if both identity maps $ \br{S, \UUU} \to \br{S, \UUU'} $ and $ \br{S, \UUU'} \to \br{S, \UUU} $ are holomorphic. Being compatible is an equivalence relation, and one can say that a Riemann surface is a topological space $ S $, together with an equivalence class of compatible atlases.
\end{remark}

\begin{exercise**}
Let $ S $ and $ S' $ be Riemann surfaces in the sense of Remark \ref{rem:15.11}, and let $ f : X \to Y $ be a function. Let $ \UUU_1 $ and $ \UUU_2 $ be two compatible atlases for $ X $, and $ \VVV_1 $ and $ \VVV_2 $ be two compatible atlases for $ Y $. Show that $ f $ is holomorphic with respect to $ \UUU_1 $ and $ \VVV_1 $ if and only if it is holomorphic with respect to $ \UUU_2 $ and $ \VVV_2 $.
\end{exercise**}

This says that it does not matter what specific atlas we use on a Riemann surface, in the given equivalence class, to define holomorphic functions.

\begin{exercise**}
Show that every equivalence class of atlases on a topological space $ S $ contains exactly one maximal element, with respect to inclusion. Describe this maximal atlas.
\end{exercise**}

\begin{exercise**}
Given an example of a topological space $ S $ with two non-equivalent atlases.
\end{exercise**}

\begin{exercise**}
Let $ S_1, S_2, S_3 $ be Riemann surfaces, and $ f : S_1 \to S_2 $ and $ g : S_2 \to S_3 $ be holomorphic functions. Show that $ g \circ f : S_1 \to S_3 $ is holomorphic.
\end{exercise**}

\begin{example}
\label{eg:15.12}
Let $ C \subseteq \PP^2 $ be a smooth plane projective curve and assume that $ \sbr{0, 0, 1} \notin C $. Then
$$ \function[f]{C}{\PP^1}{\sbr{x_0, x_1, x_2}}{\sbr{x_0, x_1}} $$
is not defined on $ \sbr{0, 0, 1} $, so assume $ \sbr{0, 0, 1} \notin C $. This function defines a holomorphic map \footnote{Exercise} that we will eventually use to prove the degree-genus formula.
\end{example}

\pagebreak

\section{Reminder about complex analysis}

We recall a few results in the theory of holomorphic and meromorphic functions. Let $ U \subseteq \CC $ be an open set and $ f : U \to \CC $ be a function. For ease of notation, we will always assume that $ U \subseteq K $, where $ K $ is compact. The function $ f $ is \textbf{holomorphic} if it satisfies one of the equivalent conditions.
\begin{itemize}
\item $ f $ is \textbf{complex differentiable}. For each point $ z_0 \in U $, $ f'\br{z_0} = \lim_{z \to z_0} \tfrac{f\br{z} - f\br{z_0}}{z - z_0} $ exists.
\item $ f $ admits \textbf{power series expansions}. For a disc $ \D\br{a, r} \subseteq U $, then $ f\br{z} = \sum_{n = 0}^\infty c_n\br{z - a}^n $ for all $ z \in \D\br{a, r} $.
\item \textbf{Cauchy's integral formula} holds for $ f $. If a closed disc $ \overline{\D}\br{a, r} \subseteq U $, then $ f\br{z} = \tfrac{1}{2\pi i}\intd{\gamma\br{a, r}}{}{\tfrac{f\br{\omega}}{\omega - z}}{\omega} $ if $ \abs{z - a} < r $, where $ \gamma\br{a, r} $ is the circle with centre $ a $ and radius $ r $ that bounds $ \D\br{a, r} $.
\end{itemize}
If $ f $ and $ g $ are holomorphic functions, $ f + g, fg, f \circ g $, where defined, are holomorphic, and $ 1 / f $ is holomorphic at $ a $ if $ f\br{a} \ne 0 $. The \textbf{maximum modulus principle} says that if $ f : U \to \CC $ is holomorphic with $ U $ open connected, and if $ \abs{f} $ attains a maximum at $ z_0 \in \D\br{a, r} $, an interior point of a disc, then $ f $ is constant. If $ f $ is holomorphic on a \textbf{punctured disc} $ \D^*\br{a, r} = \cbr{z \in \CC \st 0 < \abs{z - a} < r} $ about $ a $, then $ f $ has an isolated singularity at $ a $, and $ f $ expands in a unique way in a \textbf{Laurent series} locally at $ a $,
$$ f\br{z} = \sum_{k = -\infty}^\infty a_k\br{z - a}^k, \qquad 0 < \abs{z - a} < r, \qquad a_k = \dfrac{1}{2\pi i}\intd{\gamma\br{a, r}}{}{\dfrac{f\br{z}}{\br{z - a}^{k + 1}}}{z}. $$
The sum $ \sum_{k = -\infty}^{-1} a_k\br{z - a}^k $ is the \textbf{principal part} of the Laurent series. Then $ f $ has a \textbf{removable singularity} if $ a_k = 0 $ for all $ k < 0 $, a \textbf{pole of order $ m $} if $ a_{-m} \ne 0 $ and $ a_k = 0 $ for all $ k < -m $, and an \textbf{essential singularity} otherwise. The \textbf{identity theorem} says that zeroes of a holomorphic function $ f : U \to \CC $ are isolated in $ U $ unless $ f \equiv 0 $. If $ f\br{a} = 0 $, there exists an open $ a \in U $ such that $ a $ is the only zero of $ f $ in $ U $, so $ f\br{z} \ne 0 $ for $ z \in U $ such that $ z \ne a $. If $ f\br{a} = 0 $ and $ f $ is holomorphic, there exists $ m \in \NN^* $ and $ r > 0 $ such that for all $ \abs{z - a} < r $, the power series expansion is
$$ f\br{z} = c_m\br{z - a}^m + c_{m + 1}\br{z - a}^{m + 1} + \dots, \qquad c_m \ne 0. $$
The function $ f $ has a \textbf{zero of order $ m $} at $ a $, and $ m $ is the \textbf{order of vanishing} of $ f $ at $ a $, which is the multiplicity of $ f $ at $ a $ if $ f $ is a polynomial. In this case, can write $ f\br{z} = \br{z - a}^mg\br{z} $ around $ a $, where $ g\br{z} $ is holomorphic and $ g\br{a} \ne 0 $. If $ f : U \to \CC $ and $ K \subseteq U $ is a compact subset, then $ f $ has finitely many zeroes in $ K $. Let $ z_1, \dots, z_N \in K $ be all the zeroes of $ f $ in $ K $ and $ m_1, \dots, m_N $ be their orders, then
$$ f\br{z} = \br{z - z_1}^{m_1} \dots \br{z - z_N}^{m_N}g\br{z}, \qquad z \in K, $$
where $ g $ is holomorphic on $ K $ and $ g\br{z} \ne 0 $.

\begin{proposition}
Let $ f : U \to \CC $. If $ f $ is holomorphic on $ \D^*\br{a, r} = \cbr{z \in \CC \st 0 < \abs{z - a} < r} $ and $ \abs{f\br{z}} \le M\abs{z - a}^{-m} $ for some $ M > 0 $ and $ m \in \NN^* $, then $ f $ has at $ z = a $ a pole of order at most $ m $.
\end{proposition}

A function $ f : U \to \CC $ is \textbf{meromorphic} if there are finitely many points $ a_1, \dots, a_N \in U $ such that $ f $ is holomorphic on $ U \setminus \cbr{a_1, \dots, a_N} $ and has poles at $ a_1, \dots, a_N $. When $ f $ is meromorphic, we write $ f\br{a} = \infty $ when $ a $ is a pole of $ f $. Poles are isolated by definition, and as above, if $ K \subseteq U $ is compact, then $ f $ has finitely many poles in $ K $. If $ f : \D^*\br{a, \epsilon} \to \CC $ is meromorphic, with a pole of order $ m $, then can write $ f\br{z} = g\br{z} / \br{z - a}^m $, for some $ g $ holomorphic at $ z = a $, and $ g\br{a} \ne 0 $.

\begin{proposition}
Let $ f : U \to \CC $ be meromorphic and $ K \subseteq U $ be a compact subset. Let $ a_1, \dots, a_N $ be all the poles of $ f $ in $ K $ and $ k_1, \dots, k_N $ be their orders, and let $ b_1, \dots, b_M $ be the zeroes of $ f $ in $ K $ and $ l_1, \dots, l_M $ be their orders. Then
$$ f\br{z} = \dfrac{\br{z - b_1}^{l_1} \dots \br{z - b_M}^{l_M}}{\br{z - a_1}^{k_1} \dots \br{z - a_N}^{k_N}}\widetilde{g}\br{z}, \qquad z \in K, $$
for a uniquely determined holomorphic function $ \widetilde{g} $ on $ K $.
\end{proposition}

If $ f $ and $ g $ are meromorphic functions, then $ f + g, fg, f \circ g $, when defined, and $ 1 / f $ are meromorphic. Meromorphic functions form a field.

\pagebreak

\section{Holomorphic functions and ramification}

\lecture{26}{Thursday}{06/12/18}

We now study holomorphic functions between Riemann surfaces and the concept of ramification. From now on, Riemann surfaces will mostly be compact and connected. Compact is exactly the ones that can be embedded in some $ \PP^n $. First, we can observe that on a compact Riemann surface, holomorphic functions to $ \CC $ are uninteresting.

\begin{proposition}
Let $ X $ be a compact and connected Riemann surface and $ f : X \to \CC $ be a holomorphic function. Then, $ f $ is constant.
\end{proposition}

Recall that connected means cannot be written as a disjoint union of two open subsets. If $ X $ is connected, and $ Y \subseteq X $ open and closed, then $ Y = \emptyset $ or $ Y = X $.

\begin{proof}
By compactness of $ X $, $ \abs{f} : X \to \RR_{\ge 0} $ has a maximum on $ X $, say at a point $ a $. Around $ a $, $ f $ has to be constant, and equal to $ f\br{a} $. Let $ U $ be an open set with $ a \in U $, $ \phi_U $ be a holomorphic coordinate on $ U $ with $ \phi\br{a} = 0 $, and let $ F = f \circ \phi_U^{-1} $ be the holomorphic function representing $ f $ on $ U $. Then $ F $ has a maximum at an interior point, so that $ F $ is constant near $ a $. The set $ \cbr{z \in U \st f\br{z} = f\br{a}} $ is open and non-empty, by the maximum modulus principle. The same argument shows that $ \cbr{x \in X \st f\br{x} = f\br{a}} \subseteq X $ is open in $ X $. But it is also closed, because $ f $ is continuous, and we are looking at $ f^{-1}\br{f\br{a}} $ and $ \cbr{f\br{a}} $ is closed in $ \CC $. By connectedness, we get $ \cbr{x \in X \st f\br{x} = f\br{a}} = X $, so $ f $ is constant.
\end{proof}

\begin{remark}
Note that the situation is very different for non-compact Riemann surfaces. There are plenty of interesting holomorphic functions $ f : \CC \to \CC $, such as polynomials, but also $ z \mapsto e^z $, or $ z \mapsto \sin z $, etc.
\end{remark}

A \textbf{meromorphic} function $ f $ on a Riemann surface $ X $ is a map $ f : X \to \CC \cup \cbr{\infty} $ such that locally around every point $ a \in X $ has a coordinate chart $ \br{U, \phi_U} $ with $ a \in U $, and for which $ f \circ \phi_U^{-1} : \phi_U\br{U} \to \CC \cup \cbr{\infty} $ is a meromorphic function, so only has poles.

\begin{lemma}
If $ X $ is connected, there is a one-to-one correspondence
$$ \correspondence{\text{meromorphic functions} \\ f : X \to \CC \cup \cbr{\infty}}{\text{holomorphic functions} \ \widetilde{f} : X \to \PP^1 \\ \text{that are not constantly} \ \infty}. $$
\end{lemma}

\begin{fact**}
One can prove that there always are non-constant meromorphic functions on any Riemann surface.
\end{fact**}

\begin{proof}
We cover $ \PP^1 $ with the two standard charts $ U_0 = \cbr{\sbr{x_0, x_1} \st x_0 \ne 0} $ and $ U_1 = \cbr{\sbr{x_0, x_1} \st x_1 \ne 0} $, and identify $ \PP^1 $ with $ \CC \cup \cbr{\infty} $, with $ \CC = U_1 $ and $ \infty = \sbr{1, 0} $. This gives a bijection
$$ \correspondence{\text{functions} \ f : X \to \CC \cup \cbr{\infty}}{\text{functions} \ \widetilde{f} : X \to \PP^1}. $$
We just have to prove that $ f $ is meromorphic if and only if $ \widetilde{f} $ is holomorphic. Let $ a \in X $ be such that $ f\br{a} \ne \infty $. Then there is a chart $ \br{U, \phi_U} $ around $ a $, where $ f $ never takes the value $ \infty $, so $ f $ restricts to $ f : U \to \CC \subseteq \CC \cup \cbr{\infty} = U_1 \cup \cbr{\infty} = \PP^1 $, and the function $ F = f \circ \phi_U^{-1} $ is holomorphic if and only if it is meromorphic. All that is left is to look at points with $ f\br{a} = \infty $. Around such a point $ a $, assume first that $ f $ is meromorphic. Then there is a chart $ \br{U, \phi_U} $ around $ a $ such that the function $ F = f \circ \phi_U^{-1} : \phi_U\br{U} \to \CC \cup \cbr{\infty} $ is meromorphic. By shrinking $ U $ we may assume that $ a $ is the only pole in $ U $ and $ U $ contains no zeroes of $ f $. To pass to the chart $ U_0 $ in $ \PP^1 $, where $ \infty \in \PP^1 $ becomes $ 0 \in \CC $, just have to take $ 1 / F\br{z} $, which is a well-defined holomorphic map on $ \phi_U\br{U} $, and it is the function that represents $ \widetilde{f} $ using the chart $ U_0 $ on the target $ \PP^1 $. Therefore $ \widetilde{f} $ is holomorphic around $ a $. On the other hand, assume that $ \widetilde{f} $ is holomorphic around $ a $. Choose a chart $ \br{U, \phi_U} $ around $ a $ such that $ a $ is the only point such that $ f\br{a} = \infty $, $ \phi_U\br{a} = 0 $, and $ U $ contains no zeroes of $ \widetilde{f} $. And let $ \br{V, \psi_V} $ be the chart of $ \PP^1 $ around $ \infty $ given by $ V = U_0 $, and
$$ \function[\psi_V]{U_0}{\CC}{\sbr{x_0, x_1}}{\dfrac{x_1}{x_0}}. $$
In this chart, $ \infty \in \PP^1 $ corresponds to $ 0 \in \CC $. Then by assumption the function $ F = \psi_V \circ \widetilde{f} \circ \phi_U^{-1} $ is holomorphic. Write, after possibly shrinking $ U $, $ F\br{z} = z^ng\br{z} $, with $ g\br{z} \ne 0 $ and holomorphic. Then passing back to the chart $ U_1 = \CC $ in the target $ \PP^1 $, this becomes $ 1 / F\br{z} = h\br{z} / z^n $, where $ h\br{z} = 1 / g\br{z} $ is holomorphic around $ z = 0 $, and therefore in these charts, $ f $ becomes a meromorphic function around $ a $.
\end{proof}

\pagebreak

\begin{example}
Recall that a rational function over $ \CC $ is of the form $ f\br{z} = p\br{z} / q\br{z} $, where $ p, q \in \CC\sbr{z} $ are polynomials with no common factor. Then $ f $ defines a meromorphic function on $ \PP^1 $, or equivalently a holomorphic function $ f : \PP^1 \to \PP^1 $. Explicitly, if $ f : \CC \to \CC $ is rational, the associated map is defined by
$$ \function[f]{\PP^1 = \CC \cup \cbr{\infty}}{\CC \cup \cbr{\infty}}{z}{
\begin{cases}
\dfrac{p\br{z}}{q\br{z}} & q\br{z} \ne 0 \\
\infty & q\br{z} = 0 \\
\lim_{\abs{z} \to \infty} \dfrac{p\br{z}}{q\br{z}} & z = \infty
\end{cases}
}. $$
This is holomorphic. \footnote{Exercise} Note that if $ f = p / q $ is non-constant, $ f : \PP^1 \to \PP^1 $ is surjective. Indeed, if $ f $ is non-constant, $ \max\cbr{\deg p, \deg q} > 0 $. Assume for example that $ \deg p > \deg q $. Other cases are similar. Then if $ a \in \CC $, $ f\br{z} = a $ if and only if $ p\br{z} / q\br{z} = a $, if and only if $ p\br{z} - aq\br{z} = 0 $. This is a polynomial equation of degree $ \deg p $, so has $ \deg p $ solutions, counted with multiplicity for $ z \in \CC $. It remains to check that there is $ z \in \CC $ for which $ f\br{z} = \infty $, which is also true. But since $ \deg p > \deg q $, $ p\br{z} / q\br{z} $ behaves like a polynomial of degree $ \deg p - \deg q $ when $ z \to \infty $, so $ f $ has a pole of order $ \deg p - \deg q $ at $ \infty $, and the other poles of $ f $ are solutions to $ q\br{z} = 0 $ counted with multiplicity, which are the $ \deg q $ zeroes of $ q $, so that $ f\br{z} = \infty $ also has $ \deg p $ solutions counted with multiplicity. In particular, the number of solutions of $ \cbr{z \in \PP^1 \st f\br{z} = a} $ is independent of $ a \in \CC \cup \cbr{\infty} = \PP^1 $ counted with multiplicity. It is called the \textbf{degree} of the holomorphic function $ f $ and is equal to $ \max\cbr{\deg p, \deg q} $. In this case, a rational function $ f : \PP^1 \to \PP^1 $ is biholomorphic if and only if $ \deg f = 1 $, that is if and only if $ f $ is a M\"obius transformation
$$ z \mapsto \dfrac{az + b}{cz + d}, $$
by Example \ref{eg:8.4}. Strictly speaking, we have that $ f $ is biholomorphic implies that $ \deg f = 1 $, the converse is easy to check.
\end{example}

\begin{exercise**}
Check that the equality $ \deg f = \#f^{-1}\br{Q} $ for $ Q \in \PP^1 $, counted with multiplicities, holds when $ \deg p < \deg q $, and when $ \deg p = \deg q $.
\end{exercise**}

\begin{exercise**}
Any holomorphic map $ f : \PP^1 \to \PP^1 $ is defined by a rational function.
\end{exercise**}

\begin{remark}
The example of
$$ \correspondence{\text{holomorphic maps} \ \PP^1 \to \PP^1}{\text{rational functions}} $$
illustrates an important point. We have combined the notions of holomorphy and compactness, both on the source and target, and have found that the result is algebraic, defined by polynomials. This is the first instance of a remarkable phenomenon connecting algebraic and analytic geometries, here Riemann surfaces and algebraic curves, called the \textbf{GAGA principle}, from the paper g\'eom\'etrie alg\'ebrique et g\'eom\'etrie analytique by J P Serre, that turns out to be very general.
\end{remark}

\begin{example}
Recall the holomorphic map $ f : C \to \PP^1 $ defined in Example \ref{eg:15.12}. Then $ f $ is the meromorphic function
$$ \function[f]{C}{\CC \cup \cbr{\infty}}{\sbr{x_0, x_1, x_2}}{\dfrac{x_0}{x_1}}, $$
using the chart $ U_1 = \CC $ on the target $ \PP^1 $. Note that the only point where $ x_0 / x_1 $ is undefined is $ \sbr{0, 0, 1} $, which we are assuming is not contained in $ C $. To check carefully that $ f $ is meromorphic, use the charts constructed in Lemma \ref{lem:15.5}. \footnote{Exercise}
\end{example}

\lecture{27}{Friday}{07/12/18}

We could define more complicated holomorphic maps $ C \to \PP^1 $ by taking any polynomial in $ f $, or any ratio of such polynomials. Now we are going to define the concept of ramification of holomorphic maps of Riemann surfaces.

\begin{proposition}
\label{prop:17.7}
Let $ X $ and $ Y $ be compact connected Riemann surfaces, and $ f : X \to Y $ a non-constant holomorphic map. Then for every $ a \in Y $, $ f^{-1}\br{a} \subseteq X $ is a finite set.
\end{proposition}

\pagebreak

In the proof we will use the following.

\begin{exercise**}
\label{ex:48}
Prove that for an $ f $ as above, we have that its restriction to any non-empty open subset of $ X $ is also non-constant. A hint is to suppose that $ f $ is constant on a non-empty open $ U \subseteq X $, with value $ a \in Y $. Show that the union
$$ \emptyset \ne U \subseteq \bigcup_{V \subseteq X \ \text{open}, \ f\br{V} = \cbr{a} \subseteq Y} V \subseteq X $$
is both open and closed in $ X $, and non-empty. Then by connectedness it is equal to $ X $.
\end{exercise**}

\begin{remark}
The conclusion of Exercise \ref{ex:48} above is false for real $ \C^\infty $ functions, such as bump functions.
\end{remark}

\begin{proof}[Proof of Proposition \ref{prop:17.7}]
Using compactness of $ X $, the conclusion follows from the fact that $ f^{-1}\br{a} $ is closed and discrete, that is for every $ x \in f^{-1}\br{a} $ there is an open neighbourhood $ x \in U \subseteq X $ such that $ f\br{y} \ne a $ for every $ y \in U \setminus \cbr{x} $, so $ U \cap f^{-1}\br{a} = \cbr{x} $. After I show this, $ X $ is compact and a closed discrete subset has to be finite. The discreteness follows from Exercise \ref{ex:48} and the identity theorem in usual complex analysis. Indeed, fix some $ x \in f^{-1}\br{a} $ and take a coordinate neighbourhood $ \br{U, \phi_U} $ around $ x $. Then the zeroes of the function $ g\br{z} = f\br{z} - a $ are isolated on $ U $. If $ f^{-1}\br{a} $ is not discrete at $ x $, then there exist $ x_n \to x $ of distinct points in $ f^{-1}\br{a} \setminus \cbr{x} $. Then $ g^{-1}\br{0} $ has an accumulation point in the disc, so $ g\br{z} = 0 $. Then $ f\br{z} $ is constant, which cannot happen because of Exercise \ref{ex:48}, therefore we can find a small neighbourhood $ U' \subseteq U $ where $ x $ is the only point with $ f\br{z} = a $ in $ U' $.
\end{proof}

\begin{remark}
A basic fact about non-constant holomorphic maps between connected compact Riemann surfaces is that they are always surjective. Indeed, every such $ f $ is an open map, because of exercise $ 4 $ in the third problem sheet, but also closed, since every closed $ Z \subseteq X $ is compact, therefore $ f\br{Z} \subseteq Y $ is compact, and since $ Y $ is Hausdorff, $ f\br{Z} $ is closed. In particular $ f\br{X} \subseteq Y $ is both open and closed, and non-empty. By connectedness of $ Y $, it follows that $ f\br{X} = Y $.
\end{remark}

\begin{example}
Let $ a = \sbr{a_0, a_1} \in \PP^1 $, and consider $ f : C \to \PP^1 $, the map defined in Example \ref{eg:15.12}. The set
$$ f^{-1}\br{a} = \cbr{\sbr{ta_0, ta_1, z} \st t \in \CC^*, \ z \in \CC, \ P\br{ta_0, ta_1, z} = 0} $$
is almost the set of solutions of the homogeneous polynomial $ Q\br{t, z} = P\br{ta_0, ta_1, z} $ of degree $ \deg P $, which is finite as a subset of $ \PP^1 $, by Lemma \ref{lem:6.2}, of cardinality $ \deg Q = \deg P $ if we count with multiplicity. Note that there is no solution with $ t = 0 $, because that would correspond to the point $ \sbr{0, 0, 1} $, which is not in $ C $.
\end{example}

Now let us look at points where $ f' = 0 $. Let us look at $ f $ in charts instead. Recall that for each $ p \in X $, let $ p \in U $ be a coordinate neighbourhood, $ \phi_U $ be a holomorphic coordinate on $ U $, and similarly, $ \br{V, \psi_V} $ be a coordinate neighbourhood and holomorphic coordinate with $ f\br{p} \in V $. Then, $ f $ is described locally by the holomorphic function
$$ F = \psi_V \circ f \circ \psi_U^{-1} : \phi_U\br{U \cap f^{-1}\br{V}} \to \psi_V\br{V}. $$
By the same kind of argument used above, there is a finite number of points at which the derivative $ F' $ vanishes.

\begin{exercise**}
Take a moment to think about the derivative $ f' $ of the holomorphic function of Riemann surfaces $ X \to Y $. Does it make sense? How would you define it? What kind of object is it? A spoiler is that to define it properly, we would need to talk about tangent bundles.
\end{exercise**}

\begin{exercise**}
Let $ f : X \to Y $ be a holomorphic function of Riemann surfaces and $ x \in X $. Consider charts $ \br{U, \phi_U} $ and $ \br{U', \phi_{U'}} $ around $ x $ and $ \br{V, \psi_V} $ and $ \br{V', \psi_{V'}} $ around $ f\br{x} $. Let $ F = \psi_V \circ f \circ \phi_U^{-1} $ and $ G = \psi_{V'} \circ f \circ \phi_{U'}^{-1} $. Show that $ F'\br{\phi_U\br{x}} = 0 $ if and only if $ G'\br{\phi_{U'}\br{x}} = 0 $. These are derivatives of usual holomorphic functions between opens of $ \CC $.
\end{exercise**}

Therefore it makes sense to say that the derivative of $ f $ vanishes at $ x $, and to talk about the number of points $ x \in X $ where $ f'\br{x} = 0 $.

\begin{definition}
Let $ f : X \to Y $ be a non-constant holomorphic map of Riemann surfaces. The point $ x \in X $ is a \textbf{ramification point} of $ f $ if $ f'\br{x} = 0 $, that is in local coordinates $ f $ is represented by a holomorphic function $ F $ with $ F'\br{x} = 0 $ at $ x \in X $.
\end{definition}

\pagebreak

\begin{example}
\label{eg:17.12}
Let $ n \in \NN $, and consider the holomorphic function $ z \mapsto z^n $. Then $ 0 \in \CC $ is the only ramification point of $ f $, unless $ n = 1 $, in which case there is not any.
\end{example}

In fact, we will show that this Example \ref{eg:17.12} gives a local model for every holomorphic function $ X \to Y $ of Riemann surfaces. Let $ x \in X $, $ U $ a coordinate neighbourhood around $ x $ with holomorphic coordinate $ \phi_U $, and $ V $ a coordinate neighbourhood around $ f\br{x} \in Y $ with holomorphic coordinate $ \psi_V $. Up to composition of $ \phi_U $ and $ \psi_V $ with suitable biholomorphic functions, we may assume that $ \phi_U\br{x} = 0 $ and $ \psi_V\br{f\br{x}} = 0 $. Denote by $ F = \psi_V \circ f \circ \phi_U^{-1} : \phi_U\br{U \cap f^{-1}\br{V}} \to \psi_V\br{V} $ the holomorphic function representing $ f $ in the charts $ U $ and $ V $. Then $ F\br{0} = 0 $, so after possibly shrinking $ U $, $ F\br{z} = z^n \cdot g\br{z} $ for all $ z \in \phi_U\br{U} $, where $ n \in \NN $ is the order of $ F $ at zero and $ g $ is a holomorphic function with $ g\br{0} \ne 0 $. The point $ x $ is a ramification point of $ f $ if and only if $ n \ge 2 $. In this case we call $ n = \v_f\br{x} \in \NN $ the \textbf{ramification index} of $ f $ at $ x \in X $. This is a sort of multiplicity of the solution $ x $ for the equation $ f\br{z} = a $, where $ a = f\br{x} \in Y $ and $ z $ is a coordinate on $ X $. Note that since $ g $ is a holomorphic function with $ g\br{0} \ne 0 $, I can define a holomorphic $ g\br{z}^{1 / n} $ around $ x $, so the function $ h : z \mapsto zg\br{z}^{1 / n} $ is holomorphic, and since $ h'\br{0} \ne 0 $, \footnote{Exercise} $ h $ is biholomorphic on $ \D\br{0, r} $ for some $ r > 0 $ by the inverse function theorem. Replacing $ V $ with $ \widetilde{V} = V \cap \psi_V^{-1}\br{h\br{\D\br{0, r}}} $, and $ \psi_V $ with the holomorphic coordinate $ \widetilde{\psi}_V = h^{-1} \circ \psi_V $, we obtain a simpler local holomorphic representative for $ f $, $ \widetilde{F} = \widetilde{\psi}_V \circ f \circ \phi_U^{-1} : z \mapsto z^n $. We see immediately that no other point of $ U $ is a ramification point, and that for every $ y \ne f\br{x} \in \widetilde{V} $ in a small neighbourhood of $ f\br{x} $, $ \#\cbr{f^{-1}\br{y} \cap U} = n = \v_f\br{x} $. Let $ f : X \to Y $ be a non-constant holomorphic map between connected compact Riemann surfaces.

\lecture{28}{Monday}{10/12/18}

\begin{lemma}
For every $ y \in Y $, define the \textbf{degree} of $ f $
$$ k\br{y} = \sum_{x \in f^{-1}\br{y}} \v_f\br{x} \in \NN, $$
a finite sum. Then for all $ y, y' \in Y $, we have $ k\br{y} = k\br{y'} $, so $ k $ is independent of $ y \in Y $.
\end{lemma}

\begin{proof}
We have seen that $ f^{-1}\br{y} $ is a finite set so that $ k\br{y} $ is well-defined. As above, for all $ x \in X $ with $ f\br{x} = y $, let $ N_x $ be an open coordinate neighbourhood of $ x \in X $ and $ V_x $ be an open coordinate neighbourhood of $ y \in Y $ such that $ f $ looks like $ z \mapsto z^{\v_f\br{x}} $ around $ x $ and $ y $, so for all $ x' \in N_x \setminus \cbr{x} $, $ \v_f\br{x'} = 1 $, and for all $ y' \in V_x \setminus \cbr{y} $, $ f\br{x'} = y' $ has precisely $ \v_f\br{x} $ solutions in $ N_x $. Let $ V = \bigcap_{x \in f^{-1}\br{y}} V_x $ and $ U_x = f^{-1}\br{V} \cap N_x $. Possibly shrinking $ V $, we may assume that the neighbourhoods $ U_x $ are disjoint, pairwise, so that $ f^{-1}\br{V} = \bigsqcup_{x \in f^{-1}\br{y}} U_x $. For all $ y' \in V \setminus \cbr{y} $, $ f\br{x'} = y' $ admits $ \v_f\br{x} $ solutions in $ U_x $ and none of these are ramification points, so that
$$ k\br{y'} = \sum_{x' \in f^{-1}\br{y'}} \v_f\br{x'} = \sum_{x' \in f^{-1}\br{y'}} 1 = \sum_{x \in f^{-1}\br{y}} \br{\sum_{x' \in f^{-1}\br{y'}, \ x' \in U_x} 1} = \sum_{x \in f^{-1}\br{y}} \v_f\br{x} = k\br{y}, $$
since $ \v_f\br{x'} = 1 $ for all such $ x' $. The function $ k : Y \to \ZZ $ is then locally constant, and $ Y $ is connected. Therefore $ k $ is constant and the degree is well-defined.
\end{proof}

\begin{remark*}
For all but finitely many points of $ Y $, we have $ \v_f\br{x} = 1 $ for all $ x \in f^{-1}\br{y} $.
\end{remark*}

\begin{example}
\label{eg:17.14}
If $ f : C \to \PP^1 $ is as in Example \ref{eg:15.12}, for fixed $ \sbr{a_0, a_1} \in \PP^1 $,
$$ f^{-1}\br{a_0, a_1} = \cbr{\sbr{ta_0, ta_1, z} \st t \in \CC^*, \ z \in \CC, \ P\br{ta_0, ta_1, z} = 0}, $$
where $ Q\br{t, z} = P\br{ta_0, ta_1, z} $ is a homogeneous polynomial of two variables of degree $ \deg P $. A point $ \sbr{ta_0, ta_1, z} $ is a ramification point of $ f $ over $ \sbr{a_0, a_1} $ if and only if $ \cbr{P\br{ta_0, ta_1, z} = 0} $ has repeated roots, if and only if $ \br{t_0, z_0} $ is a repeated root of $ Q\br{t, z} $, and the multiplicity of the root corresponds to the ramification index. \footnote{Exercise} We thus have $ \deg f = \deg P $.
\end{example}

The following characterisation of the ramification points and indices of $ f $ will be used in the proof of the degree-genus formula. We will admit it without proof.

\begin{proposition}
\label{prop:17.15}
Let $ f : C \to \PP^1 $ be the map defined in Example \ref{eg:15.12}. The ramification points are those $ p \in C $ such that $ \sbr{0, 0, 1} \in \T_p C $, and the ramification index at $ p $ is then $ \I\br{p, C, \T_p C} $.
\end{proposition}

\pagebreak

\section{The degree-genus formula}

Let $ X $ be a compact connected Riemann surface. We temporarily disregard the complex structure on $ X $, and just consider the underlying topological surface. Since $ X $ is a topological manifold, it is orientable. Orientable compact connected topological surfaces are classified up to homeomorphism by their Euler characteristic or equivalently, by their genus $ g $. Each such surface is homeomorphic to a sphere $ \S^2 \subseteq \RR^3 $ with $ g $ handles attached. Here we collect a few definitions and facts on the topology of connected compact orientable surfaces. These are non-examinable, and you may be familiar with part of it. As a topological surface, A Riemann surface $ X $ is always orientable because of the Cauchy-Riemann equations. Informally, this means that $ X $ has two sides. For a precise definition of orientability, start from a real vector space $ W \cong \RR^k $. An \textbf{orientation} of $ W $ is an equivalence class of bases of $ W $. Two bases are equivalent, or have the same orientation, if and only if the matrix expressing the transition between these bases has positive determinant. An abstract \textbf{surface} $ X $, or a two-dimensional real differentiable manifold, is a given by an atlas of charts $ \cbr{\br{U, \phi_U}} $, where $ \phi_U : U \to \RR^2 $ are homeomorphic and define local coordinates on the coordinate patches $ U $, and the transition functions $ \phi_{U'} \circ \phi_U^{-1} : \phi_U\br{U \cap U'} \to \phi_{U'}\br{U \cap U'} $ are differentiable where defined. In general, a transition map $ \RR^2 \to \RR^2 $ is non-linear but, at each point, it has a good linear approximation given by its derivative. Here, we view the derivative as a $ 2 \times 2 $ matrix of partial differentials that acts on vectors in $ \RR^2 $. Then, $ X $ is \textbf{orientable} if it has an atlas $ \cbr{\br{U, \phi_U}} $ such that for all transition functions $ \tau = \phi_{U'} \circ \phi_U^{-1} : \RR^2 \to \RR^2 $, the $ 2 \times 2 $ Jacobian matrices of partial differentials of $ \tau $ preserves the orientation, that is has positive determinant at every point where it is defined. In the case of a Riemann surface, the transition functions are holomorphic, and we are looking at linearisations of holomorphic functions, that is we consider biholomorphic transition functions $ z \mapsto \tau\br{z} $ between holomorphic coordinates. The corresponding $ 2 \times 2 $ real matrices always have positive determinant. This is a consequence of the holomorphicity of $ \tau $. Compact connected orientable surfaces are classified up to a homeomorphism by their Euler characteristic $ \chi $, or, equivalently, by their genus. In order to define $ \chi $, we need a concept of triangulation. I only include an outline, and state some results without proof. Let $ X $ be a compact connected orientable surface. Then, informally a \textbf{triangulation} $ T $ is obtained by cutting $ X $ into a finite number of polygonal triangle regions, called faces, by smooth non-self-intersecting arcs, called edges, joined at vertices, so that a triangulated surface looks like a topological polyhedron. More precisely is the following.
\begin{itemize}
\item An \textbf{edge} of $ T $ is the image in $ X $ of a homeomorphic map $ \phi : \sbr{0, 1} \subseteq \RR \to \phi\br{\sbr{0, 1}} \subseteq X $.
\item The images of $ 0 $ and $ 1 $ are \textbf{vertices} of $ T $.
\item The complement in $ X $ of the edges of $ T $ consists of finitely many connected components. Each one is required to be homeomorphic to an open disc. The \textbf{faces} of $ T $ are the closures of these components.
\end{itemize}
In addition, one requires the following properties.
\begin{itemize}
\item Two faces share at most one edge, and each edge belongs to the boundaries of exactly two faces.
\item Two edges meet only in one common end-point, a vertex of both, if at all.
\item Any vertex has a neighbourhood homeomorphic to an open disc with edges corresponding to rays from the centre to the boundary of that disc. Any two distinct sectors cut out by these rays correspond to distinct faces of $ T $. In particular, at least three edges meet at each vertex.
\end{itemize}

\begin{remark}
There are variations in the literature on what is allowed or not in a triangulation. These variations all lead to the same Euler characteristic, and can be ignored from our point of view.
\end{remark}

Let $ V\br{T}, E\br{T}, F\br{T} $ denote the number of vertices, edges, and faces of a triangulation $ T $ of $ X $. A remarkable fact is that the quantity
$$ \chi\br{X, T} = V\br{T} - E\br{T} + F\br{T} $$
only depends on $ X $ itself, and not on the choice of triangulation $ T $ of $ X $. It is called the \textbf{Euler characteristic} of $ X $, and denoted by $ \chi\br{X} $. The \textbf{genus} $ \g\br{X} $ of $ X $ is related to the Euler characteristic by
$$ \chi\br{X} = 2 - 2\g\br{X}. $$
As has been already mentioned, $ \g\br{X} $ can be visualised as the number of handles that one needs to attach to the sphere in order to obtain $ X $. In particular, $ \g\br{X} \ge 0 $, and so $ \chi\br{X} \le 2 $.

\pagebreak

\begin{example*}
\hfill
\begin{itemize}
\item Let $ \PP^1 \cong \S^2 $. The surface of a tetrahedron is a triangulation, so $ \chi\br{\S^2} = \chi\br{\PP^1} = 4 - 6 + 4 = 2 $ and $ \g\br{\S^2} = \g\br{\PP^1} = 0 $.
\item The torus $ X = \CC / \Lambda $ has $ \chi\br{X} = 1 - 3 + 2 = 0 $ and $ \g\br{X} = 1 $.
\end{itemize}
\end{example*}

\begin{remark}
The Euler characteristic $ \chi\br{X} $ is always even. Recall that we only consider orientable surfaces here. An example of topological surface with an odd $ \chi $ is the quotient $ \S^2 / \cbr{\pm 1} $ of $ \S^2 \subseteq \RR^3 $ by the antipodal map which has $ \chi = 1 $, but it is not orientable, in particular, not a Riemann surface.
\end{remark}

We shall use without proof the following topological result.

\begin{theorem}
Every topological surface underlying a compact Riemann surface has a triangulation.
\end{theorem}

\lecture{29}{Thursday}{13/12/18}

Therefore, it makes sense to talk about Euler characteristic and genus of a Riemann surface. We now go back to the study of holomorphic maps between compact, connected Riemann surfaces. So far, we have seen how to associate to such a map
\begin{itemize}
\item an algebraic quantity, the degree of the map $ d = \deg f $, which generalises the degree of polynomials,
\item analytic quantities, the ramification index $ \v_f\br{x} \in \NN $ at points $ x \in X $, that are defined via the local holomorphic descriptions of the map, where all but finitely many are one, and
\item topological quantities, the Euler characteristics $ \chi\br{X} $ and $ \chi\br{Y} $ or genera $ \g\br{X} $ and $ \g\br{Y} $ of the source and target surfaces.
\end{itemize}
The next theorem relates these different quantities. We only give a sketch of the proof in simple cases. The proof is not examinable.

\begin{theorem}[Riemann-Hurwitz formula]
Let $ f : X \to Y $ be a non-constant holomorphic map between compact connected Riemann surfaces, and denote $ d = \deg f $ its degree. Then the Euler characteristics of $ X $ and $ Y $ satisfy
$$ \chi\br{X} = d \cdot \chi\br{Y} - \sum_{p \in X} \br{\v_f\br{p} - 1}, $$
or, equivalently, the genera of $ X $ and $ Y $ are related by
$$ 2\br{\g\br{X} - 1} = 2d \cdot \br{\g\br{Y} - 1} + \sum_{p \in X} \br{\v_f\br{p} - 1}. $$
\end{theorem}

\begin{remark}
It follows in particular that the sum $ \sum_{p \in X} \br{\v_f\br{p} - 1} $ is always an even number.
\end{remark}

\begin{example}
\hfill
\begin{itemize}
\item It immediately follows from the Riemann-Hurwitz formula that if there exists a non-constant and holomorphic $ f : X \to Y $, then we have $ \g\br{X} \ge \g\br{Y} $.
\item Consider the holomorphic map
$$ \function[f]{\PP^1}{\PP^1}{z}{z^2}, $$
which is non-constant. This is degree two, ramified over $ 0 $ and $ \infty $, so $ \v_f\br{0} = \v_f\br{\infty} = 2 $. Therefore, by the Riemann-Hurwitz formula we have $ 2\br{\g\br{\PP^1} - 1} = 2\br{2\g\br{\PP^1} - 2} + 2 $, and so $ \g\br{\PP^1} = 0 $.
\item Let us go back to the example of the projection
$$ \function[f]{C = \cbr{y^2 = x\br{x - 1}\br{x - \lambda}}}{\PP^1}{\br{x, y}}{x}, \qquad \lambda \in \CC \setminus \cbr{0, 1} $$
from a point of a smooth cubic $ C $. For this map, the degree is $ \deg f = 2 $ and there are exactly four ramification points $ x = 0, 1, \lambda, \infty $. The ramification index can only be $ \v_f\br{p} = 2 $ at each of these points. The Riemann-Hurwitz formula gives $ 2\g\br{C} - 2 = \deg f\br{\g\br{\PP^1} - 2} + \sum_{p \in C} \br{\v_f\br{p} - 1} = 2\br{-2} + 4 $, so $ \g\br{C} = 1 $. This proves that smooth cubics are homeomorphic to a torus.
\end{itemize}
\end{example}

\pagebreak

\begin{proof}
The idea is to consider a triangulation of $ Y $ and pull it back to $ X $.
\begin{itemize}
\item Suppose first that there is no branching, that is that there is no ramification point. This means that for all $ y \in Y $, there is a coordinate neighbourhood $ y \in V_y \subseteq Y $ such that $ f^{-1}\br{V_y} = \bigsqcup_{f\br{x} = y} U_x $ is a disjoint union of $ d $ open sets $ U_x $, each of which is mapped biholomorphically onto $ V_y $ by $ f : U_x \to V_y $, which looks like $ z \mapsto z $ in charts. By compactness of $ Y $, can choose finitely many $ V_y $ that cover all of $ Y $, $ V_1, \dots, V_k $. Choose a triangulation $ T_Y $ of $ Y $ that is so fine that every face of $ T_Y $ is contained in one of the $ V_i $. A triangulation can always be refined by adding vertices in the interior of faces and subdividing. Then, $ f $ lifts back to a triangulation $ T_X $ of $ X $, and clearly $ f $ is $ d $-to-one everywhere, so
$$ V\br{T_X} = d \cdot V\br{T_Y}, \qquad E\br{T_X} = d \cdot E\br{T_Y}, \qquad F\br{T_X} = d \cdot F\br{T_Y}, $$
so that $ \chi\br{X} = d \cdot \chi\br{Y} $ in this case.
\item Next, assume that $ f $ has a single ramification point $ x \in X $, and focus around this $ x $. Denote $ \v_f\br{x} = r \le d $ and $ y = f\br{x} $. Everything still holds, except at $ y = f\br{x} $. We may assume, up to subdivision of $ T_Y $ that $ y $ is a vertex of the triangulation $ T_Y $. Let $ x \in U $ and $ y \in V $ be coordinate neighbourhoods of $ x \in X $ and $ y \in Y $. A local holomorphic representative $ \psi_V \circ f \circ \phi_U^{-1} $ of $ f $ is $ z \mapsto z^r $, and this is $ r $-to-one for $ z \ne 0 $. Lifting the triangulation $ T_Y $ back to $ X $ will yield a triangulation $ T_X $ with $ d $ times of everything, so everything still has $ \deg f = d $ preimages, except for the vertex point $ y $, which has only $ d - \br{r - 1} $ preimages in $ X $. Now when computing $ \chi $, one has $ \chi\br{X} = d \cdot \chi\br{Y} - \br{r - 1} $.
\end{itemize}
This can be turned into a proof in the general case, with some work.
\end{proof}

We now use the Riemann-Hurwitz formula to prove the degree-genus formula.

\begin{theorem}[Degree-genus formula]
Let $ C \subseteq \PP^2 $ be a non-singular projective curve of degree $ \deg C = d $. Then the genus of $ C $ is
$$ \g\br{C} = \dfrac{\br{d - 1}\br{d - 2}}{2}. $$
\end{theorem}

\begin{remark}
For $ d = 1, 2 $ we get $ \g\br{C} = 0 $, and for $ d = 3 $ we get $ \g\br{C} = 1 $. Note that on the other hand $ d = 4 $ already gives $ \g\br{C} = 3 $, so that there is no plane curve of genus two, and more generally, of any number not of the form $ k\br{k - 1} / 2 $. There are, though, compact Riemann surfaces of any genus $ g $. If $ g $ is not of the form $ k\br{k - 1} / 2 $, it is not possible to embed these Riemann surfaces in $ \PP^2 $.
\end{remark}

\lecture{30}{Friday}{14/12/18}

\begin{proof}
Let $ C = \cbr{P = 0} \subseteq \PP^2 $, where $ P $ is a homogeneous polynomial of degree $ d $. Up to projective transformation, we may assume that $ \sbr{0, 0, 1} \notin C $ and we consider, as above, the holomorphic map $ f : C \to \PP^1 $ defined in Example \ref{eg:15.12}. Then as noted in Example \ref{eg:17.14}, the degree of $ f $ is $ n $, so that, by the Riemann-Hurwitz formula, the genus of $ C $ satisfies
$$ \g\br{C} = 1 - d + \dfrac{1}{2}\sum_{p \in C} \br{\v_f\br{p} - 1}, $$
since we have seen $ \deg f = \deg P = d $. Claim that, after possibly applying a projective transformation, I can assume $ \v_f\br{p} = 2 $ for all ramification points in $ C $.
\begin{itemize}
\item By Proposition \ref{prop:17.15}, the ramification points of $ C $ are those $ p \in C $ such that $ \sbr{0, 0, 1} \in \T_p C $, and the ramification index at $ p $ is then precisely $ \I\br{p, C, \T_p C} $.
\item One can show that \footnote{Exercise} $ \I\br{p, C, \T_p C} \ge 3 $ precisely when $ p $ is an inflection point of $ C $. For a sketch, let $ P\br{x_0, x_1, x_2} = 0 $ be the equation of $ C $ and $ a_0x_0 + a_1x_1 + a_2x_2 = 0 $ be the tangent line. Say $ a_0 \ne 0 $, so $ x_0 = -\br{a_1 / a_0}x_1 - \br{a_2 / a_0}x_2 $. Plugging this in $ P $,
$$ Q\br{x_1, x_2} = P\br{-\dfrac{a_1}{a_0}x_1 - \dfrac{a_2}{a_0}x_2, x_1, x_2}. $$
Check that $ p $ has multiplicity at least three in this, if and only if $ \HHH_P\br{p} = 0 $, the determinant of the Hessian.
\item As mentioned in Remark \ref{rem:13.6}, $ C $ has finitely many points of inflection.
\end{itemize}

\pagebreak

Consider
$$ C' = C \cup \bigcup_{q \ \text{inflection point of} \ C} \T_q C \subseteq \PP^2. $$
Pick $ p_0 $ in the complement of $ C' $ and send that to $ \sbr{0, 0, 1} $, and consider the new $ f : C \to \PP^1 $. We may therefore assume, up to projective transformation of $ \PP^2 $, that $ \sbr{0, 0, 1} $ does not lie on $ C' $, so that $ \v_f\br{p} = \I\br{p, C, \T_p C} = 2 $ for every ramification point of $ C $. Let $ N $ be the number of ramification points of $ f $. We have
$$ \g\br{C} = 1 - d + \dfrac{1}{2} \cdot N, $$
so that in order to prove the degree-genus formula, we have to show that $ N = d\br{d - 1} $. We use B\'ezout's theorem to count ramification points. Since
\begin{align*}
p \in C \ \text{is a ramification point} \qquad
& \iff \qquad \sbr{0, 0, 1} \in \T_p C \\
& \iff \qquad P_{x_0}\br{p} \cdot x_0 + P_{x_1}\br{p} \cdot x_1 + P_{x_2}\br{p} \cdot x_2 = 0 \\
& \iff \qquad P_{x_2}\br{p} = 0,
\end{align*}
the ramification points of $ f $ are the points of intersection of $ C $ with the curve $ D = \cbr{P_{x_2} = 0} \subseteq \PP^2 $. Since $ C $ is irreducible and $ D $ has degree $ d - 1 < \deg C $, noting that $ P_{x_2} $ cannot be identically zero, since $ \sbr{0, 0, 1} \notin C $ implies that $ x_2^d $ is a monomial in $ P $, otherwise every point of $ C $ would be a ramification point, by the strong B\'ezout theorem,
$$ \deg C \cdot \deg D = d\br{d - 1} = \sum_{p \in C \cap D} \I\br{p, C, D}, $$
and the right hand side is equal to $ N = \#\br{C \cap D} $ if and only if $ \I\br{p, C, D} = 1 $ for all $ p \in C \cap D $. By Proposition \ref{prop:12.11}, this is the case if and only if, for all $ p \in C \cap D $, $ p $ is a smooth point of $ C $, $ p $ is a smooth point of $ D $, and $ \T_p C \ne \T_p D $, so $ C $ and $ D $ intersect transversally. We already know that $ p $ is a smooth point of $ C $. Let $ p = \sbr{p_0, p_1, p_2} $, and denote $ P_{x_i, x_j} = \tmd{P}{2}{x_i}{}{x_j}{} $, recalling that $ \br{p_0, p_1} \ne \br{0, 0} $, since $ \sbr{0, 0, 1} \notin C $. The point $ p $ is a smooth point of $ D $, because otherwise $ \br{P_{x_2, x_0}\br{p}, P_{x_2, x_1}\br{p}, P_{x_2, x_2}\br{p}} = \br{0, 0, 0} $, and then $ p $ would be an inflection point of $ C $, by Definition \ref{def:13.2}. If these vanish, then
$$ \HHH_P\br{p} = \det \threebythree{P_{x_0, x_0}}{P_{x_0, x_1}}{P_{x_0, x_2}}{P_{x_0, x_1}}{P_{x_1, x_1}}{P_{x_1, x_2}}{P_{x_0, x_2}}{P_{x_1, x_2}}{P_{x_2, x_2}} = 0. $$
So $ p $ is a smooth point of $ D $. Finally let us prove that $ \T_p C \ne \T_p D $. Otherwise, we would have $ \sbr{0, 0, 1} \in \T_p D $, because $ \sbr{0, 0, 1} \in \T_p C $, and therefore $ P_{x_2}\br{p} = P_{x_2, x_2}\br{p} = 0 $. Recall that, by Lemma \ref{lem:13.3},
$$ x_1^2 \cdot \HHH_P = \br{d - 1}^2 \cdot \det \threebythree{P_{x_0, x_0}}{P_{x_0}}{P_{x_0, x_2}}{P_{x_0}}{\tfrac{d}{d - 1} \cdot P}{P_{x_2}}{P_{x_0, x_2}}{P_{x_2}}{P_{x_2, x_2}}, $$
so that
$$ p_1^2 \cdot \HHH_P\br{p} = \br{d - 1}^2 \cdot \det \threebythree{P_{x_0, x_0}}{P_{x_0}}{P_{x_0, x_2}}{P_{x_0}}{0}{0}{P_{x_0, x_2}}{0}{0} = 0. $$
Doing the same for $ p_0 $,
$$ p_0^2 \cdot \HHH_P\br{p} = \br{d - 1}^2 \cdot \det \threebythree{0}{P_{x_1}}{0}{P_{x_1}}{P_{x_1, x_1}}{P_{x_1, x_2}}{0}{P_{x_1, x_2}}{0} = 0. $$
Since $ \br{p_0, p_1} \ne \br{0, 0} $, $ p $ would be an inflection point, a contradiction. We have thus proved that $ \I\br{p, C, D} = 1 $ for all $ p \in C \cap D $, and this finishes the proof of the degree-genus formula.
\end{proof}

\pagebreak

\appendix

\section{What's next?}

In this course, we have only looked at complex projective plane curves, or complex-analytic manifolds of dimension one.
\begin{itemize}
\item Higher dimensional algebraic geometry. For example, surfaces in $ \PP^3 $, threefolds, etc. The classification problem is to try to classify smooth projective varieties up to birational transformations. This is birational geometry.
\item Moduli spaces. Classify smooth curves up to isomorphism. One discrete invariant is the genus. For $ g = 0 $, there is only $ \PP^1 $. For $ g = 1 $, cubics, there is an infinite family
$$ y^2 = x\br{x - 1}\br{x - \lambda}, \qquad \lambda \in \CC \setminus \cbr{0, 1}. $$
The space of curves of genus one is isomorphic to $ \CC $. The coordinate is the $ j $-invariant. The moduli space of isomorphism classes of genus $ g $,
$$ \M_g = \cbr{\text{isomorphism classes of genus} \ g \ \text{curves}}, $$
has a natural structure of an algebraic variety, defined by polynomial equations in some $ \PP^N $.
\item Arithmetic geometry. Work over other fields, such as $ \QQ $, or over rings, such as $ \ZZ $,
$$ 2x^2 + 3y^2 = 100. $$
Characteristic zero talks to characteristic $ p $.
\item Computational or combinatorial algebraic geometry. Algorithms to find nice sets of equations to
$$
\begin{cases}
p_1 = 0 \\
\vdots \\
p_k = 0
\end{cases}.
$$
\end{itemize}

\end{document}