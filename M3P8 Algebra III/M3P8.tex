\def\module{M3P8 Algebra III}
\def\lecturer{Dr David Helm}
\def\term{Autumn 2018}
\def\cover{
$$
\begin{tikzpicture}
\draw [fill=lightgray, opacity=0.1, very thick] (0, 2) circle (7.5);
\draw (0, 9) node{Modules};
\draw [fill=lightgray, opacity=0.1, very thick] (0, -1.25) ellipse (5 and 4.25);
\draw (0, -5) node{Noetherian modules};
\draw [fill=lightgray, opacity=0.1, very thick] (0, 2) circle (6.5);
\draw (0, 8) node{Rings};
\draw (0, -4) node{Noetherian rings};
\draw [fill=lightgray, opacity=0.1, very thick] (0, 2) circle (5.5);
\draw (0, 6.5) node{Integral domains};
\draw (0, -3) node{Noetherian domains};
\draw [fill=lightgray, opacity=0.1, very thick] (0, 1.75) ellipse (4.75 and 4.25);
\draw (0, 5) node{Integrally closed domains};
\draw [fill=lightgray, opacity=0.1, very thick] (0, 1.75) ellipse (4 and 2.75);
\draw (0, 3.5) node{Unique factorisation domains};
\draw [fill=gray, opacity=0.1, very thick] (0, 0.25) ellipse (4 and 2.75);
\draw (0, -2) node{Dedekind domains};
\draw (0, 2.5) node{Principal ideal domains};
\draw [fill=gray, opacity=0.1, very thick] (0, 0.5) ellipse (2.5 and 1.5);
\draw (0, 1.5) node{Euclidean domains};
\draw [fill=gray, opacity=0.1, very thick] (0, 0) circle (1);
\draw (0, 0) node{Fields};
\end{tikzpicture}
$$
}
\def\syllabus{Rings. Homomorphisms, ideals, and quotients. Factorisation. The Chinese remainder theorem. Fields and field extensions. Finite fields. $ R $-modules. Noetherian rings and modules. Polynomial rings in several variables. Integral extensions and algebraic integers. Dedekind domains. Integers in number fields. Introduction to algebraic geometry.}
\def\thm{subsection}

\input{../style/header}

\begin{document}

\input{../style/cover}

\section{Introduction}

\lecture{1}{Friday}{05/10/18}

This course is an introduction to ring theory. The topics covered will include ideals, factorisation, the theory of field extensions, finite fields, polynomial rings in several variables, and the theory of modules. In addition to the lecture notes, the following will cover much of the material we will be studying.
\begin{itemize}
\item M Artin, Algebra, 1991
\end{itemize}
Rings are contexts in which it makes sense to add and multiply. For example,
$$ \ZZ, \qquad \QQ, \qquad \RR, \qquad \CC, \qquad \text{polynomials}, \qquad \cbr{0, 1} \to \RR, \qquad \ZZ / n\ZZ $$
are rings. The goals of this course include
\begin{itemize}
\item to unify arguments that apply in all of the above contexts, and
\item to study relationships between different rings.
\end{itemize}
The applications of rings include
\begin{itemize}
\item number theory, by studying extensions of $ \ZZ $ in which particular Diophantine equations have solutions, such as $ n = x^2 + y^2 = \br{x + iy}\br{x - iy} $, to study solutions in $ \ZZ\sbr{i} $ and pass to result about $ \ZZ $,
\item algebraic geometry, by the study of zero sets of polynomials in several variables via rings of functions, and
\item topology, by the cohomology classes of topological spaces.
\end{itemize}

\begin{note*}
The official notes are integrated in these unofficial notes.
\end{note*}

\pagebreak

\section{Basic definitions and examples}

\subsection{Rings}

Recall the definition of a commutative ring.

\begin{definition}
A \textbf{commutative ring with identity} $ R $ is a set together with two binary operations
$$ +_R : R \times R \to R, \qquad \cdot_R : R \times R \to R, $$
\textbf{addition} and \textbf{multiplication}, and two distinguished elements $ 0_R $ and $ 1_R $, such that the following holds.
\begin{itemize}
\item The operation $ +_R $ makes $ R $ into an abelian group with identity $ 0_R $, that is
\begin{itemize}
\item for all $ r \in R $, $ 0_R +_R r = r +_R 0_R = 0_R $,
\item for all $ r, s, t \in R $, $ \br{r +_R s} +_R t = r +_R \br{s +_R t} $,
\item for all $ r, s \in R $, $ r +_R s = s +_R r $, and
\item for all $ r \in R $, there exists $ -r \in R $ such that $ r +_R \br{-r} = \br{-r} +_R r = 0_R $.
\end{itemize}
\item The operation $ \cdot_R $ is associative and commutative with identity $ 1_R $. That is,
\begin{itemize}
\item for all $ r \in R $, $ 1_R \cdot_R r = r \cdot_R 1_R = 1_R $,
\item for all $ r, s, t \in R $, $ \br{r \cdot_R s} \cdot_R t = r \cdot_R \br{s \cdot_R t} $, and
\item for all $ r, s \in R $, $ r \cdot_R s = s \cdot_R r $.
\end{itemize}
\item Multiplication distributes over addition. That is,
\begin{itemize}
\item for all $ r, s, t \in R $, $ r \cdot_R \br{s +_R t} = r \cdot_R s +_R r \cdot_R t $, and
\item for all $ r, s, t \in R $, $ \br{s +_R t} \cdot_R r = s \cdot_R r +_R t \cdot_R r $.
\end{itemize}
\end{itemize}
\end{definition}

There is some redundancy here, of course. I have written things this way so that one obtains the definition of a \textbf{noncommutative ring} simply by removing the condition that multiplication is commutative. In this course, however, all rings will be commutative. When it is clear from the context what ring we are working with, we will write $ 0_R $ and $ 1_R $ as $ 0 $ and $ 1 $, $ a +_R b $ as $ a + b $, and $ a \cdot_R b $ as $ ab $.

\begin{proposition}
Let $ R $ be a ring. Then for all $ r \in R $, $ r \cdot_R 0_R = 0_R $.
\end{proposition}

\begin{proof}
$ r \cdot_R 0_R = r \cdot_R \br{0_R +_R 0_R} = r \cdot_R 0_R +_R r \cdot_R 0_R $, so
$$ 0_R = -\br{r \cdot_R 0_R} +_R \br{r \cdot_R 0_R} = -\br{r \cdot_R 0_R} +_R \br{r \cdot_R 0_R +_R r \cdot_R 0_R} = r \cdot_R 0_R. $$
\end{proof}

\begin{note*}
Some definitions of rings require $ 1_R \ne 0_R $ in $ R $. We will not do this.
\end{note*}

\begin{proposition}
If $ 0_R = 1_R $, then $ R $ is the one-element ring $ \cbr{0_R} $.
\end{proposition}

\begin{proof}
We certainly have $ r = 1_R \cdot_R r = 0_R \cdot_R r $. On the other hand
$$ 0_R \cdot_R r = \br{0_R +_R 0_R} \cdot_R r = 0_R \cdot_R r +_R 0_R \cdot_R r, $$
and subtracting $ 0_R \cdot_R r $ from both sides we find that $ 0_R \cdot_R r = 0_R $.
\end{proof}

\begin{definition}
A ring $ R $ is a \textbf{field} if $ R \ne \cbr{0_R} $ and every nonzero element of $ R $ has a multiplicative inverse. That is, for every $ r \in R \setminus \cbr{0_R} $ there exists $ r^{-1} \in R $ such that
$$ rr^{-1} = r^{-1}r = 1_R. $$
\end{definition}

We do not consider the zero ring $ \cbr{0_R} $ to be a field. We have seen many examples of rings at this point.

\pagebreak

\begin{example*}
The sets $ \ZZ, \QQ, \RR, \CC $ are all rings with their usual notion of addition and multiplication. All of them but $ \ZZ $ are in fact fields. We have the ring $ \ZZ / n\ZZ $ of integers modulo $ n $. Let $ n \in \ZZ_{> 0} $, and recall that $ a $ and $ b $ are said to be \textbf{congruent modulo $ n $} if $ a - b $ is divisible by $ n $. It is easy to check that this is an equivalence relation on $ \ZZ $. Moreover, since any $ a \in \ZZ $ can uniquely be written as $ qn + r $ with $ q, r \in \ZZ $ and $ 0 \le r < n $, the set
$$ \cbr{\sbr{0}_n, \dots, \sbr{n - 1}_n} $$
is a complete list of the equivalence classes under this relation, where $ \sbr{a}_n $ denotes the set of all integers congruent to $ a \mod n $. We denote this $ n $-element set by $ \ZZ / n\ZZ $, and we can define addition and multiplication in $ \ZZ / n\ZZ $ by setting
$$ \sbr{a}_n + \sbr{b}_n = \sbr{a + b}_n, \qquad \sbr{a}_n\sbr{b}_n = \sbr{ab}_n. $$
This defines a ring structure on $ \ZZ / n\ZZ $, once one checks that it is well-defined. This is the first example of a general construction we will see more of later, the quotient of a ring by an ideal.
\end{example*}

\subsection{Polynomial rings}

\lecture{2}{Monday}{08/10/18}

A very important class of rings that we will study are the polynomial rings. Let $ R $ be any ring. Then we can form a new ring $ R\sbr{X} $, called the \textbf{ring of polynomials in $ X $ with coefficients in $ R $}. Informally, a polynomial in $ R\sbr{X} $ is a finite sum of the form
$$ r_0 + \dots + r_nX^n, \qquad n \in \ZZ_{\ge 0}, \qquad r_0, \dots, r_n \in R. $$
If $ n > m $, we consider $ r_0 + \dots + r_nX^n $ to represent the same polynomial of $ R\sbr{X} $ as $ s_0 + \dots + s_mX^m $ if $ r_i = s_i $ for $ i \le m $ and $ r_i = 0_R $ for $ i > m $. That is, you can pad out polynomials with terms of the form $ 0_RX^i $ without changing it. From a formal standpoint, it is better to define a polynomial to be an infinite sum
$$ \sum_{n = 0}^\infty r_iX^i = r_0 + r_1X + \dots, \qquad r_i \in R, $$
in which all but finitely many $ r_i $ are zero. This makes it easier to define addition and multiplication. The \textbf{degree} of such an expression is the largest $ i $ such that $ r_i $ is nonzero. We add and multiply in $ R\sbr{X} $ just as we would any other polynomials,
$$ \sum_{i = 0}^\infty r_iX^i +_{R\sbr{X}} \sum_{i = 0}^\infty s_iX^i = \sum_{i = 0}^\infty \br{r_i +_R s_i} X^i, \qquad \sum_{i = 0}^\infty r_iX^i \cdot_{R\sbr{X}} \sum_{i = 0}^\infty s_iX^i = \sum_{i = 0}^\infty \sum_{j = 0}^i \br{r_j \cdot_R s_{i - j}} X^i. $$
What about polynomial rings in more than one variable? Since the construction of polynomial rings takes an arbitrary ring as input, one can iterate it. Start with a ring $ R $, and consider first the ring $ R\sbr{X} $ and then the ring $ \br{R\sbr{X}}\sbr{Y} $. A polynomial of this has the form
$$ \sum_{i = 0}^\infty \sum_{j = 0}^\infty r_{ij}X^jY^i, \qquad r_{ij} \in R. $$
On the other hand, we can consider the ring $ \br{R\sbr{Y}}\sbr{X} $, whose polynomials have the form
$$ \sum_{i = 0}^\infty \sum_{j = 0}^\infty r_{ij}Y^jX^i, \qquad r_{ij} \in R. $$
Alternatively, we could consider the ring $ R\sbr{X, Y} $ whose polynomials are formal expressions of the form
$$ \sum_{i, j = 0}^\infty r_{ij}X^iY^j, \qquad r_{ij} \in R. $$
It is not hard to see that all three approaches yield the same ring. If we identify these elements, we see that addition and multiplication in any of these three rings gives the same answer. We will therefore primarily use notation like $ R\sbr{X, Y} $ for polynomial rings in multiple variables, but we will occasionally need to know that this is the same as $ \br{R\sbr{X}}\sbr{Y} $ or $ \br{R\sbr{Y}}\sbr{X} $. The identifications we have made here are an example of isomorphisms of rings, a notion we will make precise later.

\pagebreak

\subsection{Subrings and extensions}

\begin{definition}
Let $ R $ be a ring. A subset $ S $ of $ R $ is a \textbf{subring} of $ R $ if
\begin{itemize}
\item $ 0_R, 1_R, -1_R \in S $, and
\item $ S $ is closed under $ +_R $ and $ \cdot_R $, so if $ r, s \in S $, then so are $ r +_R s $ and $ r \cdot_R s $.
\end{itemize}
\end{definition}

\begin{example*}
$ \ZZ $ is a subring of $ \RR $, which is itself a subring of $ \CC $.
\end{example*}

Subrings inherit the additive and multiplicative structures from the ring that contains them, and are thus themselves rings. It is easy to see that the intersection of two subrings of $ R $, or even an arbitrary collection of subrings of $ R $, is also a subring of $ R $.

\begin{definition}
Now let $ S \subseteq R $ be a subring of a ring $ R $, and let $ \alpha $ be an element of $ R $. We can then form a subring $ S\sbr{\alpha} $ of $ R $, called the \textbf{subring of $ R $ generated by $ \alpha $ over $ S $}, as follows. An element of $ R $ lies in $ S\sbr{\alpha} $ if and only if it can be expressed in the form
$$ r_0 + \dots + r_n\alpha^n, \qquad n \in \ZZ^*, \qquad r_0, \dots, r_n \in S. $$
This operation is known as \textbf{adjoining} the element $ \alpha $ to the ring $ S $.
\end{definition}

\begin{example*}
Let $ i $ denote a square root of $ -1 $ in $ \CC $, and consider the subring $ \ZZ\sbr{i} $ of $ \CC $ formed by $ \ZZ \subseteq \CC $ and $ i $. This consists of all complex numbers that can be expressed as polynomials in $ i $ with integer coefficients. Note that such an expression need not be unique. For instance the element $ 1 + i $ of $ \ZZ\sbr{i} $ can also be written as $ 2 + i + i^2 $, and $ -1 = i^2 = i^6 = i + i^3 + i^{10} $.
\end{example*}

Indeed, since $ i^2 = -1 $, the following holds.

\begin{proposition}
We can uniquely express any element $ a_0 + \dots + a_ni^n $ of $ \ZZ\sbr{i} $ as $ a + bi $ for $ a, b \in \ZZ $.
\end{proposition}

\begin{proof}
Given $ \sum_{n = 0}^\infty a_ni^n $ with only finitely many $ a_n $ nonzero, set $ a = a_0 - a_2 + \dots \in \ZZ $ and $ b = a_1 - a_3 + \dots \in \ZZ $. Then
$$ \sum_{n = 0}^\infty a_ni^n = a + bi. $$
This expression is clearly unique, as if $ a + bi = c + di $ in $ \CC $ for $ a, b, c, d \in \ZZ $, then $ a = c $ and $ b = d $.
\end{proof}

If $ \alpha $ is more complicated then the elements of $ R\sbr{\alpha} $ may well be harder to describe, and indeed, a nice description might not exist at all.

\begin{example*}
\hfill
\begin{itemize}
\item If $ \alpha $ is the real cube root of $ 2 $, then every element of $ \ZZ\sbr{\alpha} $ can be uniquely expressed as $ a + b\alpha + c\alpha^2 $, where $ a, b, c \in \ZZ $.
\item In $ \ZZ\sbr{\pi} $, any element has a unique expression in the form $ \sum_{n = 0}^\infty a_n\pi^n $ for all but finitely many $ a_n $ are zero. Suppose $ \sum_{n = 0}^\infty a_n\pi^n = \sum_{n = 0}^\infty b_n\pi^n $, then
$$ 0 = \sum_{n = 0}^\infty \br{a_n - b_n}\pi^n. $$
Since $ \pi $ is transcendental, this polynomial must be zero. Thus each $ a_n = b_n $.
\item The elements of $ \ZZ\sbr{\tfrac{1}{2}} $ can be expressed uniquely as $ a / b $, where $ b $ is a power of $ 2 $ and $ a $ is odd unless $ b = 1 $. If $ \alpha $ is a root of the polynomial $ x^2 - x / 2 + 1 $ then $ \alpha^2 \in \ZZ\sbr{\alpha} $ and $ \alpha^2 = \alpha / 2 - 1 $. Can show that every element of $ \ZZ\sbr{\alpha} $ can be uniquely expressed as $ a + b\alpha $, where $ a $ and $ b $ lie in $ \ZZ\sbr{\tfrac{1}{2}} $, but there are pairs $ a $ and $ b $ such that $ a + b\alpha $ does not lie in $ \ZZ\sbr{\alpha} $.
\end{itemize}
\end{example*}

\begin{exercise*}
For which pairs $ a $ and $ b $ of elements of $ \ZZ\sbr{\tfrac{1}{2}} $ does $ a + b\alpha $ lie in $ \ZZ\sbr{\alpha} $?
\end{exercise*}

An alternative way of defining the ring $ S\sbr{\alpha} $ is to note that it is the smallest subring of $ R $ containing $ S $ and $ \alpha $. In one direction, any such subring contains every expression of the form $ r_0 + \dots + r_n\alpha^n $, with $ r_i \in S $, so any subring of $ R $ containing $ S $ and $ \alpha $ contains $ S\sbr{\alpha} $. One can thus construct $ S\sbr{\alpha} $ as the intersection of every subring of $ R $ containing $ S $ and $ \alpha $. Since the intersection of any collection of subrings of $ R $ is a subring of $ R $ it is clear that this intersection is equal to $ S\sbr{\alpha} $ as defined above.

\pagebreak

\subsection{Integral domains and rings of fractions}

\lecture{3}{Wednesday}{10/10/18}

\begin{definition}
A \textbf{zero divisor} in a ring $ R $ is a nonzero element $ r $ of $ R $ such that there exists a nonzero $ s \in R $ with $ rs = 0 $. A ring $ R $ in which there are no zero divisors is called an \textbf{integral domain}.
\end{definition}

\begin{example*}
$ \ZZ $ is an integral domain and any subring of a field is an integral domain, but $ \ZZ / 6\ZZ $ is not an integral domain, as $ \sbr{2}\sbr{3} $ is $ 0 \mod 6 $ even though neither $ \sbr{2} $ nor $ \sbr{3} $ is $ 0 \mod 6 $.
\end{example*}

If $ R $ is an integral domain, then we can form the field of fractions of $ R $ in analogy to the way we build $ \QQ $ from $ \ZZ $.

\begin{definition}
Let $ R $ be an integral domain. The \textbf{field of fractions} $ K\br{R} $ is the set of equivalence classes of expressions of the form $ a / b $, where $ a $ and $ b $ are elements of $ R $ with $ b $ nonzero, and $ a / b $ is equivalent to $ a' / b' $ if and only if $ ab' = a'b $. We add and multiply elements of $ K\br{R} $ just as we do for fractions,
$$ \dfrac{a}{b} + \dfrac{a'}{b'} = \dfrac{ab' + ba'}{bb'}, \qquad \dfrac{a}{b} \cdot \dfrac{a'}{b'} = \dfrac{aa'}{bb'}. $$
Then $ K\br{R} $ is a field, and it contains $ R $ in a natural way as a subring if we identify $ r $ with $ r / 1_R \in K\br{R} $.
$$ 0_{K\br{R}} = \dfrac{0_R}{1_R}, \qquad 1_{K\br{R}} = \dfrac{1_R}{1_R}. $$
If $ a \ne 0 $ in $ R $, then $ b / a \in K\br{R} $, so
$$ \dfrac{a}{b} \cdot \dfrac{b}{a} = \dfrac{ab}{ba} \sim \dfrac{1}{1}. $$
\end{definition}

The field $ K\br{R} $ is in some sense the smallest field containing $ R $ as a subring. When we talk about homomorphisms and isomorphisms, we will be able to state this more precisely. More generally, let the \textbf{multiplicative system} $ S $ be a subset of $ R $ that contains $ 1_R $, does not contain $ 0_R $ and is closed under multiplication. That is, if $ a $ and $ b $ are in $ S $ then so is $ ab $. For any integral domain $ R $ and any multiplicative system $ S $, we can define $ S^{-1}R $ to be the subring of $ K\br{R} $ consisting of all fractions of the form $ a / b $ with $ b \in S $. It is easy to see that this is closed under addition and multiplication, and defines a ring in between $ R $ and $ K\br{R} $.

\begin{example*}
If $ R = \ZZ $ and $ S $ is the set of powers of $ 2 $, then $ S^{-1}R = \ZZ\sbr{\tfrac{1}{2}} $. On the other hand, if $ S $ is the set of odd integers, then $ S^{-1}R $ is the set of all rational numbers of the form $ a / b $ with $ b $ odd.
\end{example*}

In general $ S^{-1}R $ is the smallest subring of $ K\br{R} $ containing $ R $ in which every element of $ S $ has a multiplicative inverse, that is $ 1 / b \in S $ for all $ b \in S $. The process of obtaining $ S^{-1}R $ from $ R $ is called \textbf{localisation} and is an extremely powerful tool. One can even make sense of it when $ R $ is not an integral domain, but one has to be more careful. The equivalence relation on fractions is trickier, for example. We will not discuss this in this course but it will be quite useful in future courses.

\pagebreak

\section{Homomorphisms, ideals, and quotients}

\subsection{Homomorphisms}

Let $ R $ and $ S $ be rings. A ring homomorphism from $ R $ to $ S $ is, roughly, a way of interpreting elements of $ R $ as elements of $ S $, in a way that is compatible with the addition and multiplication laws on $ R $ and $ S $. More precisely is the following.

\begin{definition}
A function $ f : R \to S $ is a \textbf{ring homomorphism} if
\begin{enumerate}
\item $ f\br{1_R} = 1_S $,
\item for all $ r, r' \in R $, $ f\br{r +_R r'} = f\br{r} +_S f\br{r'} $,
\item for all $ r, r' \in R $, $ f\br{r \cdot_R r'} = f\br{r} \cdot_S f\br{r'} $.
\end{enumerate}
\end{definition}

\begin{note*}
If $ f $ is a homomorphism then $ f\br{0_R} = 0_S $. This is because $ f\br{0_R} = f\br{0_R + 0_R} = f\br{0_R} +_S f\br{0_R} $. Adding the additive inverse, in $ S $, of $ f\br{0_R} $ to both sides gives $ 0_S = f\br{0_R} $. Thus we do not need to require this as an axiom. On the other hand we do need to require $ f\br{1_R} = 1_S $. For certain $ R $ and $ S $ one can construct examples of maps $ f : R \to S $ that satisfy properties $ 2 $ and $ 3 $ of the definition without satisfying property $ 1 $.
\end{note*}

\begin{definition}
A bijective homomorphism $ f : R \to S $ is called an \textbf{isomorphism}. Write $ S \cong R $ for $ S $ is isomorphic to $ R $. In this case one verifies easily that the inverse map $ f^{-1} : S \to R $ is also a bijective homomorphism.
\end{definition}

\begin{example*}
\hfill
\begin{itemize}
\item If $ R $ is a subring of $ S $, then the inclusion of $ R $ into $ S $ is a homomorphism. This is just a fancy way of saying that the addition and multiplication on $ R $ are induced from the corresponding operations on $ S $. In particular the inclusions $ \ZZ \subset \QQ \subset \RR \subset \CC $ are all homomorphisms.
\item The composition of two homomorphisms is a homomorphism, as is easily checked from the definitions.
\item The map $ \ZZ \to \ZZ / n\ZZ $ that takes $ m \in \ZZ $ into its congruence class modulo $ n $ is a ring homomorphism.
\end{itemize}
\end{example*}

In fact, this is a special case of the following construction.

\begin{proposition}
Let $ R $ be any ring. Then there is a unique ring homomorphism $ f : \ZZ \to R $ such that
$$ f\br{n} =
\begin{cases}
1_R + \dots + 1_R & n > 0 \\
0_R & n = 0 \\
-\br{1_R + \dots + 1_R} & n < 0
\end{cases}.
$$
\end{proposition}

\begin{proof}
Let $ f : \ZZ \to R $ be a homomorphism. Then, directly from the definition, we have $ f\br{0} = 0_R $ and $ f\br{1} = 1_R $. In particular for all $ n > 0 $,
$$ f\br{n} = f\br{1 + \dots + 1} = 1_R + \dots + 1_R, $$
where there are $ n $ copies of $ 1_R $ in the sum. Moreover, since
$$ 0_R = f\br{n + \br{-n}} = f\br{n} + f\br{-n}, $$
we find that $ f\br{-n} $ is the additive inverse of $ 1_R + \dots + 1_R $. Thus $ f\br{n} $ is determined, for all $ n $, completely by the fact that $ f $ is a homomorphism. In the converse direction, it is not hard to check that the map defined above is in fact a homomorphism.
\end{proof}

Thus, for any ring $ R $, we can regard an integer as an element of $ R $ via this homomorphism.

\pagebreak

\subsection{Evaluation homomorphisms}

Let $ R $ be a ring, and consider the ring $ R\sbr{X} $ of polynomials in $ X $ with coefficients in $ R $. If $ s $ is an element of $ R $, then we can define a homomorphism $ R\sbr{X} \to R $ by \textbf{evaluation at $ s $}. More precisely, given an element of $ R\sbr{X} $ of the form
$$ P\br{X} = r_0 + \dots + r_nX^n, \qquad n \in \ZZ_{\ge 0}, \qquad r_i \in R. $$
Then $ P\br{s} $ for $ s \in R $ is defined to be
$$ P\br{s} = r_0 + \dots + r_ns^n \in R. $$
Consider the map
$$ \function[\phi_s]{R\sbr{X}}{R}{P\br{X}}{P\br{s}}. $$
In effect, it substitutes $ s $ for $ X $. It is easy to check that this is in fact a ring homomorphism. More generally, if $ R $ and $ S $ are rings and $ f : R \to S $ is a homomorphism, and $ s $ is an element of $ S $, then we can define a map
$$ \function[\phi_{s, f}]{R\sbr{X}}{S}{r_0 + \dots + r_nX^n}{f\br{r_0} + \dots + f\br{r_n}s^n}. $$
That is, by applying $ f $ to the coefficients and substituting $ s $ for $ X $. Again, this is clearly a homomorphism. The evaluation homomorphisms $ \phi_{s, f} $ are a fundamental property of polynomial rings. In some sense, they are the reason polynomial rings are worth studying. In fact, the ring $ R\sbr{X} $ is uniquely characterised by the fact that homomorphisms from $ R\sbr{X} $ to $ S $ are in bijection with pairs $ \br{s, f} $, where $ f : R \to S $ is a homomorphism and $ s $ is an element of $ S $.

\subsection{Images, kernels, and ideals}

\begin{definition}
Let $ f : R \to S $ be a homomorphism. The \textbf{image} of $ f $ is
$$ \im f = \cbr{f\br{r} \st r \in R} \subseteq S. $$
The \textbf{kernel} of $ f $ is
$$ \ker f = \cbr{r \in R \st f\br{r} = 0} \subseteq R. $$
\end{definition}

The image of a homomorphism $ f : R \to S $ is easily seen to be a subring of $ S $.

\begin{example*}
If $ R $ is a subring of $ S $, $ f : R \to S $ is the inclusion and $ s $ lies in $ S $, then the image of the map $ \phi_{s, f} : R\sbr{X} \to S $ is precisely the subring $ R\sbr{s} $ of $ S $.
\end{example*}

By contrast, the kernel of a homomorphism $ f $ is almost never a subring of $ R $. For instance, subrings contain the identity. However, we have the following.

\lecture{4}{Friday}{12/10/18}

\begin{definition}
A nonempty subset $ I $ of $ R $ is an \textbf{ideal} of $ R $ if $ I $ is closed under addition, that is for all elements $ i $ and $ j $ of $ I $, $ i + j $ is an element of $ I $, and for all elements $ i $ of $ I $ and $ r $ of $ R $, $ ri $ is an element of $ I $.
\end{definition}

Then one can verify, directly from the definition, that the kernel of any homomorphism $ f : R \to S $ is an ideal of $ R $. Any ideal of $ R $ contains $ 0_R $, and conversely the subset $ \cbr{0_R} $ of $ R $ is an ideal, called the \textbf{zero ideal}.

\begin{note*}
A homomorphism $ f : R \to S $ is injective if and only if its kernel is the zero ideal. Forward direction is easy. Conversely, if $ f\br{x} = f\br{y} $, then $ f\br{x - y} = 0 $, so $ x - y \in \ker f $. If $ \ker f = \cbr{0} $, $ x = y $.
\end{note*}

The kernel of the homomorphism $ \ZZ \to R $ is either the zero ideal, or the ideal of multiples of $ n $ in $ \ZZ $ for some $ n > 0 $. We say that $ R $ has \textbf{characteristic zero} or \textbf{characteristic $ n $}, respectively. If not zero, the characteristic of $ R $ is the smallest $ n $ such that the sum of $ n $ copies of $ 1_R $ is equal to zero.

\pagebreak

\subsection{Ideals: examples and basic operations}

If $ r $ is an element of $ R $, then any ideal containing $ R $ contains any multiple $ sr $ of $ R $, for any $ r $ in $ S $. Conversely, one checks easily that the set
$$ \cbr{sr \st s \in R} $$
is an ideal of $ R $. It is known as the ideal of $ R $ generated by $ r $, and denoted $ \abr{r} $. An ideal generated by one element in this way is called a \textbf{principal ideal}.

\begin{note*}
The ideal generated by $ 1_R $, or more generally by any element of $ R $ with a multiplicative inverse, is all of $ R $. This ideal is called the \textbf{unit ideal} of $ R $.
\end{note*}

\begin{proposition}
$ R $ is a field if and only if the only ideals of $ R $ are the zero ideal $ \cbr{0} $ and unit ideal $ R $.
\end{proposition}

\begin{proof}
If $ R $ is a field, let $ I \subseteq R $ be a nonzero ideal. There exists $ r \in I \ne 0 $. Then for all $ s \in R $, $ \br{sr^{-1}}\br{r} \in I $, so $ s \in I $ for all $ s \in R $. Conversely, if $ R $ has only the zero ideal and the unit ideal, let $ r \in R \ne 0 $, and let $ I = \cbr{sr \st s \in R} $. This is an ideal that is not the zero ideal, so it is all of $ R $. In particular, $ 1 \in I $, so there exists $ s \in R $ such that $ sr = 1 $.
\end{proof}

More generally is the following.

\begin{definition}
If $ S $ is a subset of elements of $ R $, then any ideal containing $ S $ consists of all elements of $ R $ of the form
$$ r_0s_0 + \dots + r_ns_n, \qquad n \in \ZZ_{\ge 0}, \qquad r_i \in R, \qquad s_i \in S. $$
The set of all elements of this form is an ideal of $ R $, known as the \textbf{ideal of $ R $ generated by $ S $}, and denoted $ \abr{S} $. It is the intersection of all the ideals of $ R $ containing $ S $. It is also the smallest ideal of $ R $ containing $ S $.
\end{definition}

If $ S $ has one element, $ \abr{S} $ is a principal ideal. We will show soon that any ideal of $ \ZZ $ is a principal ideal, as is any ideal of the ring $ K\sbr{X} $ for any field $ K $. You may well have seen this in last year's
algebra course. On the other hand, there are rings in which not every ideal is principal. For example, the ideal $ \abr{X, Y} $ of $ K\sbr{X, Y} $ is not a principal ideal. Given ideals $ I $ and $ J $ there are several ways to create new ideals.

\begin{example*}
\hfill
\begin{itemize}
\item If $ I $ and $ J $ are ideals, then the intersection $ I \cap J $ is an ideal. Note that if $ I $ and $ J $ are given by generators, it might be hard to find generators for the intersection. Certainly it is not enough to intersect the generating sets.
\item If $ I $ and $ J $ are ideals, then the union of ideals is not usually an ideal. Taking $ R = \ZZ $, $ \abr{3} \cup \abr{5} $ contains $ 3 $ and $ 5 $ but not $ 3 + 5 $. The sum $ I + J = \cbr{i + j \st i \in I, j \in J} $ is an ideal. It is the smallest ideal containing both $ I $ and $ J $, or equivalently the ideal generated by $ I \cup J $.
\item If $ I $ and $ J $ are ideals, the product $ IJ $ is the ideal generated by $ \cbr{ij \st i \in I, \ j \in J} $. This may be strictly larger than the set of such products. For example, consider the product of the ideals $ I = \abr{X, Y} $ and $ J = \abr{Z, W} $ in $ R = K\sbr{X, Y, Z, W} $ for $ K $ a field. The product $ IJ = \abr{XZ, XW, YZ, YW} $ contains $ XZ + YW $, but the latter is not a product of an element in $ I $ with an element in $ J $.
\item If $ I $ and $ J $ are general ideals, the product of ideals $ I $ and $ J $ is always contained in the intersection of $ I $ and $ J $, but the two need not be equal, even in simple rings like $ \ZZ $, since $ \abr{3} \cdot \abr{3} = \abr{9} $ and $ \abr{3} \cap \abr{3} = \abr{3} $.
\end{itemize}
\end{example*}

\subsection{Quotients}

Let $ R $ be a ring and let $ I $ be an ideal of $ R $. If $ x $ and $ y $ are elements of $ R $, we say that $ x $ is congruent to $ y \mod I $ if $ x - y $ is in $ I $. This is an equivalence relation on $ R $. We denote the equivalence class of $ r $ by $ r + I $, or as the alternative notations $ \sbr{r}_I $ and $ \overline{r} $. It is the set
$$ \cbr{r + s \st s \in I}. $$
Let $ R / I $ denote the set of equivalence classes on $ R \mod I $. This set has the natural structure of a ring. The additive and multiplicative identities are $ 0_R + I $ and $ 1_R + I $, respectively, and addition and multiplication are defined by
$$ \br{r + I} + \br{s + I} = \br{r + s} + I, \qquad \br{r + I} \cdot \br{s + I} = \br{rs} + I $$
respectively. One has to check that these are well-defined, but this is not difficult.

\pagebreak

\begin{example*}
If $ R = \ZZ $ and $ I $ is the ideal generated by $ n $, then $ R / I $ is the ring $ \ZZ / n\ZZ $ that we have already seen.
\end{example*}

The ring $ R / I $ is called the \textbf{quotient} of $ R $ by the ideal $ I $. There is a natural quotient homomorphism, \textbf{reduction modulo $ I $},
$$ \function{R}{R / I}{r}{r + I}. $$
This homomorphism is surjective with kernel $ I $. We then have the following.

\begin{proposition}[Universal property of the quotient]
\label{prop:2.5.1}
Let $ I \subseteq R $ be an ideal and let $ f : R \to S $ be a homomorphism, and suppose that the kernel of $ f $ contains $ I $. Then there is a unique homomorphism
$$ \overline{f} : R / I \to S, $$
such that for all $ r \in R $, $ f\br{r} = \overline{f}\br{r + I} $.
\end{proposition}

\begin{proof}
Note that $ \overline{f} $ is necessarily unique, as every element of $ R / I $ has the form $ r + I $ for some $ r $. We must thus show that it is well-defined and gives a homomorphism. If $ r + I = r' + I $, then $ r $ and $ r' $ differ by an element of $ I $, so $ f\br{r - r'} = 0 $, so $ f\br{r} = f\br{r'} $ since $ I $ is contained in the kernel of $ f $. Thus $ \overline{f} $ is well-defined. Checking that it is a homomorphism follows from $ f $ is a homomorphism.
\end{proof}

\begin{note*}
The kernel of $ \overline{f} $ in Proposition \ref{prop:2.5.1} above is just the image of the kernel of $ f $ in $ R / I $. If the kernel of $ f $ is equal to $ I $, this image is the zero ideal and $ \overline{f} $ is injective. In particular, any homomorphism of $ R $ to $ S $ can be thought of as an isomorphism of some quotient of $ R $ with a subring of $ S $.
\end{note*}

\begin{example*}
Let $ R \subseteq S $ be a subring, $ \alpha \in S $, and $ \iota : R \to S $ be the inclusion map. Recall that we have an evaluation at $ \alpha $ by $ \phi_{\iota, \alpha} : R\sbr{X} \to S $. Image of this is $ R\sbr{\alpha} $. Let $ I = \ker \phi_{\iota, \alpha} $. Then $ \phi_{\iota, \alpha} $ descends to a map $ R\sbr{X} / I \to S $ that is injective with image $ R\sbr{\alpha} $. So $ R\sbr{\alpha} $ is isomorphic to a quotient of $ R\sbr{X} $.
\end{example*}

\subsection{Prime and maximal ideals}

\lecture{5}{Monday}{15/10/18}

\begin{definition}
\label{def:2.6.1}
An ideal $ I $ of $ R $ is \textbf{prime} if the quotient $ R / I $ is an integral domain. It is \textbf{maximal} if $ R / I $ is a field.
\end{definition}

\begin{note*}
As fields are integral domains, every maximal ideal is prime. The converse need not hold, of course. The zero ideal in $ \ZZ $ is prime but not maximal.
\end{note*}

\begin{lemma}
An ideal $ I $ is prime if and only if for every pair of elements $ r $ and $ s $ in $ R $ such that $ rs $ is in $ I $, either $ r $ is in $ I $ or $ s $ is in $ I $.
\end{lemma}

\begin{proof}
This is just a restatement of Definition \ref{def:2.6.1}. $ R / I $ is an integral domain if and only if for all whenever two elements $ r + I $ and $ s + I $ in $ R / I $ satisfy $ \br{r + I}\br{s + I} = 0 + I $ in $ R / I $, either $ r + I = 0 + I $ or $ s + I = 0 + I $ in $ R / I $. This is the same as saying $ rs $ lies in $ I $ if and only if either $ r $ or $ s $ lies in $ I $.
\end{proof}

\begin{lemma}
An ideal $ I $ is maximal if and only if the only ideals of $ R $ containing $ I $ are $ I $ and the unit ideal $ R $.
\end{lemma}

This justifies the name maximal for such ideals.

\begin{proof}
First suppose that $ R / I $ is a field. Recall that $ R / I $ is a field if and only if only the ideals of $ R / I $ are $ \cbr{0} $ and $ R / I $. Given an ideal $ J \subseteq R / I $, let $ \widetilde{J} $ be the preimage of $ J $ under $ R \to R / I $. Then $ \widetilde{J} $ is an ideal containing $ I $ and contained in $ R $, so $ J $ is either the zero ideal of $ R / I $, in which case $ \widetilde{J} $ is contained in, and thus equal to, $ I $, or $ J $ is all of $ R / I $, in which case $ \widetilde{J} $ contains $ I $ and an element of $ 1_R + I $, so $ \widetilde{J} $ contains $ 1_R $ and is thus the unit ideal of $ R $. Conversely, if the only ideals of $ R $ containing $ I $ are $ I $ and the unit ideal, then for any $ r $ in $ R \setminus I $, the ideal of $ R $ generated by $ I $ and $ r $ contains $ 1_R $. We can thus write $ 1_R = rs + i $, where $ i \in I $ and $ s \in R $. This means that $ s + I $ and $ r + I $ are multiplicative inverses of each other in $ R / I $, so $ R / I $ is a field.
\end{proof}

\pagebreak

\section{Factorisation}

In these notes $ R $ always denotes an integral domain.

\subsection{Divisibility, units, associates, and irreducibles}

\begin{definition}
Let $ r $ and $ s $ be elements of $ R $. We say $ r $ \textbf{divides} $ s $, denoted $ r \mid s $, if there exists $ r' \in R $ with $ rr' = s $, or, equivalently, $ s $ lies in the principal ideal $ \abr{r} $ generated by $ r $. An element $ r $ that divides $ 1_R $ is called a \textbf{unit} of $ R $, or, equivalently, $ \abr{r} = R $. The set of units in $ R $ forms a group under multiplication denoted $ R^\times $.
\end{definition}

For any element $ r \in R $ and any unit $ u $ of $ R $, both $ u $ and $ ur $ divide $ r $.

\begin{definition}
The set of elements of $ R $ of the form $ ur $, with $ u \in R^\times $ are called \textbf{associates} of $ R $.
\end{definition}

That is, $ r $ and $ r' $ are associates if $ r = ur' $ for a unit $ u \in R^\times $. This implies $ r \mid r' $, that is there exists $ u' $ with $ u'u = 1 $ and $ u'r = r' $.

\begin{note*}
The principal ideals $ \abr{r} $ and $ \abr{r'} $ are equal if and only if $ r $ and $ r' $ are associates.
\end{note*}

\begin{definition}
A nonzero element $ r $ of $ R $ is called \textbf{irreducible} if $ r $ is not a unit and the only elements of $ R $ that divide $ r $ are the units and the associates of $ r $.
\end{definition}

\subsection{Unique factorisation domains}

An interesting question is when elements of rings admit unique factorisations into irreducibles? To that end we define the following.

\begin{definition}
A \textbf{unique factorisation domain (UFD)} is a ring $ R $ in which
\begin{enumerate}
\item every nonzero, nonunit element $ r $ of $ R $ admits a factorisation as a finite product of irreducibles in $ R $, and
\item if $ r = p_1 \dots p_n = q_1 \dots q_m \in R $ are two factorisations of $ r $ as products of irreducibles $ p_i $ and $ q_i $, then $ n = m $ and, after permuting the $ q_i $, each $ q_i $ is an associate of $ p_i $.
\end{enumerate}
\end{definition}

Both conditions can fail.

\begin{example*}
\hfill
\begin{itemize}
\item There are certainly domains in which $ 1 $ can fail, although they are somewhat exotic. One example is to take the rational polynomial ring $ R = \CC\sbr{X^\QQ} $ with coefficients in $ \CC $, whose entries are finite formal sums
$$ \sum_{i = 0}^N a_iX^{n_i}, \qquad a_i \in \CC, \qquad n_i \in \QQ_{\ge 0}. $$
Any such expression of $ R $ is a polynomial in $ X^{1 / n} $ for some $ n $. The element $ X $ of this ring is not a unit, and also not a finite product of irreducibles. In $ \CC\sbr{X^\QQ} $, $ X $ factors as $ \br{X^{1 / n}}^n $, so $ X $ has no factorisation into irreducibles in $ R $.
\item Even if $ 1 $ holds, $ 2 $ often fails. The classic example of this is $ R = \ZZ\sbr{\sqrt{-5}} $, in which $ 2, 3, 1 + \sqrt{-5}, 1 - \sqrt{-5} $ are all irreducibles, none are associates of each other, yet $ \br{2}\br{3} = \br{1 + \sqrt{-5}}\br{1 - \sqrt{-5}} $.
\end{itemize}
\end{example*}

We will show later that a very mild finiteness condition on a domain $ R $, the condition that $ R $ is Noetherian, actually guarantees that $ 1 $ holds. Another way to interpret condition $ 2 $ is as follows.

\begin{definition}
We say an element $ r $ of $ R $ is \textbf{prime} if the principal ideal $ \abr{r} $ of $ R $ is a prime ideal. In other words, for any $ s $ and $ s' $ in $ R $, if $ r $ divides $ ss' $, then $ r \mid s $ or $ r \mid s' $.
\end{definition}

\begin{lemma}
Prime elements are irreducible.
\end{lemma}

\begin{proof}
If $ r $ is prime and $ s $ divides $ r $, we can write $ r = ss' $. Then since $ r $ divides $ ss' $ we have that either $ r $ divides $ s $, in which case $ rs'' = s $, then $ ss's'' = s $ and $ s's'' = 1 $, so $ r $ is an associate of $ s $, or $ r $ divides $ s' $, in which case $ s' = rs'' $, then $ r = srs'' $ and $ ss'' = 1 $, so $ r $ is an associate of $ s' $ and $ s $ is a unit.
\end{proof}

\pagebreak

The converse is not necessarily true, but we have the following observation as criteria for $ R $ to be a UFD.

\begin{proposition}
Let $ R $ be a domain in which condition $ 1 $ holds. Then condition $ 2 $ above holds for $ R $ if and only if every irreducible element of $ R $ is prime.
\end{proposition}

\begin{proof}
First suppose condition $ 2 $ holds, and let $ r $ be an irreducible element of $ R $. If $ r $ divides $ ab $, we can write $ rs = ab $ for some $ s \in R $. Expanding out $ s, a, b $ as products of irreducibles we see that $ r $ is an associate of some irreducible dividing $ a $ or $ b $, so $ r $ is prime. Conversely, if every irreducible element of $ R $ is prime, and we have products of irreducibles
$$ p_1 \dots p_n = q_1 \dots q_m, $$
then, since $ p_1 $ is prime, it divides the product $ q_1 \dots q_m $ and is thus an associate of some $ q_i $. We can thus cancel $ p_1 $ from the left and $ q_i $ from the right, after introducing a unit on one side. This is possible because $ R $ is an integral domain. Repeating the process we find that, up to reordering the terms and multiplying by units, the two expressions coincide.
\end{proof}

\subsection{Principal ideal domains}

\begin{definition}
An integral domain $ R $ is a \textbf{principal ideal domain (PID)} if every ideal of $ R $ is a principal ideal.
\end{definition}

\begin{theorem}
\label{thm:3.3.2}
Every PID is a UFD.
\end{theorem}

We first show $ 1 $. It is true for units trivially.

\begin{lemma}
Let $ R $ be a PID. Then every nonzero nonunit $ r \in R $ has a irreducible divisor.
\end{lemma}

\begin{proof}
Fix $ r = r_0 \in R $. We first show $ r $ has an irreducible factor. If $ r_0 $ is irreducible we are done. Otherwise if $ r_0 $ is not irreducible, we can choose an $ r_1 $, not a unit nor an associate of $ r_0 $, such that $ r_1 $ divides $ r_0 $, so $ r_0 = r_1s_1 $ with $ r_1 $ and $ s_1 $ not units. If $ r_1 $ is not irreducible we choose $ r_2 $ similarly, and repeat. If this process ever terminates we have found an irreducible divisor of $ r $. It suffices to show this terminates. Suppose it does not terminate. We obtain an increasing tower of ideals
$$ \abr{r_0} \subsetneq \abr{r_1} \subsetneq \dots. $$
Let $ I $ be the union of all these ideals generated by $ r_0, r_1, \dots $. Then $ I $ is an ideal, so it is generated by some element $ s \in I $. Thus $ s $ divides $ r_i $ for all $ i $. On the other hand, $ s $ lives in some $ \abr{r_j} $, so $ r_j $ divides $ s $. Thus $ s $ is an associate of $ r_j $, and therefore an associate of $ r_i $ for all $ i > j $, that is $ I \subseteq \abr{r_j} $. This contradicts our construction, because $ \abr{r_{j + 1}} \subseteq I $ and $ \abr{r_{j + 1}} \ne \abr{r_j} $.
\end{proof}

Thus $ r $ has an irreducible divisor $ s_0 $.

\begin{lemma}
Let $ R $ be a PID. Every nonzero nonunit $ r \in R $ is a finite product of irreducibles.
\end{lemma}

\begin{proof}
Consider $ rs_0^{-1} $. If this is a unit we are done. If not let $ s_1 $ be an irreducible divisor of $ rs_0^{-1} $. If $ r\br{s_0s_1}^{-1} $ is a unit we are done. Otherwise repeat. We obtain a sequence of irreducibles $ s_0, s_1, \dots $ such that $ s_0 \dots s_i $ divides $ r $ for all $ i $, so
$$ r = r_0s_0 = r_0r_1s_1 = \dots, $$
with $ r_0, r_1, \dots $ irreducible. If this process ever terminates we are done. Suppose it does not. Then we have a strictly increasing tower of ideals
$$ \abr{r} \subsetneq \abr{s_0} \subsetneq \abr{s_1} \subsetneq \dots. $$
This cannot continue forever. Arguing as above we arrive at a contradiction.
\end{proof}

Now we show $ 2 $.

\begin{proof}[Proof of Theorem \ref{thm:3.3.2}]
It suffices to show that in a PID every irreducible is prime. Let $ r \in R $ be irreducible, and suppose that $ r $ divides $ st $. Want $ r \mid s $ or $ r \mid t $. Let $ q $ be a generator of the ideal $ \abr{r, s} $ of $ R $, so $ \abr{r, s} = \abr{q} $. Then $ q $ divides $ r $, so either $ q $ is a unit or $ q $ is an associate of $ r $. If $ q $ is an associate of $ r $, then since $ q $ divides $ s $, $ r $ divides $ s $. On the other hand, if $ q $ is a unit, then the ideal generated by $ r $ and $ s $ is the unit ideal and $ 1 \in \abr{r, s} $, so we can write $ 1 = xr + ys $ for $ x $ and $ y $ elements of $ R $. We then have $ t = xrt + yst $, and since $ r $ divides both $ yst $ and $ xrt $, $ r $ divides $ t $.
\end{proof}

\pagebreak

\subsection{Euclidean domains}

\lecture{6}{Wednesday}{16/10/18}

One technique for proving that rings are PIDs is Euclid's algorithm. We formalise this in an abstract setting as follows.

\begin{definition}
Let $ R $ be an integral domain.
\begin{itemize}
\item A \textbf{Euclidean norm} on $ R $ is a function $ \N : R \to \ZZ_{\ge 0} $ such that for all $ a, b \in R $, with $ b \ne 0 $, there exist $ q, r \in R $ such that $ a = qb + r $, and either $ r = 0 $ or $ \N\br{r} < \N\br{b} $.
\item An integral domain $ R $ is called a \textbf{Euclidean domain} if there is a Euclidean norm on $ R $.
\end{itemize}
\end{definition}

\begin{theorem}
Any Euclidean domain is a PID.
\end{theorem}

\begin{proof}
Let $ R $ be a Euclidean domain, $ \N $ be a Euclidean norm on $ R $, and $ I \subseteq R $ be a nonzero ideal of $ R $. Let $ n $ be the smallest integer such that there exists a nonzero element $ a \in I $ with $ \N\br{a} = n $ minimal, that is if $ b \in I $ and $ b \ne 0 $, then $ \N\br{b} < \N\br{a} $. Claim that $ I = \abr{a} $. Then for any $ b \in I $, we can write $ b = qa + r $ with $ \N\br{r} < \N\br{a} $ unless $ r = 0 $. But since $ \N\br{a} $ is the smallest possible norm in $ I $, we must have $ r = 0 $, so $ b = qa $. Thus $ I $ is generated by $ a $ and we are done.
\end{proof}

\subsection{Examples}

\begin{example*}
\hfill
\begin{itemize}
\item The classic example of a Euclidean domain is $ \ZZ $, with $ \N\br{x} = \abs{x} $ for $ x \in \ZZ $.
\item The ring $ \ZZ\sbr{i} $ is a Euclidean domain, with $ \N\br{z} = z\overline{z} = \abs{z}^2 $, so
$$ \N\br{x + yi} = \abs{x + yi}^2 = x^2 + y^2. $$
To see this, note that given $ a $ and $ b $ in $ \ZZ\sbr{i} $ for $ b \ne 0 $, set $ q' = a / b \in \QQ\sbr{i} $. Write $ q' = x' + iy' $ for $ x', y' \in \QQ $. Let $ x $ and $ y $ be the closest integers to $ x' $ and $ y' $, such that $ \abs{x - x'}, \abs{y - y'} \le \tfrac{1}{2} $, and set $ q = x + iy $ in $ \ZZ\sbr{i} $ and $ r = a - bq $. Then
$$ \N\br{r} = \abs{r}^2 = \abs{a - bq}^2 = \abs{a - b\br{\dfrac{a}{b} + \br{q - q'}}}^2 = \abs{b\br{q - q'}}^2 = \abs{b}^2\abs{q - q'}^2 \le \dfrac{\N\br{b}}{2}. $$
\item Similar arguments can be used to prove that $ \ZZ\sbr{\alpha} $ is a Euclidean domain for
$$ \alpha = \sqrt{-2}, \qquad \alpha = \tfrac{-1 + \sqrt{-3}}{2}, \qquad \alpha = \tfrac{-1 + \sqrt{-7}}{2}. $$
Beyond this one needs other tricks, and for most $ \alpha $ unique factorisation fails.
\item A critical example is the polynomial ring $ K\sbr{X} $ for $ K $ a field. Here we can take $ \N\br{P\br{X}} $ to be the degree of $ P\br{X} $. Then, given polynomials $ P\br{X}, T\br{X} \in K\sbr{X} $ and $ T\br{X} \ne 0 $, we can use polynomial long division to write $ P\br{X} = Q\br{X}T\br{X} + R\br{X} $ for some $ Q\br{X} $ with the degree of $ R\br{X} $ strictly less than that of $ T\br{X} $, unless $ T\br{X} $ is constant, in which case we can make $ R\br{X} = 0 $. To prove this, fix $ T\br{X} $. If $ \deg T\br{X} = 0 $, then $ T\br{X} $ is constant, so $ T\br{X} = c \ne 0 \in K $. Take $ Q\br{X} = P\br{X} / c $ and $ R\br{X} = 0 $. Otherwise induct on $ \deg P\br{X} $. If $ \deg P\br{X} < \deg T\br{X} $, set $ R\br{X} = P\br{X} $ and $ Q\br{X} = 0 $. Suppose the claim is true for polynomials of degree $ n $ and $ P\br{X} $ has degree $ n + 1 $, so
$$ P\br{X} = \sum_{i = 0}^{n + 1} a_iX^i, \qquad T\br{X} = \sum_{i = 0}^d b_iX^i, \qquad d < n + 1. $$
Then $ S\br{X} = P\br{X} - \br{a_{n + 1} / b_d}X^{n + 1 - d}T\br{X} $ has degree $ n $. By the inductive hypothesis there exist $ Q\br{X} $ and $ R\br{X} $ with $ \deg R\br{X} < \deg T\br{X} $ such that $ S\br{X} = Q\br{X}T\br{X} + R\br{X} $, so
$$ P\br{X} = \br{\dfrac{a_{n + 1}}{b_d}X^{n + 1 - d} + Q\br{X}}T\br{X} + R\br{X}. $$
\item Later, will show if $ R $ is a UFD, then $ R\sbr{X} $ is also a UFD.
\end{itemize}
\end{example*}

\pagebreak

\section{The Chinese remainder theorem}

In elementary number theory, let $ m_1, m_2 \in \ZZ $ be relatively prime and $ a_1, a_2 \in \ZZ $. Then there exists $ a \in \ZZ $ such that $ a \equiv a_1 \mod m_1 $ and $ a \equiv a_2 \mod m_2 $. Moreover, $ a $ is unique up to congruence modulo $ m_1m_2 $. A question is given ideals $ I_1, \dots, I_r $ and $ a_1, \dots, a_r \in R $, when can we find a $ a \in R $ with $ a \in a_1 + I_1, \dots, a \in a_r + I_r $?

\subsection{Products}

\begin{definition}
Let $ R_1, \dots, R_n $ be rings. The \textbf{direct product} $ R_1 \times \dots \times R_n $ is a ring whose elements are $ n $-tuples $ \br{r_1, \dots, r_n} $ with $ r_i \in R_i $ for all $ i $. The addition and multiplication are given componentwise by
$$ \br{r_1, \dots, r_n} + \br{r_1', \dots, r_n'} = \br{r_1 + r_1', \dots, r_n + r_n'}, \qquad \br{r_1, \dots, r_n}\br{r_1', \dots, r_n'} = \br{r_1r_1', \dots, r_nr_n'}. $$
\end{definition}

\begin{note*}
The product comes with natural homomorphisms $ \pi_i $ for all $ i $, the \textbf{projection} onto the $ i $-th factor, defined by
$$ \function[\pi_i]{R_1 \times \dots \times R_n}{R_i}{\br{r_1, \dots, r_n}}{r_i}. $$
\end{note*}

The product also comes with the following universal property.

\begin{theorem}[Universal property of the product]
Let $ S, R_1, \dots, R_n $ be any rings. For any homomorphisms $ f_1 : S \to R_1, \dots, f_n : S \to R_n $, there exists a unique homomorphism
$$ f : S \to R_1 \times \dots \times R_n, $$
such that $ \pi_i \circ f = f_i $ for all $ i $.
\end{theorem}

\begin{proof}
Given $ f_i $, the homomorphism $ f $ is defined by $ f\br{s} = \br{f_1\br{t}, \dots, f_n\br{t}} $. Then $ \br{\pi_i \circ f}\br{s} = f_i\br{s} $. For uniqueness, if $ \br{\pi_i \circ g}\br{s} = f_i\br{s} $ for all $ i $, then $ g\br{s} = \br{f_1\br{s}, \dots, f_n\br{s}} = f\br{s} $.
\end{proof}

More generally, if $ I $ is any index set, and for each $ i \in I $ we have a ring $ R_i $, we can define the product $ \prod_i R_i $. An element $ r $ of this product is a choice, for each $ i \in I $, of an element of $ R_i $. We write such an element as $ \br{r_i}_{i \in I} $. For each $ j \in I $ we have a map
$$ \function[\pi_j]{\prod_i R_i}{R_j}{\br{r_i}_{i \in I}}{r_j}. $$
Such a product satisfies a very similar universal property. For any collection $ f_i : S \to R_i $ for $ i \in I $ of maps, we get a unique map
$$ f : S \to \prod_i R_i, $$
such that $ \pi_j \circ f = f_j $.

\subsection{The Chinese remainder theorem}

Let $ R $ be a ring, and let $ I_1, \dots, I_r $ be a finite collection of ideals of $ R $. We have the natural maps $ R \to R / I_1, \dots R \to R / I_r $, which are surjective with kernel $ I_j $. Consider the product map $ R \to R / I_1 \times \dots \times R / I_r $. It is easy to see that the kernel of this map is the set of $ r \in R $ such that $ r $ maps to zero in $ R / I_j $ for all $ j $. That is, the kernel is the intersection $ I_1 \cap \dots \cap I_r $. Call this ideal $ J $. We thus have an injective embedding $ R / J \hookrightarrow R / I_1 \times \dots \times R / I_r $. A natural question to ask is, what can we say about the image? In other words, given congruence classes modulo $ I_1, \dots, I_r $, when is there a single element of $ R $ that lives in all those congruence classes simultaneously?

\begin{note*}
Because the above map is injective, if one such element exists, then there is a unique congruence class modulo $ J $ that satisfies all of the required congruences.
\end{note*}

Of course, without further hypotheses we cannot expect this map to be surjective. Think about what happens when $ I_1 = I_2 $, for instance. Nonetheless, we have the following.

\begin{definition}
We will say $ I_1, \dots, I_r $ are \textbf{pairwise relatively prime} if for each $ i \ne j $, the sum $ I_i + I_j $ is the unit ideal in $ R $.
\end{definition}

\pagebreak

\begin{theorem}
Let $ R $ be a ring and $ I_1, \dots, I_r $ be pairwise relatively prime ideals. Then the natural map
$$ R / J \hookrightarrow R / I_1 \times \dots \times R / I_r $$
is an isomorphism.
\end{theorem}

\begin{proof}
We have to prove it is surjective. Fix any tuple $ \br{c_1, \dots, c_r} $ of elements of $ R $. We need to find $ c \in R $ such that $ c \in c_i + I_i $ for all $ i $. It suffices to construct, for each $ i $, an element $ e_i $ of $ R $ that is congruent to $ 1 \mod I_i $ and $ 0 \mod I_j $ for $ j \ne i $. Suppose we have such an element. Then the element
$$ c = c_1e_1 + \dots + c_re_r $$
is congruent to $ c_j \mod I_j $ for all $ j $. Given $ i $ and $ j $ with $ i \ne j $, we know that $ I_i + I_j $ is the unit ideal. That is, we can write $ a_{ij} + b_{ij} = 1 $ for $ a_{ij} \in I_i $ and $ b_{ij} \in I_j $. Then $ a_{ij} $ is congruent to $ 1 \mod I_j $ and $ 0 \mod I_i $ as an element of $ R / I_1 \times \dots \times R / I_r $, so $ a_{ij} $ has zero in the $ i $-th place and one in the $ j $-th place. Then for any $ j $ we can take $ e_j = \prod_{i \ne j} a_{ij} $, and $ e_j $ will be congruent to $ 1 \mod I_j $ and $ 0 \mod I_i $ for all $ j \ne i $, so $ e_j $ has one only in the $ j $-th place. So $ R \to R / I_1 \times \dots \times R / I_r $ is surjective. The result follows.
\end{proof}

\subsection{Examples}

When $ R = \ZZ $, then every ideal is principal, so we can write $ I_j = \abr{n_j} $ for all $ j $. The condition that $ I_i + I_j $ is the unit ideal becomes the condition that $ n_i \in \ZZ $ are pairwise relatively prime. In this case the ideal $ J $ is generated by the product $ n $ of the $ n_i $. Specialising, we find the version of the Chinese remainder theorem from elementary number theory.

\begin{theorem}
If $ \cbr{n_j \in \ZZ} $ is a finite collection of pairwise relatively prime integers, and $ n $ is their product, then for any $ c_1, \dots, c_r \in \ZZ $, there exists $ c \in \ZZ $ unique up to congruence modulo $ n $ such that $ c $ is congruent to $ c_i \mod n_i $ for all $ i $.
\end{theorem}

Now let $ K $ be a field and take $ R = K\sbr{X} $. If $ c_1, \dots, c_r \in K $ are distinct elements of $ K $, the ideals $ I_i = \abr{X - c_i} \subseteq R $ are such that $ I_i + I_j = \abr{X - c_i} + \abr{X - c_j} \ni c_i - c_j \in K^\times $, so contains one. That is, $ I_i + I_j $ is the unit ideal in $ R $ and the ideals $ I_i $ are pairwise relatively prime. Moreover, for each $ i $, $ I_i $ is the kernel of the evaluation map
$$ \function[f_i]{R}{K}{P\br{X}}{P\br{c_i}}. $$
Let
$$ \function[f]{R}{K \times \dots \times K}{P\br{X}}{\br{P\br{c_1}, \dots, P\br{c_r}}}. $$
Then the following diagram commutes.
$$
\begin{tikzcd}
R \arrow{r}{f} \arrow[twoheadrightarrow]{d} & K \times \dots \times K \\
R / J \arrow{r}[swap]{\sim} & R / I_1 \times \dots \times R / I_r \arrow{u}[swap]{\sim}
\end{tikzcd}.
$$
Chinese remainder theorem implies that $ f $ is surjective. We thus have an isomorphism
$$ \function{R / I_i}{K}{P\br{X}}{P\br{c_i}}, $$
for all polynomials $ P $. We thus obtain the following.

\begin{theorem}
For any $ c_1, \dots, c_n \in K $, there is a polynomial $ P\br{X} $ in $ K\sbr{X} $, unique up to congruence modulo $ \br{X - a_1} \dots \br{X - a_n} $, such that $ P\br{a_i} = c_i $ for all $ i $.
\end{theorem}

\pagebreak

\section{Fields and field extensions}

\lecture{7}{Friday}{19/10/18}

Next we will use that $ K\sbr{X} $ is a PID for $ K $ a field to study fields systematically.

\subsection{Prime fields}

Let $ K $ be a field. We have a unique ring homomorphism
$$ \function[\iota]{\ZZ}{K}{n}{n_K = 1_K + \dots + 1_K}, \qquad n \ge 0. $$
Let $ I $ be the kernel. Then $ \ZZ / I \hookrightarrow K $ so $ \ZZ / I $ is an integral domain, so $ I $ is a prime ideal. Thus $ I $ is either the zero ideal $ \cbr{0} $, if $ K $ has characteristic zero, or the ideal $ \abr{p} $ for some prime $ p $ of $ \ZZ $. In the former case $ I = \cbr{0} $, the injection $ \ZZ \hookrightarrow K $ extends to an inclusion
$$ \function{\QQ}{K}{\dfrac{a}{b}}{\br{\iota a}\br{\iota b^{-1}} = \dfrac{a_K}{b_K}}. $$
In the latter case $ I = \abr{p} $, we get an injection $ \ZZ / p\ZZ \hookrightarrow K $, which we often denote $ \FF_p $ when we think of it as a field. The upshot is that every field $ K $ contains exactly one of $ \QQ $ or $ \FF_p $ for $ p $ prime, in exactly one way depending on its characteristic. This field is called the \textbf{prime field} of $ K $, and it is contained in $ K $ in a unique way.

\subsection{Field extensions}

The prime fields are in some sense the smallest possible fields. Once we know they exist, it makes sense to study fields by studying pairs $ K $ and $ L $ of fields such that $ K \subseteq L $ of fields, trying to relate $ L $ to $ K $.

\begin{definition}
A \textbf{field extension} is such a pair of fields $ K $ and $ L $ with $ K \subseteq L $, and is often denoted $ L / K $.
\end{definition}

\begin{note*}
Such an inclusion of fields $ L / K $ makes $ L $ into a $ K $-vector space, that is a vector space over $ K $.
\end{note*}

\begin{definition}
We say that a field extension $ L / K $ is \textbf{finite} if $ L $ is finite-dimensional as a $ K $-vector space. If this is the case, the \textbf{degree} of such an extension is the dimension of $ L $ as a $ K $-vector space $ \dim_K L $, and is denoted $ \sbr{L : K} $.
\end{definition}

\begin{proposition}
Let $ K \subseteq L \subseteq M $ be fields. Then $ M / K $ is finite if and only if $ M / L $ and $ L / K $ are both finite. If this is the case then
$$ \sbr{M : K} = \sbr{M : L}\sbr{L : K}. $$
\end{proposition}

\begin{proof}
First suppose that $ M / K $ is finite. Then $ L $ is a $ K $-subspace of $ M $, so finite-dimensional as a $ K $-vector space. Moreover, there exists a $ K $-basis $ m_1, \dots, m_r $, and this basis spans $ M $ over $ K $ and thus also over $ L $. Thus $ M $ is finite-dimensional as an $ L $-vector space, so $ M / L $ is finite. Conversely, suppose $ L / K $ and $ M / L $ are finite. Let $ e_1, \dots, e_n $ be a $ K $-basis for $ L $, and let $ f_1, \dots, f_n $ be an $ L $-basis for $ M $. Then claim that
$$ e_1f_1, \dots, e_1f_m, \dots, e_nf_1, \dots, e_nf_m $$
is a $ K $-basis for $ M $. Every element $ x $ of $ M $ can be expressed uniquely as $ c_1f_1 + \dots + c_mf_m $ for $ c_i \in L $. Each $ c_i $ in turn can be expressed as $ d_{1, i}e_1 + \dots + d_{n, i}e_n $ for $ d_{j, i} \in K $. Thus we can express $ x $ as
$$ d_{1, 1}e_1f_1 + \dots + d_{n, 1}e_nf_1 + \dots + d_{1, m}e_1f_m + \dots + d_{n, m}e_nf_m. $$
In particular the set $ \cbr{e_if_j \st 1 \le i \le n, \ 1 \le j \le m} $ spans $ M $ over $ K $. In this case the degree of $ L $ over $ K $ is $ n $ and the degree of $ M $ over $ L $ is $ m $, so it remains to show that $ \cbr{e_if_j} $ is linearly independent over $ K $. Suppose we have elements $ d_{i, j} $ of $ K $ such that $ \sum_{i, j} d_{i, j}e_if_j = 0 $. Then, regrouping, we find that $ \sum_j \sum_i d_{i, j}e_if_j = 0 $ is an $ L $-linear combination of the $ f_j $ that is zero. Since the $ f_j $ are linearly independent over $ L $ we must have $ \sum_i d_{i, j}e_i = 0 $ for all $ j $. Since the $ e_i $ are linearly independent over $ K $ we must have $ d_{i, j} = 0 $ for all $ i $ and $ j $.
\end{proof}

\pagebreak

\subsection{Extensions generated by one element}

\lecture{8}{Monday}{22/10/18}

Let $ L / K $ be a field extension, and let $ \alpha $ be an element of $ L $.

\begin{definition}
We let $ K\br{\alpha} $ denote the subfield of $ L $ consisting of all elements of $ L $ that can be expressed in the form $ P\br{\alpha} / Q\br{\alpha} $, where $ P $ and $ Q $ are polynomials with coefficients in $ K $ and $ Q\br{\alpha} $ is not zero. This is the smallest subfield of $ L $ containing $ K $ and $ \alpha $.
\end{definition}

Recall that if $ R $ and $ S $ are rings, $ f : R \to S $ is a homomorphism, and $ \alpha \in S $, then have
$$ \function[\phi_{f, a}]{R\sbr{X}}{S}{\sum_{i = 1}^n r_iX^i}{\sum_{i = 1}^n f\br{r_i}\alpha^i}. $$
We also have a natural map
$$ \function{K\sbr{X}}{K\br{\alpha} \subseteq L}{P\br{X}}{P\br{\alpha}}. $$
the inclusion on $ K $. It is a ring homomorphism. Let $ I $ be the kernel of this homomorphism. We then get an injection of $ K\sbr{X} / I $ into the field $ K\br{\alpha} $. Thus $ K\sbr{X} / I $ is an integral domain, so $ I $ is a prime ideal of $ K\sbr{X} $. Since $ K\sbr{X} $ is a PID, every nonzero prime ideal is maximal. There are thus two cases. In the first $ I $ is the zero ideal that is not maximal. That is, there is no nonzero polynomial $ Q $ in $ K\sbr{X} $ such that $ Q\br{\alpha} $ is zero in $ L $. We say that $ \alpha $ is \textbf{transcendental} over $ K $ in this case. In the second $ I $ is an ideal $ \abr{Q} $ for $ Q \in K\sbr{X} $ a nonzero irreducible polynomial that is a maximal ideal of $ K\sbr{X} $. In this case we say $ \alpha $ is \textbf{algebraic} over $ K $.

\begin{definition}
$ K\br{X} $ is the \textbf{field of rational functions} on $ X $,
$$ K\br{X} = \cbr{\dfrac{P\br{X}}{Q\br{X}} \st P, Q \in K\sbr{X}, \ Q \ne 0} / \sim. $$
\end{definition}

Assume first that $ \alpha $ is transcendental over $ K $, that is $ I = \cbr{0} $. Recall $ I = \cbr{P\br{X} \in K\sbr{X} \st P\br{\alpha} = 0} $. So in this case there is no nonzero polynomial $ P \in K\sbr{X} $ with $ P\br{\alpha} = 0 $. In this case the map taking $ P\br{X} $ to $ P\br{\alpha} $ is an injection of $ K\sbr{X} $ into $ K\br{\alpha} \subseteq L $. In particular every nonzero element of $ K\sbr{X} $ gets sent to a nonzero, hence invertible, element of $ L $. Thus the map from $ K\sbr{X} $ to $ L $ extends to an injective map from the field of fractions of $ K\sbr{X} $,
$$ \function{K\br{X}}{L}{\dfrac{P\br{X}}{Q\br{X}}}{\dfrac{P\br{\alpha}}{Q\br{\alpha}}}. $$
By definition of $ K\br{\alpha} $, this map is surjective so the image of this map is $ K\br{\alpha} $. In particular $ K\br{X} $ and $ K\br{\alpha} $ are isomorphic.

\begin{note*}
In this case $ K\br{\alpha} $ is infinite-dimensional as a $ K $-vector space. It contains a subspace isomorphic to $ K\sbr{X} $, for instance.
\end{note*}

If $ \alpha $ is algebraic over $ K $, then $ I $ is a nonzero maximal ideal of the PID $ K\sbr{X} $, so it is generated by a single irreducible polynomial $ Q\br{X} $ in $ K\sbr{X} $. As a consequence, since the units in $ K\sbr{X} $ are just the constant polynomials, the polynomial $ Q\br{X} $ is well-defined up to a constant factor. It is called the \textbf{minimal polynomial} of $ \alpha $. By definition, it divides every polynomial $ P\br{X} $ such that $ P\br{\alpha} = 0 $. Since $ \abr{Q\br{X}} $ is maximal, the ring $ K\sbr{X} / \abr{Q\br{X}} $ is a field. Recall that for any $ P \in K\sbr{X} $, can write $ P\br{X} $ uniquely as $ A\br{X}Q\br{X} + R\br{X} $ for $ \deg R < \deg Q $. So $ 1, \dots, X^{\deg Q - 1} $ are a $ K $-basis of $ K\sbr{X} / \abr{Q\br{X}} $. So its dimension as a $ K $-vector space is equal to the degree of $ Q\br{X} $. The map $ K\sbr{X} \to K\br{\alpha} \subseteq L $ descends to an injection of $ K\sbr{X} / \abr{Q\br{X}} $ into $ L $. Since its image is a subfield of $ K\br{\alpha} $ containing $ K $ and $ \alpha $, this map is an isomorphism
$$ K\br{\alpha} \cong K\sbr{X} / \abr{Q\br{X}}. $$
Thus in this case the extension $ K\br{\alpha} / K $ is a finite extension, of degree equal to the degree of $ Q\br{X} $. To summarise, extend $ K $ by a single element by
\begin{itemize}
\item building $ K\sbr{X} $, and
\item either passing to field of fractions $ K\br{X} $ to form a transcendental extension, or choosing an irreducible polynomial $ Q $ to form an algebraic extension $ K\sbr{X} / \abr{Q\br{X}} $.
\end{itemize}
Slightly informally, instead of $ K\sbr{X} / \abr{Q\br{X}} $, we sometimes write $ K\br{\alpha} $, where $ \alpha $ is a root of $ Q\br{X} $.

\pagebreak

\subsection{Algebraic extensions}

\begin{definition}
An extension $ L / K $ is \textbf{algebraic} if every element of $ L $ is algebraic over $ K $.
\end{definition}

\begin{proposition}
If $ L / K $ is finite, then $ L / K $ is algebraic.
\end{proposition}

\begin{proof}
Let $ d $ be the dimension of $ L $ over $ K $. Then for any $ \alpha $, the set $ 1, \dots, \alpha^d $ must be linearly dependent over $ K $. This gives a nonzero polynomial $ P $ such that $ P\br{\alpha} = 0 $.
\end{proof}

\begin{corollary}
Let $ L / K $ be a field extension, and suppose $ \alpha $ and $ \beta $ are elements of $ L $ algebraic over $ K $. Then $ \alpha + \beta $ and $ \alpha\beta $ are algebraic over $ K $. Moreover, if $ \alpha $ is nonzero then $ \alpha^{-1} $ is algebraic over $ K $.
\end{corollary}

\begin{proof}
Consider the chain of extensions $ K \subseteq K\br{\alpha} \subseteq K\br{\alpha, \beta} $, where we write $ K\br{\alpha, \beta} $ for $ \br{K\br{\alpha}}\br{\beta} $. Since $ \alpha $ is algebraic over $ K $, $ K\br{\alpha} $ is finite over $ K $, of degree $ \deg \alpha $. Since $ \beta $ is algebraic over $ K $, it is also algebraic over $ K\br{\alpha} $, so $ K\br{\alpha, \beta} $ is finite over $ K\br{\alpha} $, of degree at most $ \deg \beta $. Thus $ K\br{\alpha, \beta} $ is algebraic over $ K $, of degree at most $ \deg \alpha\deg \beta $. On the other hand, we also have a chain of extensions $ K \subseteq K\br{\alpha + \beta} \subseteq K\br{\alpha, \beta} $, so $ K\br{\alpha + \beta} $ is finite over $ K $, of degree at most $ \deg \alpha\deg \beta $. Hence $ \alpha + \beta $ is algebraic over $ K $. The proofs for $ \alpha\beta $ and $ \alpha^{-1} $ are similar.
\end{proof}

\begin{corollary}
For any extension $ L / K $, let $ L^{\alg} $ be the subset of $ L $ consisting of all elements of $ L $ that are algebraic over $ K $. Then $ L^{\alg} $ is a field.
\end{corollary}

\begin{proof}
We have seen that $ L^{\alg} $ is closed under addition, multiplication, and taking inverses. For example, if $ a_0 + \dots + a_n\alpha^n = 0 $, then $ a_0\br{\alpha^{-1}}^n + \dots + a_n = 0 $.
\end{proof}

\begin{example*}
In particular, the subfield $ \overline{\QQ} \subseteq \CC $ of complex numbers that are algebraic over $ \QQ $ is a field, called the \textbf{field of algebraic numbers}.
\end{example*}

\subsection{Example}

\begin{example*}
Consider the polynomial $ X^2 + X + 1 $ in $ \FF_2\sbr{X} $. It has no roots in $ \FF_2 $, so it is irreducible, as it is a polynomial of degree two any nontrivial factor would be linear. The other polynomials of degree two are
$$ X^2, \qquad X^2 + X = X\br{X + 1}, \qquad X^2 + 1 = \br{X + 1}^2, $$
so $ X^2 + X + 1 $ is the unique irreducible polynomial of degree two. Thus the quotient $ \FF_2\sbr{X} / \abr{X^2 + X + 1} $ is a field extension of degree two of $ \FF_2 $, which is denoted $ \FF_4 $. Its four elements are $ 0, 1, X, X + 1 $, or more precisely, their classes modulo $ \abr{X^2 + X + 1} $, and
$$
\begin{array}{c|cccc}
\cdot & 0 & 1 & X & X + 1 \\
\hline
0 & 0 & 0 & 0 & 0 \\
1 & 0 & 1 & X & X + 1 \\
X & 0 & X & X + 1 & 1 \\
X + 1 & 0 & X + 1 & 1 & X
\end{array}.
$$
In particular the multiplicative group of $ \FF_4 $ is cyclic of order three. This is not particularly surprising, as all groups of order three are cyclic. We will see later that the multiplicative group of any finite field is cyclic.
\end{example*}

\begin{proposition}
Let $ K $ be a field with four elements. Then $ K \cong \FF_4 $.
\end{proposition}

\begin{proof}
Let $ \alpha \in K $ with $ \alpha \ne 0 $ and $ \alpha \ne 1 $. Consider $ 1, \alpha, \alpha^2 $. Since $ K $ has dimension two over $ \FF_2 $, there is a linear dependence. So there exists a polynomial $ P $ in $ \FF_2\sbr{X} $ of degree at most two such that $ P\br{\alpha} = 0 $. In fact $ P $ must be irreducible of degree two. If it is divisible by something of degree one, then a polynomial of degree one vanishes on $ \alpha $, so $ \alpha = 0 $ or $ \alpha = 1 $. So $ \alpha^2 + \alpha + 1 = 0 $. The map
$$ \function{\FF_2\sbr{X}}{K}{X}{\alpha}. $$
descends to $ \FF_2\sbr{X} / \abr{X^2 + X + 1} \to K $. So $ \FF_4 $ embeds in $ K $. Thus $ K \cong \FF_4 $.
\end{proof}

\pagebreak

\section{Finite fields}

\subsection{Finite fields}

\lecture{9}{Wednesday}{24/10/18}

Let $ K $ be a finite field. That is, a field with only finitely many elements. Then $ K $ has characteristic $ p $ for some prime $ p $, and is in particular a finite-dimensional $ \FF_p $-vector space. Thus its order is a power $ p^r $ of $ p $ for $ r \in \ZZ_{> 0} $. If we fix a particular prime power $ p^r $, then two questions naturally arise. Does there exist a field of order $ p^r $? If so, can we classify fields of order $ p^r $ up to isomorphism? We will see that in fact, up to isomorphism, there is a unique field $ \FF_{p^r} $ of order $ p^r $.

\subsection{The Frobenius automorphism}

Let $ p $ be a prime. For any ring $ R $, the map $ x \mapsto x^p $ on $ R $ certainly satisfies $ \br{xy}^p = x^py^p $ for $ x, y \in R $. On the other hand,
$$ \br{x + y}^p = x^p + \binom{p}{1}xy^{p - 1} + \dots + \binom{p}{p - 1}x^{p - 1}y + y^p. $$
Now the binomial coefficients satisfy $ p \mid p! / i!\br{p - i}! $ for $ 1 \le i \le p - 1 $, so if $ R $ has characteristic $ p $, we have $ \br{x + y}^p = x^p + y^p $. Thus, when $ R $ has characteristic $ p $, the map $ x \mapsto x^p $ is a ring homomorphism from $ R $ to $ R $, called the \textbf{Frobenius endomorphism} of $ R $. If $ R $ is a field of characteristic $ p $, then the Frobenius endomorphism is injective. If in addition $ R $ is finite, then any injective map from $ R $ to $ R $ is surjective. In particular the Frobenius endomorphism is a bijective and an isomorphism from $ R $ to $ R $ when $ R $ is a finite field of characteristic $ p $. In this case we call the map $ x \mapsto x^p $ the \textbf{Frobenius automorphism}. Composing the Frobenius endomorphism with itself, we find that for any $ r $, $ x \mapsto x^{p^r} $ is also an endomorphism of any ring $ R $ of characteristic $ p $.

\begin{example*}
Let $ R = \FF_4 $. Then $ y \mapsto y^2 $ gives
$$ 0 \mapsto 0, \qquad 1 \mapsto 1, \qquad X \mapsto X + 1, \qquad X + 1 \mapsto X. $$
\end{example*}

Let $ K $ be a field of $ p^r $ elements. Then $ \alpha^{p^r} = \alpha $ for all $ \alpha \in K $. If $ \alpha = 0 $, this is clear. Otherwise $ \alpha \in K^* $, so $ K^* $ is an abelian group of order $ p^r - 1 $. Lagrange's theorem implies that $ \alpha^{p^r - 1} = 1 $, so $ \alpha^{p^r} = \alpha $. We have the following.

\begin{proposition}
Let $ K $ be a field of characteristic $ p $, such that $ \alpha^{p^r} = \alpha $ for all $ \alpha \in K $. Let $ P\br{X} \in K\sbr{X} $ be an irreducible factor of $ X^{p^r} - X $ over $ K\sbr{X} $. Then every element $ \beta $ of $ K\sbr{X} / \abr{P\br{X}} $ satisfies $ \beta^{p^r} = \beta $.
\end{proposition}

\begin{proof}
Let $ d = \deg P $. Can write $ \beta = c_0 + \dots + c_{d - 1}X^{d - 1} $. Moreover, since $ P\br{X} = 0 $ in $ K\sbr{X} / \abr{P\br{X}} $ and $ P\br{X} $ divides $ X^{p^r} - X $, we have $ X^{p^r} = X $ in $ K\sbr{X} / \abr{P\br{X}} $. Thus
$$ \beta^{p^r} = c_0^{p^r} + \dots + c_{d - 1}^{p^r}\br{X^{p^r}}^{d - 1} = c_0 + \dots + c_{d - 1}\br{X^{p^r}}^{d - 1} = c_0 + \dots + c_{d - 1}X^{d - 1} = \beta. $$
\end{proof}

\begin{corollary}
There exists a field $ K $ of characteristic $ p $ such that
\begin{enumerate}
\item $ \alpha^{p^r} = \alpha $ for all $ \alpha \in K $, and
\item the polynomial $ X^{p^r} - X $ of $ K\sbr{X} $ factors into linear factors over $ K\sbr{X} $.
\end{enumerate}
\end{corollary}

\begin{proof}
Let $ K_0 = \FF_p $. Then $ K_0 $ satisfies $ 1 $. We construct a tower of fields
$$ K_0 = \FF_p \subsetneq K_1 \subsetneq K_2 \subsetneq \dots $$
all satisfying $ 1 $ as follows. Suppose we have constructed $ K_i $ satisfying $ 1 $. If $ X^{p^r} - X $ factors into linear factors over $ K_i\sbr{X} $, we are done. Otherwise, choose a nonlinear irreducible factor $ P_i\br{X} $ of $ X^{p^r} - X $ in $ K_i\sbr{X} $ of degree at least two, and set $ K_{i + 1} = K_i\sbr{X} / \abr{P_i\br{X}} $. Then $ K_{i + 1} $ is strictly larger than $ K_i $ and still satisfies $ 1 $. On the other hand, in any field $ K_i $ satisfying $ 1 $, every element is a root of $ X^{p^r} - X $, so $ \#K_i \le p^r $ for all $ i $. Since this polynomial can have at most $ p^r $ roots, this process must eventually terminate.
\end{proof}

Since $ X^{p^r} - X $ has degree $ p^r $, we expect the field $ K $ constructed above to have $ p^r $ elements. So it suffices to show that over any field $ K $ of characteristic $ p $, $ X^{p^r} - X $ has no repeated roots. To prove this we need an additional tool.

\pagebreak

\subsection{Derivatives}

\begin{definition}
Let $ R $ be a ring, and let $ P\br{X} = r_0 + \dots + r_dX^d $ be an element of $ R\sbr{X} $. The \textbf{derivative} $ P'\br{X} $ of $ P\br{X} $ is the polynomial
$$ r_1 + \dots + dr_dX^{d - 1}. $$
\end{definition}

\begin{note*}
Just as for differentiation in calculus, we have a Leibniz rule. For $ P, Q \in R\sbr{X} $,
$$ \br{PQ}'\br{X} = P\br{X}Q'\br{X} + P'\br{X}Q\br{X}, $$
by reducing to $ P $ and $ Q $ monomials.
\end{note*}

From this we deduce the following.

\begin{lemma}
Let $ K $ be a field, and let $ P\br{X} $ be a polynomial in $ K\sbr{X} $ with a multiple root in $ K $. Then $ P\br{X} $ and $ P'\br{X} $ have a common factor of degree greater than zero.
\end{lemma}

\begin{proof}
Let $ \alpha \in K $ be the multiple root. Then we can write $ P\br{X} = \br{X - \alpha}^2Q\br{X} $. Applying the Leibniz rule we get $ P'\br{X} = 2\br{X - \alpha}Q\br{X} + \br{X - \alpha}^2Q'\br{X} $, and it is clear that $ X - \alpha $ divides both $ P\br{X} $ and $ P'\br{X} $.
\end{proof}

\begin{corollary}
Let $ K $ be a field of characteristic $ p $. Then $ X^{p^r} - X $ has no repeated roots in $ K $.
\end{corollary}

\begin{proof}
Let $ P\br{X} = X^{p^r} - X $. Then $ P'\br{X} = -1 $, so $ P\br{X} $ and $ P'\br{X} $ have no common factor.
\end{proof}

\begin{corollary}
There exists a finite field of $ p^r $ elements.
\end{corollary}

\subsection{The multiplicative group}

\lecture{10}{Friday}{26/10/18}

Rather than show immediately that there is a unique finite field of $ p^r $ elements, we make a detour to study the multiplicative group of a finite field. This is not strictly necessary to prove uniqueness, but will simplify the proof, and is of interest in its own right. Let $ K $ denote a field of $ p^r $ elements. The goal of this section is to show that $ K^* $ is cyclic.

\begin{note*}
As a multiplicative group, $ K^* $ is an abelian group of order $ p^r - 1 $, so by Lagrange's theorem, we have $ \alpha^{p^r - 1} = 1 $ for all $ \alpha \in K^* $.
\end{note*}

The order of an element $ a $ of $ A $ divides the order of $ A $. If $ d'a = 0 $ for some $ d' \in \ZZ $ then the order of $ a $ divides $ d' $. The order of an element $ a $ of $ K^* $ is the smallest $ d \in \ZZ_{> 0} $ such that $ a^d = 1 $. Since $ a^{p^r - 1} = 1 $, the order of $ a $ is a divisor of $ p^r - 1 $. On the other hand, if $ d $ is a divisor of $ p^r - 1 $, then any element of order dividing $ d $ is a root of the polynomial $ X^d - 1 $. Since $ K $ is a field, this polynomial has at most $ d $ roots, so we find that there are at most $ d $ elements of $ K^* $ of order dividing $ d $. Order of any element divides $ p^r - 1 $. Know $ X^{p^r - 1} - 1 $ has $ p^r - 1 $ distinct roots in $ K $. For $ d \mid p^r - 1 $, $ X^d - 1 \mid X^{p^r - 1} - 1 $, so $ X^d - 1 $ has exactly $ d $ roots in $ K $. That is, for all $ d \mid p^r - 1 $, $ K^* $ has exactly $ d $ elements of order dividing $ d $. In fact, we have the following.

\begin{proposition}
\label{prop:6.4.1}
Let $ A $ be a finite abelian group of order $ n $, and suppose that $ A $ has exactly $ d $ elements of order dividing $ d $, for all $ d $ dividing $ n $. Then $ A $ is cyclic.
\end{proposition}

The remainder of this section will be devoted to proving Proposition \ref{prop:6.4.1}. As a corollary, we deduce that the multiplicative group $ K^* $ of any finite field $ K $ is cyclic. Consider the cyclic group $ \ZZ / n\ZZ $. The order of any element in this group is a divisor of $ n $.

\begin{definition}
For $ n \in \ZZ $, we let $ \Phi\br{n} $ denote the number of elements in $ \br{\ZZ / n\ZZ, +} $ of exact order $ n $. This equals to the number of elements $ t \in \ZZ $ for $ 1 \le t \le n $ such that $ \br{t, n} = 1 $.
\end{definition}

\begin{note*}
Since $ \sbr{1} $ in $ \ZZ / n\ZZ $ has order $ n $, $ \Phi\br{n} $ is nonzero for all $ n $.
\end{note*}

\begin{lemma}
For any $ d $ dividing $ n $, the cyclic group $ \ZZ / n\ZZ $ contains a unique subgroup of order $ d $, and any element of $ \ZZ / n\ZZ $ of order dividing $ d $ is contained in this subgroup.
\end{lemma}

\begin{proof}
The cyclic subgroup $ C $ of $ \ZZ / n\ZZ $ generated by $ n / d $ is clearly a subgroup of order $ d $. This has $ d $ elements $ \sbr{0}, \dots, \br{d - 1}\sbr{\tfrac{n}{d}} $. Conversely, if $ x $ is an element of a subgroup of $ \ZZ / n\ZZ $ of order $ d $, then the order of $ x $ divides $ d $, so $ dx $ is divisible by $ n $, and hence, by unique factorisation, $ x $ is divisible by $ n / d $. Thus $ x $ is in $ C $ and the claim follows.
\end{proof}

\pagebreak

As a consequence, we deduce the following.

\begin{corollary}
For any $ d $ dividing $ n $, $ \Phi\br{d} $ is the number of elements of $ \ZZ / n\ZZ $ of order $ d $.
\end{corollary}

\begin{corollary}
\label{cor:6.4.5}
For any $ n \in \ZZ $, we have $ \sum_{d \mid n} \Phi\br{d} = n $.
\end{corollary}

\begin{proof}
Since every element of $ \ZZ / n\ZZ $ has order $ d $ for some $ d $ dividing $ n $, the sum over all possible $ d $ dividing $ n $ of the number of elements of order $ d $ is just the number of elements of $ \ZZ / n\ZZ $, which is $ n $.
\end{proof}

\begin{proof}[Proof of Proposition \ref{prop:6.4.1}]
Let $ A $ be as in Proposition \ref{prop:6.4.1}. We must show that $ A $ contains an element of order $ n $. In fact, we will show, by induction on $ d $, that $ A $ contains exactly $ \Phi\br{d} $ elements of order $ d $ for all $ d \mid n $. In particular, $ A $ has $ \Phi\br{n} > 0 $ elements of order $ n $, so it is cyclic. If $ d = 1 $, the only element of order one is the identity of $ A $. Since $ \Phi\br{1} = 1 $ the base case holds. Assume the claim is true for all $ d' < d $. Then $ A $ has $ d $ elements of order dividing $ d $, and $ \Phi\br{d} $ elements of order $ d' $ for $ d' \mid d $ and $ d' < d $, so the number of elements of exact order $ d $ is $ d - \sum_{d' \mid d, \ d' < d} \Phi\br{d'} $. By Corollary \ref{cor:6.4.5}, this is precisely $ \Phi\br{d} $.
\end{proof}

\subsection{Uniqueness}

We now turn to the question of showing that any two fields of $ p^r $ elements are isomorphic. Let $ K $ be such a field. The cyclicity of $ K^* $ immediately shows the following.

\begin{proposition}
Any finite field $ K $ of characteristic $ p $ is generated over $ \FF_p $ by a single element $ \alpha \in K $.
\end{proposition}

\begin{proof}
Let $ \alpha $ be an element of $ K $, that generates $ K^* $ as an abelian group. Then $ \FF_p\br{\alpha} $ is contained in $ K $, but contains $ \alpha^n $ for all $ n $, so contains $ K^* $, hence $ K = \FF_p\br{\alpha} $.
\end{proof}

As a corollary, we deduce the following.

\begin{proposition}
For any prime $ p $ and any $ r \in \ZZ_{> 0} $, there exists an irreducible polynomial $ P\br{X} \in \FF_p\sbr{X} $ of degree $ r $ in $ \FF_p\sbr{X} $.
\end{proposition}

\begin{proof}
Let $ K $ be a finite field of $ p^r $ elements, let $ \alpha $ be an element of $ K $ that generates $ K $ over $ \FF_p $, and let $ P $ the minimal polynomial of $ \alpha $ over $ \FF_p $. We then have a surjective map
$$ \function{\FF_p\sbr{X}}{K}{X}{\alpha}. $$
Its kernel is generated by the irreducible polynomial $ P\br{X} $ of degree $ \deg P = \sbr{\FF_p\br{\alpha} : \FF_p} = r $.
\end{proof}

We also have the following trick.

\begin{lemma}
Every irreducible polynomial $ P\br{X} $ of degree $ r $ in $ \FF_p\sbr{X} $ is a divisor of $ X^{p^r - 1} - 1 $.
\end{lemma}

\begin{proof}
Let $ K = \FF_p\br{\alpha} $ where $ \alpha $ is a root of $ P $. Then $ \#K = p^r $ so $ \alpha^{p^r} - \alpha $ is zero in $ K $. So $ P\br{X} \mid X^{p^r} - X $.
\end{proof}

\begin{corollary}
Any two finite fields $ K $ and $ K' $ of cardinality $ p^r $ are isomorphic.
\end{corollary}

\begin{proof}
Choose $ \alpha \in K $ such that $ \alpha $ generates $ K $ over $ \FF_p $. We can then write
$$ K = \FF_p\br{\alpha} \cong \FF_p\sbr{X} / \abr{P\br{X}}, $$
where $ P\br{X} $ is the minimal polynomial of $ \alpha $ over $ \FF_p $. In particular $ P\br{X} $ is irreducible of degree $ r $. Since $ P\br{X} $ divides $ X^{p^r - 1} - 1 $ in $ \FF_p\sbr{X} $, it also divides $ X^{p^r - 1} - 1 $ in $ K'\sbr{X} $. Since in $ K'\sbr{X} $, the latter factors into linear factors, $ P\br{X} $ also factors into linear factors over $ K' $. In particular there exists a root $ \alpha' \in K' $ of $ P\br{X} $ in $ K'\sbr{X} $ such that $ P\br{\alpha'} = 0 $. Then there is a map
$$
\begin{array}{rcccl}
K & \to & \FF_p\sbr{X} / \abr{P\br{X}} & \to & K' \\
Q\br{\alpha} & \mapsto & Q\br{X} & \mapsto & Q\br{\alpha'}
\end{array}.
$$
Since this is map of fields from $ K $ to $ K' $ that takes $ \alpha $ to $ \alpha' $ it is injective. Since both fields $ K $ and $ K' $ have the same cardinality $ p^r $, it is also surjective and an isomorphism.
\end{proof}

If $ K = \QQ $, $ \QQ\sbr{X} / \abr{X^2 - p} $ are pairwise nonisomorphic extensions of degree $ \alpha $ for every prime $ p $.

\lecture{11}{Monday}{29/10/18}

Lecture 11 is a problems class.

\pagebreak

\section{\texorpdfstring{$ R $}{R}-modules}

\subsection{Definitions}

\lecture{12}{Wednesday}{31/10/18}

\begin{definition}
An \textbf{$ R $-module} $ M $ is a set, together with two operations
$$ +_M : M \times M \to M, \qquad \cdot_M : R \times M \to M, $$
such that
\begin{enumerate}
\item $ \br{M, +} $ makes $ M $ into an abelian group with identity $ 0_M $,
\item for all $ r \in R $ and $ m, m' \in M $, $ r\br{m + m'} = rm + rm' $,
\item for all $ r, r' \in R $ and $ m \in M $, $ \br{r + r'}m = rm + r'm $,
\item for all $ r, r' \in R $ and $ m \in M $, $ \br{rr'}m = r\br{r'm} $, and
\item for all $ m \in M $, $ 1_R \cdot m = m $.
\end{enumerate}
\end{definition}

\begin{note*}
For an abelian group $ M $, let $ \End\br{M} $ denote the set of homomorphisms $ M \to M $ of abelian groups. Then $ \End\br{M} $ is a noncommutative ring, where $ 2 $ if and only if for all $ r \in R $, $ \cdot r : M \to M $ lives in $ \End\br{M} $, and $ 3, 4, 5 $ if and only if the map $ R \to \End\br{M} $ given by $ 2 $ is a homomorphism of rings.
\end{note*}

\begin{example*}
\hfill
\begin{itemize}
\item The usual addition and multiplication on $ R $ naturally makes $ R $ into an $ R $-module.
\item More generally, any ideal $ I $ of $ R $ is an $ R $-module with the usual addition and multiplication.
\item If $ f : R \to S $, then $ f $ makes $ S $ into an $ R $-module, where the addition $ + $ is the usual addition in $ S $, and the multiplication law is defined by $ r \cdot s = f\br{r} \cdot_S s $ for $ r \in S $ and $ s \in S $.
\item In particular any quotient $ R / I $ is an $ R $-module.
\item More generally, if $ f : R \to S $ is a homomorphism, and $ M $ is any $ S $-module, then $ M $ is also an $ R $-module via $ r \cdot m = f\br{r} \cdot m $.
\item In particular, $ R \to R / I $ lets us treat any $ R / I $-module $ M $ as an $ R $-module. Note that if $ M $ is an $ R / I $-module, then for all $ r \in I $ and $ m \in M $, $ r \cdot m = 0 $. We say that $ I $ \textbf{annihilates} $ M $ in this situation.
\item Conversely, if $ M $ is an $ R $-module and $ r \cdot m = 0 $ for all $ r \in I $ and $ m \in M $, then $ M $ naturally has the structure of an $ R / I $-module. Given $ r + I \in R / I $ and $ m \in M $, we define $ \br{r + I} \cdot m = rm $.
If $ r + I = r' + I $, then $ r - r' \in I $, so $ rm - r'm = \br{r - r'}m = 0 $, by assumption.
\item Let $ R = \ZZ $, and let $ M $ be an abelian group. Then $ M $ has the unique natural structure of $ \ZZ $-module, as follows. Property $ 3 $ from the module axioms shows that
$$ n \cdot m =
\begin{cases}
m + \dots + m & n > 0 \\
0 & n = 0 \\
\br{-m} + \dots + \br{-m} & n < 0
\end{cases}.
$$
Thus the multiplication law $ \ZZ \times M \to M $ is forced on us, and one checks that it does satisfy properties $ 2 $ to $ 5 $ above. Informally, we say that abelian groups are $ \ZZ $-modules.
\item If $ R $ is a field, then $ R $-modules are just $ R $-vector spaces.
\item Let $ S $ be a set, and let $ M_S $ be the set of $ R $-valued functions $ f : S \to R $. We add and multiply pointwise. For $ f, g \in M_S $, we can define
$$ f + g = s \mapsto f\br{s} + g\br{s}, \qquad rf = s \mapsto r \cdot f\br{s}. $$
$ M_S $ is clearly an $ R $-module.
\item Also of interest is the $ R $-submodule $ \F_S $ of $ M_S $ that consists of functions $ f : S \to R $ such that $ f\br{s} = 0_R $ for all but finitely many $ s $. The $ R $-module $ \F_S $ is called the \textbf{free $ R $-module on the set $ S $} and will be very important for us.
\end{itemize}
\end{example*}

\pagebreak

\subsection{Submodules, quotients, and direct sums}

\begin{definition}
Let $ M $ be an $ R $-module. A subset $ N $ of $ M $ is an \textbf{$ R $-submodule} of $ M $ if $ N $ is closed under addition and multiplication by elements of $ R $. That is, $ N $ is an additive subgroup of $ M $, and for all $ r \in R $, we have $ rN \subseteq N $.
\end{definition}

In particular, the ideals of $ R $ are just the $ R $-submodules of $ R $.

\begin{definition}
If $ S $ is any subset of $ M $, we define the $ R $-submodule of $ M $ \textbf{generated} by $ S $ to be the set of all elements of $ M $ of the form
$$ r_1s_1 + \dots + r_ns_n, \qquad r_i \in R, \qquad s_i \in S. $$
It is the smallest $ R $-submodule of $ M $ containing $ S $.
\end{definition}

\begin{definition}
An $ R $-module $ M $ is a \textbf{finitely generated} $ R $-module if $ M $ admits a finite subset $ S $ of $ M $ such that the $ R $-submodule of $ M $ generated by $ S $ is all of $ M $. We say $ S $ is a \textbf{generating set} for $ M $.
\end{definition}

\begin{definition}
Let $ M $ be an $ R $-module and $ N $ be an $ R $-submodule of $ M $. We say two elements $ m $ and $ m' $ of $ M $ are \textbf{congruent modulo $ N $} if their difference $ m - m' $ lies in $ N $. This is easily seen to be an equivalence relation, and the equivalence classes are the cosets of the form $ m + N $ for $ m \in M $. The set of equivalence classes is denoted $ M / N $. It has the natural structure of an $ R $-module, where
$$ \br{m + N} + \br{m' + N} = \br{m + m'} + N, \qquad r \cdot \br{m + N} = \br{rm} + N. $$
This $ R $-module is called the \textbf{quotient} of $ M $ by $ N $. If $ m + N = m' + N $, then $ m - m' \in N $, so $ rm - rm' = r\br{m - m'} \in N $. So this is well-defined. Have a natural map
$$ \function{M}{M / N}{m}{m + N}. $$
\end{definition}

\begin{definition}
Given two $ R $-modules $ M_1 $ and $ M_2 $, the \textbf{direct sum} $ M_1 \oplus M_2 $ is the set of ordered pairs $ \br{m_1, m_2} $ with
$$ \br{m_1, m_2} + \br{m_1', m_2'} = \br{m_1 + m_1', m_2 + m_2'}, \qquad r\br{m_1, m_2} = \br{rm_1, rm_2}. $$
\end{definition}

\begin{example*}
Let $ M $ be an $ R $-module and $ I $ an ideal of $ R $. Then we can form the $ R $-submodule $ IM $ of $ M $ consisting of all elements of $ M $ of the form
$$ i_1m_1 + \dots + i_rm_r, \qquad i_j \in I, \qquad m_j \in M. $$
This is an $ R $-submodule of $ M $, so we can form the quotient $ M / IM $. Then $ M / IM $ is certainly an $ R $-module, but it is also an $ R / I $-module. One can define multiplication
$$ \function{R / I \times M / IM}{M / IM}{\br{r + I, m + IM}}{rm + IM}. $$
As always one has to check that this is well-defined, but this is straightforward. We need that if $ r - r' $ lies in $ I $, and $ m - m' $ lies in $ IM $, then $ rm - r'm' $ lies in $ IM $. But $ rm - r'm' = \br{r - r'}m + r'\br{m - m'} $, which is clearly in $ IM $.
\end{example*}

\subsection{Module homomorphisms, kernels, and images}

\begin{definition}
A map $ f : M \to N $ of $ R $-modules is called a \textbf{homomorphism of $ R $-modules} if
\begin{itemize}
\item $ f $ is a homomorphism of the underlying abelian groups, and
\item for all $ r \in R $ and $ m \in M $,
$$ f\br{rm} = rf\br{m}. $$
\end{itemize}
\end{definition}

A warning is that a ring homomorphism $ R \to R $ satisfies $ f\br{rr'} = f\br{r}f\br{r'} $, but an $ R $-module homomorphism $ R \to R $ satisfies $ f\br{rr'} = rf\br{r'} $.

\pagebreak

\begin{definition}
The \textbf{kernel} of $ f : M \to N $ is the set
$$ \cbr{m \in M \st f\br{m} = 0}, $$
and the \textbf{image} of $ f : M \to N $ is the set
$$ \cbr{n \in N \st \exists m \in M, \ f\br{m} = n}. $$
\end{definition}

It is easy to see that the kernel and image of a homomorphism of $ R $-modules $ f : M \to N $ are $ R $-submodules of $ M $ and $ N $, respectively.

\begin{note*}
In particular there is a natural homomorphism
$$ \function{M}{M / N}{m}{m + N}. $$
\end{note*}

This homomorphism has the following universal property, exactly analogous to the universal property of the quotient construction for rings.

\begin{proposition}[Universal property of the quotient]
Let $ N $ be an $ R $-submodule of $ M $, and let $ f : M \to M' $ be an $ R $-module homomorphism whose kernel contains $ N $. Then there is unique homomorphism
$$ \overline{f} : M / N \to M', $$
such that $ \overline{f}\br{m + N} = f\br{m} $ for all $ m \in M $. In particular the kernel of $ \overline{f} $ is the image of $ \ker f $ in $ M / N $.
\end{proposition}

\begin{proof}
The proof is identical to that for quotient rings, and will be omitted.
\end{proof}

\subsection{Free modules}

\begin{definition}
Let $ M $ be an $ R $-module. A subset $ S $ of $ M $ is a \textbf{basis} for $ M $ if the following two conditions hold.
\begin{itemize}
\item $ S $ \textbf{spans $ M $ over $ R $}. For all $ m \in M $, there exist $ s_1, \dots, s_n \in S $ finite and $ r_1, \dots, r_n \in R $ such that $ m = r_1s_1 + \dots + r_ns_n $, that is the $ R $-submodule of $ M $ generated by $ S $ is all of $ M $.
\item $ S $ is \textbf{$ R $-linearly independent}. For any collection $ s_1, \dots, s_n $ of distinct elements of $ S $, and any $ r_1, \dots, r_n \in R $, $ r_1s_1 + \dots + r_ns_n $ is nonzero in $ M $ unless all $ r_i $ are zero.
\end{itemize}
\end{definition}

\begin{definition}
An $ R $-module $ M $ that has a basis $ S $ is called a \textbf{free} $ R $-module. The cardinality $ n $ of the basis $ S $ is called the \textbf{rank} of the free $ R $-module $ M $ over $ R $.
\end{definition}

\lecture{13}{Friday}{02/11/18}

\begin{remark}
If $ R $ is a field, then the notion of a basis for an $ R $-module coincides with the usual notion for vector spaces. In this case, at least if one assumes the axiom of choice, every $ R $-module has a basis. When $ R $ is not a field only very special $ R $-modules have bases. For instance any quotient $ R / I $ of $ R $ for $ I $ a nonzero ideal has no basis.
\end{remark}

\begin{example*}
The ring $ R $ is a free $ R $-module of rank one over $ R $, with basis $ \cbr{1_R} $. More generally any unit $ u \in R^\times $ gives a basis of $ R $ as an $ R $-module.
\end{example*}

Recall that the free $ R $-module $ \F_S $ on a set $ S $ was defined to be the set of functions $ f : S \to R $ such that $ f\br{s} = 0 $ for all but finitely many $ s \in S $. For each $ s \in S $, we have an element $ e_s $ of $ \F_S $ defined by $ e_s\br{t} = 0 $ for all $ t \in S $ with $ t \ne s $, and $ e_s\br{s} = 1 $. Claim that the $ e_s $ form a basis for $ \F_S $. In particular, given $ f : S \to R $ with $ f\br{s} = 0 $ for all but finitely many $ s $, let $ s_1, \dots, s_n $ be the set of elements in $ S $ on which $ f\br{s_i} $ is nonzero. Set $ r_i = f\br{s_i} $. Claim that
$$ f = r_1e_{s_1} + \dots + r_ne_{s_n}. $$
If $ f\br{s} = 0 $, then $ s \notin \cbr{s_1, \dots, s_n} $ so $ e_{s_i}\br{s} = 0 $ for all $ i $. For any $ i $, $ e_{s_i}\br{s_j} = 0 $ if $ i \ne j $ and $ e_{s_i}\br{s_i} = 1 $, so $ \br{\sum_{i = 1}^n r_ie_{s_i}}\br{s_j} = r_j = f\br{s_j} $. Then $ f $ can be written as $ r_1e_{s_1} + \dots + r_ne_{s_n} $, so the $ e_s $ span $ \F_S $. On the other hand, for all $ s_1, \dots, s_n \in S $ distinct with $ \sum_{i = 1}^n r_ie_{s_i} = 0 $, $ \sum_{i = 1}^n r_ie_{s_i} $ takes the value $ r_i $ by evaluating at $ s_i $ for all $ i $, and thus is only the zero function when all $ r_i $ are zero for all $ i $, so we do have $ R $-linear independence. Thus $ \F_S $ is free, justifying its name.

\pagebreak

\begin{proposition}
Let $ F_1 $ and $ F_2 $ be free $ R $-modules with basis $ S_1 $ and $ S_2 $. Then $ F_1 \oplus F_2 $ is free with basis
$$ \cbr{\br{s, 0} \st s \in S_1} \cup \cbr{\br{0, s'} \st s' \in S_2}. $$ Moreover, if $ F_1 $ and $ F_2 $ are free of finite ranks $ n_1 $ and $ n_2 $ respectively, then $ F_1 \oplus F_2 $ is free of rank $ n_1 + n_2 $.
\end{proposition}

\begin{proof}
For linear independence, let $ s_1, \dots, s_m \in S_1 $ and $ s_1', \dots, s_l' \in S_2 $ be distinct. Suppose we have $ r_1, \dots, r_m, r_1', \dots, r_l' \in R $ such that
$$ r_1\br{s_1, 0} + \dots + r_m\br{s_m, 0} + r_1'\br{0, s_1'} + \dots + r_l'\br{0, s_l'} = 0. $$
Then
$$ r_1s_1 + \dots + r_ms_m = 0 \in M_1, \qquad r_1's_1' + \dots + r_l's_l' = 0 \in M_2, $$
so $ r_i = 0 $ and $ r_i' = 0 $. For spanning set, let $ \br{m, m'} \in M_1 \oplus M_2 $. Write
$$ m = r_1s_1 + \dots + r_ms_m, \qquad s_i \in S_1, \qquad m' = r_1's_1' + \dots + r_l's_l', \qquad s_i' \in S_2, $$
then
$$ \br{m, m'} = r_1\br{s_1, 0} + \dots + r_m\br{s_m, 0} + r_1'\br{0, s_1'} + \dots + r_l'\br{0, s_l'}. $$
Thus $ S_1 \cup S_2 $ is a basis for $ F_1 \oplus F_2 $, which immediately proves the claim.
\end{proof}

Free modules have the following universal property.

\begin{proposition}[Universal property of free modules]
Let $ \F_S $ be a free $ R $-module on a set $ S $. Then for any $ R $-module $ M $, and any map of sets $ f : S \to M $, there is a unique homomorphism of $ R $-modules
$$ \phi_f : \F_S \to M, $$
such that $ \phi_f\br{e_s} = f\br{s} $ for all $ s \in S $.
\end{proposition}

\begin{proof}
Define $ \phi_f $ by
$$ \phi_f\br{g} = \sum_{s \in S, \ g\br{s} \ne 0} g\br{s}f\br{s}. $$
Note that this is a finite sum since all but finitely many $ s $ have $ g\br{s} = 0 $. Then it is clear that this is a homomorphism of $ R $-modules. On the other hand suppose $ \phi $ is any other map $ \F_S \to N $ with $ \phi\br{e_s} = f\br{s} $ for all $ s $. Then we can write $ g = \sum_{s \in S, \ g\br{s} \ne 0} g\br{s}e_s $, again a finite sum, so
$$ \phi\br{g} = \sum_{s \in S, \ g\br{s} \ne 0} g\br{s}\phi\br{e_s} = \sum_{s \in S, \ g\br{s} \ne 0} g\br{s}f\br{s}, $$
so uniqueness is clear.
\end{proof}

The image of $ \phi_f $ is the $ R $-submodule of $ N $ generated by the elements $ f\br{s} $ for $ s \in S $.

\begin{corollary}
Let $ M $ be a free $ R $-module with a basis $ T $ for $ M $. Let $ S $ be any set of the same cardinality as $ T $, and let $ g : T \to S $ be any bijection. Then the map $ \phi_f : \F_S \to M $ is an isomorphism. In particular, any two free $ R $-modules of the same rank are isomorphic.
\end{corollary}

\begin{proof}
The map $ \phi_f : \F_S \to M $ is such that $ \phi_f\br{e_s} = f\br{s} $. Since elements of $ T $ are linearly independent, this map is injective. Suppose $ \phi_f\br{g} = 0 $. Can write $ g = \sum_i r_ie_{s_i} $ for $ s_i $ distinct, then $ \phi_f\br{g} = \sum_i r_if\br{s_i} $. Since $ s_i $ are distinct, $ f\br{s_i} $ are distinct elements of $ T $, so $ \sum_i r_if\br{s_i} = 0 $. So $ r_i = 0 $, so $ g = 0 $. Since elements of $ T $ span $ M $, this map is surjective. Given $ m \in M $, write $ m = \sum_i r_it_i $. For all $ i $, find $ s_i $, with $ f\br{s_i} = t_i $. Then $ \phi_f\br{\sum_i r_ie_{s_i}} = \sum_i r_it_i = m $. Thus $ M $ is isomorphic to $ \F_S $. Since $ M $ was arbitrary, any $ R $-module of rank equal to the cardinality of $ S $ is isomorphic to $ \F_S $ and the result follows.
\end{proof}

\begin{note*}
It is also true, but harder to prove, that if $ M $ and $ N $ are free of different ranks, then $ M \ncong N $.
\end{note*}

\pagebreak

\subsection{Generators and relations}

\lecture{14}{Monday}{05/11/18}

Now let $ M $ be any $ R $-module, and let $ S = \cbr{s_1, \dots, s_n} \subseteq M $ be a finite subset of $ M $ generating $ M $. Then we have a natural map
$$ \function[\psi]{\F_S}{M}{\sum_{i = 1}^n m_ie_{s_i}}{\sum_{i = 1}^n m_is_i}, \qquad m_i \in R, $$
and this map is surjective. Elements of the kernel $ K = \ker \psi $ are called \textbf{relations} among $ S $. Explicitly, an element of $ K $ is a map $ f = \sum_{i = 1}^n m_ie_{s_i} : S \to R $ such that $ f\br{s_i} = 0 $ for all but finitely many $ s_i $, and $ \sum_{i = 1}^n f\br{s_i}s_i = 0 $, since
$$ \sum_{i = 1}^n f\br{s_i}s_i = \sum_{i = 1}^n \br{\sum_{j = 1}^n m_je_{s_j}}\br{s_i}s_i = \sum_{i = 1}^n \br{\sum_{j = 1}^n m_je_{s_j}\br{s_i}}s_i = \sum_{i = 1}^n m_ie_{s_i}\br{e_{s_i}}s_i = \sum_{i = 1}^n m_is_i. $$
In other words, each element of $ K $ encodes a linear relation among the elements of $ S $. It is a measure of how far the elements of $ S $ are from being linearly independent. Let $ T = \cbr{t_1, \dots, t_m} \subseteq K $ be a subset of $ K $ that generates $ K $. Then in the same way as above, we get a surjection
$$ \function{\F_T}{K}{\sum_{j = 1}^m k_je_{t_j}}{\sum_{j = 1}^m k_jt_j}, \qquad k_j \in R, $$
with $ \F_T $ a free module of rank $ m $. Composing with the inclusion of $ K $ in $ \F_S $ gives us a map $ \phi : \F_T \to \F_S $ whose image is $ K $. Thus $ K = \ker \psi = \im \phi = \phi\br{\F_T} $. The map $ \psi $ determines $ M $ up to isomorphism with the quotient $ \F_S / K $, and hence with $ \F_S / \phi\br{\F_T} $. A description of a module as a quotient of a free module by the image of a map of free modules is called a \textbf{presentation} of $ M $. If both modules have finite rank the presentation is called \textbf{finite}. A module that has a finite presentation is called \textbf{finitely presented}. Put another way, a presentation is a description of a module $ M $ in terms of
\begin{itemize}
\item a generating set $ S $ for $ M $, and
\item a generating set $ T $ for the linear relations satisfied by $ S $.
\end{itemize}

When $ S $ and $ T $ are finite we can encode a presentation in a matrix, called the \textbf{presentation matrix}. Write $ S = \cbr{s_1, \dots, s_n} $ and $ T = \cbr{t_1, \dots, t_m} $. Then $ \phi $ is determined by $ \phi\br{e_{t_1}}, \dots, \phi\br{e_{t_m}} $. For each $ j $ we can write $ \phi\br{e_{t_j}} $ as a sum $ \sum_{i = 1}^n r_{ij}e_{s_i} $, and let $ A $ be the $ n $ by $ m $ matrix whose $ i $ and $ j $ entry is $ r_{ij} $. Then $ A $ gives a map from $ R^m $ to $ R^n $, and the quotient of $ R^n $ by the $ R $-submodule $ AR^m $ of $ R^n $ is isomorphic to $ M $.

\begin{example*}
\hfill
\begin{itemize}
\item Let $ R = \ZZ $ and $ M = \ZZ / n\ZZ $ generated by $ \sbr{1}_n $. The map $ \ZZ \to M $ is the quotient map with kernel $ \abr{n} $. So the presentation matrix is just $ \br{n} $.
\item Let $ R = \ZZ\sbr{\sqrt{-5}} $ and $ I = \abr{2, 1 + \sqrt{-5}} $, so $ s_1 = 2 $ and $ s_2 = 1 + \sqrt{-5} $. Then
$$ \psi\br{\br{1 + \sqrt{-5}}e_{s_1} - 2e_{s_2}} = \br{1 + \sqrt{-5}}s_1 - 2s_2 = 0. $$
Since $ \br{2}\br{3} = \br{1 + \sqrt{-5}}\br{1 - \sqrt{-5}} $,
$$ \psi\br{3e_{s_1} - \br{1 - \sqrt{-5}}e_{s_2}} = 3s_1 - \br{1 - \sqrt{-5}}s_2 = 0. $$
Claim that the two relations $ \br{1 + \sqrt{-5}}e_{s_1} - 2e_{s_2} $ and $ 3e_{s_1} - \br{1 - \sqrt{-5}}e_{s_2} $ generate $ K $. Let $ ae_{s_1} + be_{s_2} $ be a relation, so $ a, b \in R $ and $ as_1 + bs_2 = 0 $, that is $ a = -\tfrac{1 + \sqrt{-5}}{2}b $ for $ a, b \in R $. A question is for which $ b $ does $ a $ lie in $ R $? Claim that the set of such $ b $ is an ideal $ J $ of $ R $. $ 2 \in J $ and $ 1 - \sqrt{-5} \in J $ so $ J $ contains $ \abr{2, 1 - \sqrt{-5}} $, and $ 1 \notin J $, since $ \abr{2, 1 - \sqrt{-5}} $ is maximal, so $ J = \abr{2, 1 - \sqrt{-5}} $. Similarly, the set of $ a $ is an ideal $ \abr{1 + \sqrt{-5}, 3} $ of $ R $. Thus let $ t_1 = \br{1 + \sqrt{-5}}e_{s_1} - 2e_{s_2} $ and $ t_2 = 3e_{s_1} - \br{1 - \sqrt{-5}}e_{s_2} $, so we have a map $ A : R^2 \to R^2 $ with presentation matrix
$$ \twobytwo{1 + \sqrt{-5}}{3}{-2}{-1 + \sqrt{-5}}. $$
\end{itemize}
\end{example*}

The general idea is if we have a presentation matrix $ A : R^m \to R^n $ for $ M $, with $ n $ rows and $ m $ columns, then $ BAC $ is also a presentation matrix for $ M $, where $ B $ is $ n \times n $ and $ C $ is $ m \times m $, and $ B $ and $ C $ are invertible matrices with inverse matrix entries in $ R $.

\pagebreak

\section{Noetherian rings and modules}

\subsection{Definitions and basic properties}

\begin{definition}
Let $ R $ be a ring and let $ M $ be an $ R $-module. We say $ M $ is \textbf{Noetherian} if every increasing infinite chain
$$ M_1 \subseteq M_2 \subseteq \dots $$
of $ R $-submodules $ M_i $ of $ M $ is \textbf{eventually constant}. That is, for any such chain, there exists $ N $ such that we have $ M_i = M_N $ for all $ i \ge N $. A ring $ R $ is Noetherian if $ R $ is Noetherian as an $ R $-module over itself. Since the $ R $-submodules of $ R $ are just the ideals of $ R $, a ring $ R $ is Noetherian if every increasing infinite chain
$$ I_1 \subseteq I_2 \subseteq \dots $$
of ideals $ I_j $ of $ R $ is eventually constant.
\end{definition}

The following result about Noetherian $ R $-modules is fundamental.

\begin{theorem}
An $ R $-module $ M $ is Noetherian if and only if every $ R $-submodule $ N $ of $ M $ is finitely generated.
\end{theorem}

\begin{proof}
Suppose first that $ M $ is Noetherian, and let $ N $ be an $ R $-submodule of $ M $. Choose an element $ n_0 $ of $ N $, and let $ N_0 $ be the $ R $-submodule of $ N $ generated by $ n_0 $. If $ N_0 $ is all of $ N $, then $ N $ is finitely generated. Otherwise, choose $ n_1 $ in $ N \setminus N_0 $, and let $ N_1 $ be the $ R $-submodule of $ N $ generated by $ n_0 $ and $ n_1 $. If $ N $ is not finitely generated, we may continue this process indefinitely, choosing for each $ i $ an $ n_i $ in $ N \setminus N_{i - 1} $, which is nonempty since $ N $ is not finitely generated, and letting $ N_i $ be generated by $ n_0, \dots, n_i $. In this way we obtain a strictly increasing infinite chain
$$ N_0 \subsetneq N_1 \subsetneq \dots $$
of $ R $-submodules of $ M $, contradicting the fact that $ M $ is Noetherian. Conversely, suppose that every $ R $-submodule of $ M $ is finitely generated, and let
$$ M_0 \subseteq M_1 \subseteq \dots $$
be an increasing chain. We must show that this chain is eventually constant. Let $ N $ be the union of the $ R $-submodules $ M_i $. Note that $ N $ is an $ R $-submodule of $ M $. Thus $ N $ is finitely generated, say by $ n_1, \dots, n_s $. If $ n_1, n_2 \in N $, then there exist $ i $ and $ j $ with $ n_1 \in M_i $ and $ n_2 \in M_j $. If $ d \ge i $ and $ d \ge j $, then $ n_1, n_2 \in M_d $, so $ n_1 + n_2 \in M_d $, so $ n_1 + n_2 \in N $. Since $ N $ is the union of the $ M_j $, there exist $ i_1, \dots, i_s $ such that $ n_j $ is in $ M_{i_j} $ for all $ j $. Let $ d $ be the largest of the $ i_j $. Then $ M_d $ contains $ n_1, \dots, n_s $ so it contains $ N $. In particular for any $ d' \ge d $ we have $ N \subseteq M_d \subseteq M_{d'} \subseteq N $, so $ N = M_d = M_{d'} $ for all such $ d' $ and the chain is constant after $ M_d $.
\end{proof}

\lecture{15}{Wednesday}{07/11/18}

\begin{corollary}
Let $ R $ be a PID. Then $ R $ is Noetherian.
\end{corollary}

\begin{proof}
Every ideal of $ R $ is principal, hence finitely generated.
\end{proof}

\begin{example*}
\hfill
\begin{itemize}
\item Any field is Noetherian.
\item The ring $ \CC\sbr{X^{\QQ_{\ge 0}}} $ is not Noetherian. The ideal consisting of all elements with no constant term is not finitely generated.
\end{itemize}
\end{example*}

\subsection{Finitely generated modules over Noetherian rings}

The plan is
\begin{itemize}
\item to show that Noetherianness has strong consequences, and
\item to use these properties to show $ R $ is Noetherian implies that $ R\sbr{X} $ is Noetherian and other consequences.
\end{itemize}
The goal of this section is to prove the following theorem.

\begin{theorem}
\label{thm:8.2.1}
Any finitely generated $ R $-module $ M $ over a Noetherian ring $ R $ is Noetherian.
\end{theorem}

\pagebreak

We proceed in several steps. First note the following.

\begin{proposition}
Let $ M $ be a Noetherian $ R $-module. Then for any $ R $-submodule $ N $ of $ M $,
\begin{enumerate}
\item $ N $ is Noetherian, and
\item $ M / N $ is Noetherian.
\end{enumerate}
\end{proposition}

\begin{proof}
\hfill
\begin{enumerate}
\item Since $ M $ is Noetherian, any $ R $-submodule of $ M $ is finitely generated, and thus any $ R $-submodule of $ N $ is finitely generated.
\item Given a $ R $-submodule $ N' $ of $ M / N $, let $ \widetilde{N'} $ be its preimage in $ N $ under the canonical quotient map $ f : M \to M / N $. We have a surjection from $ \widetilde{N'} $ to $ N' $ induced by $ f $. Then $ \widetilde{N'} \subseteq M $, so $ \widetilde{N'} $ is finitely generated, say by $ n_1, \dots, n_s $. Claim that $ f\br{n_1}, \dots, f\br{n_s} $ generate $ N' $. Given $ n \in N' $, there exists $ \widetilde{n} \in \widetilde{N'} $ such that $ f\br{\widetilde{n}} = n $. Write $ \widetilde{n} = r_1n_1 + \dots + r_sn_s $ for $ r_i \in R $. Then $ n = f\br{\widetilde{n}} = r_1f\br{n_1} + \dots + r_sf\br{n_s} $.
\end{enumerate}
\end{proof}

\begin{proposition}
Let $ M $ be an $ R $-module, let $ N $ be a Noetherian $ R $-submodule of $ M $, and suppose that $ M / N $ is Noetherian. Then $ M $ is Noetherian.
\end{proposition}

\begin{proof}
Let $ M' $ be a $ R $-submodule of $ M $. Then $ M' \cap N $ is a $ R $-submodule of $ M $, hence finitely generated. Let $ a_1, \dots, a_s \in M' \cap N $ generate $ M' \cap N $. Let $ \overline{M'} $ denote the image of $ M' $ in $ M / N $. This is a $ R $-submodule of $ M / N $ and thus finitely generated. Let $ \overline{b_1}, \dots, \overline{b_t} \in \overline{M'} \subseteq M / N $ generate $ \overline{M'} $, and choose elements $ b_1, \dots, b_t $ of $ M' $ mapping to $ \overline{b_1}, \dots, \overline{b_t} $ in $ M / N $, respectively. We now show that
$$ a_1, \dots, a_s, b_1, \dots, b_t $$
is a generating set for $ M' $, proving the claim. Given any $ m \in M' $, let $ \overline{m} $ be its image in $ M / N $ under $ f : M' \to \overline{M'} $. Then we can write $ \overline{m} $ as a sum $ r_1\overline{b_1} + \dots + r_t\overline{b_t} $ for $ r_1, \dots, r_t \in R $. Let $ m' = m - r_1b_1 - \dots - r_tb_t $. Then the image of $ m' $ in $ M / N $ is $ f\br{m'} = \overline{m} - r_1\overline{b_1} - \dots - r_t\overline{b_t} = 0 $. So $ m' $ lies in $ N $, and $ m, r_1b_1, \dots, r_tb_t \in M' $, so $ m' $ also lies in $ M' $. So it lies in $ M' \cap N $. We can thus write $ m' $ as $ q_1a_1 + \dots + q_sa_s $ for $ q_1, \dots, q_s \in R $. We then have
$$ m = q_1a_1 + \dots + q_sa_s + r_1b_1 + \dots + r_tb_t, $$
proving the claim.
\end{proof}

\begin{corollary}
Let $ M $ and $ N $ are Noetherian $ R $-modules, then so is $ M \oplus N $.
\end{corollary}

\begin{proof}
We have a surjection
$$ \function{M \oplus N}{M}{\br{m, n}}{m}. $$
Its kernel $ K $ is the set of pairs of $ M \oplus N $ of the form $ \br{0, n} $, which is isomorphic to $ N $ by the natural map $ n \mapsto \br{0, n} $, and hence Noetherian. The surjection $ M \oplus N \to M $ descends to an isomorphism $ \br{M \oplus N} / K \cong M $, so that $ \br{M \oplus N} / K $ is Noetherian. Thus $ M \oplus N $ is Noetherian.
\end{proof}

Now assume $ R $ is Noetherian. Then $ R, R \oplus R, \dots $ are all Noetherian $ R $-modules, that is the following.

\begin{corollary}
If $ R $ is Noetherian, then any free $ R $-module of finite rank is Noetherian.
\end{corollary}

\begin{proof}
A free $ R $-module of rank $ s $ is the direct sum of $ s $ copies of $ R $, each of which is Noetherian as an $ R $-module when $ R $ is Noetherian.
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:8.2.1}]
Let $ M $ be a finitely generated $ R $-module, and let $ m_1, \dots, m_s $ be a set of generators for $ M $. Then if $ R^s $ is a free $ R $-module of rank $ s $, with generators $ e_1, \dots, e_s $, we have a surjection
$$ \function{R^s}{M}{e_i}{m_i}. $$
Let $ K $ be the kernel. Then $ M $ is isomorphic to $ R^s / K $, and $ R^s $ is a Noetherian $ R $-module, so $ M $ is Noetherian as well.
\end{proof}

\pagebreak

\section{Polynomial rings in several variables}

\subsection{The Hilbert basis theorem}

In this section, we will use the ideas of the previous section to establish the following key result about polynomial rings, known as the Hilbert basis theorem.

\begin{theorem}[Hilbert basis theorem]
\label{thm:9.1.1}
Let $ R $ be a Noetherian ring. Then $ R\sbr{X} $ is Noetherian.
\end{theorem}

\lecture{16}{Friday}{09/11/18}

Let $ P\br{X} = b_0 + \dots + b_nX^n $ for $ b_n \in R^* $. We say that $ b_n $ is the \textbf{leading coefficient} of $ P\br{X} $. In general, if I have $ Q_1\br{X}, \dots, Q_r\br{X} $ with degrees $ d_1, \dots, d_r $ and leading coefficients $ a_1, \dots, a_r $ and $ P\br{X} $ of degree $ d \ge d_1, \dots, d_r $ then there exist $ n_1, \dots, n_r \in R $ such that
$$ \deg \br{P\br{X} - n_1X^{d - d_1}Q_1\br{X} - \dots - n_rX^{d - d_r}Q_r\br{X}} < d, $$
if and only if the leading coefficient of $ P\br{X} $ is in the ideal generated by $ a_1, \dots, a_r $. The following proof is due to Emmy Noether, and is a vast simplification of Hilbert's original proof.

\begin{lemma}
Let $ R $ be Noetherian and $ I \subseteq R\sbr{X} $ be an ideal. Let $ J \subseteq R $ be the set of leading coefficients of polynomials in $ I $. That is, the set of $ a \in R $ such that there exists a polynomial $ P\br{X} $ in $ I $ with leading coefficient $ a $. Then $ J $ is an ideal of $ R $.
\end{lemma}

\begin{proof}
Certainly if $ a \in J $ is the leading coefficient of $ P\br{X} \in I $ such that $ P\br{X} = aX^n + \dots $, then for any $ r \in R $, $ ra $ is the leading coefficient of $ rP\br{X} = raX^n + \dots $, so $ ra \in J $, so $ J $ is closed under multiplication. On the other hand, if $ a, b \in J $ are the leading coefficients of $ P\br{X} $ and $ Q\br{X} $ in $ I $, then let $ n $ and $ m $ be the degrees of $ P\br{X} = aX^n + \dots $ and $ Q\br{X} = bX^m + \dots $ respectively. Without loss of generality we may assume $ n \ge m $. Then $ a + b $ is the leading coefficient of $ P\br{X} + X^{n - m}Q\br{X} = \br{a + b}X^{n + m} + \dots $, and the latter polynomial is in $ I $ so $ a + b \in J $. Thus $ J $ is closed under addition, and is therefore an ideal.
\end{proof}

Now since $ R $ is Noetherian, $ J $ is finitely generated, say by $ a_1, \dots, a_s \in R $. By definition of $ J $, there are thus polynomials $ P_1, \dots, P_s $ in $ I $, of degrees $ d_1, \dots, d_n $, such that $ P_i = a_iX^{d_i} + \dots $ has leading coefficient $ a_i $ for all $ i $. Let $ N $ be the largest of the $ d_i $.

\begin{lemma}
Given $ Q\br{X} \in I $ of degree $ d \ge N $, then there exist $ R_1\br{X}, \dots, R_s\br{X} \in R\sbr{X} $ such that $ Q\br{X} - R_1\br{X}P_1\br{X} - \dots - R_s\br{X}P_s\br{X} $ has degree less than $ N $.
\end{lemma}

\begin{proof}
The proof is by induction on $ d $ and the base case $ d < N $ is clear by setting $ R_i = 0 $ for all $ i $. Suppose the claim is true for polynomials of degree less than or equal to $ d - 1 $, with $ d \ge N $. Let $ a \in J $ be the leading coefficient of $ Q\br{X} = aX^d + \dots $, so that $ Q\br{X} - aX^d $ has degree at most $ d - 1 $. Since $ a $ lies in $ J $ we can write $ a = r_1a_1 + \dots + r_sa_s $. Then the leading term of the polynomial $ r_1X^{d - d_1}P_1\br{X} + \dots + r_sX^{d - d_s}P_s\br{X} $ is $ aX^d $, so the difference $ Q\br{X} - r_1X^{d - d_1}P_1\br{X} - \dots - r_sX^{d - d_s}P_s\br{X} $ has degree at most $ d - 1 $ and lies in $ I $. By the inductive hypothesis this difference is an $ R\sbr{X} $-linear combination of the $ P_i\br{X} $. So $ Q\br{X} $ is as well.
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:9.1.1}]
Let $ I $ be an ideal of $ R\sbr{X} $. We want to show that $ I $ is finitely generated. Let $ I_{\le N} = I \cap R\sbr{X}_{\le N} $ be the subset of $ I $ consisting of all polynomials of degree at most $ N $. Then $ I_{\le N} $ is an $ R $-submodule of the $ R $-module $ R\sbr{X}_{\le N} $ of all polynomials of degree at most $ N $. The latter is free of rank $ N + 1 $ and generated by $ 1, \dots, X^N $ as an $ R $-module, so it is finitely generated, hence Noetherian. In particular since $ R $ is Noetherian $ I_{\le N} $ is also a finitely generated $ R $-module. Let $ T_1\br{X}, \dots, T_k\br{X} $ generate $ I_{\le N} $ as an $ R $-module. We will show that
$$ P_1\br{X}, \dots, P_s\br{X}, T_1\br{X}, \dots, T_k\br{X} $$
generate $ I $ as an $ R\sbr{X} $-module. More precisely, we will show that $ Q\br{X} $ is an $ R\sbr{X} $-linear combination of the $ P_i\br{X} $ and $ T_j\br{X} $. Given $ Q\br{X} \in I $, there exist $ R_1\br{X}, \dots, R_s\br{X} \in R\sbr{X} $ such that
$$ Q\br{X} = R_1\br{X}P_1\br{X} + \dots + R_s\br{X}P_s\br{X} + T\br{X}, $$
with $ T\br{X} \in I_{\le N} $. There exist $ r_1, \dots, r_k \in R $ such that $ T\br{X} = r_1T_1\br{X} + \dots + r_kT_k\br{X} $, so
$$ Q\br{X} = R_1\br{X}P_1\br{X} + \dots + R_s\br{X}P_s\br{X} + r_1T_1\br{X} + \dots + r_kT_k\br{X}. $$
\end{proof}

\pagebreak

As a corollary, we deduce the following.

\begin{corollary}
Let $ R $ be any field or PID, or indeed any Noetherian ring. Then for any $ n $, the ring $ R\sbr{X_1, \dots, X_n} $ is Noetherian.
\end{corollary}

An observation is that if $ R $ is Noetherian and $ I \subseteq R $ is an ideal, then $ R / I $ is Noetherian. Let $ J $ be an ideal of $ R / I $ and $ \widetilde{J} $ be preimage of $ J $ in $ R $. There exist $ \widetilde{j_1}, \dots, \widetilde{j_n} $ generating $ \widetilde{J} $ over $ R $. Let $ j_i = \widetilde{j_i} + I \in R / I $. These lie in $ J $ and generate $ J $ over $ R / I $. In particular, any quotient of polynomial ring over a field or PID is Noetherian. Indeed, since any quotient of a Noetherian ring is Noetherian, we can say more.

\begin{definition}
Let $ R $ be a ring. An \textbf{$ R $-algebra} is a ring $ S $ together with a homomorphism $ f : R \to S $. If $ S $ is an $ R $-algebra, we say that $ S $ is \textbf{finitely generated} as an $ R $-algebra over $ R $ if there exists a finite set of elements $ s_1, \dots, s_n \in S $ such that every element of $ S $ can be expressed as a polynomial in the $ s_i $ with coefficients in $ R $. Equivalently, $ S $ is generated over $ R $ by $ s_1, \dots, s_n $ if the homomorphism
$$ \function{R\sbr{X_1, \dots, X_n}}{S}{X_i}{s_i}, $$
induced by $ f : R \to S $, is surjective.
\end{definition}

\begin{note*}
Any finitely generated $ R $-algebra $ S $ is isomorphic to a quotient $ R\sbr{X_1, \dots, X_n} / I $ for some $ n $ and some ideal $ I $. Thus we can rephrase the Hilbert basis theorem as saying that if $ R $ is Noetherian, then any finitely generated $ R $-algebra is Noetherian.
\end{note*}

\lecture{17}{Monday}{12/11/18}

Lecture 17 is a problems class.

\subsection{Polynomial rings over UFDs are UFDs}

\lecture{18}{Wednesday}{14/11/18}

Our next goal is to study factorisation in polynomial rings of the form $ R\sbr{X} $, since $ \ZZ\sbr{X} $ is not a PID nor a UFD. The idea is to relate factorisations in $ \ZZ\sbr{X} $ to factorisations in $ \QQ\sbr{X} $. A warning is that irreducibility in $ \QQ\sbr{X} $ does not imply irreducibility in $ \ZZ\sbr{X} $.

\begin{example*}
$ 3x + 15 $ is irreducible in $ \QQ\sbr{X} $, and $ 3x + 15 = 3\br{x + 15} $ in $ \ZZ\sbr{X} $.
\end{example*}

Certainly if $ R $ is not a UFD then we cannot expect to have unique factorisation in $ R\sbr{X} $, since we do not even have it in $ R $. Assume $ R $ is a UFD. Then the ring $ R\sbr{X} $ might be quite complicated, but $ R\sbr{X} $ is contained in a much simpler ring where we do understand factorisation, the ring $ K\sbr{X} $, where $ K $ is the field of fractions of $ R $. Our goal will thus be to compare factorisations in $ K\sbr{X} $ with factorisations in $ R\sbr{X} $. Fundamental question is can we turn factorisations in $ K\sbr{X} $ of $ P\br{X} \in R\sbr{X} $ into factorisations in $ R\sbr{X} $? The key to doing this is the following result, often called Gauss' lemma.

\begin{theorem}[Gauss' lemma]
\label{thm:9.2.1}
Let $ R $ be a UFD and let $ K $ be its field of fractions. Let $ P\br{X} \in R\sbr{X} $, and let $ Q\br{X} $ be a polynomial in $ K\sbr{X} $ that divides $ P\br{X} $ in $ K\sbr{X} $. Then there is an element $ \alpha \in K^* $ such that $ \alpha Q\sbr{X} $ lies in $ R\sbr{X} $, and divides $ P\br{X} $ in $ R\sbr{X} $. In particular, if $ P\br{X} $ is reducible in $ K\sbr{X} $, then $ P\br{X} $ is also reducible in $ R\sbr{X} $.
\end{theorem}

\begin{proof}
Write $ P\br{X} = Q\br{X}T\br{X} \in K\sbr{X} $, and choose nonzero elements $ e_1, e_2 \in R $ such that $ e_1Q\br{X} $ and $ e_2T\br{X} $ have coefficients in $ R $, and so that the greatest common divisor of the coefficients of $ e_1Q\br{X} $ is one, as is the greatest common divisor of the coefficients of $ e_2T\br{X} $. Letting $ d = e_1e_2 $, we have
$$ dP\br{X} = Q'\br{X}T'\br{X}, \qquad Q'\br{X} = e_1Q\br{X}, \qquad T'\br{X} = e_2T\br{X}. $$
Suppose $ d $ is not a unit in $ R $. Then $ d $ is divisible by an irreducible element $ q $ of $ R $. Since $ R $ is a UFD, irreducibles are prime, so the ideal of $ R $ generated by $ q $ is a prime ideal. Thus $ R / \abr{q} $ is an integral domain, so $ R / \abr{q}\sbr{X} $ is as well. Moreover, if $ \overline{Q'}\br{X} $ and $ \overline{T'}\br{X} $ are the images of $ Q'\br{X} $ and $ T'\br{X} $ modulo $ \abr{q} $ in $ R / \abr{q}\sbr{X} $, then we have $ dP\br{X} = Q'\br{X}T'\br{X} $, so $ 0 = \overline{Q'}\br{X}\overline{T'}\br{X} $ in $ R / \abr{q}\sbr{X} $. Since $ R / \abr{q}\sbr{X} $ is an integral domain we must have either $ \overline{Q'}\br{X} = 0 $ or $ \overline{T'}\br{X} = 0 $ in $ R / \abr{q}\sbr{X} $. Without loss of generality assume $ \overline{Q'}\br{X} = 0 $. Then all the coefficients of $ Q'\br{X} $ are divisible by $ q $, contradicting our construction of $ Q'\br{X} $. Thus $ \alpha = d $ is a unit in $ K\sbr{X} $, and we have $ P\br{X} = e_1Q\br{X}\br{e_2 / d}T\br{X} $ for $ e_1Q\br{X}, \br{e_2 / d}T\br{X} \in R\sbr{X} $.
\end{proof}

\pagebreak

\begin{note*}
The converse to the last claim of Theorem \ref{thm:9.2.1} is not true. If $ P\br{X} $ is reducible in $ R\sbr{X} $, it might be irreducible in $ K\sbr{X} $.
\end{note*}

\begin{example*}
The polynomial $ 7x $ factors into irreducibles as $ 7 \cdot x $ in $ \ZZ\sbr{X} $, but since $ 7 $ is a unit in $ \QQ\sbr{X} $, $ 7x $ is irreducible in $ \QQ\sbr{X} $.
\end{example*}

The following lemma shows that this kind of thing is all that can happen, however.

\begin{proposition}
Let $ P\br{X} $ in $ R\sbr{X} $ be a polynomial and suppose that the greatest common divisor of all of its coefficients is one. Then $ P\br{X} $ is irreducible in $ K\sbr{X} $ if and only if it is also irreducible in $ R\sbr{X} $.
\end{proposition}

\begin{proof}
Suppose $ P\br{X} $ is reducible in $ R\sbr{X} $, and write $ P\br{X} = Q\br{X}T\br{X} $ for $ Q\br{X}, T\br{X} \in R\sbr{X} $, where $ Q\br{X} $ and $ T\br{X} $ are nonunits. If $ Q\br{X} $ or $ T\br{X} $ were constant with degree zero then it would divide every coefficient of $ P\br{X} $ and thus divide the GCD of those coefficients, making it a unit. Thus $ Q\br{X} $ and $ T\br{X} $ are nonconstant with positive degree and the factorisation $ P\br{X} = Q\br{X}T\br{X} $ is also a nontrivial factorisation in $ K\sbr{X} $, so $ P\br{X} $ is reducible in $ K\sbr{X} $. Conversely suppose $ P $ is reducible in $ K\sbr{X} $. Then there exist $ Q\br{X} \in K\sbr{X} $ with $ 0 < \deg Q < \deg P $ and $ Q\br{X} \mid P\br{X} $ in $ K\sbr{X} $. Gauss' lemma shows that there exist $ \alpha \in K^* $ such that $ \alpha Q\br{X} \in R\sbr{X} $ and $ \alpha Q\br{X} \mid P\br{X} $ in $ R\sbr{X} $.
\end{proof}

We are now in a position to prove the following.

\begin{theorem}
If $ R $ is a UFD, then $ R\sbr{X} $ is a UFD.
\end{theorem}

\begin{proof}
For existence of factorisations, let $ P\br{X} $ be an element of $ R\sbr{X} $. We must show that $ P\br{X} $ factors into irreducibles. Let $ d $ be the greatest common divisor of the coefficients of $ P\br{X} $, and write $ P\br{X} = dQ\br{X} $, where the greatest common divisor of the coefficients of $ Q\br{X} $ is one. Since $ R $ is a UFD, $ d $ factors into irreducibles $ q_1, \dots, q_s $ in $ R $, and these remain irreducible in $ R\sbr{X} $, so it suffices to show that $ Q\br{X} $ factors into irreducibles. Factoring $ Q\br{X} $ into irreducibles in $ K\sbr{X} $, $ Q\br{X} = Q_1\br{X} \dots Q_r\br{X} $. By Gauss' lemma, there exist scalars $ \alpha_1, \dots, \alpha_r \in K^* $ such that $ \alpha_1 \dots \alpha_r = 1 $ and $ \alpha_iQ_i\br{X} \in R\sbr{X} $. Let $ Q'_i \br{X} = \alpha_iQ_i\br{X} $. GCD of coefficients of $ Q'_1\br{X}, \dots, Q'_r\br{X} $ is one, so $ Q'_1\br{X}, \dots, Q'_r\br{X} $ are irreducible in $ R\sbr{X} $ since they are irreducible in $ K\sbr{X} $. For uniqueness of factorisations, it remains to show that if $ P\br{X} \in R\sbr{X} $ is irreducible in $ R\sbr{X} $ and divides $ A\br{X}B\br{X} $ in $ R\sbr{X} $ for $ A\br{X}, B\br{X} \in R\sbr{X} $, then $ P\br{X} $ divides either $ A\br{X} $ or $ B\br{X} $ in $ R\sbr{X} $.
\begin{itemize}
\item If $ P\br{X} $ is constant, then $ P\br{X} = c $ is irreducible in $ R $. In $ R / \abr{c}\sbr{X} $ a domain, $ 0 = \overline{A}\br{X}\overline{B}\br{X} $, so $ \overline{A}\br{X} = 0 $ or $ \overline{B}\br{X} = 0 $, so $ c \mid A\br{X} $ or $ c \mid B\br{X} $.
\item If $ P\br{X} $ is nonconstant, since $ P\br{X} $ is irreducible in $ R\sbr{X} $ it is irreducible in $ K\sbr{X} $ by Gauss' lemma, and hence divides either $ A\br{X} $ or $ B\br{X} $ in $ K\sbr{X} $. Suppose $ P\br{X} $ divides $ A\br{X} $ in $ K\sbr{X} $. Then $ A\br{X} = P\br{X}Q\br{X} $ in $ K\sbr{X} $. Then there is an element $ \alpha = r / s \in K^* $ for $ r, s \in R $ and $ r \ne 0 $ such that $ \alpha P\br{X} \in R\sbr{X} $, $ \alpha P\br{X} \mid A\br{X} $, and $ A\br{X} = \alpha P\br{X}\alpha^{-1} Q\br{X} \in R\sbr{X} $, by Gauss' lemma. On the other hand, since $ P\br{X} $ is irreducible in $ R\sbr{X} $ the GCD of its coefficients is one, so the only way $ \alpha P\br{X} $ lies in $ R\sbr{X} $ is if $ s $ is a unit and $ \alpha $ lies in $ R $. Thus $ \alpha^{-1}Q\br{X} \in R\sbr{X} $, $ \alpha \in R $, and $ P\br{X} \in R\sbr{X} $, so $ P\br{X} $ also divides $ A\br{X} $.
\end{itemize}
\end{proof}

\begin{corollary}
If $ K $ is a UFD, a field, or a PID, then $ K\sbr{X_1, \dots, X_n} $ is a UFD for any $ n $.
\end{corollary}

A warning is that quotients of UFDs are only rarely UFDs themselves.

\begin{example*}
$ \ZZ\sbr{X} $ is a UFD, but $ \ZZ\sbr{X} / \abr{X^2 + 5} = \ZZ\sbr{\sqrt{-5}} $ is not a UFD.
\end{example*}

\subsection{Irreducible polynomials}

\lecture{19}{Friday}{16/11/18}

A question is how can we test if $ P\br{X} \in K\sbr{X} $ is irreducible? We will now use the results of the previous section to obtain criteria for proving polynomials are irreducible. We begin with some trivial observations.

\begin{lemma}
Let $ K $ be any field, and $ P\br{X} \in K\sbr{X} $ of degree two or three. Then $ P\br{X} $ is irreducible if and only if $ P\br{X} $ has no root in $ K $.
\end{lemma}

\begin{proof}
Any nontrivial factor of $ P\br{X} $ would have to have degree one or two. Either way, if $ P\br{X} $ is reducible it must have a linear factor.
\end{proof}

\pagebreak

Slightly less trivially, if $ K $ is finite there is a necessary and sufficient criterion for irreducibility. Let $ K = \FF_q $ be a finite field with $ q = p^s $ elements.

\begin{lemma}
$ X^{q^r} - X $ is the product of $ P\br{X} \in \FF_q\sbr{X} $ irreducible, monic of degree dividing $ r $.
\end{lemma}

\begin{proof}
Let $ P\br{X} $ be irreducible monic of degree $ d \mid r $. Consider $ K\br{\alpha} $, where $ \alpha $ is a root of $ P\br{X} $. Thus $ K\br{\alpha} $ has order $ q^d $. So $ \alpha^{q^d} = \alpha $. Since $ d \mid r $, $ \alpha^{q^r} = \alpha $. So $ \alpha $ is a root of $ X^{q^r} - X $. But $ P\br{X} $ is the minimal polynomial of $ \alpha $, so $ P\br{X} \mid X^{q^r} - X $. Suppose $ P\br{X}^2 \mid X^{q^r} - X $. Write $ X^{q^r} - X = P\br{X}^2Q\br{X} $. Taking derivatives, $ -1 = 2P\br{X}P'\br{X}Q\br{X} + P\br{X}^2Q'\br{X} $. Since $ P\br{X} \nmid -1 $, this is impossible. Finally, let $ P\br{X} \in K\sbr{X} $ irreducible be a divisor of $ X^{q^r} - X $. Let $ K' = \FF_{q^r} $ contain $ K $. Then $ X^{q^r} - X $ factors into linear factors over $ K' $. So there exists $ \alpha \in K' $ such that $ P\br{\alpha} = 0 $. Then $ P\br{X} $ is the minimal polynomial of $ \alpha $ over $ K $, so have an injection
$$ \function{K\sbr{X} / \abr{P\br{X}}}{K'}{X}{\alpha}. $$
Order of $ K\sbr{X} / \abr{P\br{X}} $ is $ q^{\deg P} $ and order of $ K' $ is $ q^r $, so $ q^r = \br{q^{\deg P}}^n $, so $ \deg P \mid r $.
\end{proof}

\begin{corollary}
Let $ P\br{X} $ in $ \FF_q\sbr{X} $ have degree $ d $. Then $ P\br{X} $ is irreducible if and only if the greatest common divisor of $ P\br{X} $ and $ X^{q^r} - X $ is one for all $ 1 \le r < d $.
\end{corollary}

\begin{proof}
If the polynomial $ P\br{X} $ is irreducible, it does not divide $ X^{q^r} - X $ for $ r < d $. Conversely, if $ P\br{X} $ is reducible, there exists an irreducible polynomial $ Q\br{X} $ of degree $ 0 < r < d $ such that $ Q\br{X} \mid P\br{X} $, and then $ Q\br{X} \mid X^{q^r} - X $ in $ \FF_q\sbr{X} $.
\end{proof}

Having obtained a satisfactory criterion for finite fields, the next simplest case to look at this that of $ \QQ\sbr{X} $. This is already much more complicated. We will take advantage of the fact that $ \ZZ\sbr{X} $ lives inside $ \QQ\sbr{X} $. In fact, all of our tricks will work in the following more general situation. Let $ R $ be a UFD with field of fractions $ K $, and we consider polynomials over $ K\sbr{X} $. As we have seen, irreducibility over $ K $ is closely related to irreducibility in $ R\sbr{X} $. Let $ P\br{X} $ be a polynomial in $ K\sbr{X} $ and $ d = \deg P $. We can multiply $ P\br{X} $ by scalars without substantially changing its factorisation, so we can assume that $ P\br{X} $ is monic. In general there might be denominators in the coefficients of $ P\br{X} $, but note that for any $ r \in R $, if
$$ P\br{X} = c_0 + \dots + c_{d - 1}X^{d - 1} + X^d, $$
then define a polynomial $ Q_r\br{X} $ by
$$ Q_r\br{X} = r^dP\br{\dfrac{X}{r}} = c_0r^d + \dots + c_{d - 1}rX^{d - 1} + X^d. $$
It is easy to see that $ Q_r\br{X} $ is irreducible in $ K\sbr{X} $ if and only if $ P\br{X} $ is. Moreover, we can choose $ r $ so that $ Q_r\br{X} $ has coefficients in $ R $. We are thus reduced to the problem of deciding whether a monic polynomial with coefficients in $ R $ is irreducible in $ K\sbr{X} $. Moreover, we have shown that such a polynomial $ Q_r\br{X} $ is irreducible in $ K\sbr{X} $ if and only if it is irreducible in $ R\sbr{X} $. Therefore a question is given $ Q\br{X} $ monic in $ R\sbr{X} $, how can we prove or test irreducibility? We therefore get the following nice criterion for irreducibility.

\begin{proposition}
Let $ Q\br{X} $ be a monic polynomial in $ R\sbr{X} $, and let $ \ppp $ be a prime ideal of $ R $. Suppose that the modulo $ \ppp $ reduction $ \overline{Q}\br{X} $ is irreducible in $ R / \ppp\sbr{X} $. Then $ Q\br{X} $ is irreducible in $ R\sbr{X} $.
\end{proposition}

\begin{proof}
Suppose $ Q\br{X} $ were reducible in $ R\sbr{X} $. Since $ Q\br{X} $ is monic, $ Q\br{X} $ must factor as $ A\br{X}B\br{X} $, where both $ A\br{X} $ and $ B\br{X} $ are not units. Can assume $ A\br{X} $ and $ B\br{X} $ are monic of degree $ \deg A > 0 $ and $ \deg B > 0 $, since leading coefficients of $ A $ and $ B $ multiply to one. Then $ \overline{Q}\br{X} $ factors in $ R / \ppp\sbr{X} $ as $ \overline{A}\br{X}\overline{B}\br{X} $, where both are monic of positive degree between one and $ \deg \overline{Q}\br{X} - 1 $, so $ \overline{Q}\br{X} $ is also reducible.
\end{proof}

This means, for instance, that we can show that a monic polynomial in $ \ZZ\sbr{X} $ is irreducible if we can find even one prime $ p $ for which it is irreducible modulo $ p $.

\begin{example*}
$ X^2 + aX + b \in \ZZ\sbr{X} $ with $ a $ and $ b $ odd is irreducible in $ \QQ\sbr{X} $, since its reduction modulo two is $ X^2 + X + 1 $, which is irreducible in $ \FF_2\sbr{X} $.
\end{example*}

\pagebreak

Unfortunately, even when the polynomial is irreducible we will not always be able to do this.

\begin{example*}
The polynomial $ X^4 + 1 $ is irreducible in $ \ZZ\sbr{X} $ and $ \QQ\sbr{X} $, but reducible modulo $ p $ for every $ p $. You can prove this with some elementary number theory. Since $ X^4 + 1 = \br{X + 1}^4 $ in $ \FF_2\sbr{X} $, if $ p $ is odd, then $ X^4 + 1 $ has a common factor, and in fact divides $ X^{p^2} - X $. In fact $ X^4 + 1 \mid X^{p^2 - 1} - 1 $. If $ p = 2k + 1 $, then $ p^2 = 4k^2 + 4k + 1 = 4\br{k^2 + k} + 1 = 8m + 1 $, since $ k^2 + k $ is even, so
$$ X^{p^2 - 1} - 1 = X^{8m} - 1 = \br{X^4 + 1}\br{X^{8m - 4} - \dots - 1}. $$
\end{example*}

There is another sufficient criterion for irreducibility by reducing modulo $ \ppp $, known as Eisenstein's criterion.

\begin{proposition}[Eisenstein's criterion]
Let $ Q\br{X} = a_0 + \dots + a_{n - 1}X^{n - 1} + X^n $ be a monic polynomial in $ R\sbr{X} $, and let $ \ppp $ be a prime ideal of $ R $. Suppose that for $ 0 \le i \le n - 1 $, $ a_i \in \ppp $, and $ a_0 \notin \ppp^2 $. Then $ Q\br{X} $ is irreducible in $ R\sbr{X} $.
\end{proposition}

\begin{proof}
Suppose $ Q\br{X} $ is reducible. Then we can write $ Q\br{X} = A\br{X}B\br{X} \in R\sbr{X} $, with $ A\br{X} $ and $ B\br{X} $ monic of positive degree less than $ \deg Q\br{X} $. Reducing modulo $ \ppp $ we find that $ \overline{Q}\br{X} = X^n = \overline{A}\br{X}\overline{B}\br{X} \in R / \ppp\sbr{X} $. In particular, since $ R / \ppp $ is an integral domain, one of $ \overline{A}\br{0} $ or $ \overline{B}\br{0} $ is zero, say $ \overline{A}\br{0} = 0 $. Write $ \overline{A}\br{X} = X^d\overline{S}\br{X} $ for $ \overline{S}\br{0} \ne 0 $. Degree $ d $ term of $ \overline{A}\br{X}\overline{B}\br{X} $ is $ \overline{S}\br{0}\overline{B}\br{0} $. Then $ d < n $, so $ \overline{S}\br{0}\overline{B}\br{0} = 0 $. So $ \overline{B}\br{0} = 0 $, so both $ \overline{A}\br{0} = \overline{B}\br{0} = 0 $. But then the constant terms $ A\br{0} $ and $ B\br{0} $ of $ A\br{X} $ and $ B\br{X} $ both lie in $ \ppp $, so the constant term $ a_0 = Q\br{0} = A\br{0}B\br{0} $ of $ Q\br{X} = A\br{X}B\br{X} $ must lie in $ \ppp^2 $, contradicting our assumptions.
\end{proof}

\begin{corollary}
$ X^4 + 1 $ is irreducible.
\end{corollary}

\begin{proof}
$ X^4 + 1 $ is irreducible if and only if $ \br{X + 1}^4 + 1 $ is irreducible, and
$$ \br{X + 1}^4 + 1 = X^4 + 4X^3 + 6X^4 + 4X^2 + 2 $$
satisfies Eisenstein's criterion modulo $ 2 $.
\end{proof}

\lecture{20}{Monday}{19/11/18}

\begin{example*}
Let $ F\sbr{X, Y, Z} $ for $ F $ a field be a polynomial ring, such as $ \ZZ\sbr{X, Y, Z} $. Can write
$$ F\sbr{X, Y, Z} = F\sbr{X, Y}\sbr{Z}, \qquad R = F\sbr{X, Y}, $$
or
$$ F\sbr{X, Y, Z} = F\sbr{X, Z}\sbr{Y} = F\sbr{Y, Z}\sbr{X}. $$
Can also think of
$$ F\br{X, Y, Z} \subseteq F\br{X}\sbr{Y, Z} = F\br{X}\sbr{Y}\sbr{Z}, \qquad R = F\br{X}\sbr{Y}. $$
\begin{itemize}
\item Let
$$ P\br{X, Y} = X^4 + X^2Y^2 + Y^2 + XY \in \CC\sbr{X, Y}. $$
Take $ R = \CC\sbr{X} $ and $ K = \CC\br{X} $. Then
$$ P\br{X, Y} = \br{X^2 + 1}Y^2 + X \cdot Y + X^4 $$
is quadratic in $ Y $ with coefficients in $ R $. The GCD of the coefficients is one, so it is irreducible if and only if it is irreducible in $ K\sbr{Y} $, if and only if it has no root in $ K $, if and only if its discriminant is not a square in $ K $. The discriminant is
$$ X^2 - 4X^4\br{X^2 + 1} = X^2 - 4X^6 - 4X^4 = X^2\br{1 - 4X^4 - 4X^2}, $$
which is not a square, so $ P\br{X, Y} $ is irreducible.
\item Let
$$ P\br{X, Y, Z} = Z^5 + X^3Y^4Z + 2X^2YZ^3 - XYZ + Y^3 \in \CC\sbr{X, Y}\sbr{Z}. $$
It is irreducible if it is irreducible modulo $ X $. Then
$$ \overline{P}\br{Y, Z} = Z^5 + Y^3 \in \CC\sbr{Z}\sbr{Y} $$
is irreducible if and only if it is irreducible in $ \CC\br{Z}\sbr{Y} $, if and only if it has no root, if and only if $ -Z^5 $ is not a cube in $ \CC\br{Z} $, if and only if $ -Z^5 $ is not a cube in $ \CC\sbr{Z} $, which is clear from unique factorisation.
\end{itemize}
\end{example*}

\pagebreak

\section{Integral extensions and algebraic integers}

\subsection{Integral extensions}

\begin{definition}
$ \alpha \in \CC $ is an \textbf{algebraic integer} if there exists a monic polynomial $ P\br{X} \in \ZZ\sbr{X} $ such that $ P\br{\alpha} = 0 $.
\end{definition}

\begin{note*}
If $ Q\br{X} $ is the minimal polynomial of $ \alpha $ over $ \QQ $, monic, then $ Q\br{X} \mid P\br{X} $. By Gauss' lemma, there exists $ \alpha \in \QQ^* $ such that $ \alpha Q\br{X} \in \ZZ\sbr{X} $ and $ \alpha Q\br{X} \mid P\br{X} $ in $ \ZZ\sbr{X} $. Since $ Q\br{X} $ is monic, $ \alpha \in \ZZ $. Since $ P\br{X} $ is monic, $ \alpha \mid 1 $. So $ \alpha = \pm 1 $ and $ Q\br{X} \in \ZZ\sbr{X} $.
\end{note*}

\begin{definition}
Let $ R $ be a subring of a ring $ S $, and $ \alpha $ an element of $ S $. We say $ \alpha $ is \textbf{integral} over $ R $ if there exists a monic polynomial $ P\br{X} \in R\sbr{X} $ with coefficients in $ R $ such that $ P\br{\alpha} = 0 $ in $ S $.
\end{definition}

We can characterise integral elements in the following way.

\begin{proposition}
An element $ \alpha \in S $ is integral over $ R $ if and only if the subring $ R\sbr{\alpha} $ of $ S $ is a finitely generated $ R $-module.
\end{proposition}

\begin{proof}
Suppose $ \alpha $ is integral over $ R $, so that there exists a monic polynomial $ P\br{X} $ in $ R\sbr{X} $ with $ P\br{\alpha} = 0 $. Then $ R\sbr{\alpha} $ is a quotient of $ R\sbr{X} / \abr{P\br{X}} $ so $ 1, \dots, \alpha^{d - 1} $, where $ d $ is the degree of $ P\br{X} $, span $ R\sbr{\alpha} $ over $ R $. Given $ x \in R\sbr{\alpha} $, can write $ x = Q\br{\alpha} = r_{d - 1}\alpha^{d - 1} + \dots + r_0 $. Write $ Q\br{X} = P\br{X}T\br{X} + A\br{X} \in R\sbr{X} $ for $ \deg A\br{X} < d $, so $ Q\br{\alpha} = P\br{\alpha}T\br{\alpha} + A\br{\alpha} $. Let $ A\br{X} = a_0 + \dots + a_{d - 1}X^{d - 1} $ for $ a_i \in R $, so $ x = Q\br{\alpha} = A\br{\alpha} = a_0 + \dots + a_{d - 1}\alpha^{d - 1} $. Conversely, if $ R\sbr{\alpha} $ is finitely generated as an $ R $-module, say by $ x_1, \dots, x_r \in R\sbr{\alpha} $, we can write $ x_i = Q_i\br{\alpha} $ for $ Q_i\br{X} \in R\sbr{X} $. Let $ n $ be larger than the degree $ d_i $ of all the $ Q_i\br{X} $. We can write $ \alpha^n \in R\sbr{\alpha} $ as $ \sum_{i = 1}^r s_ix_i = \sum_{i = 1}^r s_iQ_i\br{\alpha} $ for $ s_i \in R $. So let $ P\br{X} = X^n - \sum_{i = 1}^r s_iQ_i\br{X} \in R\sbr{X} $. Then $ P\br{X} $ is a monic polynomial with coefficients in $ R $ such that $ P\br{\alpha} = 0 $.
\end{proof}

\begin{definition}
Let $ R $ be a subring of $ S $. We say that $ S $ is \textbf{integral} over $ R $ if every element of $ S $ is integral over $ R $.
\end{definition}

\begin{proposition}
Suppose $ R $ is a Noetherian ring, and $ S $ is a ring containing $ R $ that is finitely generated as an $ R $-module. Then $ S $ is a Noetherian ring and is integral over $ R $.
\end{proposition}

\begin{proof}
Let $ \alpha \in S $. The ring $ R\sbr{\alpha} $ is an $ R $-submodule of $ S $, so it is finitely generated as an $ R $-module, so $ \alpha $ is integral over $ R $. Every ideal of $ S $ is an $ R $-submodule of $ S $, thus finitely generated as an $ R $-module since $ R $ is Noetherian, and hence also finitely generated as an $ S $-module, so $ S $ is a Noetherian ring.
\end{proof}

\begin{lemma}
\label{lem:10.1.6}
Let $ R \subseteq S \subseteq T $ be rings, such that $ S $ is finitely generated as an $ R $-module and $ T $ is finitely generated as an $ S $-module. Then $ T $ is finitely generated as an $ R $-module.
\end{lemma}

\begin{proof}
Let $ t_1, \dots, t_l $ generate $ T $ over $ S $, and let $ s_1, \dots, s_m $ generate $ S $ over $ R $. Then for any element $ t $ of $ T $, we can write $ t = \sum_{i = 1}^l a_it_i $ for $ a_i \in S $. We can further write $ a_i = \sum_{j = 1}^m b_{ji}s_j $ for $ b_{ji} \in R $, so that $ t = \sum_{i = 1}^l \sum_{j = 1}^m b_{ji}s_jt_i $, so that $ T $ is generated over $ R $ by the elements $ s_it_j $.
\end{proof}

\begin{corollary}
Let $ R \subseteq S \subseteq T $, with $ R $ Noetherian. If $ T $ is integral over $ S $ and $ S $ is integral over $ R $, then $ T $ is integral over $ R $.
\end{corollary}

\begin{proof}
Let $ t \in T $. Then $ t $ satisfies a polynomial $ P\br{X} = X^n + s_{n - 1}X^{n - 1} + \dots + s_0 \in S\sbr{X} $ for $ s_i \in S $ such that $ P\br{t} = 0 $. Consider the subring $ S' = R\sbr{s_0, \dots, s_{n - 1}} \subseteq S $. Since each $ s_i $ is integral over $ R $, $ s_0 $ is in particular integral over $ R $ and $ s_i $ is integral over $ R\sbr{s_0, \dots, s_{i - 1}} $. Thus $ R\sbr{s_0} $ is a finitely generated $ R $-module and $ R\sbr{s_0, \dots, s_i} $ is a finitely generated $ R\sbr{s_0, \dots, s_{i - 1}} $-module for each $ i $ by induction. By Lemma \ref{lem:10.1.6} above, $ S' $ is a finitely generated $ R $-module. Since $ t $ is integral over $ S' $, $ S'\sbr{t} $ is a finitely generated $ S' $-module, and hence a finitely generated $ R $-module by Lemma \ref{lem:10.1.6}. Since $ R\sbr{t} $ is contained in $ S'\sbr{t} $ and $ R $ is a Noetherian ring, $ R\sbr{t} $ is a finitely generated $ R $-module and thus $ t $ is integral over $ R $.
\end{proof}

\begin{corollary}
Let $ R $ be a Noetherian subring of $ S $ and suppose $ \alpha, \beta \in S $ are integral over $ R $. Then $ \alpha\beta $ and $ \alpha + \beta $ are integral over $ R $.
\end{corollary}

\begin{proof}
The ring $ R\sbr{\alpha} $ is a finitely generated $ R $-module and thus integral over $ R $. Since $ \beta $ is integral over $ R $ it is integral over $ R\sbr{\alpha} $. Thus $ R\sbr{\alpha, \beta} = R\sbr{\alpha}\sbr{\beta} $ is integral over $ R\sbr{\alpha} $ and hence over $ R $ by Lemma \ref{lem:10.1.6}. Since $ \alpha + \beta $ and $ \alpha\beta $ lie in $ R\sbr{\alpha, \beta} $ they are integral over $ R $.
\end{proof}

\pagebreak

\begin{definition}
Let $ R $ be a Noetherian subring of $ S $. The \textbf{integral closure} of $ R $ in $ S $ is the subset of $ S $ consisting of all elements $ s \in S $ that are integral over $ R $. This is a subring of $ R $. We say that $ R $ is \textbf{integrally closed} in $ S $ if every element in $ S $ that is integral over $ R $ is contained in $ R $, so $ R $ is equal to its integral closure in $ S $. If $ R $ is an integral domain, we say that $ R $ is \textbf{integrally closed} if $ R $ is integrally closed in its field of fractions $ K $.
\end{definition}

\lecture{21}{Wednesday}{21/11/18}

\begin{lemma}
Let $ R $ be a Noetherian subring of $ S $, and let $ R' $ be the integral closure of $ R $ in $ S $. Then $ R' $ is integrally closed in $ S $.
\end{lemma}

\begin{proof}
Let $ t $ be an element of $ R $ integral over $ R' $. Then $ R'\sbr{t} $ is a finitely generated $ R' $-module, so is integral over $ R' $, and $ R' $ is integral over $ R $. Thus $ R'\sbr{t} $ is integral over $ R $, so $ t $ is integral over $ R $ and thus $ t \in R' $.
\end{proof}

\begin{example*}
$ \ZZ\sbr{\sqrt{-3}} $ is integral over $ \ZZ $. As a $ \ZZ $-module, $ \ZZ\sbr{\sqrt{-3}} $ is generated by $ 1 $ and $ \sqrt{-3} $. It is not integrally closed, since $ \tfrac{1 + \sqrt{-3}}{2} $ is in the field of fractions of $ \ZZ\sbr{\sqrt{-3}} $ and is a root of $ X^2 - X + 1 $.
\end{example*}

\begin{theorem}
Let $ R $ be a UFD. Then $ R $ is integrally closed.
\end{theorem}

\begin{proof}
Let $ K $ be the field of fractions of $ R $, and suppose $ \alpha \in K $ is integral over $ R $. Want $ \alpha \in R $. Then there exists a monic polynomial $ P\br{X} $ in $ R\sbr{X} $ with coefficients in $ R $ such that $ P\br{\alpha} = 0 $. Then $ \br{X - \alpha} $ is an element of $ K\sbr{X} $ dividing $ P\br{X} $. By Gauss' lemma there is a $ \lambda \in K^* $ such that $ \lambda\br{X - \alpha} $ is in $ R\sbr{X} $ and divides $ P\br{X} $ in $ R\sbr{X} $. Clearly $ \lambda $ must lie in $ R $, and on the other hand divide the leading coefficient of $ P\br{X} $, which is one. Thus $ \lambda \in R^\times $ is a unit, so since $ \br{X - \alpha} \in R\sbr{X} $ we must have $ \alpha \in R $.
\end{proof}

This suggests to number theorists to take an extension $ K / \QQ $ finite, and let $ \OOO_K $, the ring of integers of $ K $, be the integral closure of $ \ZZ $ in $ K $. We now focus on a specific class of examples. Let $ d \in \ZZ $ be squarefree and let $ K = \QQ\br{\sqrt{d}} $. This is precisely the set of elements of $ K $ that are integral over $ \ZZ $. That is, that satisfy a monic polynomial with integral coefficients. What is $ \OOO_K $? Every element of $ K $ is of the form $ a + b\sqrt{d} $ for $ a, b \in \QQ $. A question is when is this an algebraic integer? Need the minimal polynomial of $ a + b\sqrt{d} $ to have integer coefficients. We have the following lemma.

\begin{lemma}
Let $ \alpha \in K $ and suppose $ \alpha $ is integral over $ \ZZ $. Then the minimal polynomial of $ \alpha $, taken to be monic, has integer coefficients.
\end{lemma}

\begin{proof}
Let $ Q\br{X} $ be the minimal polynomial of $ \alpha $, normalised so it is monic. Since $ \alpha $ is integral over $ \ZZ $, there is a monic polynomial $ P\br{X} $, with integer coefficients, such that $ P\br{\alpha} = 0 $. Then $ Q\br{X} $ divides $ P\br{X} $ in $ \QQ\sbr{X} $. By Gauss' lemma, there exists $ \beta \in \QQ^* $ such that $ \beta Q\br{X} $ has integer coefficients and divides $ P\br{X} $ in $ \ZZ\sbr{X} $. Since $ Q\br{X} $ is monic, $ \beta $ lies in $ \ZZ $. Since $ \beta Q\br{X} $ divides $ P\br{X} $ we see that $ \beta $ divides one, by comparing leading coefficients, so $ \beta $ is a unit and $ Q\br{X} $ lies in $ \ZZ\sbr{X} $.
\end{proof}

Let $ \alpha = a + b\sqrt{d} $ with $ a, b \in \QQ $. Then the minimal polynomial of $ \alpha $ over $ \QQ $ is $ X^2 - 2aX + \br{a^2 - b^2d} $. Thus $ \alpha $ is an algebraic integer if and only if $ 2a, a^2 - b^2d \in \ZZ $.
\begin{itemize}
\item Suppose this is the case, and that $ a \in \ZZ $. Then $ b^2d \in \ZZ $. Suppose $ b \notin \ZZ $. There exists a prime $ p $ dividing the denominator of $ b $. Since $ b^2d \in \ZZ $ must have $ p^2 \mid d $ but we took $ d $ squarefree. So $ b \in \ZZ $.
\item On the other hand, suppose that $ a = m / 2 $ where $ m $ is odd. Then if $ a^2 - b^2d \in \ZZ $ we have $ m^2 / 4 - b^2d \in \ZZ $ and so $ m^2 - 4b^2d $ is a multiple of four. So $ 4b^2d = x $ where $ m^2 - x \in \ZZ $ is a multiple of four. Since $ \br{2k + 1}^2 = 4k^2 + 4k + 1 \equiv 1 \mod 4 $, so $ m^2 \equiv 1 \mod 4 $, this can only happen if $ d $ is odd and $ b = n / 2 $ with $ n $ odd. We then have $ m^2 - n^2d $ is a multiple of four. Since $ m^2, n^2 \in \ZZ $ are odd they are congruent to $ 1 \mod 4 $, so this is only possible if $ d $ is congruent to $ 1 \mod 4 $.
\end{itemize}
Thus if $ \alpha $ is an algebraic integer, either $ \alpha = a + b\sqrt{d} $ with $ a, b \in \ZZ $, or $ \alpha = \tfrac{m + n\sqrt{d}}{2} $ with $ m, n \in \ZZ $ odd and $ d $ congruent to $ 1 \mod 4 $. Conversely, it is easy to check that all such elements are algebraic integers, so
$$ \OOO_{\QQ\br{\sqrt{d}}} =
\begin{cases}
\ZZ\sbr{\sqrt{d}} = \cbr{a + b\sqrt{d} \st a, b \in \ZZ} & d \equiv 2, 3 \mod 4 \\
\ZZ\sbr{\tfrac{1 + \sqrt{d}}{2}} = \cbr{\tfrac{m + n\sqrt{d}}{2} \st n, m \in \ZZ, \ n \equiv m \mod 2} & d \equiv 1 \mod 4
\end{cases}.
$$

\begin{note*}
The results in this section are also true without any Noetherian hypotheses, but the proofs are more difficult, and require machinery we have not covered.
\end{note*}

\pagebreak

\section{Dedekind domains}

\subsection{Dedekind domains}

\lecture{22}{Friday}{23/11/18}

For number theorists, it is often convenient to work in a ring of the form $ \ZZ\sbr{\alpha} $, where $ \alpha \in \CC $ is an algebraic integer, or more generally in some subring $ \OOO $ of $ \CC $ that is integral over $ \ZZ $. Unfortunately, unique factorisation only rarely holds in such rings. If $ \OOO $ is integrally closed, however, there is a substitute for unique factorisation that is often good enough, unique factorisation of ideals. In this section we develop the ideas behind this result, in the more general context of what are called Dedekind domains.

\begin{definition}
An integral domain $ R $ is called a \textbf{Dedekind domain} if
\begin{itemize}
\item $ R $ is Noetherian,
\item $ R $ is integrally closed, and
\item every nonzero prime ideal of $ R $ is maximal, so $ R $ has \textbf{dimension one}.
\end{itemize}
\end{definition}

\begin{example*}
\hfill
\begin{itemize}
\item In particular, any PID is a Dedekind domain. We have seen that every nonzero prime ideal is maximal in a PID, and PIDs are certainly Noetherian. They are integrally closed because any UFD is integrally closed.
\item The rings $ \OOO_K $, the integral closure of $ \ZZ $ in $ K $, with $ K $ a quadratic extension of $ \QQ $ are
$$ \OOO_K =
\begin{cases}
\ZZ\sbr{\sqrt{d}} & d \equiv 2, 3 \mod 4 \\
\ZZ\sbr{\tfrac{1 + \sqrt{d}}{2}} & d \equiv 1 \mod 4
\end{cases}.
$$
$ \OOO_K \subseteq K $ is an integral domain, is finitely generated by a single element as a $ \ZZ $-algebra and thus Noetherian, and is also integrally closed. We proved on example sheet $ 2 $ that $ \ZZ\sbr{X} / \abr{P\br{X}} $ for $ P\br{X} $ monic and irreducible with coefficients in $ \ZZ $ has dimension one, that is every nonzero prime of such a ring is maximal.
\end{itemize}
\end{example*}

More generally, we have the following.

\begin{theorem}
Let $ R $ be a PID with field of fractions $ K $, and let $ L $ be a finite extension of $ K $. Let $ S $ be the integral closure of $ R $ in $ L $. Then $ S $ is a Dedekind domain.
\end{theorem}

We will prove this later in the course, under a mild additional hypothesis on the extension $ L / K $. In particular, let $ R = \ZZ $ and $ K = \QQ $. The ring of integers $ \OOO_L $ in $ L / \QQ $ a finite extension is a Dedekind domain. Also in particular let $ R = F\sbr{X} $ for $ F $ a field, $ K = F\br{X} $, and $ L / K $ finite. The integral closure of $ R $ in $ K $ is also Dedekind.

\begin{example*}
$ K\sbr{X, Y} / \abr{Y^2 - X^3 - aX - b} $, where $ X^3 + aX + b $ is a squarefree polynomial in $ K\sbr{X, Y} $.
\end{example*}

The reason Dedekind domains are interesting to us is that the nonzero ideals in a Dedekind domain factor uniquely as products of prime ideals. The idea to study factorisation of ideals into prime ideals comes from the following observation.

\begin{lemma}
\label{lem:11.1.3}
Let $ \ppp $ be a prime ideal of any ring $ R $, let $ I, J \subseteq R $ be ideals, and suppose that $ \ppp $ contains $ IJ $. Then either $ \ppp $ contains $ I $ or $ \ppp $ contains $ J $.
\end{lemma}

\begin{proof}
Suppose that $ \ppp $ does not contain $ I $, and fix an $ r \in I $ such that $ r $ is not in $ \ppp $. Then for all $ s \in J $, the product $ rs $ lies in $ IJ $ and hence in $ \ppp $. Since $ r $ does not lie in $ \ppp $, and $ \ppp $ is prime, we must have $ s \in \ppp $.
\end{proof}

Note the resemblance of this to the property, $ p \mid ab $ implies $ p \mid a $ or $ p \mid b $ for $ p $ irreducible, which holds in UFDs and implies unique factorisation. We might hope that the above result thus implies unique factorisation into primes for arbitrary rings, but this is too much to ask for. The problem is that ideal multiplication is usually badly behaved compared to multiplication of elements in integral domains. Recall that for $ I, J \subseteq R $ ideals, $ IJ $ is the ideal generated by all elements of the form $ rs $ for $ r \in I $ and $ s \in J $. In particular if $ r_1, \dots, r_n $ generate $ I $ and $ s_1, \dots, s_m $ generate $ J $ then $ r_1s_1, \dots, r_1s_m, \dots, r_ns_1, \dots, r_ns_m $ generate $ IJ $.

\pagebreak

\begin{example*}
$ R = \ZZ\sbr{\sqrt{-3}} $ is not a Dedekind domain, since it fails to be integrally closed. Then the ideal $ I = \abr{2, 1 + \sqrt{-3}} $ is prime, and we have
$$ \abr{2, 1 + \sqrt{-3}}^2 = \abr{4, 2 + 2\sqrt{-3}, -2 + 2\sqrt{-3}} = \abr{4, 2 + 2\sqrt{-3}}. $$
There is thus a chain of inclusions $ I \supsetneq \abr{2} \supsetneq I^2 $, so the ideal $ \abr{2} $ is not a product of prime ideals. Worse is $ I^2 = \abr{2}I $ but $ I \ne \abr{2} $, so cannot cancel ideals.
\end{example*}

Dedekind domains give precisely the context where this does not happen. In order to make this precise, we first define the following.

\begin{definition}
Let $ R $ be a Noetherian integral domain. A \textbf{fractional ideal} of $ R $ is a finitely generated nonzero $ R $-submodule of the field of fractions $ K $ of $ R $. A \textbf{principal fractional ideal} is an $ R $-submodule $ R \cdot x \subseteq K $ of $ K $ finitely generated by a single nonzero element $ x $ for $ x \in K^* $.
\end{definition}

\begin{example*}
The subgroup of $ \QQ $ generated by $ \tfrac{3}{5} $ is a principal fractional ideal of $ \ZZ $. Indeed, every fractional ideal of $ \ZZ $, or any PID, is principal.
\end{example*}

More generally, let $ R $ be a Noetherian integral domain, and let $ I $ be the $ R $-submodule of $ K $ generated by $ r_1, \dots, r_n \in K $. Then by definition $ I $ is a fractional ideal of $ R $. On the other hand, we can clear denominators. There exists an $ r \in R $, nonzero, such that $ rr_i $ lies in $ R $ for all $ i $. Then $ rI $ is generated by elements of $ R $, so is an ideal $ J $ of $ R $, and $ I = \tfrac{1}{r}J $. Thus the fractional ideals of $ R $ are precisely the subsets of $ K $ of the form $ \tfrac{1}{r}J $, where $ r $ is a nonzero element of $ R $ and $ J $ is an ideal of $ R $. Let $ I $ and $ J $ be fractional ideals of $ R $. The product $ IJ $ is the $ R $-submodule of $ K $ generated by all products of the form $ rs $ for $ r \in I $ and $ s \in J $. It is a fractional ideal of $ R $. The multiplication $ I, J \mapsto IJ $ is an associative and commutative operation. $ R $ is a fractional ideal of $ R $, and $ RJ = J $ for any fractional ideal $ J $, so $ R $ is an identity element for this operation. For a nonzero ideal $ I $ of $ R $, let $ I^{-1} $ denote the set
$$ \cbr{r \in K \st rI \subseteq R}. $$
Then $ I^{-1} $ is clearly an $ R $-submodule of $ K $. If $ r \in I $ is nonzero, then $ rI^{-1} $, by definition, is contained in $ R $, so $ I^{-1} $ is contained in $ \tfrac{1}{r} \cdot R $ and is thus a fractional ideal. A warning is that in a general ring, $ I \mapsto I^{-1} $ is not always a good inverse operation, since $ II^{-1} \subseteq R $ but need not equal $ R $. For a prime ideal $ \ppp $ of $ R $, and $ n \in \ZZ_{> 0} $, define $ \ppp^{-n} = \br{\ppp^{-1}}^n $. We then have the following.

\begin{theorem}
Let $ R $ be a Dedekind domain. Then
\begin{itemize}
\item the set of fractional ideals of $ R $ form a group under multiplication $ I, J \mapsto IJ $, identity $ R $, and inverse $ I \mapsto I^{-1} $, and
\item moreover, any fractional ideal $ I $ of $ R $ factors uniquely as $ \ppp_1^{n_1} \dots \ppp_s^{n_s} $ for $ n_i \in \ZZ $, where the $ \ppp_i $ are nonzero prime ideals.
\end{itemize}
\end{theorem}

\lecture{23}{Monday}{26/11/18}

The proof of this statement will occur in several steps. We first show the following.

\begin{proposition}
Let $ I $ be a nonzero ideal of a Noetherian ring $ R $. Then there exist nonzero primes $ \ppp_1, \dots, \ppp_r $ and $ n_1, \dots, n_r \in \ZZ_{> 0} $ such that $ I $ contains $ \ppp_1^{n_1} \dots \ppp_r^{n_r} $.
\end{proposition}

\begin{proof}
Suppose the claim fails for some $ I $. Then there exists an ideal $ I $ such that
\begin{enumerate}
\item $ I $ does not contain a product of primes, but
\item every ideal containing $ I $ does.
\end{enumerate}
Suppose not. Then let $ I_0 $ be an ideal satisfying $ 1 $. Since $ 2 $ does not hold for $ I_0 $ there exists $ I_1 \supsetneq I_0 $ such that $ 1 $ holds for $ I_1 $. Then $ 2 $ cannot hold for $ I_1 $, so there exists $ I_2 \supsetneq I_1 $ such that $ 1 $ holds for $ I_2 $, etc, so get infinite increasing chain
$$ I_0 \subsetneq I_1 \subsetneq \dots, $$
contradicting Noetherianness of $ R $. Fix such an $ I $. Certainly $ I $ cannot be prime. So there exist $ a, b \in R $ with $ ab \in I $ but $ a $ and $ b $ are not in $ I $. Then the ideals $ I + \abr{a} $ and $ I + \abr{b} $ both strictly contain $ I $, so the claim holds for both of these ideals by $ 2 $, so $ I + \abr{a} \supseteq \ppp_1 \dots \ppp_r $ and $ I + \abr{b} \supseteq \qqq_1 \dots \qqq_s $ for $ \ppp_i $ and $ \qqq_j $ prime ideals. Then it also holds for their product $ \br{I + \abr{a}}\br{I + \abr{b}} = I^2 + \abr{a}I + \abr{b}I + \abr{ab} $, but this product is contained in $ I $. Thus $ \ppp_1 \dots \ppp_r\qqq_1 \dots \qqq_s \subseteq \br{I + \abr{a}}\br{I + \abr{b}} \subseteq I $ as well and we have a contradiction to $ 1 $.
\end{proof}

\pagebreak

\begin{note*}
If the claim holds for an ideal $ I $ then it holds for any ideal containing $ I $. If the claim holds for $ I $ and $ J $ then it holds for $ I \cap J $.
\end{note*}

Next, we show that prime ideals have multiplicative inverses. To do so we use the following lemma.

\begin{lemma}
\label{lem:11.1.7}
Let $ R $ be a Dedekind domain with field of fractions $ K $, and let $ x $ be an element of $ K $ that is not in $ R $, and let $ I $ be any nonzero ideal of $ R $. Then $ xI $ is not contained in $ I $.
\end{lemma}

\begin{proof}
Suppose $ xI $ were contained in $ I $. Let $ a \in I $, and for each $ i $ let $ M_i $ be the ideal of $ I $ generated by $ a, \dots, ax^i $, so $ M_i = \abr{a, \dots, ax^i} \subseteq I $. This is an increasing tower of ideals of $ R $. In particular, since $ R $ is Noetherian, it is eventually constant, that is $ M_{i + 1} = M_i $ for some $ i $. Then $ ax^{i + 1} $ can be expressed as an $ R $-linear combination of the $ ax^j $, that is there exist $ r_0, \dots, r_i \in R $ such that we have $ ax^{i + 1} = \sum_{j = 0}^i r_jax^j $. Since $ a \ne 0 $ and $ R $ is an integral domain we can cancel the $ a $, so $ x^{i + 1} = \sum_{j = 0}^i r_jx^j $, so $ x $ satisfies a monic polynomial with coefficients in $ R $. Thus $ x $ is integral over $ R $. Since $ R $ is integrally closed and $ x $ does not lie in $ R $ this is a contradiction.
\end{proof}

When $ R $ is not integrally closed this is false.

\begin{example*}
If $ R = \ZZ\sbr{\sqrt{-3}} $, $ I \subset R $, and $ x = \tfrac{1 + \sqrt{-3}}{2} $, then $ xI = \abr{1 + \sqrt{-3}, -1 + \sqrt{-3}} = \abr{2, 1 + \sqrt{-3}} = I $.
\end{example*}

\begin{proposition}
\label{prop:11.1.8}
Let $ \ppp $ be a nonzero prime ideal of a Dedekind domain $ R $. Then $ \ppp^{-1} \cdot \ppp = R $.
\end{proposition}

\begin{proof}
We first show that there is an element $ x \in \ppp^{-1} $ such that $ x \notin R $. Let $ a $ be an element of $ \ppp $, and $ a \ne 0 $, so that we have $ \abr{a} \subset \ppp $. Choose a minimal set of nonzero primes $ \ppp_1, \dots, \ppp_r $ such that $ \ppp_1 \dots \ppp_r \subseteq \abr{a} $. Then we have in particular $ \ppp_1 \dots \ppp_r \subseteq \ppp $, so by Lemma \ref{lem:11.1.3} above we must have $ \ppp = \ppp_i $ for some $ i $. Without loss of generality we can take $ i = 1 $. Then by our minimality assumption $ \ppp_2 \dots \ppp_r $ is not contained in $ \abr{a} $. Take $ b $ to be an element of $ \ppp_2 \dots \ppp_r $ that is not in $ \abr{a} $. Then $ b / a \in K $ but not in $ R $. Take $ x = b / a $. On the other hand for any $ y \in \ppp $, $ xy = by / a $ for $ by \in \ppp_1 \dots \ppp_r \subseteq \abr{a} $. Thus $ xy $ lies in $ R $. By definition, this means $ x $ lies in $ \ppp^{-1} $ but not in $ R $. Now consider $ \ppp^{-1} \cdot \ppp $. By definition this is contained in $ R $. Since $ \ppp \subseteq R $, $ 1 \in \ppp^{-1} $ so $ \ppp^{-1} \cdot \ppp $ contains $ \ppp $. Since $ \ppp $ is a nonzero prime ideal it is maximal, so we must have either $ \ppp^{-1} \cdot \ppp = R $ or $ \ppp^{-1} \cdot \ppp = \ppp $. Suppose the latter holds. Then in particular multiplication by $ x $ sends $ \ppp $ to $ \ppp $. This contradicts Lemma \ref{lem:11.1.7} above, so $ \ppp^{-1} \cdot \ppp \supsetneq \ppp $.
\end{proof}

\begin{proposition}
\label{prop:11.1.9}
Let $ I $ be a nonzero ideal of a Dedekind domain $ R $. Then there exists a fractional ideal $ J $ of $ R $ such that $ IJ = R $.
\end{proposition}

\begin{proof}
Suppose otherwise. Then there is a maximal nonzero ideal $ I $ of $ R $ for which no such $ J $ exists. Proposition \ref{prop:11.1.8} shows that $ I $ is not a maximal ideal, so $ I $ is properly contained in some maximal ideal $ \ppp $ of $ R $. Then $ \ppp^{-1} $ is contained in $ I^{-1} $. We thus have inclusions
$$ I \subseteq I\ppp^{-1} \subseteq II^{-1} \subseteq R. $$
Suppose that $ I\ppp^{-1} = I $. By Proposition \ref{prop:11.1.8} there exists $ x \in \ppp^{-1} $ not in $ R $, so we would have $ xI \subset I $ contradicting Lemma \ref{lem:11.1.7} above. Thus $ I\ppp^{-1} $ strictly contains $ I $ and thus has an inverse $ J = \br{I\ppp^{-1}}^{-1} $. Then $ I\ppp^{-1} \cdot J = R $. But then $ I \cdot \ppp^{-1}J = R $, so $ \ppp^{-1}J \subseteq I^{-1} $. Then $ II^{-1} \supseteq R $. So $ II^{-1} = R $, a contradiction.
\end{proof}

\begin{theorem}
Let $ R $ be a Dedekind domain. Then the fractional ideals of $ R $ form a group under multiplication.
\end{theorem}

\begin{proof}
We must show that every fractional ideal of $ R $ is invertible. Let $ I $ be such a fractional ideal of $ R $. Then there is $ r \in R $ such that $ rI $ is an ideal of $ R $. Proposition \ref{prop:11.1.9} shows that $ rI $ has a multiplicative inverse $ J $, so $ I = \tfrac{1}{r}J^{-1} $. Then $ I^{-1} = rJ $ is a multiplicative inverse for $ I $, since $ II^{-1} = \tfrac{1}{r}J^{-1} \cdot rJ = JJ^{-1} = R $.
\end{proof}

\lecture{24}{Wednesday}{28/11/18}

Lecture 24 is a problems class.

\lecture{25}{Friday}{30/11/18}

It remains to show that every fractional ideal of $ R $ factors uniquely as a product of prime powers. The hard part is showing such factorisations exist, and we make heavy use of the fact that the fractional ideals are a group. Uniqueness is then almost an afterthought.

\pagebreak

\begin{proposition}
Every fractional ideal in a Dedekind domain $ R $ is uniquely expressible as a product of, possibly negative, prime powers $ \ppp_1^{n_1} \dots \ppp_s^{n_s} $ for $ n_i \in \ZZ $.
\end{proposition}

\begin{proof}
\hfill
\begin{itemize}
\item We first show that every nonzero ideal $ I $ in $ R $ is a product of nonnegative prime powers. Suppose otherwise, that for some ideal $ I $ of $ R $, $ I $ cannot be expressed as a product of primes. Claim that there is a largest ideal $ I' $ such that $ I' $ cannot be expressed as a product of primes but all $ J \supsetneq I $ can. Take $ I_0 = I $ if there exists $ I_1 \supsetneq I $ that cannot be expressed as a product of primes, either all ideals properly containing $ I_1 $ can be or there exists $ I_2 \supsetneq I_1 $ that cannot be expressed as a product of primes. Since $ R $ is Noetherian, the process terminates. Now let $ I' $ be as in the claim. Certainly $ I' \ne R $, and $ I' $ is not prime, since every maximal ideal of $ R $ is certainly such a product $ I' $ cannot be a maximal ideal. Thus $ I' $ is properly contained in a maximal ideal $ \ppp $. Then $ J = \ppp^{-1} \cdot I' $ is an ideal of $ R $. Since $ \ppp \supseteq I' $, $ \ppp^{-1} \cdot \ppp \supseteq J $, so $ J \subseteq R $. Since the nonzero fractional ideals of $ R $ form a group this ideal $ J $ strictly contains $ I' $ and thus factors as a product of prime powers $ \ppp^{-1} \cdot I' = J = \ppp_1^{n_1} \dots \ppp_s^{n_s} $. But then $ \ppp \cdot J = I' = \ppp\ppp_1^{n_1} \dots \ppp_s^{n_s} $ is also a product of prime powers, contradicting our assumption. Now suppose that $ I $ is a fractional ideal. Then $ I = \tfrac{1}{r}J $ for some nonzero ideal $ J $ of $ R $ and some nonzero element $ r $ of $ R $. Since $ \abr{r} = \qqq_1^{m_1} \dots \qqq_t^{m_t} $ and $ J = \ppp_1^{n_1} \dots \ppp_s^{n_s} $ factor as products of prime powers, so does $ I = \tfrac{1}{r}J = \abr{r}^{-1}J = \ppp_1^{n_1} \dots \ppp_s^{n_s}\qqq_1^{-m_1} \dots \qqq_t^{-m_t} $.
\item It remains to show that such factorisations are unique. Suppose otherwise for a fractional ideal $ I $. Then we have a finite collection of distinct primes $ \ppp_1, \dots, \ppp_s $ and $ \qqq_1, \dots, \qqq_t $, and two sequences $ n_1, \dots, n_s, m_1, \dots, m_t \in \ZZ $ such that $ I = \ppp_1^{n_1} \dots \ppp_s^{n_s} = \qqq_1^{m_1} \dots \qqq_t^{m_t} $, and we must show that $ m_i = n_i $ for all $ i $. Suppose this is not the case. We can make all prime powers $ n_i $ and $ m_j $ involved positive by cancelling $ \ppp_i^{n_i} $ and $ \qqq_j^{m_j} $ from both sides of the equation. We then get an expression of the form $ \ppp_1^{n_1} \dots \ppp_s^{n_s} = \qqq_1^{m_1} \dots \qqq_t^{m_t} $, where the primes $ \cbr{\ppp_i} $ and $ \cbr{\qqq_j} $ are all distinct and all powers $ a_i $ and $ b_j $ are positive. Claim that both products must be empty under these assumptions. Recall that if $ R $ is Noetherian, $ \ppp $ is prime, and $ I $ and $ J $ are ideals, then $ \ppp $ contains $ IJ $ implies that $ \ppp $ contains $ I $ or $ \ppp $ contains $ J $. If one product, say the $ \ppp_i $'s, is nonempty, then since $ \ppp_1 $ divides the left hand side it also divides the right hand side, and thus contains one of the $ \qqq_i $'s for some $ i $. Since $ \ppp_i $ and $ \qqq_j $ are maximal in a Dedekind domain, $ \ppp_1 = \qqq_i $, which contradicts disjointness and is impossible.
\end{itemize}
\end{proof}

\subsection{Ideal class groups}

Let $ R $ be a Dedekind domain. Then the fractional ideals of $ R $ form a group, which we will denote $ \III\br{R} $. The principal fractional ideals are a subset of $ \III\br{R} $ that is easily seen to be closed under multiplication and inverses. If $ r, s \in K^* $, then
$$ \br{rR}^{-1} = \dfrac{1}{r}R \qquad \br{rR}\br{sR} = rsR. $$
Denote this subgroup by $ \PPP\br{R} $. We can then form a quotient group called the ideal class group of $ R $.

\begin{definition}
The \textbf{ideal class group} of $ R $ is $ \AAA\br{R} = \III\br{R} / \PPP\br{R} $.
\end{definition}

\begin{example*}
If $ R $ is a PID, $ \AAA\br{R} = \cbr{e} $.
\end{example*}

In general $ \AAA\br{R} $ is a measure of the failure of fractional ideals of $ R $ to be principal. That is, it measures the failure of $ R $ to be a PID. We will show that if $ K $ is a finite extension of $ \QQ $ then the integral closure $ \OOO_K $ of $ \ZZ $ in $ K $ is a Dedekind domain. A fundamental result of algebraic number theory is the following.

\begin{theorem}
If $ R $ is a Dedekind domain with field of fractions a finite extension of $ K $, that is $ R = \OOO_K $ for $ K / \QQ $ finite, then the ideal class group $ \AAA\br{R} $ is a finite group.
\end{theorem}

The order of the ideal class group of $ \OOO_K $ is called the \textbf{class number} of $ K $. In particular, if $ \AAA\br{R} $ is finite, say of order $ n $, then $ \ppp^n $ is principal for every prime $ \ppp $. A warning is that it is not true that $ \AAA\br{R} $ is finite for $ R $ Dedekind. The study of class groups and class numbers is a central part of modern number theory and there are many, many open questions.

\begin{example*}
If $ R = \CC\sbr{x, y} / \abr{y^2 - x\br{x - 1}\br{x + 1}} $, then $ \AAA\br{R} $ is uncountable.
\end{example*}

\pagebreak

\section{Integers in number fields}

\subsection{Integer rings}

At one point I claimed that if $ R $ is a PID, $ K $ is its field of fractions, and $ L / K $ is finite, then the integral closure $ S $ of $ R $ in $ L $ is Dedekind. In fact, only need $ R $ is Dedekind. We will prove under a simplifying assumption, involving the trace map. Let $ K $ be a finite extension of $ \QQ $. Such an extension is called a \textbf{number field}. The integral closure $ \OOO_K $ of $ \ZZ $ in $ K $ is called the \textbf{ring of integers} of $ K $. A fundamental result of number theory is that $ \OOO_K $ is a Dedekind domain. The goal of this section is to prove this fact. Indeed, we will prove something more general, but in order to do that we need to introduce some new concepts.

\subsection{Trace and norm}

Let $ L / K $ be a finite extension of fields, and let $ \alpha $ be an element of $ L $. Then we can regard $ L $ as a finite-dimensional $ K $-vector space. Multiplication by $ \alpha $ is then a $ K $-linear map from $ L $ to $ L $. If we choose a $ K $-basis $ \beta_1, \dots, \beta_d $ for $ L $, such a map
$$ \function{L}{L}{x}{x\alpha} $$
is given by a $ d $ by $ d $ matrix $ M_\alpha \in M_d\br{K} $, with entries in $ K $ where $ d $ is the degree of $ L $ over $ K $. That is, $ \br{M_\alpha}_{i, j} $ is defined by $ \alpha\beta_i = \sum_{j = 1}^d \br{M_\alpha}_{i, j}\beta_j $. The matrix of course depends on the basis $ \beta_1, \dots, \beta_d $ chosen, but its trace and determinant are elements of $ K $ that depend only on $ \alpha $. We denote the trace of $ M_\alpha $ by $ \Tr_{L / K} \alpha \in K $ and call it the \textbf{trace} of $ \alpha $ with respect to $ L / K $. Similarly, the determinant of $ M_\alpha $ is denoted $ \Nm_{L / K} \alpha \in K $ and called the \textbf{norm} of $ \alpha $.

\begin{lemma}
The map
$$ \function[\Tr_{L / K}]{L}{K}{\alpha}{\Tr_{L / K} \alpha} $$
is $ K $-linear, so $ \Tr_{L / K} \br{\lambda\alpha + \alpha'} = \lambda \Tr_{L / K} \alpha + \Tr_{L / K} \alpha' $. The map
$$ \function[\Nm_{L / K}]{L}{K}{\alpha}{\Nm_{L / K} \alpha} $$
is multiplicative, so $ \Nm_{L / K} \alpha\alpha' = \Nm_{L / K} \alpha\Nm_{L / K} \alpha' $.
\end{lemma}

\begin{proof}
Since $ \lambda \in K $, distributivity of multiplication over addition shows that, with respect to a fixed basis of $ L $ over $ K $, $ M_{\lambda\alpha + \alpha'} = \lambda M_\alpha + M_{\alpha'} $, so
$$ \Tr_{L / K} \br{\lambda\alpha + \alpha'} = \Tr M_{\lambda\alpha + \alpha'} = \Tr \lambda M_\alpha + \Tr M_{\alpha'} = \lambda \Tr_{L / K} \alpha + \Tr_{L / K} \alpha'. $$
Similarly $ M_{\alpha\alpha'} = M_\alpha M_{\alpha'} $, by associativity of multiplication, so
$$ \Nm_{L / K} \alpha\alpha' = \det M_{\alpha\alpha'} = \det M_\alpha\det M_{\alpha'} = \Nm_{L / K} \alpha\Nm_{L / K} \alpha'. $$
\end{proof}

We will prove that if $ R $ is a PID or a Dedekind domain, such as $ \ZZ $, $ K $ is its field of fractions, and $ L / K $ is finite such that $ \Tr_{L / K} $ is not the zero map, then the integral closure of $ R $ in $ L $ is Dedekind.

\lecture{26}{Monday}{03/12/18}

\begin{proposition}
\label{prop:12.2.2}
Let $ L / K $ be a finite extension, and $ \alpha $ an element of $ L $. Let
$$ Q\br{X} = X^n + a_{n - 1}X^{n - 1} + \dots + a_0 $$
be the minimal polynomial of $ \alpha $ over $ K $. Then
\begin{itemize}
\item $ \Tr_{L / K} \alpha = -da_{n - 1} $, and
\item $ \Nm_{L / K} \alpha = \br{\br{-1}^na_0}^d $,
\end{itemize}
where $ d $ is the degree $ \sbr{L : K\br{\alpha}} $ of $ L $ over $ K\br{\alpha} $.
\end{proposition}

\pagebreak

\begin{proof}
\hfill
\begin{itemize}
\item We first prove this when $ d = 1 $, so $ L = K\br{\alpha} $ and $ n = \sbr{L : K} $. Then we have seen $ 1, \dots, \alpha^{n - 1} $ is a $ K $-basis for $ L $ over $ K $. With respect to this basis,
$$
\begin{array}{c|c|c}
\text{basis element} & \cdot \alpha & \text{in terms of basis} \\
\hline
1 & \alpha & \alpha \\
\vdots & \vdots & \vdots \\
\alpha^{n - 2} & \alpha^{n - 1} & \alpha^{n - 1} \\
\alpha^{n - 1} & \alpha^n & -a_{n - 1}\alpha^{n - 1} - \dots - a_0
\end{array}.
$$
$ M_\alpha $ has the matrix
$$ M_\alpha =
\begin{pmatrix}
0 & \dots & 0 & -a_0 \\
1 & \dots & 0 & -a_1 \\
\vdots & \ddots & \vdots & \vdots \\
0 & \dots & 1 & -a_{n - 1}
\end{pmatrix}.
$$
This matrix is called the \textbf{companion matrix} $ C_\alpha $ of the polynomial $ Q\br{X} $. Then $ \Tr M = -a_{n - 1} $ and $ \det M = \br{-1}^na_0 $, from which both claims can be easily deduced.
\item In general, $ K \subseteq K\br{\alpha} \subseteq L $. Choose a basis $ \beta_1, \dots, \beta_d $ for $ L $ over $ K\br{\alpha} $. Then
$$ \beta_1, \dots, \beta_1\alpha^{n - 1}, \dots, \beta_d, \dots, \beta_d\alpha^{n - 1} $$
is a $ K $-basis for $ L / K $. With respect to this basis,
$$
\begin{array}{c|c|c}
\text{basis vector} & \cdot \alpha & \text{in terms of basis} \\
\hline
\beta_i & \beta_i\alpha & \beta_i\alpha \\
\vdots & \vdots & \vdots \\
\beta_i\alpha^{n - 2} & \beta_i\alpha^{n - 1} & \beta_i\alpha^{n - 1} \\
\beta_i\alpha^{n - 1} & \beta_i\alpha^n & \beta_i\br{-a_{n - 1}\alpha^{n - 1} - \dots - a_0} \\
\end{array}.
$$
$ M_\alpha $ is block diagonal, consisting of $ d $ blocks along the diagonal, each of which is the $ n \times n $ matrix above,
$$ M_\alpha = \threebythree{C_\alpha}{\dots}{0}{\vdots}{\ddots}{\vdots}{0}{\dots}{C_\alpha}. $$
Thus $ \Tr M_\alpha = \Tr C_\alpha \cdot d = -da_{n - 1} $ and $ \det M_\alpha = \br{\det C_\alpha}^d = \br{\br{-1}^na_0}^d $, so the claim follows.
\end{itemize}
\end{proof}

\begin{remark}
If $ L / K $ is finite, $ \Tr_{L / K} 1 = \sbr{L : K} $, considered as an element of $ K $. The map $ \Tr_{L / K} : L \to K $ is sometimes the zero map. However, this does not happen if $ K $ has characteristic $ \ch K = 0 $ or if the degree $ d = \sbr{L : K} $ is relatively prime to the characteristic of $ K $, since the above Proposition \ref{prop:12.2.2} shows that $ \Tr_{L / K} 1 = d \ne 0 $.
\end{remark}

\begin{example*}
Let $ K = \FF_2\br{t} $, the rational functions with coefficients in $ \FF_2 $. Let
$$ L = \dfrac{K\sbr{X}}{\abr{X^2 - t}} = \FF_2\br{t^{\tfrac{1}{2}}}. $$
Then $ \Tr_{L / K} $ is $ K $-linear, and $ \Tr_{L / K} 1 = 0 $ and $ \Tr_{L / K} X = 0 $, so $ \Tr_{L / K} \br{aX + b} = 0 $ for all $ a, b \in K $.
\end{example*}

\begin{proposition}
If $ L / K $ are finite fields, then $ \Tr_{L / K} $ is not zero map.
\end{proposition}

\pagebreak

\subsection{The main result}

We can now state our main result.

\begin{theorem}
Let $ R $ be a PID, or even a Dedekind domain, with field of fractions $ K $, and let $ L / K $ be a finite extension such that $ \Tr_{L / K} $ is not the zero map. Let $ S $ be the integral closure of $ R $ in $ L $. Then $ S $ is a Dedekind domain.
\end{theorem}

To prove this, we must show three things about $ S $, that $ S $ is Noetherian, that $ S $ is integrally closed, and that $ S $ has dimension one, that is every nonzero prime ideal of $ S $ is maximal. We first show the following.

\begin{lemma}
The field of fractions of $ S $ is $ L $.
\end{lemma}

\begin{proof}
In fact, we will show that every element of $ L $ can be expressed as $ s / r $ for $ s \in S $ and $ r \in R $. Let $ x \in L $, and let $ Q\br{X} = X^n + a_{n - 1}X^{n - 1} + \dots + a_0 $ for $ a_i \in K $ be the minimal polynomial of $ x $ over $ K $, where $ K $ is the field of fractions of $ R $. We will show that there exists $ r \in R^* $ such that $ rx \in S $. Then $ x = rx / r $, so is in field of fractions of $ S $. Let $ n $ be the degree of $ Q\br{X} $. For each $ r \in R $, let $ Q_r\br{X} = r^nQ\br{X / r} = X^n + ra_{n - 1}X^{n - 1} + \dots + r^na_0 $. We can find an $ r \in R $ such that $ Q_r\br{X} $ has coefficients in $ R $. But $ Q\br{x} = 0 $, so $ Q_r\br{rx} = 0 $, so $ Q_r\br{X} $ is the minimal polynomial of $ rx $, so it follows that for such $ r $, $ rx $ is integral over $ R $ and thus lies in $ S $.
\end{proof}

\begin{corollary}
The ring $ S $ is integrally closed.
\end{corollary}

\begin{proof}
We have shown that the integral closure $ S $ of $ R $ in $ L $ is integrally closed in $ L $. Since $ L $ is the field of fractions of $ S $, we have that $ S $ is integrally closed.
\end{proof}

\lecture{27}{Wednesday}{05/12/18}

Next we show that $ S $ is Noetherian. In fact, we will show that $ S $ is a finitely generated $ R $-module. Since $ R $ is Noetherian it will then follow that $ S $ is Noetherian as an $ R $-module, and hence also as an $ S $-module. Then every $ R $-submodule of $ S $ is finitely generated over $ R $, so every ideal of $ S $ is finitely generated as an $ R $-module and as an $ S $-module. Thus $ S $ is Noetherian. To do this, choose a $ K $-basis $ \beta_1, \dots, \beta_d $ for $ L $ over $ K $. We have seen that for each $ i $ there exists $ r_i \in R^* $ such that $ r_i\beta_i \in S $, so, replacing $ \beta_i $ by $ r_i\beta_i $, we may assume that the $ \beta_i $ all lie in $ S $. Let $ M \subseteq S $ be the $ R $-module in $ S $ spanned by the $ \beta_i $, and let $ M^* $ denote
$$ M^* = \cbr{x \in L \st \forall m \in M, \ \Tr_{L / K} xm \in R} \subseteq L. $$
Claim that $ S \subseteq M^* $. Since $ M \subseteq S $, if $ x \in S $, then $ xm \in S $. So it suffices to show that for all $ s \in S $, $ \Tr_{L / K} s \in R $. Fix $ s $, let $ Q\br{X} $ be the minimal polynomial of $ s $ over $ K $. Since $ S $ is integral over $ R $, $ s $ is integral over $ R $, so $ Q\br{s} $ has coefficients in $ R $. If $ Q\br{X} = X^r + a_{r - 1}X^{r - 1} + \dots + a_0 $, last time showed that $ \Tr_{L / K} s = -na_{r - 1} $ for $ n = \sbr{L : K\br{s}} $. This lies in $ R $. We now have $ M \subseteq S \subseteq M^* $. It suffices to show $ M^* $ is finitely generated as an $ R $-module.

\begin{proposition}
There exist $ \beta_1^*, \dots, \beta_d^* \in L $ such that
$$ \Tr_{L / K} \beta_i\beta_j^* =
\begin{cases}
1 & i = j \\
0 & i \ne j
\end{cases}.
$$
\end{proposition}

\begin{proof}
Let $ A $ be the matrix where $ A_{ij} = \Tr_{L / K} \beta_i\beta_j $, a $ d \times d $ matrix with entries in $ K $. If $ x = r_1\beta_1 + \dots + r_d\beta_d $, then
$$ A\threebyone{r_1}{\vdots}{r_d} = \threebyone{r_1\Tr \beta_1\beta_1 + \dots + r_d\Tr \beta_1\beta_d}{\vdots}{r_1\Tr \beta_d\beta_1 + \dots + r_d\Tr \beta_d\beta_d} = \threebyone{\Tr \beta_1\br{r_1\beta_1 + \dots + r_d\beta_d}}{\vdots}{\Tr \beta_d\br{r_1\beta_1 + \dots + r_d\beta_d}} = \threebyone{\Tr \beta_1x}{\vdots}{\Tr \beta_dx}. $$
If I have $ y_1, \dots, y_d \in K $, finding an element $ x = r_1\beta_1 + \dots + r_d\beta_d \in L $ such that $ \Tr \beta_1x = y_1, \dots, \Tr \beta_dx = y_d $ is equivalent to solving
$$ A\onebythree{r_1}{\dots}{r_d}^\intercal = \onebythree{y_1}{\dots}{y_d}^\intercal, $$
so $ \beta_j^* $, if it exists, is $ \beta_j^* = r_1\beta_1 + \dots + r_d\beta_d $ for $ r_1, \dots, r_d $ a solution to
$$ A\onebythree{r_1}{\dots}{r_d}^\intercal = \onebythree{0 \dots 0}{1}{0 \dots 0}^\intercal. $$

\pagebreak

So it suffices to show $ A $ is invertible. Suppose otherwise. Then there exists $ r_1, \dots, r_d $ not all zero, and
$$ A\onebythree{r_1}{\dots}{r_d}^\intercal = 0. $$
Then $ x = r_1\beta_1 + \dots + r_d\beta_d \in L^* $ is such that $ \Tr_{L / K} \beta_ix = 0 $ for all $ i $. If this is true, can write $ y \in L $ as $ b_1\beta_1 + \dots + b_d\beta_d $. Then $ \Tr_{L / K} xy = b_1\Tr_{L / K} \beta_1x + \dots + b_d\Tr_{L / K} \beta_dx = 0 $. So $ \Tr_{L / K} xy = 0 $ for all $ y \in L $. But $ x \ne 0 $. Setting $ y = x^{-1}z $, we find $ \Tr_{L / K} z = 0 $ for all $ z \in L $. But we assumed $ \Tr_{L / K} \ne 0 $.
\end{proof}

\begin{corollary}
$ M^* $ is a free $ R $-module of rank $ d $.
\end{corollary}

\begin{proof}
Claim that $ \beta_j^* \in M^* $ for all $ j $, and the $ \beta_j^* $ generate $ M^* $ as an $ R $-module. Every element of $ M $ can be written as $ r_1\beta_1 + \dots + r_d\beta_d $ for $ r_i \in R $, so $ \Tr_{L / K} \beta_j^*m = r_j \in R $. Let $ x \in M^* $. We can write $ x = r_1\beta_1^* + \dots + r_d\beta_d^* $ for $ r_i \in K $. Thus $ \Tr_{L / K} \beta_ix = r_i $, so $ r_i \in R $ for all $ i $.
\end{proof}

\begin{corollary}
$ S $ is a finitely generated $ R $-module.
\end{corollary}

\begin{proof}
$ S $ is an $ R $-submodule of the finitely generated $ R $-module $ M^* $, and, since $ R $ is Noetherian, $ S $ is therefore finitely generated as an $ R $-module.
\end{proof}

Thus $ S $ is Noetherian. Now it remains to prove that every nonzero prime ideal $ \ppp $ of $ S $ is maximal. Let $ \ppp $ be a nonzero prime ideal of $ S $, and let $ s $ be an element of $ \ppp $. Consider the intersection $ \qqq = \ppp \cap R $. Then $ \qqq $ is a prime ideal of $ R $. Claim that $ \qqq = \ppp \cap R $ is a nonzero prime ideal of $ R $. Let $ Q\br{X} $ be the minimal polynomial of $ s $ over $ K $, then $ s $ is integral, so $ Q\br{X} $ has coefficients in $ R $. If $ Q\br{X} = X^r + a_{r - 1}X^{r - 1} + \dots + a_0 $ for $ a_0 \ne 0 $, where $ Q\br{X} $ is irreducible, we then have $ 0 = Q\br{s} = a_0 + \dots + a_{r - 1}s^{r - 1} + s^r $, and thus lie in $ R $. Rewriting, we get $ -a_0 = s\br{a_1 + \dots + a_{r - 1}s^{r - 2} + s^{r - 1}} $. In particular $ -a_0 $ lies in the ideal generated by $ s $, and hence in $ \ppp $. Moreover, since $ Q\br{X} $ is irreducible, $ a_0 $ is a nonzero element of $ R $, so $ \qqq $ is nonzero since $ a_0 \in \qqq $. Since $ R $ is Dedekind, thus $ \qqq $ is a maximal ideal of $ R $. Have $ R \subseteq S \to S / \ppp $, where kernel is $ R / \qqq $, a field. So get $ R / \qqq \to S / \ppp $. The ring $ S / \ppp $ is an integral domain containing the field $ R / \qqq $. Moreover, since $ S $ is a finitely generated $ R $-module, if $ s_1, \dots, s_r $ generate $ S $ as an $ R $-module, then they generate $ S / \ppp $ as an $ R / \qqq $-module, so $ S / \ppp $ is a finitely generated $ R / \qqq $-module. That is, $ S / \ppp $ is a finite-dimensional $ R / \qqq $-vector space. We now show the following.

\begin{lemma}
\label{lem:12.3.7}
Let $ K $ be an integral domain and let $ R $ be an integral domain containing $ K $ that is finite-dimensional as an $ K $-vector space. Then $ R $ is a field.
\end{lemma}

\begin{proof}
Let $ r $ be a nonzero element of $ R $. Have map
$$ \function{K\sbr{X}}{R}{X}{r}. $$
Let $ I $ be the kernel. Since $ R $ is finite-dimensional, $ I \ne 0 $. Since $ R $ is an integral domain, $ I $ is prime. So
$$ \function{K\sbr{X} / I}{R}{X + I}{r} $$
is an injection, with $ K\sbr{X} / I $ a field. Then $ X $ has an inverse in $ K\sbr{X} / I $, and this inverse maps to a multiplicative inverse for $ r $ in $ R $.
\end{proof}

Lemma \ref{lem:12.3.7} shows that $ S / I $ is a field, so $ I $ is maximal. We have thus shown that $ S $ is Noetherian, integrally closed, and that every nonzero prime ideal in $ S $ is maximal, so $ S $ is indeed a Dedekind domain. In particular, for any finite extension $ K / \QQ $, the integral closure $ \OOO_K $ of $ \ZZ $ in $ K $ is a Dedekind domain, and thus has unique factorisation of ideals. Another class of examples comes by taking $ K $ a field, letting $ L $ be a finite extension of $ K\br{t} $ such that $ \Tr_{L / K\br{t}} $ is nonzero, and letting $ R $ be the integral closure of $ K\sbr{t} $ in $ L $. The field $ L $ is called a \textbf{function field}, and the ring $ R $ is the \textbf{ring of regular functions on a smooth affine algebraic curve}. Such rings $ R $ are also Dedekind domains, and they are of considerable interest in algebraic geometry. They of course also have the unique factorisation property for ideals, and just like in ring of integers one can consider the ideal class group. In this context, the ideal class group is also known as the \textbf{Picard group}. It has a geometric interpretation in terms of \textbf{line bundles} on algebraic curves. Unlike in the number field setting, the Picard group is often not a finite group.

\pagebreak

\section{Introduction to algebraic geometry}

\lecture{28}{Friday}{07/12/18}

The idea is
\begin{itemize}
\item to study ideals in polynomial rings by studying geometry of the common zeros in ideal, and
\item to study geometry of solutions to polynomial equations via ring theory.
\end{itemize}

\subsection{Algebraically closed fields}

Work best over algebraically closed fields.

\begin{definition}
Let $ K $ be a field. We say $ K $ is \textbf{algebraically closed} if every nonconstant polynomial $ P\br{X} \in K\sbr{X} $ factors into linear factors.
\end{definition}

In particular, the only irreducible polynomials are linear polynomials.

\begin{theorem}[Fundamental theorem of algebra]
The field $ \CC $ is algebraically closed.
\end{theorem}

We will not prove this in this course. Ultimately it requires some analysis. This is unsurprising, since the construction of $ \CC $ is fundamentally an analytic one. We have the following characterisation of algebraically closed fields.

\begin{example*}
\hfill
\begin{itemize}
\item By contrast, $ \QQ, \RR, \FF_{p^r}, \FF_p\br{t} $ are all not algebraically closed.
\item $ \overline{\QQ} $ is algebraically closed.
\end{itemize}
\end{example*}

\begin{lemma}
A field $ K $ is algebraically closed if and only if every field extension $ L / K $ is either trivial, that is $ L = K $, or transcendental.
\end{lemma}

\begin{proof}
Suppose $ K $ is algebraically closed. Let $ L / K $ be an algebraic extension, and $ \alpha \in L $. Let $ P\br{X} $ be the minimal polynomial of $ \alpha $ over $ K $. Then $ P\br{X} $ is irreducible, hence linear. But then $ \alpha \in K $, so $ L = K $. Conversely, if every field extension $ L / K $ is trivial or transcendental, then if $ P\br{X} $ is an irreducible polynomial in $ K\sbr{X} $ we must have $ K\sbr{X} / \abr{P\br{X}} = K $, so $ P\br{X} $ must have degree one. Since every polynomial in $ K\sbr{X} $ factors into irreducibles, $ K $ must be algebraically closed.
\end{proof}

\subsection{Affine algebraic sets}

Fix an algebraically closed field $ K $. In fact, it is harmless to take $ K = \CC $ throughout.

\begin{definition}
Let $ \AA_K^n $, the \textbf{affine $ n $-space} over $ K $, denote the set $ K^n $ of $ n $-tuples of elements of $ K $.
\end{definition}

For $ S $ an arbitrary collection of elements of $ K\sbr{X_1, \dots, X_n} $, we let $ \Z\br{S} $ denote the subset
$$ \Z\br{S} = \cbr{\br{x_1, \dots, x_n} \in \AA_K^n \st \forall P \in S, \ P\br{x_1, \dots, x_n} = 0} \subseteq \AA_K^n. $$
In other words, $ \Z\br{S} $ is the \textbf{set of common zeros} of all the polynomials in $ S $.

\begin{example*}
\hfill
\begin{itemize}
\item $ S = \cbr{y - x\br{x - 1}\br{x + 1}} $ is $ y = x\br{x - 1}\br{x + 1} $.
\item $ S = \cbr{y\br{y - x\br{x - 1}\br{x + 1}}} $ is $ y = 0 $ or $ y = x\br{x - 1}\br{x + 1} $.
\item $ S = \cbr{y, y - x\br{x - 1}\br{x + 1}} $ is $ y = 0 $ and $ y = x\br{x - 1}\br{x + 1} $.
\item $ S = \cbr{y^2 - x\br{x - 1}\br{x + 1}} $ is connected.
\end{itemize}
\end{example*}

\pagebreak

Note that we have the following.

\begin{lemma}
Let $ S $ be a subset of $ K\sbr{X_1, \dots, X_n} $ and let $ I $ be the ideal of $ K\sbr{X_1, \dots, X_n} $ generated by $ S $. Then $ \Z\br{I} = \Z\br{S} $.
\end{lemma}

\begin{proof}
Since $ S \subseteq I $, we have $ \Z\br{I} \subseteq \Z\br{S} $. On the other hand, let $ p = \br{x_1, \dots, x_n} \in \Z\br{S} $. Then for all $ P\br{X_1, \dots, X_n} \in S $, we have $ P\br{p} = 0 $. Any polynomial $ P\br{X_1, \dots, X_n} \in I $ can be expressed as $ P = Q_1S_1 + \dots + Q_rS_r $ for $ Q_i \in K\sbr{X_1, \dots, X_n} $ and $ S_i \in S $. But then we have $ P\br{p} = Q_1\br{p}S_1\br{p} + \dots + Q_r\br{p}S_r\br{p} = 0 $, since $ S_i\br{p} = 0 $ for all $ i $. Thus we have that $ p \in \Z\br{I} $.
\end{proof}

From this and the Hilbert basis theorem we deduce, $ K\sbr{X_1, \dots, X_n} $ is Noetherian and every ideal is finitely generated, so for any subset $ S $ of polynomials in $ K\sbr{X_1, \dots, X_n} $ there is a finite collection $ S' $ of polynomials such that $ \Z\br{S} = \Z\br{S'} $. Just let $ S' $ be a generating set for the ideal generated by $ S $.

\begin{definition}
A subset $ T $ of $ \AA_K^n $ is called an \textbf{affine algebraic set} if $ T $ is for the form $ \Z\br{I} $ for some ideal $ I $ of $ K\sbr{X_1, \dots, X_n} $.
\end{definition}

Conversely, subsets of $ \AA_K^n $ define ideals of $ K\sbr{X_1, \dots, X_n} $. For $ T \subseteq \AA_K^n $, let $ \I\br{T} $ denote the ideal
$$ \I\br{T} = \cbr{P\br{X_1, \dots, X_n} \in K\sbr{X_1, \dots, X_n} \st \forall t \in T, \ P\br{t} = 0} \subseteq K. $$
Claim that $ \I\br{T} $ is an ideal. If $ P\br{t} = 0 $ and $ Q\br{t} = 0 $ for all $ t \in T $, then $ P\br{t} + Q\br{t} = 0 $ and $ R\br{t}P\br{t} = 0 $ for $ t \in T $ and $ R\br{X_1, \dots, X_n} \in K\sbr{X_1, \dots, X_n} $.

\begin{note*}
The operations $ T \mapsto \I\br{T} $ and $ I \mapsto \Z\br{I} $ are both inclusion-reversing.
\begin{itemize}
\item If $ T \subseteq T' \subseteq \AA_K^n $ then $ \I\br{T} \supseteq \I\br{T'} $.
\item If $ J \subseteq J' \subseteq K\sbr{X_1, \dots, X_n} $ then $ \Z\br{J} \supseteq \Z\br{J'} $.
\end{itemize}
\end{note*}

We have the following.

\begin{lemma}
Let $ X $ be an affine algebraic set. Then $ \Z\br{\I\br{X}} = X $.
\end{lemma}

\begin{proof}
First observe that certainly any element of $ \I\br{X} $ vanishes at all points of $ X $, so $ X \subseteq \Z\br{\I\br{X}} $. On the other hand, since $ X $ is an affine algebraic set, $ X = \Z\br{J} $ for some ideal $ J $. Want $ \Z\br{\I\br{X}} \subseteq X $, that is $ \Z\br{\I\br{\Z\br{J}}} \subseteq \Z\br{J} $. Since any $ P \in J $ vanishes on $ X $ we have $ J \subseteq \I\br{\Z\br{J}} $. Then $ \Z\br{\I\br{X}} \subseteq \Z\br{J} = X $, so $ X = \Z\br{\I\br{X}} $.
\end{proof}

This need not be equal for $ X $ arbitrary. If $ X $ is not an affine algebraic set, then $ \Z\br{\I\br{X}} $ is the smallest affine algebraic set containing $ X $. If $ Y = \Z\br{J} $ contains $ X $, then $ \I\br{Y} \subseteq \I\br{X} $, so $ \Z\br{\I\br{X}} \subseteq \Z\br{\I\br{Y}} = Y $. We call $ \Z\br{\I\br{X}} $ the \textbf{Zariski closure} of $ X $. This operation is the closure operation for a topology on $ \AA_K^n $ called the \textbf{Zariski topology} which we will define later.

\begin{example*}
Let
$$ X = \cbr{\br{n, 0} \st n \in \ZZ} \subseteq \AA_\CC^2, \qquad \I\br{X} = \cbr{P \in \CC\sbr{X, Y} \st \forall n \in \ZZ, \ P\br{n, 0} = 0}. $$
Then $ P\br{X, 0} \in \CC\sbr{X} $ is a polynomial that vanishes at every $ n \in \ZZ $, so $ P\br{X, 0} = 0 $. So $ Y \mid P\br{X, Y} $, so $ \I\br{X} = \abr{Y} $. Thus $ \Z\br{\I\br{X}} $ is the $ Y $-axis.
\end{example*}

One might thus hope that similarly $ \I\br{\Z\br{J}} = J $ for any ideal $ J $ of $ K\sbr{X_1, \dots, X_n} $. This cannot be literally true, for the following reason. Recall that
$$ \rad I = \cbr{r \in K\sbr{X_1, \dots, X_n} \st \exists m, \ r^m \in I}. $$
An ideal $ I $ is \textbf{radical} if $ \rad I = I $.

\begin{note*}
In fact, for any $ T $, the ideal $ \I\br{T} $ is a radical ideal, since
$$ P^m \in \I\br{T} \qquad \iff \qquad \forall t \in T, \ P\br{t}^m = 0 \qquad \iff \qquad \forall t \in T, \ P\br{t} = 0 \qquad \iff \qquad P \in \I\br{T}. $$
Thus if $ J $ is not a radical ideal we cannot have $ \I\br{\Z\br{J}} = J $.
\end{note*}

\pagebreak

However, one does have the following.

\begin{theorem}[Hilbert's Nullstellensatz]
\label{thm:13.2.5}
Let $ K $ be an algebraically closed field. For any ideal $ J $ of $ K\sbr{X_1, \dots, X_n} $, we have $ \I\br{\Z\br{J}} = \rad J $.
\end{theorem}

\begin{note*}
This can only possibly hold over algebraically closed fields.
\end{note*}

\begin{example*}
For $ n = 1 $, let $ P\br{X} \in K\sbr{X} $. Then $ \I\br{\Z\br{P\br{X}}} = \rad P\br{X} \ne R $, unless $ P\br{X} $ is constant, so $ \Z\br{P\br{X}} \ne \emptyset $.
\end{example*}

\begin{corollary}
If $ J \in K\sbr{X_1, \dots, X_n} $ an ideal is not the unit ideal, then $ \Z\br{J} \ne \emptyset $.
\end{corollary}

\begin{proof}
$ \I\br{\Z\br{J}} = \rad J \ne \abr{1} $, so $ \Z\br{J} \ne \emptyset $.
\end{proof}

\lecture{29}{Monday}{10/12/18}

We will prove this theorem later on. For now, we note that since $ \rad \rad J = \rad J $ for all ideals $ J $, the maps $ X \mapsto \I\br{X} $ and $ J \mapsto \Z\br{J} $ define a bijection
$$ \correspondence{\text{radical ideals} \ J \subseteq K\sbr{X_1, \dots, X_n}}{\text{affine algebraic subsets of} \ \AA_K^n}. $$
This bijection is inclusion-reversing, and it is interesting to ask what geometric properties of $ X $ are carried to algebraic properties of $ \I\br{X} $ via this bijection. For instance, the following holds.

\begin{proposition}
Let $ J \subseteq K\sbr{X_1, \dots, X_n} $ be a radical ideal. Then $ J $ is maximal if and only if $ \Z\br{J} $ is a single point.
\end{proposition}

\begin{proof}
Suppose $ \Z\br{J} = \cbr{p} $, where $ p = \br{p_1, \dots, p_n} $. Then $ \I\br{\Z\br{J}} = \I\br{\cbr{p}} $, so $ X_1 - p_1, \dots, X_n - p_n \in \I\br{\cbr{p}} $. Then $ \mmm_p = \abr{X_1 - p_1, \dots, X_n - p_n} \subseteq \I\br{\cbr{p}} \subsetneq K\sbr{X_1, \dots, X_n} $. Note that $ \mmm_p $ is maximal. Consider the map
$$ \function{K\sbr{X_1, \dots, X_n}}{K}{X_i}{p_i}, $$
and $ K \mapsto K $. The kernel of this map is $ \abr{X_i - p_i} = \mmm_p $, so $ K\sbr{X_1, \dots, X_n} / \mmm_p \cong K $. So $ \mmm_p $ is maximal, must have $ \I\br{\cbr{p}} = \mmm_p $. Thus $ J = \rad J = \I\br{\Z\br{J}} = \mmm_p $. Conversely, suppose $ J $ is maximal. Then $ \Z\br{J} \ne \emptyset $, since $ \I\br{\Z\br{J}} = J $ but $ \I\br{\emptyset} $ is the unit ideal. So there exists $ p \in \Z\br{J} $ such that $ J = \I\br{\Z\br{J}} \subseteq \I\br{\cbr{p}} = \mmm_p $, so $ J = \mmm_p $.
\end{proof}

\begin{proposition}
Let $ J_1, J_2 \subseteq K\sbr{X_1, \dots, X_n} $ be ideals. Then
$$ \Z\br{J_1 + J_2} = \Z\br{J_1} \cap \Z\br{J_2}, \qquad \Z\br{J_1 \cap J_2} = \Z\br{J_1} \cup \Z\br{J_2}. $$
\end{proposition}

\begin{proof}
Let $ p \in \AA_K^n $ be a point of $ \Z\br{J_1 + J_2} $. Then every element of $ J_1 + J_2 $ vanishes at $ p $, so since $ J_1 \subseteq J_1 + J_2 $ we have that $ p \in \Z\br{J_1} $. Similarly $ p \in \Z\br{J_2} $, so $ \Z\br{J_1 + J_2} \subseteq \Z\br{J_1} \cap \Z\br{J_2} $. Conversely, if $ p \in \Z\br{J_1} \cap \Z\br{J_2} $, then for any element $ Q $ of $ J_1 + J_2 $ we can write $ Q = R + S $ for $ R \in J_1 $ and $ S \in J_2 $. Then $ R\br{p} = S\br{p} = 0 $, so $ Q\br{p} = 0 $ and $ p \in \Z\br{J_1 + J_2} $. The proof that $ \Z\br{J_1 \cap J_2} = \Z\br{J_1} \cup \Z\br{J_2} $ is similar, and will be omitted.
\end{proof}

\begin{corollary}
Conversely, if $ X $ and $ Y $ are affine algebraic sets, then
$$ \I\br{X \cap Y} = \rad \br{\I\br{X} + \I\br{Y}}, \qquad \I\br{X \cup Y} = \I\br{X} \cap \I\br{Y}. $$
\end{corollary}

\begin{proof}
Follows from $ \Z\br{J_1 + J_2} = \Z\br{J_1} \cap \Z\br{J_1} $ and using the Nullstellensatz $ \I\br{\Z\br{J}} = \rad J $.
\end{proof}

\begin{definition}
An affine algebraic set $ X $ is \textbf{irreducible} if $ X $ cannot be written as the union $ Y \cup Z $ of two proper affine algebraic subsets $ Y $ and $ Z $, that is $ Y, Z \ne X, \emptyset $.
\end{definition}

\begin{example*}
Let
$$ X = \Z\br{\cbr{y\br{y - x\br{x - 1}\br{x + 1}}}}. $$
Then
$$ X = \Z\br{\cbr{y}} \cup \Z\br{\cbr{y - x\br{x - 1}\br{x + 1}}}, $$
so $ X $ is not irreducible.
\end{example*}

\pagebreak

\begin{proposition}
An affine algebraic set $ X $ is irreducible if and only if $ \I\br{X} $ is prime.
\end{proposition}

\begin{proof}
Suppose $ X $ is irreducible, and let $ f $ and $ g $ be elements of $ K\sbr{X_1, \dots, X_n} $ such that $ fg \in \I\br{X} $. Then $ X \subseteq \Z\br{fg} = \Z\br{f} \cap \Z\br{g} $. In particular $ X = \br{X \cap \Z\br{f}} \cup \br{X \cap \Z\br{g}} $. Since $ X $ is irreducible we must have $ X = X \cap \Z\br{f} \subseteq \Z\br{f} $, in which case $ f \in \I\br{X} $, or $ X = X \cap \Z\br{g} \subseteq \Z\br{g} $, in which case $ g \in \I\br{X} $. So $ \I\br{X} $ is prime. Conversely, suppose $ \I\br{X} $ is prime, and that $ X = Y \cup Z $, where $ Y $ and $ Z $ are affine algebraic subsets of $ X $. Then $ \I\br{X} = \I\br{Y} \cap \I\br{Z} $, so $ \I\br{X} $ contains the product $ \I\br{Y}\I\br{Z} $. Since $ \I\br{X} $ is prime, either $ \I\br{X} $ contains $ \I\br{Y} $, in which case $ X = Y $, or $ \I\br{X} $ contains $ \I\br{Z} $, in which case $ X = Z $.
\end{proof}

\begin{definition}
An affine algebraic set $ X $ has \textbf{Krull dimension} $ d $ if $ d $ is the length of the largest increasing tower of irreducible affine algebraic subsets $ X_0 \subsetneq \dots \subsetneq X_d \subseteq X $.
\end{definition}

\begin{example*}
\hfill
\begin{itemize}
\item Points have dimension zero.
\item In $ \AA^1 $, affine algebraic sets are zeros of polynomials, so irreducibles in $ \AA^1 $ are points on $ \AA^1 $, so $ \AA^1 $ has Krull dimension one.
\item In fact, $ \AA^n $ has Krull dimension $ n $ for every $ n $.
\end{itemize}
\end{example*}

\begin{definition}
A ring $ R $ has \textbf{Krull dimension} $ d $ if $ d $ is the length of the largest increasing tower $ \ppp_0 \subsetneq \dots \subsetneq \ppp_d $ of prime ideals of $ R $.
\end{definition}

\begin{example*}
If $ R $ is a domain,
\begin{itemize}
\item dimension zero implies that $ R $ is a field, and
\item dimension one implies that every nonzero prime ideal is maximal.
\end{itemize}
\end{example*}

The Hilbert basis theorem then gives us the following.

\begin{proposition}
Let $ X $ be an affine algebraic set. Then $ X $ can be written uniquely as a finite union $ X_1 \cup \dots \cup X_r $ such that each $ X_i $ is an irreducible affine algebraic set and no $ X_i $ is contained in $ X_j $ for $ i \ne j $.
\end{proposition}

\begin{proof}
We first show that if $ X $ is not irreducible, then $ X $ can be written as $ Y \cup Z $ with $ Y $ irreducible and $ Z \ne X $ affine algebraic. Certainly we can write $ X = Y_1 \cup Z_1 $ with $ Y_1 $ and $ Z_1 $ proper subsets of $ X $. If $ Y_1 $ is irreducible we are done. Otherwise write $ Y_1 = Y_2 \cup Z_2 $. Again, if $ Y_2 $ is irreducible we can write $ X = Y_2 \cup \br{Z_1 \cup Z_2} $ and we are done. Otherwise, supposing this never terminates, we obtain
$$ Y_1 \supsetneq Y_2 \supsetneq \dots, \qquad \I\br{Y_1} \subsetneq \I\br{Y_2} \subsetneq \dots, $$
which is impossible since $ K\sbr{X_1, \dots, X_n} $ is Noetherian. Now given $ X $, if $ X $ is not irreducible we can write $ X = Y_1 \cup Z_1 $ with $ Y_1 $ irreducible and $ Z_1 \ne X $. If $ Z_1 $ is not irreducible we write $ Z_1 = Y_2 \cup Z_2 $ with $ Y_2 $ irreducible and $ Z_2 \ne Z_1 $. If this process ever terminates we have written $ X $ as a finite union of irreducibles. Otherwise, we have
$$ Z_1 \supsetneq Z_2 \supsetneq \dots, $$
and as above this is impossible since $ K\sbr{X_1, \dots, X_n} $ is Noetherian. For uniqueness, suppose we have $ X = Y_1 \cup \dots \cup Y_r $ and $ X = Z_1 \cup \dots \cup Z_s $, with the $ Y_i $ and $ Z_j $ irreducible, and with no $ Y_i $, or $ Z_i $, contained in $ Y_j $, or $ Z_j $, when $ i \ne j $. Then $ \I\br{Y_i} $ and $ \I\br{Z_i} $ are prime for all $ i $. In particular $ \I\br{Y_1} $ is prime. Since $ Y_1 \subset X $, $ \I\br{X} \subset \I\br{Y_1} $, so $ \I\br{Y_1} $ contains $ \I\br{Z_1 \cup \dots \cup Z_s} = \I\br{Z_1} \cap \dots \cap \I\br{Z_s} $. It follows that $ \I\br{Y_1} $ contains the product $ \I\br{Z_1} \dots \I\br{Z_s} $. Thus $ \I\br{Y_1} $ contains $ \I\br{Z_j} $ for some $ j $. Similarly $ \I\br{Z_j} $ contains $ \I\br{Y_i} $ for some $ i $. Then $ \I\br{Y_1} \subseteq \I\br{Y_i} $, so $ Y_i \subseteq Y_1 $ and we must have $ i = 1 $. Then $ Y_1 = Z_j $. Proceeding we show that each $ Y_i $ is equal to some $ Z_j $ and vice versa, proving uniqueness.
\end{proof}

Translating this to a statement about ideals, we find the following.

\begin{corollary}
Every radical ideal in $ K\sbr{X_1, \dots, X_n} $ is uniquely expressible as a finite intersection of prime ideals, none of which contains any of the others.
\end{corollary}

This is a special case of a very general ring-theoretic phenomenon known as \textbf{primary decomposition}, which was discovered via the sort of geometric considerations we see above.

\lecture{30}{Wednesday}{12/12/18}

Lecture 30 is a problems class.

\pagebreak

\appendix

\section{Proof of the Nullstellensatz}

The ideas above rely heavily on the correspondence between radical ideals and affine algebraic sets, and thus ultimately on the Nullstellensatz. We now give a proof of the Nullstellensatz. The first step is to show that to prove the Nullstellensatz it suffices to prove the following, seemingly much weaker, special case, the so-called weak Nullstellensatz.

\begin{theorem}[Weak Nullstellensatz]
\label{thm:13.3.1}
Let $ I $ be an ideal of $ K\sbr{X_1, \dots, X_n} $ such that $ \Z\br{I} $ is empty. Then $ I $ is the unit ideal.
\end{theorem}

\begin{proof}[Proof of Theorem \ref{thm:13.2.5}]
Let $ J $ be an ideal of $ K\sbr{X_1, \dots, X_n} $. Clearly $ \I\br{\Z\br{J}} $ contains $ \rad J $. We must show the reverse containment. Let $ P $ be an element of $ \I\br{\Z\br{J}} $. We must show that $ P^m $ lies in $ J $ for some $ m $. Consider the ring $ K\sbr{X_1, \dots, X_n, T} $, and let $ \widetilde{J} $ be the ideal of $ K\sbr{X_1, \dots, X_n, T} $ generated by the polynomials in $ I $, together with the polynomial $ 1 - TP\br{X_1, \dots, X_n} $. Consider the subset
$$ \Z\br{\widetilde{J}} = \cbr{\br{x_1, \dots, x_n, t} \in K^{n + 1} \st \forall Q \in J, \ Q\br{x_1, \dots, x_n} = 0, \ 1 - tP\br{x_1, \dots, x_n} = 0} \subseteq \AA_K^{n + 1}. $$
In particular if $ \br{x_1, \dots, x_n, t} $ lies in $ \Z\br{\widetilde{J}} $, then $ \br{x_1, \dots, x_n} $ lies in $ \Z\br{J} $. Since $ P \in \I\br{\Z\br{J}} $ we have $ P\br{x_1, \dots, x_n} = 0 $, so $ 1 - tP\br{x_1, \dots, x_n} = 1 $. Thus $ \Z\br{\widetilde{J}} $ is empty. By the weak Nullstellensatz, $ \widetilde{J} $ is the unit ideal, so there are polynomials $ Q_0, \dots, Q_s $ in $ K\sbr{X_1, \dots, X_n, T} $, and $ R_1, \dots, R_s \in I $, such that $ 1 = Q_0\br{1 - TP} + Q_1R_1 + \dots + Q_sR_s $. Consider the map
$$ \function{K\sbr{X_1, \dots, X_n, T}}{K\sbr{X_1, \dots, X_n, \tfrac{1}{P}}}{T}{\tfrac{1}{P}}, $$
and $ K\sbr{X_1, \dots, X_n} \mapsto K\sbr{X_1, \dots, X_n} $. Applying this map we find that
$$ 1 = Q_1\br{X_1, \dots, X_n, \tfrac{1}{P}}R_1\br{X_1, \dots, X_n} + \dots + Q_s\br{X_1, \dots, X_n, \tfrac{1}{P}}R_s\br{X_1, \dots, X_n}, $$
in $ K\sbr{X_1, \dots, X_n, \tfrac{1}{P}} $. Multiplying by a sufficiently large power of $ P $, we get
$$ P^m = P^mQ_1\br{X_1, \dots, X_n, \tfrac{1}{P}}R_1\br{X_1, \dots, X_n} + \dots + P^mQ_s\br{X_1, \dots, X_n, \tfrac{1}{P}}R_s\br{X_1, \dots, X_n}. $$
Since for $ m $ sufficiently large $ P^mQ_s\br{X_1, \dots, X_n, \tfrac{1}{P}} $ is a polynomial in the $ X_i $ we find that $ P^m \in I $ for $ m $ sufficiently large.
\end{proof}

It remains to prove the weak Nullstellensatz. This requires some new ideas. The following approach is due to Emmy Noether.

\begin{definition}
Let $ R $ be a $ K $-algebra, that is a ring together with a map $ K \to R $. We say that elements $ y_1, \dots, y_s $ of $ R $ are \textbf{algebraically independent} over $ K $ if there is no nonzero polynomial $ P\br{X_1, \dots, X_s} \in K\sbr{X_1, \dots, X_s} $ such that $ P\br{y_1, \dots, y_s} = 0 $. Equivalently, $ y_1, \dots, y_s $ are algebraically independent if and only if the map
$$ \function{K\sbr{X_1, \dots, X_s}}{R}{X_i}{y_i} $$
is injective.
\end{definition}

\begin{proposition}[Noether's normalisation lemma]
Let $ K $ be a field, and let $ R $ be a finitely generated $ K $-algebra. Then there exists $ s \in \ZZ_{\ge 0} $, and algebraically independent elements $ y_1, \dots, y_s $ of $ R $ such that $ R $ is integral over $ K\sbr{y_1, \dots, y_s} $.
\end{proposition}

\pagebreak

\begin{proof}
Write $ R = K\sbr{X_1, \dots, X_m} / I $. We proceed by induction on $ m $. The base case $ m = 0 $ is clear. Fix $ m $ and assume the claim is true for $ m - 1 $. If $ I = 0 $ then the statement is also clear, with $ y_i = X_i $ for all $ i $. Otherwise let $ P\br{X_1, \dots, X_m} \in I $. Renumbering the variables if necessary, we may assume $ P $ is a nonconstant polynomial in $ X_m $ with coefficients in $ X_1, \dots, X_{m - 1} $. Let $ d $ be the total degree of $ P $. That is, the largest value of $ a_1 + \dots + a_m $ for any monomial $ cX_1^{a_1} \dots X_m^{a_m} $ appearing in $ P $. Let $ n_i = \br{1 + d}^i $ and $ Y_i = X_i - X_m^{n_i} $ for each $ i $ in $ 1, \dots, m - 1 $. Define
$$ Q\br{X_1, \dots, X_m} = P\br{X_1 + X_m^{n_1}, \dots, X_{m - 1} + X_m^{n_{m - 1}}, X_m}. $$
Then $ Q\br{Y_1, \dots, Y_{m - 1}, X_m} $ is zero in $ R $. We now claim that, up to a factor $ c \in K^* $, $ Q\br{X_1, \dots, X_m} $ is monic when considered as a polynomial in $ X_m $. Let $ cX_1^{a_1} \dots X_m^{a_m} $ be a monomial appearing in $ P\br{X_1, \dots, X_m} $. This monomial contributes the terms
$$ c\br{X_1 - X_m^{n_1}}^{a_1} \dots \br{X_{m - 1} - X_m^{n_{m - 1}}}^{a_{m - 1}}X_m^{a_m} $$
to $ Q\br{X_1, \dots, X_m} $. Moreover, each $ n_i $ is greater than $ d $ and hence greater than the sum of the $ a_j $. It is thus clear that the term of highest degree in the above expression is $ cX_m^N $, where
$$ N = n_1a_1 + \dots + n_{m - 1}a_{m - 1} + a_m = a_1\br{1 + d} + \dots + a_{m - 1}\br{1 + d}^{m - 1} + a_m. $$
Since $ 1 + d $ is greater than the sum of the exponents $ a $ appearing in any monomial of $ P\br{X_1, \dots, X_m} $, the terms $ cX_m^N $ appearing in different monomials are all of different degree and thus cannot cancel. It follows that the term of the form $ cX_m^N $ of highest degree is the highest degree term in $ Q\br{X_1, \dots, X_m} $, so that $ \br{1 / c}Q\br{X_1, \dots, X_m} $ is monic in $ X_m $. Write
$$ \dfrac{1}{c}Q\br{X_1, \dots, X_m} = \sum_{n = 0}^N H_n\br{X_1, \dots, X_{m - 1}}X_m^n. $$
Since $ Q\br{Y_1, \dots, Y_{m - 1}, X_m} = 0 $, we have $ \sum_{n = 0}^N H_n\br{Y_1, \dots, Y_{m - 1}}X_m = 0 $. That is, $ X_m $ is integral over the subalgebra $ S = K\sbr{Y_1, \dots, Y_{m - 1}} $ of $ R $. Since $ X_m $ generates $ R $ over $ S $, it follows that $ R $ is integral over $ S $. On the other hand we have a map
$$ \function{K\sbr{Z_1, \dots, Z_{m - 1}}}{S}{Z_i}{Y_i}. $$
Let $ J $ be the kernel. Then $ S = K\sbr{Z_1, \dots, Z_{m - 1}} / J $. Then by the inductive hypothesis there are algebraically independent elements $ y_1, \dots, y_s \in S $ such that $ S $ is integral over $ K\sbr{y_1, \dots, y_s} $. Since $ R $ is integral over $ S $, it follows that $ R $ is integral over $ K\sbr{y_1, \dots, y_s} $ and we are done.
\end{proof}

\begin{corollary}
Every maximal ideal of $ K\sbr{X_1, \dots, X_n} $ is of the form
$$ \abr{X_1 - p_1, \dots, X_n - p_n}, \qquad p_1, \dots, p_n \in K. $$
\end{corollary}

\begin{proof}
Let $ I $ be a maximal ideal of $ K\sbr{X_1, \dots, X_n} $, and consider $ R = K\sbr{X_1, \dots, X_n} / I $. Then $ R $ is a field. On the other hand, by Noether normalisation, there exist $ y_1, \dots, y_s $ algebraically independent such that $ R $ is integral over $ S = K\sbr{y_1, \dots, y_s} $. Let $ x $ be a nonzero element of $ K\sbr{y_1, \dots, y_s} $. Then $ x^{-1} $ lies in $ R $. Since $ R $ is integral over $ S $ there is a monic polynomial $ P $ with coefficients in $ S $ such that $ P\br{x^{-1}} = 0 $. We thus have $ \br{x^{-1}}^d = \sum_{i = 0}^{d - 1} a_ix^{-i} $ for $ a_i \in S $. Multiplying by $ x^{d - 1} $ we find that $ x^{-1} = \sum_{i = 0}^{d - 1} a_ix^{d - i - 1} $, so that $ x^{-1} $ is also in $ S $. Thus $ S $ is a field. But since the $ y_i $ are algebraically independent, $ S $ is also a polynomial ring in $ s $ variables. Since no such ring is a field unless $ s = 0 $ we must have $ s = 0 $ and $ R $ is integral over $ K $. But then $ R $ is a finite-dimensional $ K $-vector space, hence a finite extension of $ K $. Since $ K $ is algebraically closed, the inclusion of $ K $ in $ R $ is an isomorphism. Thus for each $ i $ there is an element $ p_i $ of $ K $ such that $ X_i $ is equal to $ p_i $ in $ R $. Then $ X_i - p_i $ is in $ I $ for all $ i $, so $ I $ contains the ideal $ \abr{X_1 - p_1, \dots, X_n - p_n} $. Since the latter is clearly maximal it must be equal to $ I $.
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:13.3.1}]
Let $ I $ be an ideal of $ K\sbr{X_1, \dots, X_n} $ such that $ I $ is not the unit ideal. Then $ I $ is contained in some maximal ideal of $ K\sbr{X_1, \dots, X_n} $, and thus in some ideal of the form $ \abr{X_1 - p_1, \dots, X_n - p_n} $. Then $ \br{p_1, \dots, p_n} $ lies in $ \Z\br{I} $.
\end{proof}

\end{document}